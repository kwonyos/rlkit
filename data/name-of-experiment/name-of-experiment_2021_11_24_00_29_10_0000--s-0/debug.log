2021-11-24 00:29:21.807868 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 0 finished
---------------------------------------  --------------
epoch                                       0
replay_buffer/size                       2000
trainer/num train calls                  1000
trainer/QF1 Loss                           14.8842
trainer/QF2 Loss                           14.9102
trainer/Policy Loss                        -3.99178
trainer/Q1 Predictions Mean                 0.00192927
trainer/Q1 Predictions Std                  0.00319399
trainer/Q1 Predictions Max                  0.0127982
trainer/Q1 Predictions Min                 -0.0047903
trainer/Q2 Predictions Mean                -0.00141737
trainer/Q2 Predictions Std                  0.00291433
trainer/Q2 Predictions Max                  0.00572764
trainer/Q2 Predictions Min                 -0.0105763
trainer/Q Targets Mean                      3.76611
trainer/Q Targets Std                       0.845918
trainer/Q Targets Max                       5.72725
trainer/Q Targets Min                       1.48241
trainer/Log Pis Mean                       -3.994
trainer/Log Pis Std                         0.503254
trainer/Log Pis Max                        -2.82484
trainer/Log Pis Min                        -5.08328
trainer/policy/mean Mean                    0.000223999
trainer/policy/mean Std                     0.00172377
trainer/policy/mean Max                     0.00652745
trainer/policy/mean Min                    -0.00452474
trainer/policy/normal/std Mean              0.9995
trainer/policy/normal/std Std               0.00143031
trainer/policy/normal/std Max               1.004
trainer/policy/normal/std Min               0.99385
trainer/policy/normal/log_std Mean         -0.000501434
trainer/policy/normal/log_std Std           0.0014313
trainer/policy/normal/log_std Max           0.00399221
trainer/policy/normal/log_std Min          -0.00616888
trainer/Alpha                               1
trainer/Alpha Loss                         -0
expl/num steps total                     2000
expl/num paths total                        2
expl/path length Mean                    1000
expl/path length Std                        0
expl/path length Max                     1000
expl/path length Min                     1000
expl/Rewards Mean                          -0.234427
expl/Rewards Std                            0.704176
expl/Rewards Max                            1.87123
expl/Rewards Min                           -2.59408
expl/Returns Mean                        -234.427
expl/Returns Std                            0
expl/Returns Max                         -234.427
expl/Returns Min                         -234.427
expl/Actions Mean                          -0.000712404
expl/Actions Std                            0.629975
expl/Actions Max                            0.998367
expl/Actions Min                           -0.999637
expl/Num Paths                              1
expl/Average Returns                     -234.427
expl/env_infos/final/reward_run Mean        1.14641
expl/env_infos/final/reward_run Std         0
expl/env_infos/final/reward_run Max         1.14641
expl/env_infos/final/reward_run Min         1.14641
expl/env_infos/initial/reward_run Mean     -0.388296
expl/env_infos/initial/reward_run Std       0
expl/env_infos/initial/reward_run Max      -0.388296
expl/env_infos/initial/reward_run Min      -0.388296
expl/env_infos/reward_run Mean              0.00369444
expl/env_infos/reward_run Std               0.702931
expl/env_infos/reward_run Max               2.10336
expl/env_infos/reward_run Min              -2.34833
expl/env_infos/final/reward_ctrl Mean      -0.339585
expl/env_infos/final/reward_ctrl Std        0
expl/env_infos/final/reward_ctrl Max       -0.339585
expl/env_infos/final/reward_ctrl Min       -0.339585
expl/env_infos/initial/reward_ctrl Mean    -0.232131
expl/env_infos/initial/reward_ctrl Std      0
expl/env_infos/initial/reward_ctrl Max     -0.232131
expl/env_infos/initial/reward_ctrl Min     -0.232131
expl/env_infos/reward_ctrl Mean            -0.238121
expl/env_infos/reward_ctrl Std              0.075283
expl/env_infos/reward_ctrl Max             -0.0252589
expl/env_infos/reward_ctrl Min             -0.532016
eval/num steps total                     5000
eval/num paths total                        5
eval/path length Mean                    1000
eval/path length Std                        0
eval/path length Max                     1000
eval/path length Min                     1000
eval/Rewards Mean                          -0.000235283
eval/Rewards Std                            0.0149038
eval/Rewards Max                            0.221085
eval/Rewards Min                           -0.386611
eval/Returns Mean                          -0.235283
eval/Returns Std                            0.513491
eval/Returns Max                            0.408614
eval/Returns Min                           -0.977656
eval/Actions Mean                          -5.74137e-06
eval/Actions Std                            2.63163e-05
eval/Actions Max                            0.000698977
eval/Actions Min                           -0.00076702
eval/Num Paths                              5
eval/Average Returns                       -0.235283
eval/env_infos/final/reward_run Mean        0
eval/env_infos/final/reward_run Std         0
eval/env_infos/final/reward_run Max         0
eval/env_infos/final/reward_run Min         0
eval/env_infos/initial/reward_run Mean      0.0669917
eval/env_infos/initial/reward_run Std       0.106881
eval/env_infos/initial/reward_run Max       0.186919
eval/env_infos/initial/reward_run Min      -0.0685558
eval/env_infos/reward_run Mean             -0.000235283
eval/env_infos/reward_run Std               0.0149038
eval/env_infos/reward_run Max               0.221085
eval/env_infos/reward_run Min              -0.386611
eval/env_infos/final/reward_ctrl Mean      -2.33405e-10
eval/env_infos/final/reward_ctrl Std        0
eval/env_infos/final/reward_ctrl Max       -2.33405e-10
eval/env_infos/final/reward_ctrl Min       -2.33405e-10
eval/env_infos/initial/reward_ctrl Mean    -9.64855e-10
eval/env_infos/initial/reward_ctrl Std      7.63952e-10
eval/env_infos/initial/reward_ctrl Max     -3.56896e-10
eval/env_infos/initial/reward_ctrl Min     -2.46991e-09
eval/env_infos/reward_ctrl Mean            -4.3514e-10
eval/env_infos/reward_ctrl Std              3.46497e-09
eval/env_infos/reward_ctrl Max             -1.89566e-10
eval/env_infos/reward_ctrl Min             -1.49969e-07
time/data storing (s)                       0.00473654
time/evaluation sampling (s)                2.88691
time/exploration sampling (s)               0.536168
time/logging (s)                            0.0138134
time/sac training (s)                       7.75213
time/saving (s)                             0.00470139
time/training (s)                           3.96339e-05
time/epoch (s)                             11.1985
time/total (s)                             11.6198
Epoch                                       0
---------------------------------------  --------------
2021-11-24 00:29:32.635664 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 1 finished
---------------------------------------  ---------------
epoch                                        1
replay_buffer/size                        3000
trainer/num train calls                   2000
trainer/QF1 Loss                             0.444655
trainer/QF2 Loss                             0.466198
trainer/Policy Loss                        -15.3142
trainer/Q1 Predictions Mean                 12.405
trainer/Q1 Predictions Std                   1.23452
trainer/Q1 Predictions Max                  17.1647
trainer/Q1 Predictions Min                   9.25156
trainer/Q2 Predictions Mean                 12.3772
trainer/Q2 Predictions Std                   1.23985
trainer/Q2 Predictions Max                  17.383
trainer/Q2 Predictions Min                   9.48847
trainer/Q Targets Mean                      12.3817
trainer/Q Targets Std                        1.40722
trainer/Q Targets Max                       16.8713
trainer/Q Targets Min                        8.74226
trainer/Log Pis Mean                        -4.04053
trainer/Log Pis Std                          0.565873
trainer/Log Pis Max                         -2.05647
trainer/Log Pis Min                         -6.01011
trainer/policy/mean Mean                     0.0372209
trainer/policy/mean Std                      0.137088
trainer/policy/mean Max                      0.553406
trainer/policy/mean Min                     -0.280396
trainer/policy/normal/std Mean               0.927666
trainer/policy/normal/std Std                0.0220298
trainer/policy/normal/std Max                0.983679
trainer/policy/normal/std Min                0.842603
trainer/policy/normal/log_std Mean          -0.0753654
trainer/policy/normal/log_std Std            0.023736
trainer/policy/normal/log_std Max           -0.0164559
trainer/policy/normal/log_std Min           -0.17126
trainer/Alpha                                0.74194
trainer/Alpha Loss                          -2.99697
expl/num steps total                      3000
expl/num paths total                         3
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.192048
expl/Rewards Std                             0.603456
expl/Rewards Max                             1.49827
expl/Rewards Min                            -2.58602
expl/Returns Mean                         -192.048
expl/Returns Std                             0
expl/Returns Max                          -192.048
expl/Returns Min                          -192.048
expl/Actions Mean                            0.0149515
expl/Actions Std                             0.610068
expl/Actions Max                             0.99794
expl/Actions Min                            -0.995928
expl/Num Paths                               1
expl/Average Returns                      -192.048
expl/env_infos/final/reward_run Mean        -0.143047
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.143047
expl/env_infos/final/reward_run Min         -0.143047
expl/env_infos/initial/reward_run Mean       0.615839
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.615839
expl/env_infos/initial/reward_run Min        0.615839
expl/env_infos/reward_run Mean               0.0313957
expl/env_infos/reward_run Std                0.604203
expl/env_infos/reward_run Max                1.80197
expl/env_infos/reward_run Min               -2.44388
expl/env_infos/final/reward_ctrl Mean       -0.188977
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.188977
expl/env_infos/final/reward_ctrl Min        -0.188977
expl/env_infos/initial/reward_ctrl Mean     -0.346123
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.346123
expl/env_infos/initial/reward_ctrl Min      -0.346123
expl/env_infos/reward_ctrl Mean             -0.223444
expl/env_infos/reward_ctrl Std               0.0717206
expl/env_infos/reward_ctrl Max              -0.0301481
expl/env_infos/reward_ctrl Min              -0.450443
eval/num steps total                     10000
eval/num paths total                        10
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                           -0.0117437
eval/Rewards Std                             0.0216851
eval/Rewards Max                             0.446014
eval/Rewards Min                            -0.429564
eval/Returns Mean                          -11.7437
eval/Returns Std                             0.594972
eval/Returns Max                           -10.5642
eval/Returns Min                           -12.1314
eval/Actions Mean                            0.105448
eval/Actions Std                             0.0873734
eval/Actions Max                             0.331956
eval/Actions Min                            -0.0295607
eval/Num Paths                               5
eval/Average Returns                       -11.7437
eval/env_infos/final/reward_run Mean        -3.1225e-17
eval/env_infos/final/reward_run Std          6.61928e-17
eval/env_infos/final/reward_run Max          5.20417e-17
eval/env_infos/final/reward_run Min         -1.38778e-16
eval/env_infos/initial/reward_run Mean       0.273864
eval/env_infos/initial/reward_run Std        0.126159
eval/env_infos/initial/reward_run Max        0.460808
eval/env_infos/initial/reward_run Min        0.0872442
eval/env_infos/reward_run Mean              -0.000491558
eval/env_infos/reward_run Std                0.0219725
eval/env_infos/reward_run Max                0.461777
eval/env_infos/reward_run Min               -0.422958
eval/env_infos/final/reward_ctrl Mean       -0.0112647
eval/env_infos/final/reward_ctrl Std         0
eval/env_infos/final/reward_ctrl Max        -0.0112647
eval/env_infos/final/reward_ctrl Min        -0.0112647
eval/env_infos/initial/reward_ctrl Mean     -0.018909
eval/env_infos/initial/reward_ctrl Std       0.00148873
eval/env_infos/initial/reward_ctrl Max      -0.0165889
eval/env_infos/initial/reward_ctrl Min      -0.0212425
eval/env_infos/reward_ctrl Mean             -0.0112521
eval/env_infos/reward_ctrl Std               0.000380436
eval/env_infos/reward_ctrl Max              -0.00576517
eval/env_infos/reward_ctrl Min              -0.0212425
time/data storing (s)                        0.00466863
time/evaluation sampling (s)                 2.13274
time/exploration sampling (s)                0.54127
time/logging (s)                             0.0144639
time/sac training (s)                        7.83222
time/saving (s)                              0.00388359
time/training (s)                            4.1438e-05
time/epoch (s)                              10.5293
time/total (s)                              22.4342
Epoch                                        1
---------------------------------------  ---------------
2021-11-24 00:29:43.342397 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 2 finished
---------------------------------------  ---------------
epoch                                        2
replay_buffer/size                        4000
trainer/num train calls                   3000
trainer/QF1 Loss                             0.872281
trainer/QF2 Loss                             0.819022
trainer/Policy Loss                        -23.2221
trainer/Q1 Predictions Mean                 21.1435
trainer/Q1 Predictions Std                   1.83806
trainer/Q1 Predictions Max                  27.7381
trainer/Q1 Predictions Min                  15.4534
trainer/Q2 Predictions Mean                 21.0828
trainer/Q2 Predictions Std                   1.86767
trainer/Q2 Predictions Max                  28.1856
trainer/Q2 Predictions Min                  14.935
trainer/Q Targets Mean                      21.2085
trainer/Q Targets Std                        2.03553
trainer/Q Targets Max                       28.1321
trainer/Q Targets Min                       13.6732
trainer/Log Pis Mean                        -3.94067
trainer/Log Pis Std                          0.658483
trainer/Log Pis Max                         -1.14438
trainer/Log Pis Min                         -5.61107
trainer/policy/mean Mean                     0.0575909
trainer/policy/mean Std                      0.159784
trainer/policy/mean Max                      0.597248
trainer/policy/mean Min                     -0.534923
trainer/policy/normal/std Mean               0.9441
trainer/policy/normal/std Std                0.0311972
trainer/policy/normal/std Max                1.03509
trainer/policy/normal/std Min                0.840363
trainer/policy/normal/log_std Mean          -0.0580714
trainer/policy/normal/log_std Std            0.0331427
trainer/policy/normal/log_std Max            0.0344916
trainer/policy/normal/log_std Min           -0.173921
trainer/Alpha                                0.54949
trainer/Alpha Loss                          -5.95213
expl/num steps total                      4000
expl/num paths total                         4
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.202734
expl/Rewards Std                             0.732717
expl/Rewards Max                             1.92356
expl/Rewards Min                            -2.85517
expl/Returns Mean                         -202.734
expl/Returns Std                             0
expl/Returns Max                          -202.734
expl/Returns Min                          -202.734
expl/Actions Mean                            0.0253967
expl/Actions Std                             0.619855
expl/Actions Max                             0.998357
expl/Actions Min                            -0.99747
expl/Num Paths                               1
expl/Average Returns                      -202.734
expl/env_infos/final/reward_run Mean        -0.519311
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.519311
expl/env_infos/final/reward_run Min         -0.519311
expl/env_infos/initial/reward_run Mean       0.326591
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.326591
expl/env_infos/initial/reward_run Min        0.326591
expl/env_infos/reward_run Mean               0.0281853
expl/env_infos/reward_run Std                0.728751
expl/env_infos/reward_run Max                2.07492
expl/env_infos/reward_run Min               -2.54255
expl/env_infos/final/reward_ctrl Mean       -0.282313
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.282313
expl/env_infos/final/reward_ctrl Min        -0.282313
expl/env_infos/initial/reward_ctrl Mean     -0.252536
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.252536
expl/env_infos/initial/reward_ctrl Min      -0.252536
expl/env_infos/reward_ctrl Mean             -0.230919
expl/env_infos/reward_ctrl Std               0.0757536
expl/env_infos/reward_ctrl Max              -0.0137796
expl/env_infos/reward_ctrl Min              -0.496482
eval/num steps total                     15000
eval/num paths total                        15
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                           -0.0133812
eval/Rewards Std                             0.0247262
eval/Rewards Max                             0.451657
eval/Rewards Min                            -0.3182
eval/Returns Mean                          -13.3812
eval/Returns Std                             0.470046
eval/Returns Max                           -12.7837
eval/Returns Min                           -13.9717
eval/Actions Mean                            0.0952029
eval/Actions Std                             0.116612
eval/Actions Max                             0.376214
eval/Actions Min                            -0.163208
eval/Num Paths                               5
eval/Average Returns                       -13.3812
eval/env_infos/final/reward_run Mean        -2.0371e-09
eval/env_infos/final/reward_run Std          1.54142e-08
eval/env_infos/final/reward_run Max          2.84887e-08
eval/env_infos/final/reward_run Min         -1.38408e-08
eval/env_infos/initial/reward_run Mean       0.279789
eval/env_infos/initial/reward_run Std        0.0932734
eval/env_infos/initial/reward_run Max        0.356229
eval/env_infos/initial/reward_run Min        0.101114
eval/env_infos/reward_run Mean               0.000216022
eval/env_infos/reward_run Std                0.0250774
eval/env_infos/reward_run Max                0.470469
eval/env_infos/reward_run Min               -0.313227
eval/env_infos/final/reward_ctrl Mean       -0.0136375
eval/env_infos/final/reward_ctrl Std         7.30005e-10
eval/env_infos/final/reward_ctrl Max        -0.0136375
eval/env_infos/final/reward_ctrl Min        -0.0136375
eval/env_infos/initial/reward_ctrl Mean     -0.0152333
eval/env_infos/initial/reward_ctrl Std       0.00165448
eval/env_infos/initial/reward_ctrl Max      -0.0134846
eval/env_infos/initial/reward_ctrl Min      -0.0181168
eval/env_infos/reward_ctrl Mean             -0.0135972
eval/env_infos/reward_ctrl Std               0.000506005
eval/env_infos/reward_ctrl Max              -0.00497244
eval/env_infos/reward_ctrl Min              -0.0188116
time/data storing (s)                        0.00451085
time/evaluation sampling (s)                 2.08928
time/exploration sampling (s)                0.526163
time/logging (s)                             0.0145126
time/sac training (s)                        7.76933
time/saving (s)                              0.00377779
time/training (s)                            4.1198e-05
time/epoch (s)                              10.4076
time/total (s)                              33.1269
Epoch                                        2
---------------------------------------  ---------------
2021-11-24 00:29:54.088966 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 3 finished
---------------------------------------  ---------------
epoch                                        3
replay_buffer/size                        5000
trainer/num train calls                   4000
trainer/QF1 Loss                             1.47415
trainer/QF2 Loss                             1.32544
trainer/Policy Loss                        -28.3756
trainer/Q1 Predictions Mean                 26.7861
trainer/Q1 Predictions Std                   2.51198
trainer/Q1 Predictions Max                  35.6705
trainer/Q1 Predictions Min                  18.9021
trainer/Q2 Predictions Mean                 26.858
trainer/Q2 Predictions Std                   2.50028
trainer/Q2 Predictions Max                  35.8953
trainer/Q2 Predictions Min                  19.0686
trainer/Q Targets Mean                      26.896
trainer/Q Targets Std                        2.78026
trainer/Q Targets Max                       36.1148
trainer/Q Targets Min                       18.3963
trainer/Log Pis Mean                        -3.73384
trainer/Log Pis Std                          0.886258
trainer/Log Pis Max                          0.0734692
trainer/Log Pis Min                         -6.07151
trainer/policy/mean Mean                     0.0430725
trainer/policy/mean Std                      0.257267
trainer/policy/mean Max                      0.817608
trainer/policy/mean Min                     -0.749056
trainer/policy/normal/std Mean               0.933847
trainer/policy/normal/std Std                0.0382917
trainer/policy/normal/std Max                1.07233
trainer/policy/normal/std Min                0.823041
trainer/policy/normal/log_std Mean          -0.0692783
trainer/policy/normal/log_std Std            0.0408447
trainer/policy/normal/log_std Max            0.0698307
trainer/policy/normal/log_std Min           -0.19475
trainer/Alpha                                0.408101
trainer/Alpha Loss                          -8.72387
expl/num steps total                      5000
expl/num paths total                         5
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.184393
expl/Rewards Std                             0.646526
expl/Rewards Max                             1.5553
expl/Rewards Min                            -2.33838
expl/Returns Mean                         -184.393
expl/Returns Std                             0
expl/Returns Max                          -184.393
expl/Returns Min                          -184.393
expl/Actions Mean                            0.00122398
expl/Actions Std                             0.61863
expl/Actions Max                             0.999223
expl/Actions Min                            -0.998332
expl/Num Paths                               1
expl/Average Returns                      -184.393
expl/env_infos/final/reward_run Mean        -0.503326
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.503326
expl/env_infos/final/reward_run Min         -0.503326
expl/env_infos/initial/reward_run Mean       0.0377486
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.0377486
expl/env_infos/initial/reward_run Min        0.0377486
expl/env_infos/reward_run Mean               0.04523
expl/env_infos/reward_run Std                0.637326
expl/env_infos/reward_run Max                1.81104
expl/env_infos/reward_run Min               -2.01486
expl/env_infos/final/reward_ctrl Mean       -0.356505
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.356505
expl/env_infos/final/reward_ctrl Min        -0.356505
expl/env_infos/initial/reward_ctrl Mean     -0.229359
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.229359
expl/env_infos/initial/reward_ctrl Min      -0.229359
expl/env_infos/reward_ctrl Mean             -0.229623
expl/env_infos/reward_ctrl Std               0.0783911
expl/env_infos/reward_ctrl Max              -0.0285995
expl/env_infos/reward_ctrl Min              -0.501178
eval/num steps total                     20000
eval/num paths total                        20
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                           -0.0199495
eval/Rewards Std                             0.0398866
eval/Rewards Max                             0.745199
eval/Rewards Min                            -0.527526
eval/Returns Mean                          -19.9495
eval/Returns Std                             1.96747
eval/Returns Max                           -16.6788
eval/Returns Min                           -22.7453
eval/Actions Mean                            0.133722
eval/Actions Std                             0.139972
eval/Actions Max                             0.627551
eval/Actions Min                            -0.335793
eval/Num Paths                               5
eval/Average Returns                       -19.9495
eval/env_infos/final/reward_run Mean        -1.16349e-06
eval/env_infos/final/reward_run Std          4.66511e-06
eval/env_infos/final/reward_run Max          6.46023e-06
eval/env_infos/final/reward_run Min         -7.99116e-06
eval/env_infos/initial/reward_run Mean       0.297704
eval/env_infos/initial/reward_run Std        0.178607
eval/env_infos/initial/reward_run Max        0.61369
eval/env_infos/initial/reward_run Min        0.0977287
eval/env_infos/reward_run Mean               0.00253475
eval/env_infos/reward_run Std                0.0408346
eval/env_infos/reward_run Max                0.800853
eval/env_infos/reward_run Min               -0.514579
eval/env_infos/final/reward_ctrl Mean       -0.0225479
eval/env_infos/final/reward_ctrl Std         4.69748e-07
eval/env_infos/final/reward_ctrl Max        -0.0225473
eval/env_infos/final/reward_ctrl Min        -0.0225487
eval/env_infos/initial/reward_ctrl Mean     -0.0266164
eval/env_infos/initial/reward_ctrl Std       0.0124445
eval/env_infos/initial/reward_ctrl Max      -0.0120872
eval/env_infos/initial/reward_ctrl Min      -0.0415276
eval/env_infos/reward_ctrl Mean             -0.0224842
eval/env_infos/reward_ctrl Std               0.00189181
eval/env_infos/reward_ctrl Max              -0.00361964
eval/env_infos/reward_ctrl Min              -0.0766698
time/data storing (s)                        0.00449608
time/evaluation sampling (s)                 2.09902
time/exploration sampling (s)                0.548064
time/logging (s)                             0.0145151
time/sac training (s)                        7.76919
time/saving (s)                              0.00412025
time/training (s)                            5.3227e-05
time/epoch (s)                              10.4395
time/total (s)                              43.8591
Epoch                                        3
---------------------------------------  ---------------
2021-11-24 00:30:04.900010 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 4 finished
---------------------------------------  --------------
epoch                                        4
replay_buffer/size                        6000
trainer/num train calls                   5000
trainer/QF1 Loss                             0.908091
trainer/QF2 Loss                             0.881108
trainer/Policy Loss                        -31.7087
trainer/Q1 Predictions Mean                 30.6358
trainer/Q1 Predictions Std                   2.54121
trainer/Q1 Predictions Max                  40.408
trainer/Q1 Predictions Min                  23.9428
trainer/Q2 Predictions Mean                 30.6367
trainer/Q2 Predictions Std                   2.52664
trainer/Q2 Predictions Max                  40.1144
trainer/Q2 Predictions Min                  24.1795
trainer/Q Targets Mean                      30.6918
trainer/Q Targets Std                        2.60074
trainer/Q Targets Max                       39.4761
trainer/Q Targets Min                       23.6334
trainer/Log Pis Mean                        -3.38589
trainer/Log Pis Std                          1.37301
trainer/Log Pis Max                          1.82952
trainer/Log Pis Min                         -6.38567
trainer/policy/mean Mean                     0.0547399
trainer/policy/mean Std                      0.349868
trainer/policy/mean Max                      0.909048
trainer/policy/mean Min                     -0.915787
trainer/policy/normal/std Mean               0.903383
trainer/policy/normal/std Std                0.0482328
trainer/policy/normal/std Max                1.02514
trainer/policy/normal/std Min                0.730728
trainer/policy/normal/log_std Mean          -0.103055
trainer/policy/normal/log_std Std            0.0540117
trainer/policy/normal/log_std Max            0.0248326
trainer/policy/normal/log_std Min           -0.313714
trainer/Alpha                                0.303893
trainer/Alpha Loss                         -11.1793
expl/num steps total                      6000
expl/num paths total                         6
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.206177
expl/Rewards Std                             0.577107
expl/Rewards Max                             1.71168
expl/Rewards Min                            -1.91492
expl/Returns Mean                         -206.177
expl/Returns Std                             0
expl/Returns Max                          -206.177
expl/Returns Min                          -206.177
expl/Actions Mean                            0.0249811
expl/Actions Std                             0.611567
expl/Actions Max                             0.998429
expl/Actions Min                            -0.999768
expl/Num Paths                               1
expl/Average Returns                      -206.177
expl/env_infos/final/reward_run Mean        -0.0466987
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.0466987
expl/env_infos/final/reward_run Min         -0.0466987
expl/env_infos/initial/reward_run Mean      -0.21463
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max       -0.21463
expl/env_infos/initial/reward_run Min       -0.21463
expl/env_infos/reward_run Mean               0.0186054
expl/env_infos/reward_run Std                0.568681
expl/env_infos/reward_run Max                2.01981
expl/env_infos/reward_run Min               -1.73904
expl/env_infos/final/reward_ctrl Mean       -0.296039
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.296039
expl/env_infos/final/reward_ctrl Min        -0.296039
expl/env_infos/initial/reward_ctrl Mean     -0.242157
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.242157
expl/env_infos/initial/reward_ctrl Min      -0.242157
expl/env_infos/reward_ctrl Mean             -0.224783
expl/env_infos/reward_ctrl Std               0.0742793
expl/env_infos/reward_ctrl Max              -0.0409102
expl/env_infos/reward_ctrl Min              -0.43839
eval/num steps total                     25000
eval/num paths total                        25
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                           -0.0109715
eval/Rewards Std                             0.343035
eval/Rewards Max                             1.27644
eval/Rewards Min                            -1.38164
eval/Returns Mean                          -10.9715
eval/Returns Std                            23.9487
eval/Returns Max                            28.9738
eval/Returns Min                           -40.1615
eval/Actions Mean                            0.0579544
eval/Actions Std                             0.236689
eval/Actions Max                             0.833486
eval/Actions Min                            -0.754429
eval/Num Paths                               5
eval/Average Returns                       -10.9715
eval/env_infos/final/reward_run Mean         0.212655
eval/env_infos/final/reward_run Std          0.22573
eval/env_infos/final/reward_run Max          0.508173
eval/env_infos/final/reward_run Min         -0.101873
eval/env_infos/initial/reward_run Mean       0.310569
eval/env_infos/initial/reward_run Std        0.139595
eval/env_infos/initial/reward_run Max        0.454394
eval/env_infos/initial/reward_run Min        0.100721
eval/env_infos/reward_run Mean               0.0246566
eval/env_infos/reward_run Std                0.349504
eval/env_infos/reward_run Max                1.32285
eval/env_infos/reward_run Min               -1.30259
eval/env_infos/final/reward_ctrl Mean       -0.0512539
eval/env_infos/final/reward_ctrl Std         0.0322889
eval/env_infos/final/reward_ctrl Max        -0.0121737
eval/env_infos/final/reward_ctrl Min        -0.10143
eval/env_infos/initial/reward_ctrl Mean     -0.0431429
eval/env_infos/initial/reward_ctrl Std       0.0124303
eval/env_infos/initial/reward_ctrl Max      -0.0256655
eval/env_infos/initial/reward_ctrl Min      -0.0637212
eval/env_infos/reward_ctrl Mean             -0.0356282
eval/env_infos/reward_ctrl Std               0.0268845
eval/env_infos/reward_ctrl Max              -0.00109191
eval/env_infos/reward_ctrl Min              -0.1691
time/data storing (s)                        0.0045215
time/evaluation sampling (s)                 2.08612
time/exploration sampling (s)                0.547448
time/logging (s)                             0.0139996
time/sac training (s)                        7.85191
time/saving (s)                              0.00380576
time/training (s)                            3.4381e-05
time/epoch (s)                              10.5078
time/total (s)                              54.6551
Epoch                                        4
---------------------------------------  --------------
2021-11-24 00:30:15.796092 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 5 finished
---------------------------------------  --------------
epoch                                        5
replay_buffer/size                        7000
trainer/num train calls                   6000
trainer/QF1 Loss                             1.1498
trainer/QF2 Loss                             1.0684
trainer/Policy Loss                        -33.0273
trainer/Q1 Predictions Mean                 32.279
trainer/Q1 Predictions Std                   2.92721
trainer/Q1 Predictions Max                  42.9474
trainer/Q1 Predictions Min                  21.8358
trainer/Q2 Predictions Mean                 32.3734
trainer/Q2 Predictions Std                   2.98626
trainer/Q2 Predictions Max                  43.1879
trainer/Q2 Predictions Min                  22.1696
trainer/Q Targets Mean                      32.3028
trainer/Q Targets Std                        3.2451
trainer/Q Targets Max                       43.8512
trainer/Q Targets Min                       19.573
trainer/Log Pis Mean                        -3.10885
trainer/Log Pis Std                          1.38248
trainer/Log Pis Max                          1.52574
trainer/Log Pis Min                         -6.87935
trainer/policy/mean Mean                    -0.0457812
trainer/policy/mean Std                      0.398665
trainer/policy/mean Max                      0.95424
trainer/policy/mean Min                     -0.960284
trainer/policy/normal/std Mean               0.873742
trainer/policy/normal/std Std                0.0623638
trainer/policy/normal/std Max                1.06887
trainer/policy/normal/std Min                0.623729
trainer/policy/normal/log_std Mean          -0.137547
trainer/policy/normal/log_std Std            0.0720687
trainer/policy/normal/log_std Max            0.0665997
trainer/policy/normal/log_std Min           -0.472039
trainer/Alpha                                0.227031
trainer/Alpha Loss                         -13.5054
expl/num steps total                      7000
expl/num paths total                         7
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.160176
expl/Rewards Std                             0.591734
expl/Rewards Max                             1.83486
expl/Rewards Min                            -1.83431
expl/Returns Mean                         -160.176
expl/Returns Std                             0
expl/Returns Max                          -160.176
expl/Returns Min                          -160.176
expl/Actions Mean                           -0.0161279
expl/Actions Std                             0.615695
expl/Actions Max                             0.997222
expl/Actions Min                            -0.998228
expl/Num Paths                               1
expl/Average Returns                      -160.176
expl/env_infos/final/reward_run Mean        -0.384929
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.384929
expl/env_infos/final/reward_run Min         -0.384929
expl/env_infos/initial/reward_run Mean       0.802632
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.802632
expl/env_infos/initial/reward_run Min        0.802632
expl/env_infos/reward_run Mean               0.0674283
expl/env_infos/reward_run Std                0.59069
expl/env_infos/reward_run Max                2.10716
expl/env_infos/reward_run Min               -1.57132
expl/env_infos/final/reward_ctrl Mean       -0.271169
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.271169
expl/env_infos/final/reward_ctrl Min        -0.271169
expl/env_infos/initial/reward_ctrl Mean     -0.254072
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.254072
expl/env_infos/initial/reward_ctrl Min      -0.254072
expl/env_infos/reward_ctrl Mean             -0.227604
expl/env_infos/reward_ctrl Std               0.0752684
expl/env_infos/reward_ctrl Max              -0.0430493
expl/env_infos/reward_ctrl Min              -0.508171
eval/num steps total                     30000
eval/num paths total                        30
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.0696035
eval/Rewards Std                             0.263893
eval/Rewards Max                             2.17409
eval/Rewards Min                            -1.87889
eval/Returns Mean                           69.6035
eval/Returns Std                            27.038
eval/Returns Max                           101.366
eval/Returns Min                            27.1975
eval/Actions Mean                           -0.135592
eval/Actions Std                             0.221123
eval/Actions Max                             0.930968
eval/Actions Min                            -0.938841
eval/Num Paths                               5
eval/Average Returns                        69.6035
eval/env_infos/final/reward_run Mean         0.0833975
eval/env_infos/final/reward_run Std          0.130944
eval/env_infos/final/reward_run Max          0.2892
eval/env_infos/final/reward_run Min         -0.0754843
eval/env_infos/initial/reward_run Mean       0.118449
eval/env_infos/initial/reward_run Std        0.103384
eval/env_infos/initial/reward_run Max        0.240335
eval/env_infos/initial/reward_run Min       -0.0411689
eval/env_infos/reward_run Mean               0.109972
eval/env_infos/reward_run Std                0.265494
eval/env_infos/reward_run Max                2.31552
eval/env_infos/reward_run Min               -1.7723
eval/env_infos/final/reward_ctrl Mean       -0.0328676
eval/env_infos/final/reward_ctrl Std         0.00413292
eval/env_infos/final/reward_ctrl Max        -0.0281743
eval/env_infos/final/reward_ctrl Min        -0.0396681
eval/env_infos/initial/reward_ctrl Mean     -0.0490762
eval/env_infos/initial/reward_ctrl Std       0.0277319
eval/env_infos/initial/reward_ctrl Max      -0.0191141
eval/env_infos/initial/reward_ctrl Min      -0.096909
eval/env_infos/reward_ctrl Mean             -0.0403683
eval/env_infos/reward_ctrl Std               0.0242295
eval/env_infos/reward_ctrl Max              -0.00762477
eval/env_infos/reward_ctrl Min              -0.286169
time/data storing (s)                        0.00451967
time/evaluation sampling (s)                 2.11288
time/exploration sampling (s)                0.537712
time/logging (s)                             0.0144579
time/sac training (s)                        7.91966
time/saving (s)                              0.00380688
time/training (s)                            3.5845e-05
time/epoch (s)                              10.5931
time/total (s)                              65.5375
Epoch                                        5
---------------------------------------  --------------
2021-11-24 00:30:26.639336 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 6 finished
---------------------------------------  --------------
epoch                                        6
replay_buffer/size                        8000
trainer/num train calls                   7000
trainer/QF1 Loss                             0.877863
trainer/QF2 Loss                             0.81947
trainer/Policy Loss                        -33.4775
trainer/Q1 Predictions Mean                 32.9123
trainer/Q1 Predictions Std                   2.69328
trainer/Q1 Predictions Max                  50.8847
trainer/Q1 Predictions Min                  23.1675
trainer/Q2 Predictions Mean                 32.9063
trainer/Q2 Predictions Std                   2.73916
trainer/Q2 Predictions Max                  51.8565
trainer/Q2 Predictions Min                  22.1898
trainer/Q Targets Mean                      32.8693
trainer/Q Targets Std                        2.80029
trainer/Q Targets Max                       50.0086
trainer/Q Targets Min                       21.4714
trainer/Log Pis Mean                        -2.81315
trainer/Log Pis Std                          1.79924
trainer/Log Pis Max                          4.85898
trainer/Log Pis Min                         -6.37358
trainer/policy/mean Mean                     0.0429308
trainer/policy/mean Std                      0.450833
trainer/policy/mean Max                      0.95676
trainer/policy/mean Min                     -0.953209
trainer/policy/normal/std Mean               0.832272
trainer/policy/normal/std Std                0.0740478
trainer/policy/normal/std Max                1.09732
trainer/policy/normal/std Min                0.581369
trainer/policy/normal/log_std Mean          -0.187617
trainer/policy/normal/log_std Std            0.0901133
trainer/policy/normal/log_std Max            0.0928675
trainer/policy/normal/log_std Min           -0.542369
trainer/Alpha                                0.170358
trainer/Alpha Loss                         -15.598
expl/num steps total                      8000
expl/num paths total                         8
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.191803
expl/Rewards Std                             0.593815
expl/Rewards Max                             1.56174
expl/Rewards Min                            -2.15905
expl/Returns Mean                         -191.803
expl/Returns Std                             0
expl/Returns Max                          -191.803
expl/Returns Min                          -191.803
expl/Actions Mean                            0.0410067
expl/Actions Std                             0.616625
expl/Actions Max                             0.999341
expl/Actions Min                            -0.997938
expl/Num Paths                               1
expl/Average Returns                      -191.803
expl/env_infos/final/reward_run Mean         0.49414
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          0.49414
expl/env_infos/final/reward_run Min          0.49414
expl/env_infos/initial/reward_run Mean       0.0365544
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.0365544
expl/env_infos/initial/reward_run Min        0.0365544
expl/env_infos/reward_run Mean               0.0373421
expl/env_infos/reward_run Std                0.583525
expl/env_infos/reward_run Max                1.84843
expl/env_infos/reward_run Min               -1.82039
expl/env_infos/final/reward_ctrl Mean       -0.217081
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.217081
expl/env_infos/final/reward_ctrl Min        -0.217081
expl/env_infos/initial/reward_ctrl Mean     -0.207734
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.207734
expl/env_infos/initial/reward_ctrl Min      -0.207734
expl/env_infos/reward_ctrl Mean             -0.229145
expl/env_infos/reward_ctrl Std               0.0771659
expl/env_infos/reward_ctrl Max              -0.0239698
expl/env_infos/reward_ctrl Min              -0.477657
eval/num steps total                     35000
eval/num paths total                        35
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                           -0.0359571
eval/Rewards Std                             0.307053
eval/Rewards Max                             2.06577
eval/Rewards Min                            -3.23794
eval/Returns Mean                          -35.9571
eval/Returns Std                            53.6565
eval/Returns Max                            18.7481
eval/Returns Min                          -126.013
eval/Actions Mean                           -0.119034
eval/Actions Std                             0.311949
eval/Actions Max                             0.995572
eval/Actions Min                            -0.988733
eval/Num Paths                               5
eval/Average Returns                       -35.9571
eval/env_infos/final/reward_run Mean         0.132268
eval/env_infos/final/reward_run Std          0.0910703
eval/env_infos/final/reward_run Max          0.223412
eval/env_infos/final/reward_run Min          0.0213796
eval/env_infos/initial/reward_run Mean       0.0340558
eval/env_infos/initial/reward_run Std        0.165413
eval/env_infos/initial/reward_run Max        0.353819
eval/env_infos/initial/reward_run Min       -0.101278
eval/env_infos/reward_run Mean               0.0309315
eval/env_infos/reward_run Std                0.299965
eval/env_infos/reward_run Max                2.47086
eval/env_infos/reward_run Min               -3.05508
eval/env_infos/final/reward_ctrl Mean       -0.064392
eval/env_infos/final/reward_ctrl Std         0.00630118
eval/env_infos/final/reward_ctrl Max        -0.059387
eval/env_infos/final/reward_ctrl Min        -0.0768082
eval/env_infos/initial/reward_ctrl Mean     -0.0672812
eval/env_infos/initial/reward_ctrl Std       0.0335669
eval/env_infos/initial/reward_ctrl Max      -0.00389111
eval/env_infos/initial/reward_ctrl Min      -0.103734
eval/env_infos/reward_ctrl Mean             -0.0668886
eval/env_infos/reward_ctrl Std               0.0487806
eval/env_infos/reward_ctrl Max              -0.00389111
eval/env_infos/reward_ctrl Min              -0.5391
time/data storing (s)                        0.00499476
time/evaluation sampling (s)                 2.09091
time/exploration sampling (s)                0.551844
time/logging (s)                             0.0143538
time/sac training (s)                        7.86735
time/saving (s)                              0.00391767
time/training (s)                            4.1596e-05
time/epoch (s)                              10.5334
time/total (s)                              76.366
Epoch                                        6
---------------------------------------  --------------
2021-11-24 00:30:37.339134 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 7 finished
---------------------------------------  ---------------
epoch                                        7
replay_buffer/size                        9000
trainer/num train calls                   8000
trainer/QF1 Loss                             0.812102
trainer/QF2 Loss                             0.851152
trainer/Policy Loss                        -34.0067
trainer/Q1 Predictions Mean                 33.5061
trainer/Q1 Predictions Std                   3.68438
trainer/Q1 Predictions Max                  50.0802
trainer/Q1 Predictions Min                  26.8166
trainer/Q2 Predictions Mean                 33.4166
trainer/Q2 Predictions Std                   3.68602
trainer/Q2 Predictions Max                  50.0816
trainer/Q2 Predictions Min                  25.8256
trainer/Q Targets Mean                      33.4986
trainer/Q Targets Std                        3.90239
trainer/Q Targets Max                       51.6486
trainer/Q Targets Min                       26.1956
trainer/Log Pis Mean                        -1.89889
trainer/Log Pis Std                          2.54681
trainer/Log Pis Max                          9.17092
trainer/Log Pis Min                         -7.58537
trainer/policy/mean Mean                    -0.00940164
trainer/policy/mean Std                      0.533274
trainer/policy/mean Max                      0.992569
trainer/policy/mean Min                     -0.991941
trainer/policy/normal/std Mean               0.790505
trainer/policy/normal/std Std                0.0848023
trainer/policy/normal/std Max                1.07654
trainer/policy/normal/std Min                0.507825
trainer/policy/normal/log_std Mean          -0.240953
trainer/policy/normal/log_std Std            0.109062
trainer/policy/normal/log_std Max            0.0737554
trainer/policy/normal/log_std Min           -0.677619
trainer/Alpha                                0.12824
trainer/Alpha Loss                         -16.2231
expl/num steps total                      9000
expl/num paths total                         9
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.0828659
expl/Rewards Std                             0.64833
expl/Rewards Max                             1.8577
expl/Rewards Min                            -2.07008
expl/Returns Mean                          -82.8659
expl/Returns Std                             0
expl/Returns Max                           -82.8659
expl/Returns Min                           -82.8659
expl/Actions Mean                           -0.00160985
expl/Actions Std                             0.630774
expl/Actions Max                             0.999618
expl/Actions Min                            -0.999642
expl/Num Paths                               1
expl/Average Returns                       -82.8659
expl/env_infos/final/reward_run Mean        -0.282316
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.282316
expl/env_infos/final/reward_run Min         -0.282316
expl/env_infos/initial/reward_run Mean      -0.275557
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max       -0.275557
expl/env_infos/initial/reward_run Min       -0.275557
expl/env_infos/reward_run Mean               0.155861
expl/env_infos/reward_run Std                0.651846
expl/env_infos/reward_run Max                2.22412
expl/env_infos/reward_run Min               -1.84282
expl/env_infos/final/reward_ctrl Mean       -0.343377
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.343377
expl/env_infos/final/reward_ctrl Min        -0.343377
expl/env_infos/initial/reward_ctrl Mean     -0.129364
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.129364
expl/env_infos/initial/reward_ctrl Min      -0.129364
expl/env_infos/reward_ctrl Mean             -0.238727
expl/env_infos/reward_ctrl Std               0.0803071
expl/env_infos/reward_ctrl Max              -0.0226353
expl/env_infos/reward_ctrl Min              -0.528526
eval/num steps total                     40000
eval/num paths total                        40
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                           -0.13258
eval/Rewards Std                             0.701026
eval/Rewards Max                             2.46691
eval/Rewards Min                            -2.13136
eval/Returns Mean                         -132.58
eval/Returns Std                           412.526
eval/Returns Max                           226.217
eval/Returns Min                          -646.55
eval/Actions Mean                           -0.0746743
eval/Actions Std                             0.465858
eval/Actions Max                             0.997601
eval/Actions Min                            -0.99924
eval/Num Paths                               5
eval/Average Returns                      -132.58
eval/env_infos/final/reward_run Mean        -0.100549
eval/env_infos/final/reward_run Std          0.603157
eval/env_infos/final/reward_run Max          0.893118
eval/env_infos/final/reward_run Min         -0.87776
eval/env_infos/initial/reward_run Mean      -0.109744
eval/env_infos/initial/reward_run Std        0.105338
eval/env_infos/initial/reward_run Max        0.0351716
eval/env_infos/initial/reward_run Min       -0.266927
eval/env_infos/reward_run Mean               0.000979997
eval/env_infos/reward_run Std                0.690802
eval/env_infos/reward_run Max                2.75536
eval/env_infos/reward_run Min               -1.89903
eval/env_infos/final/reward_ctrl Mean       -0.12353
eval/env_infos/final/reward_ctrl Std         0.0363941
eval/env_infos/final/reward_ctrl Max        -0.0679304
eval/env_infos/final/reward_ctrl Min        -0.170036
eval/env_infos/initial/reward_ctrl Mean     -0.0791832
eval/env_infos/initial/reward_ctrl Std       0.0459046
eval/env_infos/initial/reward_ctrl Max      -0.0239975
eval/env_infos/initial/reward_ctrl Min      -0.14156
eval/env_infos/reward_ctrl Mean             -0.13356
eval/env_infos/reward_ctrl Std               0.0518426
eval/env_infos/reward_ctrl Max              -0.00866681
eval/env_infos/reward_ctrl Min              -0.514289
time/data storing (s)                        0.00441921
time/evaluation sampling (s)                 2.10747
time/exploration sampling (s)                0.522922
time/logging (s)                             0.0137639
time/sac training (s)                        7.73937
time/saving (s)                              0.00383905
time/training (s)                            3.4671e-05
time/epoch (s)                              10.3918
time/total (s)                              87.0509
Epoch                                        7
---------------------------------------  ---------------
2021-11-24 00:30:48.528843 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 8 finished
---------------------------------------  --------------
epoch                                        8
replay_buffer/size                       10000
trainer/num train calls                   9000
trainer/QF1 Loss                             1.1687
trainer/QF2 Loss                             0.911028
trainer/Policy Loss                        -33.2751
trainer/Q1 Predictions Mean                 32.9699
trainer/Q1 Predictions Std                   4.37828
trainer/Q1 Predictions Max                  56.1635
trainer/Q1 Predictions Min                  25.7788
trainer/Q2 Predictions Mean                 32.8135
trainer/Q2 Predictions Std                   4.34448
trainer/Q2 Predictions Max                  57.8124
trainer/Q2 Predictions Min                  26.8778
trainer/Q Targets Mean                      32.7569
trainer/Q Targets Std                        4.42379
trainer/Q Targets Max                       57.5844
trainer/Q Targets Min                       26.408
trainer/Log Pis Mean                        -1.48801
trainer/Log Pis Std                          2.8557
trainer/Log Pis Max                         10.7023
trainer/Log Pis Min                         -7.81276
trainer/policy/mean Mean                     0.00841027
trainer/policy/mean Std                      0.555642
trainer/policy/mean Max                      0.999344
trainer/policy/mean Min                     -0.999097
trainer/policy/normal/std Mean               0.764866
trainer/policy/normal/std Std                0.0930182
trainer/policy/normal/std Max                1.06481
trainer/policy/normal/std Min                0.473351
trainer/policy/normal/log_std Mean          -0.27556
trainer/policy/normal/log_std Std            0.123175
trainer/policy/normal/log_std Max            0.0627959
trainer/policy/normal/log_std Min           -0.747917
trainer/Alpha                                0.0969159
trainer/Alpha Loss                         -17.4764
expl/num steps total                     10000
expl/num paths total                        10
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.0570848
expl/Rewards Std                             0.735246
expl/Rewards Max                             3.4046
expl/Rewards Min                            -2.77944
expl/Returns Mean                          -57.0848
expl/Returns Std                             0
expl/Returns Max                           -57.0848
expl/Returns Min                           -57.0848
expl/Actions Mean                            0.0188362
expl/Actions Std                             0.653069
expl/Actions Max                             0.999832
expl/Actions Min                            -0.999597
expl/Num Paths                               1
expl/Average Returns                       -57.0848
expl/env_infos/final/reward_run Mean         0.0125249
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          0.0125249
expl/env_infos/final/reward_run Min          0.0125249
expl/env_infos/initial/reward_run Mean      -0.165617
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max       -0.165617
expl/env_infos/initial/reward_run Min       -0.165617
expl/env_infos/reward_run Mean               0.199028
expl/env_infos/reward_run Std                0.731702
expl/env_infos/reward_run Max                3.74857
expl/env_infos/reward_run Min               -2.33309
expl/env_infos/final/reward_ctrl Mean       -0.285533
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.285533
expl/env_infos/final/reward_ctrl Min        -0.285533
expl/env_infos/initial/reward_ctrl Mean     -0.16474
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.16474
expl/env_infos/initial/reward_ctrl Min      -0.16474
expl/env_infos/reward_ctrl Mean             -0.256113
expl/env_infos/reward_ctrl Std               0.0863671
expl/env_infos/reward_ctrl Max              -0.0319206
expl/env_infos/reward_ctrl Min              -0.534277
eval/num steps total                     45000
eval/num paths total                        45
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.0263383
eval/Rewards Std                             0.876766
eval/Rewards Max                             3.0272
eval/Rewards Min                            -3.67088
eval/Returns Mean                           26.3383
eval/Returns Std                           285.005
eval/Returns Max                           370.736
eval/Returns Min                          -350.861
eval/Actions Mean                           -0.033485
eval/Actions Std                             0.58751
eval/Actions Max                             0.999595
eval/Actions Min                            -0.999105
eval/Num Paths                               5
eval/Average Returns                        26.3383
eval/env_infos/final/reward_run Mean         0.835478
eval/env_infos/final/reward_run Std          0.338656
eval/env_infos/final/reward_run Max          1.2464
eval/env_infos/final/reward_run Min          0.45468
eval/env_infos/initial/reward_run Mean      -0.0190284
eval/env_infos/initial/reward_run Std        0.160187
eval/env_infos/initial/reward_run Max        0.243895
eval/env_infos/initial/reward_run Min       -0.253399
eval/env_infos/reward_run Mean               0.234112
eval/env_infos/reward_run Std                0.863248
eval/env_infos/reward_run Max                3.39472
eval/env_infos/reward_run Min               -3.28418
eval/env_infos/final/reward_ctrl Mean       -0.206707
eval/env_infos/final/reward_ctrl Std         0.0207341
eval/env_infos/final/reward_ctrl Max        -0.173417
eval/env_infos/final/reward_ctrl Min        -0.235616
eval/env_infos/initial/reward_ctrl Mean     -0.118437
eval/env_infos/initial/reward_ctrl Std       0.0293482
eval/env_infos/initial/reward_ctrl Max      -0.0634036
eval/env_infos/initial/reward_ctrl Min      -0.143692
eval/env_infos/reward_ctrl Mean             -0.207774
eval/env_infos/reward_ctrl Std               0.0790117
eval/env_infos/reward_ctrl Max              -0.0229941
eval/env_infos/reward_ctrl Min              -0.531902
time/data storing (s)                        0.00486624
time/evaluation sampling (s)                 2.08698
time/exploration sampling (s)                0.532691
time/logging (s)                             0.0147685
time/sac training (s)                        8.2152
time/saving (s)                              0.00392743
time/training (s)                            6.0071e-05
time/epoch (s)                              10.8585
time/total (s)                              98.2264
Epoch                                        8
---------------------------------------  --------------
2021-11-24 00:30:59.318117 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 9 finished
---------------------------------------  --------------
epoch                                        9
replay_buffer/size                       11000
trainer/num train calls                  10000
trainer/QF1 Loss                             1.57324
trainer/QF2 Loss                             1.28578
trainer/Policy Loss                        -32.437
trainer/Q1 Predictions Mean                 32.3012
trainer/Q1 Predictions Std                   5.49432
trainer/Q1 Predictions Max                  53.8768
trainer/Q1 Predictions Min                  25.8327
trainer/Q2 Predictions Mean                 32.188
trainer/Q2 Predictions Std                   5.42273
trainer/Q2 Predictions Max                  53.615
trainer/Q2 Predictions Min                  24.595
trainer/Q Targets Mean                      32.2018
trainer/Q Targets Std                        5.62915
trainer/Q Targets Max                       54.592
trainer/Q Targets Min                       23.556
trainer/Log Pis Mean                        -0.843499
trainer/Log Pis Std                          3.39496
trainer/Log Pis Max                         13.8609
trainer/Log Pis Min                         -7.4109
trainer/policy/mean Mean                    -0.0220409
trainer/policy/mean Std                      0.591075
trainer/policy/mean Max                      0.997767
trainer/policy/mean Min                     -0.994522
trainer/policy/normal/std Mean               0.712998
trainer/policy/normal/std Std                0.117836
trainer/policy/normal/std Max                1.32275
trainer/policy/normal/std Min                0.383946
trainer/policy/normal/log_std Mean          -0.351908
trainer/policy/normal/log_std Std            0.165728
trainer/policy/normal/log_std Max            0.279712
trainer/policy/normal/log_std Min           -0.957254
trainer/Alpha                                0.0734092
trainer/Alpha Loss                         -17.8732
expl/num steps total                     11000
expl/num paths total                        11
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.0718861
expl/Rewards Std                             0.864087
expl/Rewards Max                             2.4558
expl/Rewards Min                            -3.12471
expl/Returns Mean                          -71.8861
expl/Returns Std                             0
expl/Returns Max                           -71.8861
expl/Returns Min                           -71.8861
expl/Actions Mean                           -0.0473596
expl/Actions Std                             0.711286
expl/Actions Max                             0.999979
expl/Actions Min                            -0.999849
expl/Num Paths                               1
expl/Average Returns                       -71.8861
expl/env_infos/final/reward_run Mean         0.574713
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          0.574713
expl/env_infos/final/reward_run Min          0.574713
expl/env_infos/initial/reward_run Mean      -0.31054
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max       -0.31054
expl/env_infos/initial/reward_run Min       -0.31054
expl/env_infos/reward_run Mean               0.233017
expl/env_infos/reward_run Std                0.847906
expl/env_infos/reward_run Max                2.69163
expl/env_infos/reward_run Min               -2.61892
expl/env_infos/final/reward_ctrl Mean       -0.182415
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.182415
expl/env_infos/final/reward_ctrl Min        -0.182415
expl/env_infos/initial/reward_ctrl Mean     -0.128122
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.128122
expl/env_infos/initial/reward_ctrl Min      -0.128122
expl/env_infos/reward_ctrl Mean             -0.304903
expl/env_infos/reward_ctrl Std               0.0933158
expl/env_infos/reward_ctrl Max              -0.0633163
expl/env_infos/reward_ctrl Min              -0.552543
eval/num steps total                     50000
eval/num paths total                        50
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.018459
eval/Rewards Std                             0.831703
eval/Rewards Max                             2.90631
eval/Rewards Min                            -3.55382
eval/Returns Mean                           18.459
eval/Returns Std                            55.3103
eval/Returns Max                            93.087
eval/Returns Min                           -66.3412
eval/Actions Mean                           -0.0667818
eval/Actions Std                             0.640313
eval/Actions Max                             0.999961
eval/Actions Min                            -0.999681
eval/Num Paths                               5
eval/Average Returns                        18.459
eval/env_infos/final/reward_run Mean         1.03915
eval/env_infos/final/reward_run Std          0.520261
eval/env_infos/final/reward_run Max          1.83927
eval/env_infos/final/reward_run Min          0.351314
eval/env_infos/initial/reward_run Mean       0.00382892
eval/env_infos/initial/reward_run Std        0.0491782
eval/env_infos/initial/reward_run Max        0.0600702
eval/env_infos/initial/reward_run Min       -0.0722083
eval/env_infos/reward_run Mean               0.267135
eval/env_infos/reward_run Std                0.822998
eval/env_infos/reward_run Max                3.05781
eval/env_infos/reward_run Min               -3.35174
eval/env_infos/final/reward_ctrl Mean       -0.244628
eval/env_infos/final/reward_ctrl Std         0.0693194
eval/env_infos/final/reward_ctrl Max        -0.141765
eval/env_infos/final/reward_ctrl Min        -0.350943
eval/env_infos/initial/reward_ctrl Mean     -0.125214
eval/env_infos/initial/reward_ctrl Std       0.0240778
eval/env_infos/initial/reward_ctrl Max      -0.101524
eval/env_infos/initial/reward_ctrl Min      -0.163133
eval/env_infos/reward_ctrl Mean             -0.248676
eval/env_infos/reward_ctrl Std               0.0935792
eval/env_infos/reward_ctrl Max              -0.0136008
eval/env_infos/reward_ctrl Min              -0.558597
time/data storing (s)                        0.00446017
time/evaluation sampling (s)                 2.09113
time/exploration sampling (s)                0.539904
time/logging (s)                             0.0139191
time/sac training (s)                        7.81988
time/saving (s)                              0.00382397
time/training (s)                            3.5194e-05
time/epoch (s)                              10.4732
time/total (s)                             109
Epoch                                        9
---------------------------------------  --------------
2021-11-24 00:31:10.141282 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 10 finished
---------------------------------------  --------------
epoch                                       10
replay_buffer/size                       12000
trainer/num train calls                  11000
trainer/QF1 Loss                             1.40645
trainer/QF2 Loss                             1.22083
trainer/Policy Loss                        -31.39
trainer/Q1 Predictions Mean                 31.1427
trainer/Q1 Predictions Std                   6.01418
trainer/Q1 Predictions Max                  58.3814
trainer/Q1 Predictions Min                  24.5388
trainer/Q2 Predictions Mean                 31.32
trainer/Q2 Predictions Std                   6.02689
trainer/Q2 Predictions Max                  57.4998
trainer/Q2 Predictions Min                  24.298
trainer/Q Targets Mean                      31.1741
trainer/Q Targets Std                        6.09045
trainer/Q Targets Max                       56.4054
trainer/Q Targets Min                       23.9066
trainer/Log Pis Mean                        -0.936021
trainer/Log Pis Std                          2.91094
trainer/Log Pis Max                          9.19705
trainer/Log Pis Min                         -8.91005
trainer/policy/mean Mean                     0.0914271
trainer/policy/mean Std                      0.573035
trainer/policy/mean Max                      0.997415
trainer/policy/mean Min                     -0.99185
trainer/policy/normal/std Mean               0.62519
trainer/policy/normal/std Std                0.106894
trainer/policy/normal/std Max                1.00991
trainer/policy/normal/std Min                0.306499
trainer/policy/normal/log_std Mean          -0.484684
trainer/policy/normal/log_std Std            0.174986
trainer/policy/normal/log_std Max            0.00986144
trainer/policy/normal/log_std Min           -1.18254
trainer/Alpha                                0.0554916
trainer/Alpha Loss                         -20.0557
expl/num steps total                     12000
expl/num paths total                        12
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                           -0.0790049
expl/Rewards Std                             0.572174
expl/Rewards Max                             1.5735
expl/Rewards Min                            -1.74422
expl/Returns Mean                          -79.0049
expl/Returns Std                             0
expl/Returns Max                           -79.0049
expl/Returns Min                           -79.0049
expl/Actions Mean                            0.0999861
expl/Actions Std                             0.640758
expl/Actions Max                             0.999814
expl/Actions Min                            -0.999654
expl/Num Paths                               1
expl/Average Returns                       -79.0049
expl/env_infos/final/reward_run Mean         0.0202847
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          0.0202847
expl/env_infos/final/reward_run Min          0.0202847
expl/env_infos/initial/reward_run Mean       0.589841
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.589841
expl/env_infos/initial/reward_run Min        0.589841
expl/env_infos/reward_run Mean               0.173336
expl/env_infos/reward_run Std                0.566725
expl/env_infos/reward_run Max                1.93744
expl/env_infos/reward_run Min               -1.48114
expl/env_infos/final/reward_ctrl Mean       -0.451232
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.451232
expl/env_infos/final/reward_ctrl Min        -0.451232
expl/env_infos/initial/reward_ctrl Mean     -0.133742
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.133742
expl/env_infos/initial/reward_ctrl Min      -0.133742
expl/env_infos/reward_ctrl Mean             -0.252341
expl/env_infos/reward_ctrl Std               0.0848404
expl/env_infos/reward_ctrl Max              -0.0316199
expl/env_infos/reward_ctrl Min              -0.590805
eval/num steps total                     55000
eval/num paths total                        55
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                           -0.100377
eval/Rewards Std                             0.51539
eval/Rewards Max                             1.52733
eval/Rewards Min                            -2.17568
eval/Returns Mean                         -100.377
eval/Returns Std                             9.70945
eval/Returns Max                           -87.2678
eval/Returns Min                          -111.112
eval/Actions Mean                            0.114839
eval/Actions Std                             0.532957
eval/Actions Max                             0.996906
eval/Actions Min                            -0.99237
eval/Num Paths                               5
eval/Average Returns                      -100.377
eval/env_infos/final/reward_run Mean         0.0633704
eval/env_infos/final/reward_run Std          0.328671
eval/env_infos/final/reward_run Max          0.575691
eval/env_infos/final/reward_run Min         -0.4079
eval/env_infos/initial/reward_run Mean       0.178709
eval/env_infos/initial/reward_run Std        0.0460089
eval/env_infos/initial/reward_run Max        0.247323
eval/env_infos/initial/reward_run Min        0.108315
eval/env_infos/reward_run Mean               0.0779616
eval/env_infos/reward_run Std                0.50754
eval/env_infos/reward_run Max                1.79144
eval/env_infos/reward_run Min               -1.76455
eval/env_infos/final/reward_ctrl Mean       -0.171843
eval/env_infos/final/reward_ctrl Std         0.0479779
eval/env_infos/final/reward_ctrl Max        -0.0878389
eval/env_infos/final/reward_ctrl Min        -0.229338
eval/env_infos/initial/reward_ctrl Mean     -0.070331
eval/env_infos/initial/reward_ctrl Std       0.00909803
eval/env_infos/initial/reward_ctrl Max      -0.0606048
eval/env_infos/initial/reward_ctrl Min      -0.0824805
eval/env_infos/reward_ctrl Mean             -0.178339
eval/env_infos/reward_ctrl Std               0.0692217
eval/env_infos/reward_ctrl Max              -0.00500981
eval/env_infos/reward_ctrl Min              -0.493377
time/data storing (s)                        0.00491572
time/evaluation sampling (s)                 2.13074
time/exploration sampling (s)                0.551073
time/logging (s)                             0.0148264
time/sac training (s)                        7.80618
time/saving (s)                              0.00405747
time/training (s)                            4.4278e-05
time/epoch (s)                              10.5118
time/total (s)                             119.81
Epoch                                       10
---------------------------------------  --------------
2021-11-24 00:31:20.813137 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 11 finished
---------------------------------------  --------------
epoch                                       11
replay_buffer/size                       13000
trainer/num train calls                  12000
trainer/QF1 Loss                             0.942208
trainer/QF2 Loss                             0.946713
trainer/Policy Loss                        -29.3118
trainer/Q1 Predictions Mean                 29.0979
trainer/Q1 Predictions Std                   5.32027
trainer/Q1 Predictions Max                  47.428
trainer/Q1 Predictions Min                  21.8546
trainer/Q2 Predictions Mean                 29.1497
trainer/Q2 Predictions Std                   5.38887
trainer/Q2 Predictions Max                  47.6217
trainer/Q2 Predictions Min                  21.4756
trainer/Q Targets Mean                      29.3214
trainer/Q Targets Std                        5.44586
trainer/Q Targets Max                       50.1186
trainer/Q Targets Min                       21.1356
trainer/Log Pis Mean                         0.153878
trainer/Log Pis Std                          3.0663
trainer/Log Pis Max                         14.6018
trainer/Log Pis Min                         -7.27175
trainer/policy/mean Mean                     0.0618796
trainer/policy/mean Std                      0.607449
trainer/policy/mean Max                      0.997562
trainer/policy/mean Min                     -0.998517
trainer/policy/normal/std Mean               0.559448
trainer/policy/normal/std Std                0.114687
trainer/policy/normal/std Max                1.00228
trainer/policy/normal/std Min                0.262697
trainer/policy/normal/log_std Mean          -0.602243
trainer/policy/normal/log_std Std            0.209316
trainer/policy/normal/log_std Max            0.00228061
trainer/policy/normal/log_std Min           -1.33675
trainer/Alpha                                0.0421707
trainer/Alpha Loss                         -18.509
expl/num steps total                     13000
expl/num paths total                        13
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.0857142
expl/Rewards Std                             0.826102
expl/Rewards Max                             2.46879
expl/Rewards Min                            -2.18296
expl/Returns Mean                           85.7142
expl/Returns Std                             0
expl/Returns Max                            85.7142
expl/Returns Min                            85.7142
expl/Actions Mean                            0.0702891
expl/Actions Std                             0.672933
expl/Actions Max                             0.999036
expl/Actions Min                            -0.999487
expl/Num Paths                               1
expl/Average Returns                        85.7142
expl/env_infos/final/reward_run Mean         1.29809
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          1.29809
expl/env_infos/final/reward_run Min          1.29809
expl/env_infos/initial/reward_run Mean       0.247953
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.247953
expl/env_infos/initial/reward_run Min        0.247953
expl/env_infos/reward_run Mean               0.360382
expl/env_infos/reward_run Std                0.80691
expl/env_infos/reward_run Max                2.76544
expl/env_infos/reward_run Min               -1.90568
expl/env_infos/final/reward_ctrl Mean       -0.155681
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.155681
expl/env_infos/final/reward_ctrl Min        -0.155681
expl/env_infos/initial/reward_ctrl Mean     -0.0785714
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.0785714
expl/env_infos/initial/reward_ctrl Min      -0.0785714
expl/env_infos/reward_ctrl Mean             -0.274667
expl/env_infos/reward_ctrl Std               0.0845326
expl/env_infos/reward_ctrl Max              -0.017243
expl/env_infos/reward_ctrl Min              -0.537857
eval/num steps total                     60000
eval/num paths total                        60
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.0854097
eval/Rewards Std                             0.892218
eval/Rewards Max                             2.69482
eval/Rewards Min                            -2.40044
eval/Returns Mean                           85.4097
eval/Returns Std                            37.0841
eval/Returns Max                           150.484
eval/Returns Min                            43.3402
eval/Actions Mean                            0.0492587
eval/Actions Std                             0.633366
eval/Actions Max                             0.999612
eval/Actions Min                            -0.999421
eval/Num Paths                               5
eval/Average Returns                        85.4097
eval/env_infos/final/reward_run Mean         0.500334
eval/env_infos/final/reward_run Std          0.553661
eval/env_infos/final/reward_run Max          1.03777
eval/env_infos/final/reward_run Min         -0.424486
eval/env_infos/initial/reward_run Mean       0.261334
eval/env_infos/initial/reward_run Std        0.178104
eval/env_infos/initial/reward_run Max        0.492445
eval/env_infos/initial/reward_run Min        0.028297
eval/env_infos/reward_run Mean               0.327557
eval/env_infos/reward_run Std                0.873176
eval/env_infos/reward_run Max                2.97478
eval/env_infos/reward_run Min               -2.01802
eval/env_infos/final/reward_ctrl Mean       -0.218317
eval/env_infos/final/reward_ctrl Std         0.0479529
eval/env_infos/final/reward_ctrl Max        -0.136857
eval/env_infos/final/reward_ctrl Min        -0.264019
eval/env_infos/initial/reward_ctrl Mean     -0.0799868
eval/env_infos/initial/reward_ctrl Std       0.0255198
eval/env_infos/initial/reward_ctrl Max      -0.0401538
eval/env_infos/initial/reward_ctrl Min      -0.118104
eval/env_infos/reward_ctrl Mean             -0.242147
eval/env_infos/reward_ctrl Std               0.0892458
eval/env_infos/reward_ctrl Max              -0.00663604
eval/env_infos/reward_ctrl Min              -0.523362
time/data storing (s)                        0.00452513
time/evaluation sampling (s)                 2.07037
time/exploration sampling (s)                0.535858
time/logging (s)                             0.0141666
time/sac training (s)                        7.73367
time/saving (s)                              0.00384812
time/training (s)                            3.8835e-05
time/epoch (s)                              10.3625
time/total (s)                             130.467
Epoch                                       11
---------------------------------------  --------------
2021-11-24 00:31:31.559852 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 12 finished
---------------------------------------  --------------
epoch                                       12
replay_buffer/size                       14000
trainer/num train calls                  13000
trainer/QF1 Loss                             1.24123
trainer/QF2 Loss                             1.09285
trainer/Policy Loss                        -27.9235
trainer/Q1 Predictions Mean                 27.8732
trainer/Q1 Predictions Std                   5.61599
trainer/Q1 Predictions Max                  53.9114
trainer/Q1 Predictions Min                  20.6942
trainer/Q2 Predictions Mean                 27.7713
trainer/Q2 Predictions Std                   5.72191
trainer/Q2 Predictions Max                  53.8971
trainer/Q2 Predictions Min                  20.4521
trainer/Q Targets Mean                      27.7635
trainer/Q Targets Std                        5.83197
trainer/Q Targets Max                       53.7937
trainer/Q Targets Min                       19.28
trainer/Log Pis Mean                         0.741622
trainer/Log Pis Std                          3.03672
trainer/Log Pis Max                         10.5414
trainer/Log Pis Min                         -6.64436
trainer/policy/mean Mean                     0.0360037
trainer/policy/mean Std                      0.599986
trainer/policy/mean Max                      0.995037
trainer/policy/mean Min                     -0.995217
trainer/policy/normal/std Mean               0.498923
trainer/policy/normal/std Std                0.114066
trainer/policy/normal/std Max                0.954387
trainer/policy/normal/std Min                0.171902
trainer/policy/normal/log_std Mean          -0.723157
trainer/policy/normal/log_std Std            0.241631
trainer/policy/normal/log_std Max           -0.046686
trainer/policy/normal/log_std Min           -1.76083
trainer/Alpha                                0.0323613
trainer/Alpha Loss                         -18.0404
expl/num steps total                     14000
expl/num paths total                        14
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.101417
expl/Rewards Std                             0.761765
expl/Rewards Max                             2.26843
expl/Rewards Min                            -1.86433
expl/Returns Mean                          101.417
expl/Returns Std                             0
expl/Returns Max                           101.417
expl/Returns Min                           101.417
expl/Actions Mean                            0.0492814
expl/Actions Std                             0.652333
expl/Actions Max                             0.999958
expl/Actions Min                            -0.999563
expl/Num Paths                               1
expl/Average Returns                       101.417
expl/env_infos/final/reward_run Mean         0.0452103
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          0.0452103
expl/env_infos/final/reward_run Min          0.0452103
expl/env_infos/initial/reward_run Mean       0.0690275
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.0690275
expl/env_infos/initial/reward_run Min        0.0690275
expl/env_infos/reward_run Mean               0.358198
expl/env_infos/reward_run Std                0.739272
expl/env_infos/reward_run Max                2.48966
expl/env_infos/reward_run Min               -1.51545
expl/env_infos/final/reward_ctrl Mean       -0.243026
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.243026
expl/env_infos/final/reward_ctrl Min        -0.243026
expl/env_infos/initial/reward_ctrl Mean     -0.019342
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.019342
expl/env_infos/initial/reward_ctrl Min      -0.019342
expl/env_infos/reward_ctrl Mean             -0.25678
expl/env_infos/reward_ctrl Std               0.0867859
expl/env_infos/reward_ctrl Max              -0.019342
expl/env_infos/reward_ctrl Min              -0.561456
eval/num steps total                     65000
eval/num paths total                        65
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.158711
eval/Rewards Std                             0.859027
eval/Rewards Max                             2.85123
eval/Rewards Min                            -2.28944
eval/Returns Mean                          158.711
eval/Returns Std                            37.8443
eval/Returns Max                           221.953
eval/Returns Min                           120.72
eval/Actions Mean                            0.0448375
eval/Actions Std                             0.618371
eval/Actions Max                             0.999796
eval/Actions Min                            -0.99996
eval/Num Paths                               5
eval/Average Returns                       158.711
eval/env_infos/final/reward_run Mean         0.152705
eval/env_infos/final/reward_run Std          0.303307
eval/env_infos/final/reward_run Max          0.483117
eval/env_infos/final/reward_run Min         -0.216397
eval/env_infos/initial/reward_run Mean      -0.0396908
eval/env_infos/initial/reward_run Std        0.105945
eval/env_infos/initial/reward_run Max        0.160624
eval/env_infos/initial/reward_run Min       -0.145459
eval/env_infos/reward_run Mean               0.389347
eval/env_infos/reward_run Std                0.826492
eval/env_infos/reward_run Max                2.9943
eval/env_infos/reward_run Min               -2.00195
eval/env_infos/final/reward_ctrl Mean       -0.277241
eval/env_infos/final/reward_ctrl Std         0.0371666
eval/env_infos/final/reward_ctrl Max        -0.239875
eval/env_infos/final/reward_ctrl Min        -0.34796
eval/env_infos/initial/reward_ctrl Mean     -0.0316214
eval/env_infos/initial/reward_ctrl Std       0.0122903
eval/env_infos/initial/reward_ctrl Max      -0.0151167
eval/env_infos/initial/reward_ctrl Min      -0.0469401
eval/env_infos/reward_ctrl Mean             -0.230636
eval/env_infos/reward_ctrl Std               0.0865279
eval/env_infos/reward_ctrl Max              -0.00593914
eval/env_infos/reward_ctrl Min              -0.576154
time/data storing (s)                        0.00452071
time/evaluation sampling (s)                 2.06224
time/exploration sampling (s)                0.526952
time/logging (s)                             0.0138687
time/sac training (s)                        7.82072
time/saving (s)                              0.00384808
time/training (s)                            3.6196e-05
time/epoch (s)                              10.4322
time/total (s)                             141.199
Epoch                                       12
---------------------------------------  --------------
2021-11-24 00:31:42.388098 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 13 finished
---------------------------------------  --------------
epoch                                       13
replay_buffer/size                       15000
trainer/num train calls                  14000
trainer/QF1 Loss                             1.08848
trainer/QF2 Loss                             0.767672
trainer/Policy Loss                        -26.6352
trainer/Q1 Predictions Mean                 26.5341
trainer/Q1 Predictions Std                   6.14243
trainer/Q1 Predictions Max                  47.3447
trainer/Q1 Predictions Min                  19.2444
trainer/Q2 Predictions Mean                 26.4787
trainer/Q2 Predictions Std                   6.17855
trainer/Q2 Predictions Max                  49.4836
trainer/Q2 Predictions Min                  18.1271
trainer/Q Targets Mean                      26.5705
trainer/Q Targets Std                        6.29663
trainer/Q Targets Max                       49.1727
trainer/Q Targets Min                       18.0882
trainer/Log Pis Mean                         1.39288
trainer/Log Pis Std                          3.12704
trainer/Log Pis Max                         13.8521
trainer/Log Pis Min                         -5.78996
trainer/policy/mean Mean                     0.0674334
trainer/policy/mean Std                      0.600085
trainer/policy/mean Max                      0.997802
trainer/policy/mean Min                     -0.998667
trainer/policy/normal/std Mean               0.440169
trainer/policy/normal/std Std                0.0991012
trainer/policy/normal/std Max                0.797432
trainer/policy/normal/std Min                0.188584
trainer/policy/normal/log_std Mean          -0.847379
trainer/policy/normal/log_std Std            0.235961
trainer/policy/normal/log_std Max           -0.226358
trainer/policy/normal/log_std Min           -1.66821
trainer/Alpha                                0.0251179
trainer/Alpha Loss                         -16.9734
expl/num steps total                     15000
expl/num paths total                        15
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.115364
expl/Rewards Std                             0.849338
expl/Rewards Max                             2.63093
expl/Rewards Min                            -2.5096
expl/Returns Mean                          115.364
expl/Returns Std                             0
expl/Returns Max                           115.364
expl/Returns Min                           115.364
expl/Actions Mean                            0.0429675
expl/Actions Std                             0.652527
expl/Actions Max                             0.999807
expl/Actions Min                            -0.999661
expl/Num Paths                               1
expl/Average Returns                       115.364
expl/env_infos/final/reward_run Mean         2.85832
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          2.85832
expl/env_infos/final/reward_run Min          2.85832
expl/env_infos/initial/reward_run Mean       0.052286
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.052286
expl/env_infos/initial/reward_run Min        0.052286
expl/env_infos/reward_run Mean               0.371946
expl/env_infos/reward_run Std                0.840442
expl/env_infos/reward_run Max                2.85832
expl/env_infos/reward_run Min               -2.01593
expl/env_infos/final/reward_ctrl Mean       -0.227391
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.227391
expl/env_infos/final/reward_ctrl Min        -0.227391
expl/env_infos/initial/reward_ctrl Mean     -0.0186809
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.0186809
expl/env_infos/initial/reward_ctrl Min      -0.0186809
expl/env_infos/reward_ctrl Mean             -0.256583
expl/env_infos/reward_ctrl Std               0.0853164
expl/env_infos/reward_ctrl Max              -0.0186809
expl/env_infos/reward_ctrl Min              -0.511205
eval/num steps total                     70000
eval/num paths total                        70
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.243308
eval/Rewards Std                             0.91722
eval/Rewards Max                             3.09464
eval/Rewards Min                            -3.50984
eval/Returns Mean                          243.308
eval/Returns Std                            56.6704
eval/Returns Max                           314.397
eval/Returns Min                           168.837
eval/Actions Mean                            0.0160251
eval/Actions Std                             0.626427
eval/Actions Max                             0.999983
eval/Actions Min                            -0.9999
eval/Num Paths                               5
eval/Average Returns                       243.308
eval/env_infos/final/reward_run Mean        -0.509641
eval/env_infos/final/reward_run Std          0.773313
eval/env_infos/final/reward_run Max          0.781363
eval/env_infos/final/reward_run Min         -1.39681
eval/env_infos/initial/reward_run Mean       0.0049715
eval/env_infos/initial/reward_run Std        0.0830709
eval/env_infos/initial/reward_run Max        0.132894
eval/env_infos/initial/reward_run Min       -0.123133
eval/env_infos/reward_run Mean               0.478908
eval/env_infos/reward_run Std                0.897522
eval/env_infos/reward_run Max                3.34359
eval/env_infos/reward_run Min               -2.99197
eval/env_infos/final/reward_ctrl Mean       -0.233298
eval/env_infos/final/reward_ctrl Std         0.0361183
eval/env_infos/final/reward_ctrl Max        -0.169491
eval/env_infos/final/reward_ctrl Min        -0.266734
eval/env_infos/initial/reward_ctrl Mean     -0.0266569
eval/env_infos/initial/reward_ctrl Std       0.0174916
eval/env_infos/initial/reward_ctrl Max      -0.00693674
eval/env_infos/initial/reward_ctrl Min      -0.0581196
eval/env_infos/reward_ctrl Mean             -0.2356
eval/env_infos/reward_ctrl Std               0.0848955
eval/env_infos/reward_ctrl Max              -0.00693674
eval/env_infos/reward_ctrl Min              -0.530746
time/data storing (s)                        0.00446535
time/evaluation sampling (s)                 2.11274
time/exploration sampling (s)                0.563987
time/logging (s)                             0.0138207
time/sac training (s)                        7.81535
time/saving (s)                              0.00393916
time/training (s)                            5.0112e-05
time/epoch (s)                              10.5144
time/total (s)                             152.013
Epoch                                       13
---------------------------------------  --------------
2021-11-24 00:31:53.181571 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 14 finished
---------------------------------------  --------------
epoch                                       14
replay_buffer/size                       16000
trainer/num train calls                  15000
trainer/QF1 Loss                             1.03491
trainer/QF2 Loss                             0.948678
trainer/Policy Loss                        -25.4842
trainer/Q1 Predictions Mean                 25.273
trainer/Q1 Predictions Std                   6.07196
trainer/Q1 Predictions Max                  50.4186
trainer/Q1 Predictions Min                  18.6073
trainer/Q2 Predictions Mean                 25.2633
trainer/Q2 Predictions Std                   6.06254
trainer/Q2 Predictions Max                  49.2672
trainer/Q2 Predictions Min                  18.5372
trainer/Q Targets Mean                      24.9419
trainer/Q Targets Std                        6.06862
trainer/Q Targets Max                       48.2524
trainer/Q Targets Min                       17.8209
trainer/Log Pis Mean                         3.01817
trainer/Log Pis Std                          3.26762
trainer/Log Pis Max                         14.4608
trainer/Log Pis Min                         -6.52323
trainer/policy/mean Mean                     0.0290262
trainer/policy/mean Std                      0.652791
trainer/policy/mean Max                      0.99878
trainer/policy/mean Min                     -0.998797
trainer/policy/normal/std Mean               0.397388
trainer/policy/normal/std Std                0.107601
trainer/policy/normal/std Max                0.809726
trainer/policy/normal/std Min                0.124804
trainer/policy/normal/log_std Mean          -0.961906
trainer/policy/normal/log_std Std            0.286516
trainer/policy/normal/log_std Max           -0.21106
trainer/policy/normal/log_std Min           -2.08101
trainer/Alpha                                0.0198211
trainer/Alpha Loss                         -11.6918
expl/num steps total                     16000
expl/num paths total                        16
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.16386
expl/Rewards Std                             0.85354
expl/Rewards Max                             2.63559
expl/Rewards Min                            -2.5245
expl/Returns Mean                          163.86
expl/Returns Std                             0
expl/Returns Max                           163.86
expl/Returns Min                           163.86
expl/Actions Mean                            0.020841
expl/Actions Std                             0.684604
expl/Actions Max                             0.99999
expl/Actions Min                            -0.999901
expl/Num Paths                               1
expl/Average Returns                       163.86
expl/env_infos/final/reward_run Mean        -0.702946
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.702946
expl/env_infos/final/reward_run Min         -0.702946
expl/env_infos/initial/reward_run Mean      -0.186558
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max       -0.186558
expl/env_infos/initial/reward_run Min       -0.186558
expl/env_infos/reward_run Mean               0.44533
expl/env_infos/reward_run Std                0.833321
expl/env_infos/reward_run Max                2.80932
expl/env_infos/reward_run Min               -2.20604
expl/env_infos/final/reward_ctrl Mean       -0.248226
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.248226
expl/env_infos/final/reward_ctrl Min        -0.248226
expl/env_infos/initial/reward_ctrl Mean     -0.0220298
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.0220298
expl/env_infos/initial/reward_ctrl Min      -0.0220298
expl/env_infos/reward_ctrl Mean             -0.28147
expl/env_infos/reward_ctrl Std               0.0903148
expl/env_infos/reward_ctrl Max              -0.0220298
expl/env_infos/reward_ctrl Min              -0.549624
eval/num steps total                     75000
eval/num paths total                        75
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.179132
eval/Rewards Std                             0.872486
eval/Rewards Max                             2.74902
eval/Rewards Min                            -2.64939
eval/Returns Mean                          179.132
eval/Returns Std                            73.4075
eval/Returns Max                           316.78
eval/Returns Min                            96.1469
eval/Actions Mean                            0.0184083
eval/Actions Std                             0.679057
eval/Actions Max                             0.999943
eval/Actions Min                            -0.999716
eval/Num Paths                               5
eval/Average Returns                       179.132
eval/env_infos/final/reward_run Mean         0.0791477
eval/env_infos/final/reward_run Std          0.578369
eval/env_infos/final/reward_run Max          1.09008
eval/env_infos/final/reward_run Min         -0.666451
eval/env_infos/initial/reward_run Mean      -0.0983174
eval/env_infos/initial/reward_run Std        0.0811729
eval/env_infos/initial/reward_run Max        0.0522895
eval/env_infos/initial/reward_run Min       -0.174475
eval/env_infos/reward_run Mean               0.456007
eval/env_infos/reward_run Std                0.85089
eval/env_infos/reward_run Max                2.97977
eval/env_infos/reward_run Min               -2.09653
eval/env_infos/final/reward_ctrl Mean       -0.303986
eval/env_infos/final/reward_ctrl Std         0.0761617
eval/env_infos/final/reward_ctrl Max        -0.163951
eval/env_infos/final/reward_ctrl Min        -0.37782
eval/env_infos/initial/reward_ctrl Mean     -0.0467802
eval/env_infos/initial/reward_ctrl Std       0.0186035
eval/env_infos/initial/reward_ctrl Max      -0.0259845
eval/env_infos/initial/reward_ctrl Min      -0.0698561
eval/env_infos/reward_ctrl Mean             -0.276875
eval/env_infos/reward_ctrl Std               0.0882297
eval/env_infos/reward_ctrl Max              -0.00969216
eval/env_infos/reward_ctrl Min              -0.552859
time/data storing (s)                        0.00452916
time/evaluation sampling (s)                 2.05232
time/exploration sampling (s)                0.553814
time/logging (s)                             0.0137198
time/sac training (s)                        7.85426
time/saving (s)                              0.00380503
time/training (s)                            3.3933e-05
time/epoch (s)                              10.4825
time/total (s)                             162.792
Epoch                                       14
---------------------------------------  --------------
2021-11-24 00:32:03.884888 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 15 finished
---------------------------------------  --------------
epoch                                       15
replay_buffer/size                       17000
trainer/num train calls                  16000
trainer/QF1 Loss                             0.992448
trainer/QF2 Loss                             0.880474
trainer/Policy Loss                        -24.7031
trainer/Q1 Predictions Mean                 24.5622
trainer/Q1 Predictions Std                   6.81665
trainer/Q1 Predictions Max                  50.6626
trainer/Q1 Predictions Min                  16.6211
trainer/Q2 Predictions Mean                 24.5883
trainer/Q2 Predictions Std                   6.8643
trainer/Q2 Predictions Max                  51.5715
trainer/Q2 Predictions Min                  17.1183
trainer/Q Targets Mean                      24.5001
trainer/Q Targets Std                        6.88062
trainer/Q Targets Max                       52.8081
trainer/Q Targets Min                       16.7645
trainer/Log Pis Mean                         3.79983
trainer/Log Pis Std                          3.59292
trainer/Log Pis Max                         21.721
trainer/Log Pis Min                         -2.75703
trainer/policy/mean Mean                     0.0661761
trainer/policy/mean Std                      0.663046
trainer/policy/mean Max                      0.999914
trainer/policy/mean Min                     -0.999566
trainer/policy/normal/std Mean               0.395398
trainer/policy/normal/std Std                0.120204
trainer/policy/normal/std Max                0.782953
trainer/policy/normal/std Min                0.113573
trainer/policy/normal/log_std Mean          -0.979578
trainer/policy/normal/log_std Std            0.333751
trainer/policy/normal/log_std Max           -0.244682
trainer/policy/normal/log_std Min           -2.17531
trainer/Alpha                                0.0159005
trainer/Alpha Loss                          -9.1118
expl/num steps total                     17000
expl/num paths total                        17
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.0675538
expl/Rewards Std                             0.900305
expl/Rewards Max                             2.60841
expl/Rewards Min                            -2.58632
expl/Returns Mean                           67.5538
expl/Returns Std                             0
expl/Returns Max                            67.5538
expl/Returns Min                            67.5538
expl/Actions Mean                            0.0790029
expl/Actions Std                             0.698752
expl/Actions Max                             0.999911
expl/Actions Min                            -0.999975
expl/Num Paths                               1
expl/Average Returns                        67.5538
expl/env_infos/final/reward_run Mean         1.31035
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          1.31035
expl/env_infos/final/reward_run Min          1.31035
expl/env_infos/initial/reward_run Mean       0.105506
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.105506
expl/env_infos/initial/reward_run Min        0.105506
expl/env_infos/reward_run Mean               0.364251
expl/env_infos/reward_run Std                0.885606
expl/env_infos/reward_run Max                2.94054
expl/env_infos/reward_run Min               -2.17462
expl/env_infos/final/reward_ctrl Mean       -0.221535
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.221535
expl/env_infos/final/reward_ctrl Min        -0.221535
expl/env_infos/initial/reward_ctrl Mean     -0.0604831
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.0604831
expl/env_infos/initial/reward_ctrl Min      -0.0604831
expl/env_infos/reward_ctrl Mean             -0.296697
expl/env_infos/reward_ctrl Std               0.0847024
expl/env_infos/reward_ctrl Max              -0.0396928
expl/env_infos/reward_ctrl Min              -0.534617
eval/num steps total                     80000
eval/num paths total                        80
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.113219
eval/Rewards Std                             0.939424
eval/Rewards Max                             3.10229
eval/Rewards Min                            -3.12521
eval/Returns Mean                          113.219
eval/Returns Std                            36.7092
eval/Returns Max                           168.944
eval/Returns Min                            63.065
eval/Actions Mean                            0.0481643
eval/Actions Std                             0.689469
eval/Actions Max                             0.999985
eval/Actions Min                            -0.999918
eval/Num Paths                               5
eval/Average Returns                       113.219
eval/env_infos/final/reward_run Mean         0.22246
eval/env_infos/final/reward_run Std          1.09163
eval/env_infos/final/reward_run Max          1.92195
eval/env_infos/final/reward_run Min         -1.2389
eval/env_infos/initial/reward_run Mean       0.140676
eval/env_infos/initial/reward_run Std        0.0777975
eval/env_infos/initial/reward_run Max        0.205742
eval/env_infos/initial/reward_run Min        0.0238669
eval/env_infos/reward_run Mean               0.399831
eval/env_infos/reward_run Std                0.91873
eval/env_infos/reward_run Max                3.28646
eval/env_infos/reward_run Min               -2.74202
eval/env_infos/final/reward_ctrl Mean       -0.25139
eval/env_infos/final/reward_ctrl Std         0.137189
eval/env_infos/final/reward_ctrl Max        -0.0559468
eval/env_infos/final/reward_ctrl Min        -0.418713
eval/env_infos/initial/reward_ctrl Mean     -0.0181137
eval/env_infos/initial/reward_ctrl Std       0.00685335
eval/env_infos/initial/reward_ctrl Max      -0.00937672
eval/env_infos/initial/reward_ctrl Min      -0.0270071
eval/env_infos/reward_ctrl Mean             -0.286612
eval/env_infos/reward_ctrl Std               0.0872226
eval/env_infos/reward_ctrl Max              -0.00784115
eval/env_infos/reward_ctrl Min              -0.553807
time/data storing (s)                        0.00516411
time/evaluation sampling (s)                 2.05822
time/exploration sampling (s)                0.538661
time/logging (s)                             0.0141399
time/sac training (s)                        7.77136
time/saving (s)                              0.00439662
time/training (s)                            3.9027e-05
time/epoch (s)                              10.392
time/total (s)                             173.481
Epoch                                       15
---------------------------------------  --------------
2021-11-24 00:32:14.530993 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 16 finished
---------------------------------------  --------------
epoch                                       16
replay_buffer/size                       18000
trainer/num train calls                  17000
trainer/QF1 Loss                             1.04048
trainer/QF2 Loss                             1.05795
trainer/Policy Loss                        -24.6152
trainer/Q1 Predictions Mean                 24.4869
trainer/Q1 Predictions Std                   8.22581
trainer/Q1 Predictions Max                  52.3964
trainer/Q1 Predictions Min                  15.8208
trainer/Q2 Predictions Mean                 24.43
trainer/Q2 Predictions Std                   8.21251
trainer/Q2 Predictions Max                  52.1311
trainer/Q2 Predictions Min                  15.511
trainer/Q Targets Mean                      24.5453
trainer/Q Targets Std                        8.36486
trainer/Q Targets Max                       52.4367
trainer/Q Targets Min                       15.854
trainer/Log Pis Mean                         4.44396
trainer/Log Pis Std                          3.92916
trainer/Log Pis Max                         22.8345
trainer/Log Pis Min                         -3.85763
trainer/policy/mean Mean                    -0.00601696
trainer/policy/mean Std                      0.671749
trainer/policy/mean Max                      0.999886
trainer/policy/mean Min                     -0.99931
trainer/policy/normal/std Mean               0.365693
trainer/policy/normal/std Std                0.111369
trainer/policy/normal/std Max                0.803954
trainer/policy/normal/std Min                0.103129
trainer/policy/normal/log_std Mean          -1.05531
trainer/policy/normal/log_std Std            0.322739
trainer/policy/normal/log_std Max           -0.218213
trainer/policy/normal/log_std Min           -2.27177
trainer/Alpha                                0.0130358
trainer/Alpha Loss                          -6.75332
expl/num steps total                     18000
expl/num paths total                        18
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.0486096
expl/Rewards Std                             0.908664
expl/Rewards Max                             2.61531
expl/Rewards Min                            -2.41105
expl/Returns Mean                           48.6096
expl/Returns Std                             0
expl/Returns Max                            48.6096
expl/Returns Min                            48.6096
expl/Actions Mean                           -0.0105889
expl/Actions Std                             0.711632
expl/Actions Max                             0.999971
expl/Actions Min                            -0.999999
expl/Num Paths                               1
expl/Average Returns                        48.6096
expl/env_infos/final/reward_run Mean        -0.621805
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.621805
expl/env_infos/final/reward_run Min         -0.621805
expl/env_infos/initial/reward_run Mean       0.0613643
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.0613643
expl/env_infos/initial/reward_run Min        0.0613643
expl/env_infos/reward_run Mean               0.352529
expl/env_infos/reward_run Std                0.900143
expl/env_infos/reward_run Max                2.95716
expl/env_infos/reward_run Min               -1.98473
expl/env_infos/final/reward_ctrl Mean       -0.210289
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.210289
expl/env_infos/final/reward_ctrl Min        -0.210289
expl/env_infos/initial/reward_ctrl Mean     -0.0323305
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.0323305
expl/env_infos/initial/reward_ctrl Min      -0.0323305
expl/env_infos/reward_ctrl Mean             -0.30392
expl/env_infos/reward_ctrl Std               0.0914105
expl/env_infos/reward_ctrl Max              -0.0323305
expl/env_infos/reward_ctrl Min              -0.577014
eval/num steps total                     85000
eval/num paths total                        85
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.204881
eval/Rewards Std                             0.913901
eval/Rewards Max                             2.85033
eval/Rewards Min                            -4.52791
eval/Returns Mean                          204.881
eval/Returns Std                            65.2386
eval/Returns Max                           282.615
eval/Returns Min                           113.84
eval/Actions Mean                           -0.00761837
eval/Actions Std                             0.693012
eval/Actions Max                             0.999996
eval/Actions Min                            -0.999997
eval/Num Paths                               5
eval/Average Returns                       204.881
eval/env_infos/final/reward_run Mean         1.39761
eval/env_infos/final/reward_run Std          0.915708
eval/env_infos/final/reward_run Max          2.90472
eval/env_infos/final/reward_run Min          0.280775
eval/env_infos/initial/reward_run Mean      -0.00234437
eval/env_infos/initial/reward_run Std        0.0672191
eval/env_infos/initial/reward_run Max        0.0662945
eval/env_infos/initial/reward_run Min       -0.107548
eval/env_infos/reward_run Mean               0.493075
eval/env_infos/reward_run Std                0.904564
eval/env_infos/reward_run Max                3.23402
eval/env_infos/reward_run Min               -4.16747
eval/env_infos/final/reward_ctrl Mean       -0.33918
eval/env_infos/final/reward_ctrl Std         0.0643494
eval/env_infos/final/reward_ctrl Max        -0.240117
eval/env_infos/final/reward_ctrl Min        -0.418008
eval/env_infos/initial/reward_ctrl Mean     -0.0185508
eval/env_infos/initial/reward_ctrl Std       0.0068144
eval/env_infos/initial/reward_ctrl Max      -0.00604644
eval/env_infos/initial/reward_ctrl Min      -0.0258196
eval/env_infos/reward_ctrl Mean             -0.288194
eval/env_infos/reward_ctrl Std               0.0972662
eval/env_infos/reward_ctrl Max              -0.00604644
eval/env_infos/reward_ctrl Min              -0.57889
time/data storing (s)                        0.00449168
time/evaluation sampling (s)                 2.04391
time/exploration sampling (s)                0.539042
time/logging (s)                             0.0161218
time/sac training (s)                        7.72653
time/saving (s)                              0.00389508
time/training (s)                            4.9526e-05
time/epoch (s)                              10.334
time/total (s)                             184.115
Epoch                                       16
---------------------------------------  --------------
2021-11-24 00:32:25.253100 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 17 finished
---------------------------------------  --------------
epoch                                       17
replay_buffer/size                       19000
trainer/num train calls                  18000
trainer/QF1 Loss                             1.35136
trainer/QF2 Loss                             1.24634
trainer/Policy Loss                        -23.2524
trainer/Q1 Predictions Mean                 23.206
trainer/Q1 Predictions Std                   8.04496
trainer/Q1 Predictions Max                  52.6388
trainer/Q1 Predictions Min                  14.754
trainer/Q2 Predictions Mean                 23.149
trainer/Q2 Predictions Std                   8.01314
trainer/Q2 Predictions Max                  53.1812
trainer/Q2 Predictions Min                  14.102
trainer/Q Targets Mean                      23.2128
trainer/Q Targets Std                        8.19451
trainer/Q Targets Max                       52.516
trainer/Q Targets Min                       14.8501
trainer/Log Pis Mean                         5.678
trainer/Log Pis Std                          4.31781
trainer/Log Pis Max                         20.0488
trainer/Log Pis Min                         -3.1642
trainer/policy/mean Mean                    -0.0752756
trainer/policy/mean Std                      0.692463
trainer/policy/mean Max                      0.999981
trainer/policy/mean Min                     -0.999486
trainer/policy/normal/std Mean               0.343541
trainer/policy/normal/std Std                0.12549
trainer/policy/normal/std Max                0.94831
trainer/policy/normal/std Min                0.0861806
trainer/policy/normal/log_std Mean          -1.13668
trainer/policy/normal/log_std Std            0.377968
trainer/policy/normal/log_std Max           -0.0530737
trainer/policy/normal/log_std Min           -2.45131
trainer/Alpha                                0.0110948
trainer/Alpha Loss                          -1.4494
expl/num steps total                     19000
expl/num paths total                        19
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.198579
expl/Rewards Std                             0.876351
expl/Rewards Max                             2.38367
expl/Rewards Min                            -2.46917
expl/Returns Mean                          198.579
expl/Returns Std                             0
expl/Returns Max                           198.579
expl/Returns Min                           198.579
expl/Actions Mean                           -0.102085
expl/Actions Std                             0.712684
expl/Actions Max                             0.999944
expl/Actions Min                            -0.99998
expl/Num Paths                               1
expl/Average Returns                       198.579
expl/env_infos/final/reward_run Mean         0.497313
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max          0.497313
expl/env_infos/final/reward_run Min          0.497313
expl/env_infos/initial/reward_run Mean       0.0780852
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max        0.0780852
expl/env_infos/initial/reward_run Min        0.0780852
expl/env_infos/reward_run Mean               0.509582
expl/env_infos/reward_run Std                0.871086
expl/env_infos/reward_run Max                2.61487
expl/env_infos/reward_run Min               -2.03777
expl/env_infos/final/reward_ctrl Mean       -0.365996
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.365996
expl/env_infos/final/reward_ctrl Min        -0.365996
expl/env_infos/initial/reward_ctrl Mean     -0.0154883
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.0154883
expl/env_infos/initial/reward_ctrl Min      -0.0154883
expl/env_infos/reward_ctrl Mean             -0.311004
expl/env_infos/reward_ctrl Std               0.0959699
expl/env_infos/reward_ctrl Max              -0.0154883
expl/env_infos/reward_ctrl Min              -0.559302
eval/num steps total                     90000
eval/num paths total                        90
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.18832
eval/Rewards Std                             0.922229
eval/Rewards Max                             2.9209
eval/Rewards Min                            -4.15865
eval/Returns Mean                          188.32
eval/Returns Std                            35.4914
eval/Returns Max                           218.075
eval/Returns Min                           119.673
eval/Actions Mean                           -0.106038
eval/Actions Std                             0.716857
eval/Actions Max                             0.999997
eval/Actions Min                            -0.99998
eval/Num Paths                               5
eval/Average Returns                       188.32
eval/env_infos/final/reward_run Mean         0.627039
eval/env_infos/final/reward_run Std          0.897177
eval/env_infos/final/reward_run Max          2.25946
eval/env_infos/final/reward_run Min         -0.104217
eval/env_infos/initial/reward_run Mean      -0.14313
eval/env_infos/initial/reward_run Std        0.179578
eval/env_infos/initial/reward_run Max        0.193139
eval/env_infos/initial/reward_run Min       -0.303558
eval/env_infos/reward_run Mean               0.503398
eval/env_infos/reward_run Std                0.91016
eval/env_infos/reward_run Max                3.05471
eval/env_infos/reward_run Min               -3.61029
eval/env_infos/final/reward_ctrl Mean       -0.328632
eval/env_infos/final/reward_ctrl Std         0.0527891
eval/env_infos/final/reward_ctrl Max        -0.273796
eval/env_infos/final/reward_ctrl Min        -0.423908
eval/env_infos/initial/reward_ctrl Mean     -0.0217421
eval/env_infos/initial/reward_ctrl Std       0.0108723
eval/env_infos/initial/reward_ctrl Max      -0.00498872
eval/env_infos/initial/reward_ctrl Min      -0.0332211
eval/env_infos/reward_ctrl Mean             -0.315077
eval/env_infos/reward_ctrl Std               0.0958332
eval/env_infos/reward_ctrl Max              -0.00498872
eval/env_infos/reward_ctrl Min              -0.579967
time/data storing (s)                        0.00451027
time/evaluation sampling (s)                 2.05042
time/exploration sampling (s)                0.542393
time/logging (s)                             0.0141667
time/sac training (s)                        7.78821
time/saving (s)                              0.00392026
time/training (s)                            3.4685e-05
time/epoch (s)                              10.4037
time/total (s)                             194.82
Epoch                                       17
---------------------------------------  --------------
2021-11-24 00:32:36.094208 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 18 finished
---------------------------------------  --------------
epoch                                       18
replay_buffer/size                       20000
trainer/num train calls                  19000
trainer/QF1 Loss                             1.03378
trainer/QF2 Loss                             0.94084
trainer/Policy Loss                        -23.1254
trainer/Q1 Predictions Mean                 22.9393
trainer/Q1 Predictions Std                   8.66235
trainer/Q1 Predictions Max                  53.9743
trainer/Q1 Predictions Min                  14.2488
trainer/Q2 Predictions Mean                 22.9232
trainer/Q2 Predictions Std                   8.71376
trainer/Q2 Predictions Max                  53.613
trainer/Q2 Predictions Min                  14.0557
trainer/Q Targets Mean                      22.8735
trainer/Q Targets Std                        8.78058
trainer/Q Targets Max                       56.6612
trainer/Q Targets Min                       13.5416
trainer/Log Pis Mean                         5.7022
trainer/Log Pis Std                          4.87013
trainer/Log Pis Max                         21.0225
trainer/Log Pis Min                        -12.0971
trainer/policy/mean Mean                     0.0902317
trainer/policy/mean Std                      0.685573
trainer/policy/mean Max                      0.999915
trainer/policy/mean Min                     -0.999931
trainer/policy/normal/std Mean               0.335926
trainer/policy/normal/std Std                0.120911
trainer/policy/normal/std Max                1.02042
trainer/policy/normal/std Min                0.0409419
trainer/policy/normal/log_std Mean          -1.1606
trainer/policy/normal/log_std Std            0.389631
trainer/policy/normal/log_std Max            0.0202102
trainer/policy/normal/log_std Min           -3.1956
trainer/Alpha                                0.0101899
trainer/Alpha Loss                          -1.3658
expl/num steps total                     20000
expl/num paths total                        20
expl/path length Mean                     1000
expl/path length Std                         0
expl/path length Max                      1000
expl/path length Min                      1000
expl/Rewards Mean                            0.334515
expl/Rewards Std                             0.816249
expl/Rewards Max                             2.46677
expl/Rewards Min                            -2.45431
expl/Returns Mean                          334.515
expl/Returns Std                             0
expl/Returns Max                           334.515
expl/Returns Min                           334.515
expl/Actions Mean                           -0.0181834
expl/Actions Std                             0.693438
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                               1
expl/Average Returns                       334.515
expl/env_infos/final/reward_run Mean        -0.555799
expl/env_infos/final/reward_run Std          0
expl/env_infos/final/reward_run Max         -0.555799
expl/env_infos/final/reward_run Min         -0.555799
expl/env_infos/initial/reward_run Mean      -0.241837
expl/env_infos/initial/reward_run Std        0
expl/env_infos/initial/reward_run Max       -0.241837
expl/env_infos/initial/reward_run Min       -0.241837
expl/env_infos/reward_run Mean               0.623226
expl/env_infos/reward_run Std                0.788147
expl/env_infos/reward_run Max                2.84072
expl/env_infos/reward_run Min               -1.99876
expl/env_infos/final/reward_ctrl Mean       -0.408214
expl/env_infos/final/reward_ctrl Std         0
expl/env_infos/final/reward_ctrl Max        -0.408214
expl/env_infos/final/reward_ctrl Min        -0.408214
expl/env_infos/initial/reward_ctrl Mean     -0.0376646
expl/env_infos/initial/reward_ctrl Std       0
expl/env_infos/initial/reward_ctrl Max      -0.0376646
expl/env_infos/initial/reward_ctrl Min      -0.0376646
expl/env_infos/reward_ctrl Mean             -0.288712
expl/env_infos/reward_ctrl Std               0.105783
expl/env_infos/reward_ctrl Max              -0.0231329
expl/env_infos/reward_ctrl Min              -0.5878
eval/num steps total                     95000
eval/num paths total                        95
eval/path length Mean                     1000
eval/path length Std                         0
eval/path length Max                      1000
eval/path length Min                      1000
eval/Rewards Mean                            0.135495
eval/Rewards Std                             0.921101
eval/Rewards Max                             2.70109
eval/Rewards Min                            -3.19277
eval/Returns Mean                          135.495
eval/Returns Std                            68.7098
eval/Returns Max                           231.311
eval/Returns Min                            58.5125
eval/Actions Mean                            0.0417726
eval/Actions Std                             0.724846
eval/Actions Max                             0.999997
eval/Actions Min                            -0.999992
eval/Num Paths                               5
eval/Average Returns                       135.495
eval/env_infos/final/reward_run Mean         1.29255
eval/env_infos/final/reward_run Std          0.340643
eval/env_infos/final/reward_run Max          1.69235
eval/env_infos/final/reward_run Min          0.756029
eval/env_infos/initial/reward_run Mean      -0.14715
eval/env_infos/initial/reward_run Std        0.206766
eval/env_infos/initial/reward_run Max        0.123504
eval/env_infos/initial/reward_run Min       -0.486301
eval/env_infos/reward_run Mean               0.451783
eval/env_infos/reward_run Std                0.900297
eval/env_infos/reward_run Max                3.05227
eval/env_infos/reward_run Min               -2.77978
eval/env_infos/final/reward_ctrl Mean       -0.319461
eval/env_infos/final/reward_ctrl Std         0.0881838
eval/env_infos/final/reward_ctrl Max        -0.182933
eval/env_infos/final/reward_ctrl Min        -0.415718
eval/env_infos/initial/reward_ctrl Mean     -0.0178941
eval/env_infos/initial/reward_ctrl Std       0.012165
eval/env_infos/initial/reward_ctrl Max      -0.00530941
eval/env_infos/initial/reward_ctrl Min      -0.0387644
eval/env_infos/reward_ctrl Mean             -0.316288
eval/env_infos/reward_ctrl Std               0.104491
eval/env_infos/reward_ctrl Max              -0.00530941
eval/env_infos/reward_ctrl Min              -0.592726
time/data storing (s)                        0.00447933
time/evaluation sampling (s)                 2.05081
time/exploration sampling (s)                0.52592
time/logging (s)                             0.0145835
time/sac training (s)                        7.91532
time/saving (s)                              0.00387013
time/training (s)                            4.7091e-05
time/epoch (s)                              10.515
time/total (s)                             205.647
Epoch                                       18
---------------------------------------  --------------
2021-11-24 00:32:46.959213 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 19 finished
---------------------------------------  ---------------
epoch                                        19
replay_buffer/size                        21000
trainer/num train calls                   20000
trainer/QF1 Loss                              1.21561
trainer/QF2 Loss                              1.12238
trainer/Policy Loss                         -22.4987
trainer/Q1 Predictions Mean                  22.3679
trainer/Q1 Predictions Std                    9.31651
trainer/Q1 Predictions Max                   53.6813
trainer/Q1 Predictions Min                   12.0243
trainer/Q2 Predictions Mean                  22.3824
trainer/Q2 Predictions Std                    9.42886
trainer/Q2 Predictions Max                   53.7848
trainer/Q2 Predictions Min                   11.546
trainer/Q Targets Mean                       22.1918
trainer/Q Targets Std                         9.50602
trainer/Q Targets Max                        50.2042
trainer/Q Targets Min                        10.528
trainer/Log Pis Mean                          6.05332
trainer/Log Pis Std                           4.54153
trainer/Log Pis Max                          21.2481
trainer/Log Pis Min                          -5.92628
trainer/policy/mean Mean                      0.0320428
trainer/policy/mean Std                       0.710623
trainer/policy/mean Max                       0.999738
trainer/policy/mean Min                      -0.999911
trainer/policy/normal/std Mean                0.337071
trainer/policy/normal/std Std                 0.118518
trainer/policy/normal/std Max                 1.03869
trainer/policy/normal/std Min                 0.0971443
trainer/policy/normal/log_std Mean           -1.1513
trainer/policy/normal/log_std Std             0.365657
trainer/policy/normal/log_std Max             0.0379634
trainer/policy/normal/log_std Min            -2.33156
trainer/Alpha                                 0.0100205
trainer/Alpha Loss                            0.245431
expl/num steps total                      21000
expl/num paths total                         21
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.319199
expl/Rewards Std                              0.903503
expl/Rewards Max                              2.83727
expl/Rewards Min                             -2.20138
expl/Returns Mean                           319.199
expl/Returns Std                              0
expl/Returns Max                            319.199
expl/Returns Min                            319.199
expl/Actions Mean                            -0.00696221
expl/Actions Std                              0.73876
expl/Actions Max                              0.999998
expl/Actions Min                             -0.999996
expl/Num Paths                                1
expl/Average Returns                        319.199
expl/env_infos/final/reward_run Mean         -0.60265
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max          -0.60265
expl/env_infos/final/reward_run Min          -0.60265
expl/env_infos/initial/reward_run Mean       -0.0924992
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0924992
expl/env_infos/initial/reward_run Min        -0.0924992
expl/env_infos/reward_run Mean                0.646688
expl/env_infos/reward_run Std                 0.884634
expl/env_infos/reward_run Max                 3.17143
expl/env_infos/reward_run Min                -1.63927
expl/env_infos/final/reward_ctrl Mean        -0.345856
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.345856
expl/env_infos/final/reward_ctrl Min         -0.345856
expl/env_infos/initial/reward_ctrl Mean      -0.0220355
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0220355
expl/env_infos/initial/reward_ctrl Min       -0.0220355
expl/env_infos/reward_ctrl Mean              -0.327489
expl/env_infos/reward_ctrl Std                0.100067
expl/env_infos/reward_ctrl Max               -0.0220355
expl/env_infos/reward_ctrl Min               -0.573882
eval/num steps total                     100000
eval/num paths total                        100
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             0.28785
eval/Rewards Std                              0.915764
eval/Rewards Max                              3.14163
eval/Rewards Min                             -2.91853
eval/Returns Mean                           287.85
eval/Returns Std                            121.582
eval/Returns Max                            512.564
eval/Returns Min                            162.789
eval/Actions Mean                             0.00374719
eval/Actions Std                              0.737804
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                                5
eval/Average Returns                        287.85
eval/env_infos/final/reward_run Mean         -0.0528011
eval/env_infos/final/reward_run Std           0.278054
eval/env_infos/final/reward_run Max           0.243058
eval/env_infos/final/reward_run Min          -0.429462
eval/env_infos/initial/reward_run Mean       -0.00202556
eval/env_infos/initial/reward_run Std         0.113449
eval/env_infos/initial/reward_run Max         0.15655
eval/env_infos/initial/reward_run Min        -0.182515
eval/env_infos/reward_run Mean                0.614471
eval/env_infos/reward_run Std                 0.886346
eval/env_infos/reward_run Max                 3.39652
eval/env_infos/reward_run Min                -2.4234
eval/env_infos/final/reward_ctrl Mean        -0.350107
eval/env_infos/final/reward_ctrl Std          0.0822357
eval/env_infos/final/reward_ctrl Max         -0.224838
eval/env_infos/final/reward_ctrl Min         -0.455825
eval/env_infos/initial/reward_ctrl Mean      -0.0184777
eval/env_infos/initial/reward_ctrl Std        0.00803037
eval/env_infos/initial/reward_ctrl Max       -0.00631127
eval/env_infos/initial/reward_ctrl Min       -0.0282036
eval/env_infos/reward_ctrl Mean              -0.326621
eval/env_infos/reward_ctrl Std                0.111879
eval/env_infos/reward_ctrl Max               -0.00631127
eval/env_infos/reward_ctrl Min               -0.587623
time/data storing (s)                         0.00453199
time/evaluation sampling (s)                  2.20755
time/exploration sampling (s)                 0.534835
time/logging (s)                              0.0137751
time/sac training (s)                         7.78369
time/saving (s)                               0.00382352
time/training (s)                             3.4416e-05
time/epoch (s)                               10.5482
time/total (s)                              216.497
Epoch                                        19
---------------------------------------  ---------------
2021-11-24 00:32:57.677370 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 20 finished
---------------------------------------  ---------------
epoch                                        20
replay_buffer/size                        22000
trainer/num train calls                   21000
trainer/QF1 Loss                              1.22858
trainer/QF2 Loss                              1.19386
trainer/Policy Loss                         -22.6651
trainer/Q1 Predictions Mean                  22.531
trainer/Q1 Predictions Std                   10.5006
trainer/Q1 Predictions Max                   53.1544
trainer/Q1 Predictions Min                   10.6396
trainer/Q2 Predictions Mean                  22.5211
trainer/Q2 Predictions Std                   10.4737
trainer/Q2 Predictions Max                   52.1709
trainer/Q2 Predictions Min                   10.3091
trainer/Q Targets Mean                       22.5731
trainer/Q Targets Std                        10.5404
trainer/Q Targets Max                        53.4051
trainer/Q Targets Min                         9.89544
trainer/Log Pis Mean                          6.06424
trainer/Log Pis Std                           4.07599
trainer/Log Pis Max                          20.8694
trainer/Log Pis Min                          -3.70225
trainer/policy/mean Mean                     -0.00564145
trainer/policy/mean Std                       0.707176
trainer/policy/mean Max                       0.999564
trainer/policy/mean Min                      -0.999923
trainer/policy/normal/std Mean                0.331478
trainer/policy/normal/std Std                 0.123564
trainer/policy/normal/std Max                 0.811368
trainer/policy/normal/std Min                 0.082126
trainer/policy/normal/log_std Mean           -1.17688
trainer/policy/normal/log_std Std             0.391482
trainer/policy/normal/log_std Max            -0.209033
trainer/policy/normal/log_std Min            -2.4995
trainer/Alpha                                 0.00971888
trainer/Alpha Loss                            0.297673
expl/num steps total                      22000
expl/num paths total                         22
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.223884
expl/Rewards Std                              0.992878
expl/Rewards Max                              2.73439
expl/Rewards Min                             -3.0841
expl/Returns Mean                           223.884
expl/Returns Std                              0
expl/Returns Max                            223.884
expl/Returns Min                            223.884
expl/Actions Mean                             0.0218087
expl/Actions Std                              0.74671
expl/Actions Max                              0.999979
expl/Actions Min                             -0.999998
expl/Num Paths                                1
expl/Average Returns                        223.884
expl/env_infos/final/reward_run Mean          0.438912
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.438912
expl/env_infos/final/reward_run Min           0.438912
expl/env_infos/initial/reward_run Mean       -0.265841
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.265841
expl/env_infos/initial/reward_run Min        -0.265841
expl/env_infos/reward_run Mean                0.558715
expl/env_infos/reward_run Std                 0.97332
expl/env_infos/reward_run Max                 2.96487
expl/env_infos/reward_run Min                -2.68999
expl/env_infos/final/reward_ctrl Mean        -0.450789
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.450789
expl/env_infos/final/reward_ctrl Min         -0.450789
expl/env_infos/initial/reward_ctrl Mean      -0.0294258
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0294258
expl/env_infos/initial/reward_ctrl Min       -0.0294258
expl/env_infos/reward_ctrl Mean              -0.334831
expl/env_infos/reward_ctrl Std                0.103945
expl/env_infos/reward_ctrl Max               -0.0294258
expl/env_infos/reward_ctrl Min               -0.566938
eval/num steps total                     105000
eval/num paths total                        105
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             0.249442
eval/Rewards Std                              0.931126
eval/Rewards Max                              2.66994
eval/Rewards Min                             -2.64429
eval/Returns Mean                           249.442
eval/Returns Std                             45.5844
eval/Returns Max                            301.976
eval/Returns Min                            169.709
eval/Actions Mean                             0.0311747
eval/Actions Std                              0.738229
eval/Actions Max                              0.999988
eval/Actions Min                             -0.999993
eval/Num Paths                                5
eval/Average Returns                        249.442
eval/env_infos/final/reward_run Mean          0.116658
eval/env_infos/final/reward_run Std           0.869627
eval/env_infos/final/reward_run Max           1.69019
eval/env_infos/final/reward_run Min          -0.645054
eval/env_infos/initial/reward_run Mean        0.0783714
eval/env_infos/initial/reward_run Std         0.151819
eval/env_infos/initial/reward_run Max         0.234204
eval/env_infos/initial/reward_run Min        -0.185476
eval/env_infos/reward_run Mean                0.577014
eval/env_infos/reward_run Std                 0.907564
eval/env_infos/reward_run Max                 3.02586
eval/env_infos/reward_run Min                -2.16776
eval/env_infos/final/reward_ctrl Mean        -0.386647
eval/env_infos/final/reward_ctrl Std          0.0271798
eval/env_infos/final/reward_ctrl Max         -0.347264
eval/env_infos/final/reward_ctrl Min         -0.426152
eval/env_infos/initial/reward_ctrl Mean      -0.0186894
eval/env_infos/initial/reward_ctrl Std        0.0134147
eval/env_infos/initial/reward_ctrl Max       -0.00962597
eval/env_infos/initial/reward_ctrl Min       -0.0452153
eval/env_infos/reward_ctrl Mean              -0.327572
eval/env_infos/reward_ctrl Std                0.103812
eval/env_infos/reward_ctrl Max               -0.00962597
eval/env_infos/reward_ctrl Min               -0.587651
time/data storing (s)                         0.00446381
time/evaluation sampling (s)                  2.07329
time/exploration sampling (s)                 0.54206
time/logging (s)                              0.0137925
time/sac training (s)                         7.7659
time/saving (s)                               0.00379736
time/training (s)                             3.5403e-05
time/epoch (s)                               10.4033
time/total (s)                              227.201
Epoch                                        20
---------------------------------------  ---------------
2021-11-24 00:33:08.369373 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 21 finished
---------------------------------------  ---------------
epoch                                        21
replay_buffer/size                        23000
trainer/num train calls                   22000
trainer/QF1 Loss                              0.929189
trainer/QF2 Loss                              1.10498
trainer/Policy Loss                         -23.4279
trainer/Q1 Predictions Mean                  23.2837
trainer/Q1 Predictions Std                   10.9757
trainer/Q1 Predictions Max                   52.8986
trainer/Q1 Predictions Min                   11.1824
trainer/Q2 Predictions Mean                  23.2771
trainer/Q2 Predictions Std                   11.054
trainer/Q2 Predictions Max                   53.6513
trainer/Q2 Predictions Min                   10.3362
trainer/Q Targets Mean                       23.3124
trainer/Q Targets Std                        10.9995
trainer/Q Targets Max                        54.6739
trainer/Q Targets Min                        10.3189
trainer/Log Pis Mean                          6.07881
trainer/Log Pis Std                           4.13072
trainer/Log Pis Max                          23.8941
trainer/Log Pis Min                          -4.0062
trainer/policy/mean Mean                      0.0320253
trainer/policy/mean Std                       0.68917
trainer/policy/mean Max                       0.999868
trainer/policy/mean Min                      -0.99991
trainer/policy/normal/std Mean                0.31767
trainer/policy/normal/std Std                 0.129035
trainer/policy/normal/std Max                 0.935006
trainer/policy/normal/std Min                 0.0575501
trainer/policy/normal/log_std Mean           -1.23146
trainer/policy/normal/log_std Std             0.421429
trainer/policy/normal/log_std Max            -0.0672027
trainer/policy/normal/log_std Min            -2.8551
trainer/Alpha                                 0.00953238
trainer/Alpha Loss                            0.366684
expl/num steps total                      23000
expl/num paths total                         23
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.470876
expl/Rewards Std                              0.61062
expl/Rewards Max                              2.37124
expl/Rewards Min                             -2.47554
expl/Returns Mean                           470.876
expl/Returns Std                              0
expl/Returns Max                            470.876
expl/Returns Min                            470.876
expl/Actions Mean                             0.0510329
expl/Actions Std                              0.639139
expl/Actions Max                              0.999973
expl/Actions Min                             -0.999994
expl/Num Paths                                1
expl/Average Returns                        470.876
expl/env_infos/final/reward_run Mean          0.09568
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.09568
expl/env_infos/final/reward_run Min           0.09568
expl/env_infos/initial/reward_run Mean        0.0875888
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0875888
expl/env_infos/initial/reward_run Min         0.0875888
expl/env_infos/reward_run Mean                0.717538
expl/env_infos/reward_run Std                 0.5729
expl/env_infos/reward_run Max                 2.57747
expl/env_infos/reward_run Min                -2.00301
expl/env_infos/final/reward_ctrl Mean        -0.410914
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.410914
expl/env_infos/final/reward_ctrl Min         -0.410914
expl/env_infos/initial/reward_ctrl Mean      -0.0129313
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0129313
expl/env_infos/initial/reward_ctrl Min       -0.0129313
expl/env_infos/reward_ctrl Mean              -0.246662
expl/env_infos/reward_ctrl Std                0.11229
expl/env_infos/reward_ctrl Max               -0.0129313
expl/env_infos/reward_ctrl Min               -0.558304
eval/num steps total                     110000
eval/num paths total                        110
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             0.54666
eval/Rewards Std                              0.560908
eval/Rewards Max                              2.40076
eval/Rewards Min                             -2.3947
eval/Returns Mean                           546.66
eval/Returns Std                             47.2882
eval/Returns Max                            587.969
eval/Returns Min                            457.142
eval/Actions Mean                             0.0311198
eval/Actions Std                              0.595689
eval/Actions Max                              0.999985
eval/Actions Min                             -0.999829
eval/Num Paths                                5
eval/Average Returns                        546.66
eval/env_infos/final/reward_run Mean          0.87009
eval/env_infos/final/reward_run Std           0.516002
eval/env_infos/final/reward_run Max           1.66096
eval/env_infos/final/reward_run Min           0.25655
eval/env_infos/initial/reward_run Mean        0.0636713
eval/env_infos/initial/reward_run Std         0.188023
eval/env_infos/initial/reward_run Max         0.36691
eval/env_infos/initial/reward_run Min        -0.162297
eval/env_infos/reward_run Mean                0.760149
eval/env_infos/reward_run Std                 0.543126
eval/env_infos/reward_run Max                 2.76249
eval/env_infos/reward_run Min                -1.97322
eval/env_infos/final/reward_ctrl Mean        -0.309078
eval/env_infos/final/reward_ctrl Std          0.133589
eval/env_infos/final/reward_ctrl Max         -0.0818783
eval/env_infos/final/reward_ctrl Min         -0.490571
eval/env_infos/initial/reward_ctrl Mean      -0.0138904
eval/env_infos/initial/reward_ctrl Std        0.00672164
eval/env_infos/initial/reward_ctrl Max       -0.00313045
eval/env_infos/initial/reward_ctrl Min       -0.0237732
eval/env_infos/reward_ctrl Mean              -0.213488
eval/env_infos/reward_ctrl Std                0.0982003
eval/env_infos/reward_ctrl Max               -0.00313045
eval/env_infos/reward_ctrl Min               -0.555081
time/data storing (s)                         0.00453348
time/evaluation sampling (s)                  2.11927
time/exploration sampling (s)                 0.548658
time/logging (s)                              0.0139031
time/sac training (s)                         7.69171
time/saving (s)                               0.00392765
time/training (s)                             4.7029e-05
time/epoch (s)                               10.3821
time/total (s)                              237.879
Epoch                                        21
---------------------------------------  ---------------
2021-11-24 00:33:18.968424 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 22 finished
---------------------------------------  ---------------
epoch                                        22
replay_buffer/size                        24000
trainer/num train calls                   23000
trainer/QF1 Loss                              1.24843
trainer/QF2 Loss                              1.03405
trainer/Policy Loss                         -21.6116
trainer/Q1 Predictions Mean                  21.5287
trainer/Q1 Predictions Std                   10.2375
trainer/Q1 Predictions Max                   47.3435
trainer/Q1 Predictions Min                   10.5162
trainer/Q2 Predictions Mean                  21.535
trainer/Q2 Predictions Std                   10.2912
trainer/Q2 Predictions Max                   47.3752
trainer/Q2 Predictions Min                   10.33
trainer/Q Targets Mean                       21.4745
trainer/Q Targets Std                        10.5253
trainer/Q Targets Max                        48.3563
trainer/Q Targets Min                         9.09519
trainer/Log Pis Mean                          6.86627
trainer/Log Pis Std                           4.56804
trainer/Log Pis Max                          26.0682
trainer/Log Pis Min                          -2.64842
trainer/policy/mean Mean                     -0.0794513
trainer/policy/mean Std                       0.706896
trainer/policy/mean Max                       0.999776
trainer/policy/mean Min                      -0.999982
trainer/policy/normal/std Mean                0.317948
trainer/policy/normal/std Std                 0.124933
trainer/policy/normal/std Max                 1.20414
trainer/policy/normal/std Min                 0.0411262
trainer/policy/normal/log_std Mean           -1.22437
trainer/policy/normal/log_std Std             0.407176
trainer/policy/normal/log_std Max             0.185767
trainer/policy/normal/log_std Min            -3.19111
trainer/Alpha                                 0.00964302
trainer/Alpha Loss                            4.02081
expl/num steps total                      24000
expl/num paths total                         24
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.28838
expl/Rewards Std                              0.838098
expl/Rewards Max                              2.63693
expl/Rewards Min                             -3.12697
expl/Returns Mean                           288.38
expl/Returns Std                              0
expl/Returns Max                            288.38
expl/Returns Min                            288.38
expl/Actions Mean                            -0.0474979
expl/Actions Std                              0.740587
expl/Actions Max                              0.99999
expl/Actions Min                             -0.999997
expl/Num Paths                                1
expl/Average Returns                        288.38
expl/env_infos/final/reward_run Mean         -0.149133
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max          -0.149133
expl/env_infos/final/reward_run Min          -0.149133
expl/env_infos/initial/reward_run Mean        0.00794186
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.00794186
expl/env_infos/initial/reward_run Min         0.00794186
expl/env_infos/reward_run Mean                0.618815
expl/env_infos/reward_run Std                 0.81369
expl/env_infos/reward_run Max                 2.88675
expl/env_infos/reward_run Min                -2.59895
expl/env_infos/final/reward_ctrl Mean        -0.272139
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.272139
expl/env_infos/final/reward_ctrl Min         -0.272139
expl/env_infos/initial/reward_ctrl Mean      -0.0205658
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0205658
expl/env_infos/initial/reward_ctrl Min       -0.0205658
expl/env_infos/reward_ctrl Mean              -0.330435
expl/env_infos/reward_ctrl Std                0.1133
expl/env_infos/reward_ctrl Max               -0.0205658
expl/env_infos/reward_ctrl Min               -0.569765
eval/num steps total                     115000
eval/num paths total                        115
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             0.423835
eval/Rewards Std                              0.828343
eval/Rewards Max                              3.18221
eval/Rewards Min                             -2.42254
eval/Returns Mean                           423.835
eval/Returns Std                            141.789
eval/Returns Max                            633.497
eval/Returns Min                            278.604
eval/Actions Mean                            -0.0604506
eval/Actions Std                              0.710852
eval/Actions Max                              0.999989
eval/Actions Min                             -0.999981
eval/Num Paths                                5
eval/Average Returns                        423.835
eval/env_infos/final/reward_run Mean          0.651888
eval/env_infos/final/reward_run Std           1.14253
eval/env_infos/final/reward_run Max           2.17002
eval/env_infos/final/reward_run Min          -1.34078
eval/env_infos/initial/reward_run Mean       -0.0104859
eval/env_infos/initial/reward_run Std         0.130604
eval/env_infos/initial/reward_run Max         0.1614
eval/env_infos/initial/reward_run Min        -0.18475
eval/env_infos/reward_run Mean                0.729214
eval/env_infos/reward_run Std                 0.794977
eval/env_infos/reward_run Max                 3.39305
eval/env_infos/reward_run Min                -1.98233
eval/env_infos/final/reward_ctrl Mean        -0.422164
eval/env_infos/final/reward_ctrl Std          0.0291223
eval/env_infos/final/reward_ctrl Max         -0.385957
eval/env_infos/final/reward_ctrl Min         -0.464466
eval/env_infos/initial/reward_ctrl Mean      -0.0205958
eval/env_infos/initial/reward_ctrl Std        0.00886678
eval/env_infos/initial/reward_ctrl Max       -0.0108484
eval/env_infos/initial/reward_ctrl Min       -0.0361668
eval/env_infos/reward_ctrl Mean              -0.305379
eval/env_infos/reward_ctrl Std                0.12421
eval/env_infos/reward_ctrl Max               -0.0108484
eval/env_infos/reward_ctrl Min               -0.579358
time/data storing (s)                         0.00450085
time/evaluation sampling (s)                  2.02888
time/exploration sampling (s)                 0.537126
time/logging (s)                              0.0139352
time/sac training (s)                         7.69708
time/saving (s)                               0.0038465
time/training (s)                             3.4403e-05
time/epoch (s)                               10.2854
time/total (s)                              248.464
Epoch                                        22
---------------------------------------  ---------------
2021-11-24 00:33:29.597083 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 23 finished
---------------------------------------  ---------------
epoch                                        23
replay_buffer/size                        25000
trainer/num train calls                   24000
trainer/QF1 Loss                              0.999952
trainer/QF2 Loss                              1.26117
trainer/Policy Loss                         -24.4162
trainer/Q1 Predictions Mean                  24.3255
trainer/Q1 Predictions Std                   12.3556
trainer/Q1 Predictions Max                   53.4642
trainer/Q1 Predictions Min                    8.45273
trainer/Q2 Predictions Mean                  24.2713
trainer/Q2 Predictions Std                   12.51
trainer/Q2 Predictions Max                   52.8091
trainer/Q2 Predictions Min                    8.35003
trainer/Q Targets Mean                       24.2015
trainer/Q Targets Std                        12.4207
trainer/Q Targets Max                        54.2769
trainer/Q Targets Min                         7.49952
trainer/Log Pis Mean                          6.17744
trainer/Log Pis Std                           4.21127
trainer/Log Pis Max                          22.1607
trainer/Log Pis Min                          -2.84021
trainer/policy/mean Mean                     -0.00590339
trainer/policy/mean Std                       0.692891
trainer/policy/mean Max                       0.999921
trainer/policy/mean Min                      -0.999808
trainer/policy/normal/std Mean                0.304637
trainer/policy/normal/std Std                 0.132197
trainer/policy/normal/std Max                 1.05098
trainer/policy/normal/std Min                 0.0374532
trainer/policy/normal/log_std Mean           -1.28336
trainer/policy/normal/log_std Std             0.445931
trainer/policy/normal/log_std Max             0.0497209
trainer/policy/normal/log_std Min            -3.28466
trainer/Alpha                                 0.0100113
trainer/Alpha Loss                            0.816963
expl/num steps total                      25000
expl/num paths total                         25
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.880754
expl/Rewards Std                              0.642267
expl/Rewards Max                              3.18267
expl/Rewards Min                             -1.35514
expl/Returns Mean                           880.754
expl/Returns Std                              0
expl/Returns Max                            880.754
expl/Returns Min                            880.754
expl/Actions Mean                            -0.0531792
expl/Actions Std                              0.624264
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999978
expl/Num Paths                                1
expl/Average Returns                        880.754
expl/env_infos/final/reward_run Mean          0.676712
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.676712
expl/env_infos/final/reward_run Min           0.676712
expl/env_infos/initial/reward_run Mean        0.139247
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.139247
expl/env_infos/initial/reward_run Min         0.139247
expl/env_infos/reward_run Mean                1.11627
expl/env_infos/reward_run Std                 0.64396
expl/env_infos/reward_run Max                 3.37423
expl/env_infos/reward_run Min                -1.15589
expl/env_infos/final/reward_ctrl Mean        -0.212997
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.212997
expl/env_infos/final/reward_ctrl Min         -0.212997
expl/env_infos/initial/reward_ctrl Mean      -0.0176952
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0176952
expl/env_infos/initial/reward_ctrl Min       -0.0176952
expl/env_infos/reward_ctrl Mean              -0.23552
expl/env_infos/reward_ctrl Std                0.0985817
expl/env_infos/reward_ctrl Max               -0.0129666
expl/env_infos/reward_ctrl Min               -0.585162
eval/num steps total                     120000
eval/num paths total                        120
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             0.879345
eval/Rewards Std                              0.59099
eval/Rewards Max                              3.13519
eval/Rewards Min                             -1.52047
eval/Returns Mean                           879.345
eval/Returns Std                             52.5144
eval/Returns Max                            943.606
eval/Returns Min                            797.486
eval/Actions Mean                            -0.0462855
eval/Actions Std                              0.609413
eval/Actions Max                              1
eval/Actions Min                             -0.999985
eval/Num Paths                                5
eval/Average Returns                        879.345
eval/env_infos/final/reward_run Mean          0.661779
eval/env_infos/final/reward_run Std           0.703058
eval/env_infos/final/reward_run Max           1.93966
eval/env_infos/final/reward_run Min          -0.175364
eval/env_infos/initial/reward_run Mean        0.0233762
eval/env_infos/initial/reward_run Std         0.106114
eval/env_infos/initial/reward_run Max         0.124357
eval/env_infos/initial/reward_run Min        -0.146685
eval/env_infos/reward_run Mean                1.10346
eval/env_infos/reward_run Std                 0.5852
eval/env_infos/reward_run Max                 3.40444
eval/env_infos/reward_run Min                -1.15737
eval/env_infos/final/reward_ctrl Mean        -0.200793
eval/env_infos/final/reward_ctrl Std          0.0562692
eval/env_infos/final/reward_ctrl Max         -0.132865
eval/env_infos/final/reward_ctrl Min         -0.278137
eval/env_infos/initial/reward_ctrl Mean      -0.00597233
eval/env_infos/initial/reward_ctrl Std        0.00184001
eval/env_infos/initial/reward_ctrl Max       -0.00408755
eval/env_infos/initial/reward_ctrl Min       -0.00917012
eval/env_infos/reward_ctrl Mean              -0.224116
eval/env_infos/reward_ctrl Std                0.101307
eval/env_infos/reward_ctrl Max               -0.00254018
eval/env_infos/reward_ctrl Min               -0.575861
time/data storing (s)                         0.00446726
time/evaluation sampling (s)                  2.05765
time/exploration sampling (s)                 0.534972
time/logging (s)                              0.0137658
time/sac training (s)                         7.70222
time/saving (s)                               0.00379316
time/training (s)                             3.5592e-05
time/epoch (s)                               10.3169
time/total (s)                              259.078
Epoch                                        23
---------------------------------------  ---------------
2021-11-24 00:33:40.530910 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 24 finished
---------------------------------------  ---------------
epoch                                        24
replay_buffer/size                        26000
trainer/num train calls                   25000
trainer/QF1 Loss                              1.47523
trainer/QF2 Loss                              1.56257
trainer/Policy Loss                         -23.3639
trainer/Q1 Predictions Mean                  23.3082
trainer/Q1 Predictions Std                   13.1128
trainer/Q1 Predictions Max                   53.8263
trainer/Q1 Predictions Min                    8.20736
trainer/Q2 Predictions Mean                  23.2067
trainer/Q2 Predictions Std                   13.0374
trainer/Q2 Predictions Max                   54.247
trainer/Q2 Predictions Min                    8.1858
trainer/Q Targets Mean                       23.274
trainer/Q Targets Std                        13.0331
trainer/Q Targets Max                        54.4545
trainer/Q Targets Min                         7.94932
trainer/Log Pis Mean                          6.13206
trainer/Log Pis Std                           4.67676
trainer/Log Pis Max                          31.3709
trainer/Log Pis Min                          -3.62677
trainer/policy/mean Mean                      0.0220774
trainer/policy/mean Std                       0.681944
trainer/policy/mean Max                       0.999989
trainer/policy/mean Min                      -0.999859
trainer/policy/normal/std Mean                0.320085
trainer/policy/normal/std Std                 0.133036
trainer/policy/normal/std Max                 1.03849
trainer/policy/normal/std Min                 0.0689013
trainer/policy/normal/log_std Mean           -1.22818
trainer/policy/normal/log_std Std             0.434126
trainer/policy/normal/log_std Max             0.0377637
trainer/policy/normal/log_std Min            -2.67508
trainer/Alpha                                 0.0104595
trainer/Alpha Loss                            0.602213
expl/num steps total                      26000
expl/num paths total                         26
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.700916
expl/Rewards Std                              0.773037
expl/Rewards Max                              2.57058
expl/Rewards Min                             -1.67683
expl/Returns Mean                           700.916
expl/Returns Std                              0
expl/Returns Max                            700.916
expl/Returns Min                            700.916
expl/Actions Mean                            -0.00205315
expl/Actions Std                              0.687124
expl/Actions Max                              1
expl/Actions Min                             -0.999986
expl/Num Paths                                1
expl/Average Returns                        700.916
expl/env_infos/final/reward_run Mean          0.730093
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.730093
expl/env_infos/final/reward_run Min           0.730093
expl/env_infos/initial/reward_run Mean       -0.115553
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.115553
expl/env_infos/initial/reward_run Min        -0.115553
expl/env_infos/reward_run Mean                0.984202
expl/env_infos/reward_run Std                 0.747845
expl/env_infos/reward_run Max                 2.86352
expl/env_infos/reward_run Min                -1.28457
expl/env_infos/final/reward_ctrl Mean        -0.171564
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.171564
expl/env_infos/final/reward_ctrl Min         -0.171564
expl/env_infos/initial/reward_ctrl Mean      -0.0323498
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0323498
expl/env_infos/initial/reward_ctrl Min       -0.0323498
expl/env_infos/reward_ctrl Mean              -0.283286
expl/env_infos/reward_ctrl Std                0.120561
expl/env_infos/reward_ctrl Max               -0.00918783
expl/env_infos/reward_ctrl Min               -0.586391
eval/num steps total                     125000
eval/num paths total                        125
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             0.788534
eval/Rewards Std                              0.716814
eval/Rewards Max                              3.03112
eval/Rewards Min                             -2.24842
eval/Returns Mean                           788.534
eval/Returns Std                             56.9596
eval/Returns Max                            862.391
eval/Returns Min                            700.792
eval/Actions Mean                            -0.00683072
eval/Actions Std                              0.643777
eval/Actions Max                              1
eval/Actions Min                             -0.999987
eval/Num Paths                                5
eval/Average Returns                        788.534
eval/env_infos/final/reward_run Mean          0.871219
eval/env_infos/final/reward_run Std           0.808895
eval/env_infos/final/reward_run Max           2.19648
eval/env_infos/final/reward_run Min          -0.284155
eval/env_infos/initial/reward_run Mean        0.0348547
eval/env_infos/initial/reward_run Std         0.0504279
eval/env_infos/initial/reward_run Max         0.131901
eval/env_infos/initial/reward_run Min        -0.0150387
eval/env_infos/reward_run Mean                1.03723
eval/env_infos/reward_run Std                 0.700439
eval/env_infos/reward_run Max                 3.22901
eval/env_infos/reward_run Min                -1.85743
eval/env_infos/final/reward_ctrl Mean        -0.351722
eval/env_infos/final/reward_ctrl Std          0.0440316
eval/env_infos/final/reward_ctrl Max         -0.296924
eval/env_infos/final/reward_ctrl Min         -0.415031
eval/env_infos/initial/reward_ctrl Mean      -0.0189518
eval/env_infos/initial/reward_ctrl Std        0.00749406
eval/env_infos/initial/reward_ctrl Max       -0.0059541
eval/env_infos/initial/reward_ctrl Min       -0.0268707
eval/env_infos/reward_ctrl Mean              -0.248697
eval/env_infos/reward_ctrl Std                0.112673
eval/env_infos/reward_ctrl Max               -0.0059541
eval/env_infos/reward_ctrl Min               -0.592627
time/data storing (s)                         0.00445333
time/evaluation sampling (s)                  2.0568
time/exploration sampling (s)                 0.551437
time/logging (s)                              0.0168673
time/sac training (s)                         7.97525
time/saving (s)                               0.0039339
time/training (s)                             4.8044e-05
time/epoch (s)                               10.6088
time/total (s)                              270
Epoch                                        24
---------------------------------------  ---------------
2021-11-24 00:33:51.311115 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 25 finished
---------------------------------------  ---------------
epoch                                        25
replay_buffer/size                        27000
trainer/num train calls                   26000
trainer/QF1 Loss                              1.76944
trainer/QF2 Loss                              1.47243
trainer/Policy Loss                         -24.6409
trainer/Q1 Predictions Mean                  24.5172
trainer/Q1 Predictions Std                   14.3959
trainer/Q1 Predictions Max                   55.1668
trainer/Q1 Predictions Min                    7.85074
trainer/Q2 Predictions Mean                  24.4292
trainer/Q2 Predictions Std                   14.3655
trainer/Q2 Predictions Max                   54.6987
trainer/Q2 Predictions Min                    7.95896
trainer/Q Targets Mean                       24.3864
trainer/Q Targets Std                        14.4673
trainer/Q Targets Max                        56.6159
trainer/Q Targets Min                         8.54582
trainer/Log Pis Mean                          6.01882
trainer/Log Pis Std                           4.84229
trainer/Log Pis Max                          24.4403
trainer/Log Pis Min                          -5.1105
trainer/policy/mean Mean                      0.0273364
trainer/policy/mean Std                       0.682244
trainer/policy/mean Max                       0.99999
trainer/policy/mean Min                      -0.999919
trainer/policy/normal/std Mean                0.317769
trainer/policy/normal/std Std                 0.136886
trainer/policy/normal/std Max                 1.08118
trainer/policy/normal/std Min                 0.0528302
trainer/policy/normal/log_std Mean           -1.24479
trainer/policy/normal/log_std Std             0.459044
trainer/policy/normal/log_std Max             0.0780548
trainer/policy/normal/log_std Min            -2.94067
trainer/Alpha                                 0.0109162
trainer/Alpha Loss                            0.0850032
expl/num steps total                      27000
expl/num paths total                         27
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.10359
expl/Rewards Std                              0.610882
expl/Rewards Max                              2.92621
expl/Rewards Min                             -1.36843
expl/Returns Mean                          1103.59
expl/Returns Std                              0
expl/Returns Max                           1103.59
expl/Returns Min                           1103.59
expl/Actions Mean                             0.0186573
expl/Actions Std                              0.616278
expl/Actions Max                              1
expl/Actions Min                             -0.999275
expl/Num Paths                                1
expl/Average Returns                       1103.59
expl/env_infos/final/reward_run Mean          1.92592
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.92592
expl/env_infos/final/reward_run Min           1.92592
expl/env_infos/initial/reward_run Mean        0.161839
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.161839
expl/env_infos/initial/reward_run Min         0.161839
expl/env_infos/reward_run Mean                1.33168
expl/env_infos/reward_run Std                 0.599654
expl/env_infos/reward_run Max                 3.2618
expl/env_infos/reward_run Min                -1.16732
expl/env_infos/final/reward_ctrl Mean        -0.336874
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.336874
expl/env_infos/final/reward_ctrl Min         -0.336874
expl/env_infos/initial/reward_ctrl Mean      -0.0291601
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0291601
expl/env_infos/initial/reward_ctrl Min       -0.0291601
expl/env_infos/reward_ctrl Mean              -0.228088
expl/env_infos/reward_ctrl Std                0.101955
expl/env_infos/reward_ctrl Max               -0.0219097
expl/env_infos/reward_ctrl Min               -0.552244
eval/num steps total                     130000
eval/num paths total                        130
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.03603
eval/Rewards Std                              0.619173
eval/Rewards Max                              2.93639
eval/Rewards Min                             -1.82165
eval/Returns Mean                          1036.03
eval/Returns Std                             79.7591
eval/Returns Max                           1145.63
eval/Returns Min                            906.382
eval/Actions Mean                             0.0297962
eval/Actions Std                              0.616776
eval/Actions Max                              1
eval/Actions Min                             -0.999975
eval/Num Paths                                5
eval/Average Returns                       1036.03
eval/env_infos/final/reward_run Mean          0.802812
eval/env_infos/final/reward_run Std           0.542675
eval/env_infos/final/reward_run Max           1.46804
eval/env_infos/final/reward_run Min           0.116601
eval/env_infos/initial/reward_run Mean        0.099953
eval/env_infos/initial/reward_run Std         0.0850083
eval/env_infos/initial/reward_run Max         0.189857
eval/env_infos/initial/reward_run Min        -0.0343473
eval/env_infos/reward_run Mean                1.26481
eval/env_infos/reward_run Std                 0.602594
eval/env_infos/reward_run Max                 3.15342
eval/env_infos/reward_run Min                -1.41054
eval/env_infos/final/reward_ctrl Mean        -0.247943
eval/env_infos/final/reward_ctrl Std          0.116017
eval/env_infos/final/reward_ctrl Max         -0.132637
eval/env_infos/final/reward_ctrl Min         -0.398999
eval/env_infos/initial/reward_ctrl Mean      -0.0247083
eval/env_infos/initial/reward_ctrl Std        0.0148411
eval/env_infos/initial/reward_ctrl Max       -0.00572069
eval/env_infos/initial/reward_ctrl Min       -0.0471877
eval/env_infos/reward_ctrl Mean              -0.22878
eval/env_infos/reward_ctrl Std                0.103558
eval/env_infos/reward_ctrl Max               -0.00572069
eval/env_infos/reward_ctrl Min               -0.549147
time/data storing (s)                         0.00446386
time/evaluation sampling (s)                  2.10651
time/exploration sampling (s)                 0.549505
time/logging (s)                              0.0141926
time/sac training (s)                         7.78014
time/saving (s)                               0.00380911
time/training (s)                             3.5359e-05
time/epoch (s)                               10.4587
time/total (s)                              280.763
Epoch                                        25
---------------------------------------  ---------------
2021-11-24 00:34:02.134560 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 26 finished
---------------------------------------  ---------------
epoch                                        26
replay_buffer/size                        28000
trainer/num train calls                   27000
trainer/QF1 Loss                              1.39275
trainer/QF2 Loss                              1.27821
trainer/Policy Loss                         -23.8693
trainer/Q1 Predictions Mean                  23.6179
trainer/Q1 Predictions Std                   13.8258
trainer/Q1 Predictions Max                   58.3807
trainer/Q1 Predictions Min                    7.91681
trainer/Q2 Predictions Mean                  23.7062
trainer/Q2 Predictions Std                   13.8246
trainer/Q2 Predictions Max                   57.5349
trainer/Q2 Predictions Min                    8.05797
trainer/Q Targets Mean                       23.7747
trainer/Q Targets Std                        14.0159
trainer/Q Targets Max                        59.2612
trainer/Q Targets Min                         6.74758
trainer/Log Pis Mean                          6.17766
trainer/Log Pis Std                           4.44951
trainer/Log Pis Max                          22.4235
trainer/Log Pis Min                          -3.38827
trainer/policy/mean Mean                      0.0190532
trainer/policy/mean Std                       0.704225
trainer/policy/mean Max                       0.999901
trainer/policy/mean Min                      -0.999942
trainer/policy/normal/std Mean                0.34445
trainer/policy/normal/std Std                 0.135561
trainer/policy/normal/std Max                 0.978058
trainer/policy/normal/std Min                 0.0809453
trainer/policy/normal/log_std Mean           -1.14928
trainer/policy/normal/log_std Std             0.423656
trainer/policy/normal/log_std Max            -0.0221866
trainer/policy/normal/log_std Min            -2.51398
trainer/Alpha                                 0.0121846
trainer/Alpha Loss                            0.783065
expl/num steps total                      28000
expl/num paths total                         28
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.06519
expl/Rewards Std                              0.619408
expl/Rewards Max                              2.88895
expl/Rewards Min                             -1.2425
expl/Returns Mean                          1065.19
expl/Returns Std                              0
expl/Returns Max                           1065.19
expl/Returns Min                           1065.19
expl/Actions Mean                            -0.0378675
expl/Actions Std                              0.625927
expl/Actions Max                              1
expl/Actions Min                             -0.999928
expl/Num Paths                                1
expl/Average Returns                       1065.19
expl/env_infos/final/reward_run Mean          1.14507
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.14507
expl/env_infos/final/reward_run Min           1.14507
expl/env_infos/initial/reward_run Mean        0.196015
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.196015
expl/env_infos/initial/reward_run Min         0.196015
expl/env_infos/reward_run Mean                1.30112
expl/env_infos/reward_run Std                 0.600647
expl/env_infos/reward_run Max                 2.99507
expl/env_infos/reward_run Min                -0.909735
expl/env_infos/final/reward_ctrl Mean        -0.0605397
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.0605397
expl/env_infos/final/reward_ctrl Min         -0.0605397
expl/env_infos/initial/reward_ctrl Mean      -0.0241834
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0241834
expl/env_infos/initial/reward_ctrl Min       -0.0241834
expl/env_infos/reward_ctrl Mean              -0.235931
expl/env_infos/reward_ctrl Std                0.10781
expl/env_infos/reward_ctrl Max               -0.0213644
expl/env_infos/reward_ctrl Min               -0.538701
eval/num steps total                     135000
eval/num paths total                        135
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.06424
eval/Rewards Std                              0.682591
eval/Rewards Max                              3.54032
eval/Rewards Min                             -1.90674
eval/Returns Mean                          1064.24
eval/Returns Std                             90.5056
eval/Returns Max                           1197.31
eval/Returns Min                            927.806
eval/Actions Mean                            -0.031765
eval/Actions Std                              0.623764
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                                5
eval/Average Returns                       1064.24
eval/env_infos/final/reward_run Mean          1.44543
eval/env_infos/final/reward_run Std           0.506449
eval/env_infos/final/reward_run Max           2.2648
eval/env_infos/final/reward_run Min           0.777756
eval/env_infos/initial/reward_run Mean        0.0716312
eval/env_infos/initial/reward_run Std         0.0372748
eval/env_infos/initial/reward_run Max         0.139873
eval/env_infos/initial/reward_run Min         0.0400326
eval/env_infos/reward_run Mean                1.29829
eval/env_infos/reward_run Std                 0.669318
eval/env_infos/reward_run Max                 4.01304
eval/env_infos/reward_run Min                -1.46905
eval/env_infos/final/reward_ctrl Mean        -0.248524
eval/env_infos/final/reward_ctrl Std          0.117929
eval/env_infos/final/reward_ctrl Max         -0.116334
eval/env_infos/final/reward_ctrl Min         -0.420253
eval/env_infos/initial/reward_ctrl Mean      -0.0152115
eval/env_infos/initial/reward_ctrl Std        0.00836457
eval/env_infos/initial/reward_ctrl Max       -0.00327031
eval/env_infos/initial/reward_ctrl Min       -0.0289943
eval/env_infos/reward_ctrl Mean              -0.234054
eval/env_infos/reward_ctrl Std                0.113659
eval/env_infos/reward_ctrl Max               -0.00327031
eval/env_infos/reward_ctrl Min               -0.567247
time/data storing (s)                         0.00453256
time/evaluation sampling (s)                  2.10017
time/exploration sampling (s)                 0.519866
time/logging (s)                              0.0145471
time/sac training (s)                         7.86121
time/saving (s)                               0.00388324
time/training (s)                             4.2284e-05
time/epoch (s)                               10.5043
time/total (s)                              291.572
Epoch                                        26
---------------------------------------  ---------------
2021-11-24 00:34:12.830005 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 27 finished
---------------------------------------  ---------------
epoch                                        27
replay_buffer/size                        29000
trainer/num train calls                   28000
trainer/QF1 Loss                              1.66617
trainer/QF2 Loss                              1.41033
trainer/Policy Loss                         -25.8017
trainer/Q1 Predictions Mean                  25.6011
trainer/Q1 Predictions Std                   16.123
trainer/Q1 Predictions Max                   60.9283
trainer/Q1 Predictions Min                    7.85616
trainer/Q2 Predictions Mean                  25.5299
trainer/Q2 Predictions Std                   16.2037
trainer/Q2 Predictions Max                   59.168
trainer/Q2 Predictions Min                    7.39163
trainer/Q Targets Mean                       25.5319
trainer/Q Targets Std                        16.3424
trainer/Q Targets Max                        58.7351
trainer/Q Targets Min                         6.75491
trainer/Log Pis Mean                          6.00018
trainer/Log Pis Std                           4.67364
trainer/Log Pis Max                          23.478
trainer/Log Pis Min                          -3.99841
trainer/policy/mean Mean                      0.0825506
trainer/policy/mean Std                       0.694783
trainer/policy/mean Max                       0.999997
trainer/policy/mean Min                      -0.999938
trainer/policy/normal/std Mean                0.348211
trainer/policy/normal/std Std                 0.143318
trainer/policy/normal/std Max                 1.47225
trainer/policy/normal/std Min                 0.104896
trainer/policy/normal/log_std Mean           -1.13457
trainer/policy/normal/log_std Std             0.402077
trainer/policy/normal/log_std Max             0.38679
trainer/policy/normal/log_std Min            -2.25479
trainer/Alpha                                 0.0128094
trainer/Alpha Loss                            0.00078851
expl/num steps total                      29000
expl/num paths total                         29
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.40093
expl/Rewards Std                              0.637233
expl/Rewards Max                              3.17058
expl/Rewards Min                             -0.868228
expl/Returns Mean                          1400.93
expl/Returns Std                              0
expl/Returns Max                           1400.93
expl/Returns Min                           1400.93
expl/Actions Mean                             0.0821456
expl/Actions Std                              0.619711
expl/Actions Max                              1
expl/Actions Min                             -0.999882
expl/Num Paths                                1
expl/Average Returns                       1400.93
expl/env_infos/final/reward_run Mean          1.03006
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.03006
expl/env_infos/final/reward_run Min           1.03006
expl/env_infos/initial/reward_run Mean        0.11225
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.11225
expl/env_infos/initial/reward_run Min         0.11225
expl/env_infos/reward_run Mean                1.6354
expl/env_infos/reward_run Std                 0.6131
expl/env_infos/reward_run Max                 3.30162
expl/env_infos/reward_run Min                -0.620468
expl/env_infos/final/reward_ctrl Mean        -0.328773
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.328773
expl/env_infos/final/reward_ctrl Min         -0.328773
expl/env_infos/initial/reward_ctrl Mean      -0.0488407
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0488407
expl/env_infos/initial/reward_ctrl Min       -0.0488407
expl/env_infos/reward_ctrl Mean              -0.234474
expl/env_infos/reward_ctrl Std                0.106592
expl/env_infos/reward_ctrl Max               -0.0167173
expl/env_infos/reward_ctrl Min               -0.54315
eval/num steps total                     140000
eval/num paths total                        140
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.33912
eval/Rewards Std                              0.610057
eval/Rewards Max                              3.9365
eval/Rewards Min                             -1.26953
eval/Returns Mean                          1339.12
eval/Returns Std                             37.5814
eval/Returns Max                           1397.02
eval/Returns Min                           1300.67
eval/Actions Mean                             0.0797104
eval/Actions Std                              0.612363
eval/Actions Max                              0.999999
eval/Actions Min                             -0.999918
eval/Num Paths                                5
eval/Average Returns                       1339.12
eval/env_infos/final/reward_run Mean          1.43838
eval/env_infos/final/reward_run Std           0.725304
eval/env_infos/final/reward_run Max           2.25556
eval/env_infos/final/reward_run Min           0.0905763
eval/env_infos/initial/reward_run Mean        0.0771636
eval/env_infos/initial/reward_run Std         0.0489757
eval/env_infos/initial/reward_run Max         0.138165
eval/env_infos/initial/reward_run Min        -0.00865987
eval/env_infos/reward_run Mean                1.56793
eval/env_infos/reward_run Std                 0.587827
eval/env_infos/reward_run Max                 4.18687
eval/env_infos/reward_run Min                -0.875839
eval/env_infos/final/reward_ctrl Mean        -0.175363
eval/env_infos/final/reward_ctrl Std          0.102697
eval/env_infos/final/reward_ctrl Max         -0.0852858
eval/env_infos/final/reward_ctrl Min         -0.30529
eval/env_infos/initial/reward_ctrl Mean      -0.0211841
eval/env_infos/initial/reward_ctrl Std        0.00600632
eval/env_infos/initial/reward_ctrl Max       -0.011462
eval/env_infos/initial/reward_ctrl Min       -0.0275916
eval/env_infos/reward_ctrl Mean              -0.228805
eval/env_infos/reward_ctrl Std                0.115331
eval/env_infos/reward_ctrl Max               -0.00336733
eval/env_infos/reward_ctrl Min               -0.57392
time/data storing (s)                         0.0044731
time/evaluation sampling (s)                  2.0638
time/exploration sampling (s)                 0.558657
time/logging (s)                              0.0141281
time/sac training (s)                         7.73733
time/saving (s)                               0.00388236
time/training (s)                             4.2465e-05
time/epoch (s)                               10.3823
time/total (s)                              302.253
Epoch                                        27
---------------------------------------  ---------------
2021-11-24 00:34:23.429435 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 28 finished
---------------------------------------  ---------------
epoch                                        28
replay_buffer/size                        30000
trainer/num train calls                   29000
trainer/QF1 Loss                              1.46292
trainer/QF2 Loss                              1.18186
trainer/Policy Loss                         -26.9075
trainer/Q1 Predictions Mean                  26.7315
trainer/Q1 Predictions Std                   18.2093
trainer/Q1 Predictions Max                   62.6098
trainer/Q1 Predictions Min                    7.06377
trainer/Q2 Predictions Mean                  26.7653
trainer/Q2 Predictions Std                   18.1249
trainer/Q2 Predictions Max                   62.325
trainer/Q2 Predictions Min                    6.89722
trainer/Q Targets Mean                       26.7724
trainer/Q Targets Std                        18.2612
trainer/Q Targets Max                        62.1746
trainer/Q Targets Min                         7.15489
trainer/Log Pis Mean                          5.41138
trainer/Log Pis Std                           4.389
trainer/Log Pis Max                          18.8874
trainer/Log Pis Min                          -7.58916
trainer/policy/mean Mean                      0.0545783
trainer/policy/mean Std                       0.676513
trainer/policy/mean Max                       0.999987
trainer/policy/mean Min                      -0.999707
trainer/policy/normal/std Mean                0.333133
trainer/policy/normal/std Std                 0.132049
trainer/policy/normal/std Max                 1.48599
trainer/policy/normal/std Min                 0.0708593
trainer/policy/normal/log_std Mean           -1.17892
trainer/policy/normal/log_std Std             0.409712
trainer/policy/normal/log_std Max             0.396084
trainer/policy/normal/log_std Min            -2.64706
trainer/Alpha                                 0.0140005
trainer/Alpha Loss                           -2.51262
expl/num steps total                      30000
expl/num paths total                         30
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.49071
expl/Rewards Std                              0.549021
expl/Rewards Max                              3.08739
expl/Rewards Min                             -0.620237
expl/Returns Mean                          1490.71
expl/Returns Std                              0
expl/Returns Max                           1490.71
expl/Returns Min                           1490.71
expl/Actions Mean                             0.0522107
expl/Actions Std                              0.628305
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999925
expl/Num Paths                                1
expl/Average Returns                       1490.71
expl/env_infos/final/reward_run Mean          2.20122
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.20122
expl/env_infos/final/reward_run Min           2.20122
expl/env_infos/initial/reward_run Mean        0.0484273
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0484273
expl/env_infos/initial/reward_run Min         0.0484273
expl/env_infos/reward_run Mean                1.7292
expl/env_infos/reward_run Std                 0.533976
expl/env_infos/reward_run Max                 3.45615
expl/env_infos/reward_run Min                -0.107934
expl/env_infos/final/reward_ctrl Mean        -0.103105
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.103105
expl/env_infos/final/reward_ctrl Min         -0.103105
expl/env_infos/initial/reward_ctrl Mean      -0.0243088
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0243088
expl/env_infos/initial/reward_ctrl Min       -0.0243088
expl/env_infos/reward_ctrl Mean              -0.238496
expl/env_infos/reward_ctrl Std                0.116834
expl/env_infos/reward_ctrl Max               -0.0120228
expl/env_infos/reward_ctrl Min               -0.557351
eval/num steps total                     145000
eval/num paths total                        145
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.38547
eval/Rewards Std                              0.612046
eval/Rewards Max                              3.52427
eval/Rewards Min                             -0.935274
eval/Returns Mean                          1385.47
eval/Returns Std                             61.862
eval/Returns Max                           1462.97
eval/Returns Min                           1295.55
eval/Actions Mean                             0.0357588
eval/Actions Std                              0.630967
eval/Actions Max                              1
eval/Actions Min                             -0.999925
eval/Num Paths                                5
eval/Average Returns                       1385.47
eval/env_infos/final/reward_run Mean          1.7335
eval/env_infos/final/reward_run Std           0.278541
eval/env_infos/final/reward_run Max           2.06374
eval/env_infos/final/reward_run Min           1.29124
eval/env_infos/initial/reward_run Mean        0.0398057
eval/env_infos/initial/reward_run Std         0.070827
eval/env_infos/initial/reward_run Max         0.148611
eval/env_infos/initial/reward_run Min        -0.0651348
eval/env_infos/reward_run Mean                1.6251
eval/env_infos/reward_run Std                 0.598269
eval/env_infos/reward_run Max                 3.89308
eval/env_infos/reward_run Min                -0.514182
eval/env_infos/final/reward_ctrl Mean        -0.169573
eval/env_infos/final/reward_ctrl Std          0.106226
eval/env_infos/final/reward_ctrl Max         -0.0791438
eval/env_infos/final/reward_ctrl Min         -0.377833
eval/env_infos/initial/reward_ctrl Mean      -0.0356261
eval/env_infos/initial/reward_ctrl Std        0.0177662
eval/env_infos/initial/reward_ctrl Max       -0.00684523
eval/env_infos/initial/reward_ctrl Min       -0.0610902
eval/env_infos/reward_ctrl Mean              -0.239639
eval/env_infos/reward_ctrl Std                0.12015
eval/env_infos/reward_ctrl Max               -0.00684523
eval/env_infos/reward_ctrl Min               -0.571996
time/data storing (s)                         0.00447843
time/evaluation sampling (s)                  2.03803
time/exploration sampling (s)                 0.535455
time/logging (s)                              0.0140431
time/sac training (s)                         7.69282
time/saving (s)                               0.00378456
time/training (s)                             3.5623e-05
time/epoch (s)                               10.2886
time/total (s)                              312.838
Epoch                                        28
---------------------------------------  ---------------
2021-11-24 00:34:34.346460 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 29 finished
---------------------------------------  ---------------
epoch                                        29
replay_buffer/size                        31000
trainer/num train calls                   30000
trainer/QF1 Loss                              1.44694
trainer/QF2 Loss                              1.41008
trainer/Policy Loss                         -30.8659
trainer/Q1 Predictions Mean                  30.7255
trainer/Q1 Predictions Std                   20.1704
trainer/Q1 Predictions Max                   67.9479
trainer/Q1 Predictions Min                    7.53154
trainer/Q2 Predictions Mean                  30.6326
trainer/Q2 Predictions Std                   20.1578
trainer/Q2 Predictions Max                   68.1942
trainer/Q2 Predictions Min                    6.76791
trainer/Q Targets Mean                       30.556
trainer/Q Targets Std                        20.2374
trainer/Q Targets Max                        66.8233
trainer/Q Targets Min                         5.28391
trainer/Log Pis Mean                          6.1494
trainer/Log Pis Std                           4.6155
trainer/Log Pis Max                          23.4693
trainer/Log Pis Min                          -2.70538
trainer/policy/mean Mean                      0.0618416
trainer/policy/mean Std                       0.707738
trainer/policy/mean Max                       0.999982
trainer/policy/mean Min                      -0.999981
trainer/policy/normal/std Mean                0.349866
trainer/policy/normal/std Std                 0.14928
trainer/policy/normal/std Max                 1.43889
trainer/policy/normal/std Min                 0.0855711
trainer/policy/normal/log_std Mean           -1.14135
trainer/policy/normal/log_std Std             0.434383
trainer/policy/normal/log_std Max             0.363872
trainer/policy/normal/log_std Min            -2.45841
trainer/Alpha                                 0.0157478
trainer/Alpha Loss                            0.62016
expl/num steps total                      31000
expl/num paths total                         31
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.59278
expl/Rewards Std                              0.782067
expl/Rewards Max                              3.69162
expl/Rewards Min                             -1.00525
expl/Returns Mean                          1592.78
expl/Returns Std                              0
expl/Returns Max                           1592.78
expl/Returns Min                           1592.78
expl/Actions Mean                             0.0149821
expl/Actions Std                              0.730035
expl/Actions Max                              1
expl/Actions Min                             -0.999996
expl/Num Paths                                1
expl/Average Returns                       1592.78
expl/env_infos/final/reward_run Mean          2.41336
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.41336
expl/env_infos/final/reward_run Min           2.41336
expl/env_infos/initial/reward_run Mean        0.0791282
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0791282
expl/env_infos/initial/reward_run Min         0.0791282
expl/env_infos/reward_run Mean                1.91268
expl/env_infos/reward_run Std                 0.769016
expl/env_infos/reward_run Max                 4.08942
expl/env_infos/reward_run Min                -0.806162
expl/env_infos/final/reward_ctrl Mean        -0.299765
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.299765
expl/env_infos/final/reward_ctrl Min         -0.299765
expl/env_infos/initial/reward_ctrl Mean      -0.00903222
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.00903222
expl/env_infos/initial/reward_ctrl Min       -0.00903222
expl/env_infos/reward_ctrl Mean              -0.319906
expl/env_infos/reward_ctrl Std                0.118619
expl/env_infos/reward_ctrl Max               -0.00903222
expl/env_infos/reward_ctrl Min               -0.58733
eval/num steps total                     150000
eval/num paths total                        150
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.77728
eval/Rewards Std                              0.807532
eval/Rewards Max                              4.02951
eval/Rewards Min                             -1.54351
eval/Returns Mean                          1777.28
eval/Returns Std                            112.97
eval/Returns Max                           1978.57
eval/Returns Min                           1632.49
eval/Actions Mean                             0.0364464
eval/Actions Std                              0.713275
eval/Actions Max                              1
eval/Actions Min                             -0.999976
eval/Num Paths                                5
eval/Average Returns                       1777.28
eval/env_infos/final/reward_run Mean          2.45251
eval/env_infos/final/reward_run Std           0.390534
eval/env_infos/final/reward_run Max           2.81572
eval/env_infos/final/reward_run Min           1.71479
eval/env_infos/initial/reward_run Mean        0.0713652
eval/env_infos/initial/reward_run Std         0.0765188
eval/env_infos/initial/reward_run Max         0.183045
eval/env_infos/initial/reward_run Min        -0.0162873
eval/env_infos/reward_run Mean                2.08334
eval/env_infos/reward_run Std                 0.787766
eval/env_infos/reward_run Max                 4.48734
eval/env_infos/reward_run Min                -1.17689
eval/env_infos/final/reward_ctrl Mean        -0.375976
eval/env_infos/final/reward_ctrl Std          0.0688105
eval/env_infos/final/reward_ctrl Max         -0.281861
eval/env_infos/final/reward_ctrl Min         -0.484889
eval/env_infos/initial/reward_ctrl Mean      -0.0187508
eval/env_infos/initial/reward_ctrl Std        0.0140316
eval/env_infos/initial/reward_ctrl Max       -0.00692393
eval/env_infos/initial/reward_ctrl Min       -0.0458491
eval/env_infos/reward_ctrl Mean              -0.306054
eval/env_infos/reward_ctrl Std                0.121231
eval/env_infos/reward_ctrl Max               -0.00692393
eval/env_infos/reward_ctrl Min               -0.592892
time/data storing (s)                         0.00465232
time/evaluation sampling (s)                  2.02082
time/exploration sampling (s)                 0.561339
time/logging (s)                              0.01823
time/sac training (s)                         7.98641
time/saving (s)                               0.00471742
time/training (s)                             4.4615e-05
time/epoch (s)                               10.5962
time/total (s)                              323.744
Epoch                                        29
---------------------------------------  ---------------
2021-11-24 00:34:45.258676 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 30 finished
---------------------------------------  ---------------
epoch                                        30
replay_buffer/size                        32000
trainer/num train calls                   31000
trainer/QF1 Loss                              1.75061
trainer/QF2 Loss                              1.7099
trainer/Policy Loss                         -30.902
trainer/Q1 Predictions Mean                  30.6791
trainer/Q1 Predictions Std                   21.3508
trainer/Q1 Predictions Max                   75.9822
trainer/Q1 Predictions Min                    6.50756
trainer/Q2 Predictions Mean                  30.5589
trainer/Q2 Predictions Std                   21.2411
trainer/Q2 Predictions Max                   74.3707
trainer/Q2 Predictions Min                    5.34704
trainer/Q Targets Mean                       30.5669
trainer/Q Targets Std                        21.3244
trainer/Q Targets Max                        74.4941
trainer/Q Targets Min                         5.94226
trainer/Log Pis Mean                          6.18323
trainer/Log Pis Std                           5.14713
trainer/Log Pis Max                          25.0024
trainer/Log Pis Min                          -5.4751
trainer/policy/mean Mean                      0.0228545
trainer/policy/mean Std                       0.729144
trainer/policy/mean Max                       0.999998
trainer/policy/mean Min                      -0.99999
trainer/policy/normal/std Mean                0.392907
trainer/policy/normal/std Std                 0.14502
trainer/policy/normal/std Max                 1.31887
trainer/policy/normal/std Min                 0.112794
trainer/policy/normal/log_std Mean           -1.00266
trainer/policy/normal/log_std Std             0.376963
trainer/policy/normal/log_std Max             0.276776
trainer/policy/normal/log_std Min            -2.1822
trainer/Alpha                                 0.0177944
trainer/Alpha Loss                            0.7382
expl/num steps total                      32000
expl/num paths total                         32
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.80318
expl/Rewards Std                              0.80046
expl/Rewards Max                              3.65729
expl/Rewards Min                             -0.52106
expl/Returns Mean                          1803.18
expl/Returns Std                              0
expl/Returns Max                           1803.18
expl/Returns Min                           1803.18
expl/Actions Mean                             0.0516274
expl/Actions Std                              0.76765
expl/Actions Max                              1
expl/Actions Min                             -0.999991
expl/Num Paths                                1
expl/Average Returns                       1803.18
expl/env_infos/final/reward_run Mean          2.73849
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.73849
expl/env_infos/final/reward_run Min           2.73849
expl/env_infos/initial/reward_run Mean       -0.102676
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.102676
expl/env_infos/initial/reward_run Min        -0.102676
expl/env_infos/reward_run Mean                2.15835
expl/env_infos/reward_run Std                 0.79312
expl/env_infos/reward_run Max                 4.0985
expl/env_infos/reward_run Min                -0.26211
expl/env_infos/final/reward_ctrl Mean        -0.444196
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.444196
expl/env_infos/final/reward_ctrl Min         -0.444196
expl/env_infos/initial/reward_ctrl Mean      -0.024709
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.024709
expl/env_infos/initial/reward_ctrl Min       -0.024709
expl/env_infos/reward_ctrl Mean              -0.355171
expl/env_infos/reward_ctrl Std                0.118265
expl/env_infos/reward_ctrl Max               -0.024709
expl/env_infos/reward_ctrl Min               -0.595511
eval/num steps total                     155000
eval/num paths total                        155
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.82921
eval/Rewards Std                              0.809079
eval/Rewards Max                              4.50395
eval/Rewards Min                             -1.391
eval/Returns Mean                          1829.21
eval/Returns Std                             34.1301
eval/Returns Max                           1881.98
eval/Returns Min                           1786.56
eval/Actions Mean                             0.0531646
eval/Actions Std                              0.764043
eval/Actions Max                              1
eval/Actions Min                             -0.999991
eval/Num Paths                                5
eval/Average Returns                       1829.21
eval/env_infos/final/reward_run Mean          1.97043
eval/env_infos/final/reward_run Std           0.715554
eval/env_infos/final/reward_run Max           2.86953
eval/env_infos/final/reward_run Min           0.72457
eval/env_infos/initial/reward_run Mean        0.0911652
eval/env_infos/initial/reward_run Std         0.0747338
eval/env_infos/initial/reward_run Max         0.195836
eval/env_infos/initial/reward_run Min        -0.0286933
eval/env_infos/reward_run Mean                2.18117
eval/env_infos/reward_run Std                 0.811005
eval/env_infos/reward_run Max                 4.99566
eval/env_infos/reward_run Min                -1.06135
eval/env_infos/final/reward_ctrl Mean        -0.331056
eval/env_infos/final/reward_ctrl Std          0.175821
eval/env_infos/final/reward_ctrl Max         -0.0963382
eval/env_infos/final/reward_ctrl Min         -0.544774
eval/env_infos/initial/reward_ctrl Mean      -0.0153607
eval/env_infos/initial/reward_ctrl Std        0.0128748
eval/env_infos/initial/reward_ctrl Max       -0.00368199
eval/env_infos/initial/reward_ctrl Min       -0.0401748
eval/env_infos/reward_ctrl Mean              -0.351953
eval/env_infos/reward_ctrl Std                0.121995
eval/env_infos/reward_ctrl Max               -0.00368199
eval/env_infos/reward_ctrl Min               -0.595996
time/data storing (s)                         0.00450218
time/evaluation sampling (s)                  2.04432
time/exploration sampling (s)                 0.537176
time/logging (s)                              0.0138841
time/sac training (s)                         7.97859
time/saving (s)                               0.00383872
time/training (s)                             3.8986e-05
time/epoch (s)                               10.5824
time/total (s)                              334.637
Epoch                                        30
---------------------------------------  ---------------
2021-11-24 00:34:56.122092 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 31 finished
---------------------------------------  ---------------
epoch                                        31
replay_buffer/size                        33000
trainer/num train calls                   32000
trainer/QF1 Loss                              1.91253
trainer/QF2 Loss                              1.99599
trainer/Policy Loss                         -33.6212
trainer/Q1 Predictions Mean                  33.3874
trainer/Q1 Predictions Std                   23.3729
trainer/Q1 Predictions Max                   77.0257
trainer/Q1 Predictions Min                    5.04722
trainer/Q2 Predictions Mean                  33.3061
trainer/Q2 Predictions Std                   23.4071
trainer/Q2 Predictions Max                   77.6795
trainer/Q2 Predictions Min                    5.12095
trainer/Q Targets Mean                       33.4394
trainer/Q Targets Std                        23.5203
trainer/Q Targets Max                        78.5892
trainer/Q Targets Min                         5.57467
trainer/Log Pis Mean                          5.77581
trainer/Log Pis Std                           4.86
trainer/Log Pis Max                          22.5406
trainer/Log Pis Min                          -3.50335
trainer/policy/mean Mean                     -0.0136299
trainer/policy/mean Std                       0.717642
trainer/policy/mean Max                       0.999989
trainer/policy/mean Min                      -0.999894
trainer/policy/normal/std Mean                0.403961
trainer/policy/normal/std Std                 0.147912
trainer/policy/normal/std Max                 1.21145
trainer/policy/normal/std Min                 0.104629
trainer/policy/normal/log_std Mean           -0.976979
trainer/policy/normal/log_std Std             0.384939
trainer/policy/normal/log_std Max             0.191815
trainer/policy/normal/log_std Min            -2.25734
trainer/Alpha                                 0.0198969
trainer/Alpha Loss                           -0.878177
expl/num steps total                      33000
expl/num paths total                         33
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.93385
expl/Rewards Std                              0.908919
expl/Rewards Max                              4.34237
expl/Rewards Min                             -0.646772
expl/Returns Mean                          1933.85
expl/Returns Std                              0
expl/Returns Max                           1933.85
expl/Returns Min                           1933.85
expl/Actions Mean                             0.0612592
expl/Actions Std                              0.7531
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                                1
expl/Average Returns                       1933.85
expl/env_infos/final/reward_run Mean          1.78745
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.78745
expl/env_infos/final/reward_run Min           1.78745
expl/env_infos/initial/reward_run Mean        0.020348
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.020348
expl/env_infos/initial/reward_run Min         0.020348
expl/env_infos/reward_run Mean                2.2764
expl/env_infos/reward_run Std                 0.913623
expl/env_infos/reward_run Max                 4.72871
expl/env_infos/reward_run Min                -0.249193
expl/env_infos/final/reward_ctrl Mean        -0.258056
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.258056
expl/env_infos/final/reward_ctrl Min         -0.258056
expl/env_infos/initial/reward_ctrl Mean      -0.0623495
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0623495
expl/env_infos/initial/reward_ctrl Min       -0.0623495
expl/env_infos/reward_ctrl Mean              -0.342547
expl/env_infos/reward_ctrl Std                0.109876
expl/env_infos/reward_ctrl Max               -0.0623495
expl/env_infos/reward_ctrl Min               -0.586939
eval/num steps total                     160000
eval/num paths total                        160
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.13535
eval/Rewards Std                              0.893434
eval/Rewards Max                              4.59052
eval/Rewards Min                             -1.2079
eval/Returns Mean                          2135.35
eval/Returns Std                             72.9354
eval/Returns Max                           2266.32
eval/Returns Min                           2065.64
eval/Actions Mean                             0.0530081
eval/Actions Std                              0.747772
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                       2135.35
eval/env_infos/final/reward_run Mean          1.97143
eval/env_infos/final/reward_run Std           0.937875
eval/env_infos/final/reward_run Max           3.15136
eval/env_infos/final/reward_run Min           0.500789
eval/env_infos/initial/reward_run Mean       -0.00544851
eval/env_infos/initial/reward_run Std         0.0425549
eval/env_infos/initial/reward_run Max         0.0498505
eval/env_infos/initial/reward_run Min        -0.0488536
eval/env_infos/reward_run Mean                2.47254
eval/env_infos/reward_run Std                 0.895652
eval/env_infos/reward_run Max                 4.95812
eval/env_infos/reward_run Min                -0.655653
eval/env_infos/final/reward_ctrl Mean        -0.342954
eval/env_infos/final/reward_ctrl Std          0.0828692
eval/env_infos/final/reward_ctrl Max         -0.236464
eval/env_infos/final/reward_ctrl Min         -0.48423
eval/env_infos/initial/reward_ctrl Mean      -0.0193394
eval/env_infos/initial/reward_ctrl Std        0.0106833
eval/env_infos/initial/reward_ctrl Max       -0.00933761
eval/env_infos/initial/reward_ctrl Min       -0.0359704
eval/env_infos/reward_ctrl Mean              -0.337184
eval/env_infos/reward_ctrl Std                0.109847
eval/env_infos/reward_ctrl Max               -0.00933761
eval/env_infos/reward_ctrl Min               -0.590172
time/data storing (s)                         0.00494066
time/evaluation sampling (s)                  2.07957
time/exploration sampling (s)                 0.540219
time/logging (s)                              0.0144774
time/sac training (s)                         7.89816
time/saving (s)                               0.00397736
time/training (s)                             4.0089e-05
time/epoch (s)                               10.5414
time/total (s)                              345.486
Epoch                                        31
---------------------------------------  ---------------
2021-11-24 00:35:07.027627 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 32 finished
---------------------------------------  ---------------
epoch                                        32
replay_buffer/size                        34000
trainer/num train calls                   33000
trainer/QF1 Loss                              2.12747
trainer/QF2 Loss                              1.94892
trainer/Policy Loss                         -39.176
trainer/Q1 Predictions Mean                  38.7983
trainer/Q1 Predictions Std                   24.5358
trainer/Q1 Predictions Max                   79.4883
trainer/Q1 Predictions Min                    7.30905
trainer/Q2 Predictions Mean                  39.0228
trainer/Q2 Predictions Std                   24.5703
trainer/Q2 Predictions Max                   79.2638
trainer/Q2 Predictions Min                    7.12088
trainer/Q Targets Mean                       38.8428
trainer/Q Targets Std                        24.6585
trainer/Q Targets Max                        78.2084
trainer/Q Targets Min                         7.00105
trainer/Log Pis Mean                          6.05604
trainer/Log Pis Std                           5.0843
trainer/Log Pis Max                          26.3607
trainer/Log Pis Min                          -4.34817
trainer/policy/mean Mean                      0.0840561
trainer/policy/mean Std                       0.710038
trainer/policy/mean Max                       0.999993
trainer/policy/mean Min                      -0.999698
trainer/policy/normal/std Mean                0.402648
trainer/policy/normal/std Std                 0.152982
trainer/policy/normal/std Max                 1.21707
trainer/policy/normal/std Min                 0.108834
trainer/policy/normal/log_std Mean           -0.982365
trainer/policy/normal/log_std Std             0.387361
trainer/policy/normal/log_std Max             0.19645
trainer/policy/normal/log_std Min            -2.21794
trainer/Alpha                                 0.0225369
trainer/Alpha Loss                            0.212549
expl/num steps total                      34000
expl/num paths total                         34
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.03973
expl/Rewards Std                              1.02629
expl/Rewards Max                              4.8626
expl/Rewards Min                             -1.03361
expl/Returns Mean                          2039.73
expl/Returns Std                              0
expl/Returns Max                           2039.73
expl/Returns Min                           2039.73
expl/Actions Mean                             0.0675152
expl/Actions Std                              0.785427
expl/Actions Max                              1
expl/Actions Min                             -0.999999
expl/Num Paths                                1
expl/Average Returns                       2039.73
expl/env_infos/final/reward_run Mean          1.24628
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.24628
expl/env_infos/final/reward_run Min           1.24628
expl/env_infos/initial/reward_run Mean        0.275292
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.275292
expl/env_infos/initial/reward_run Min         0.275292
expl/env_infos/reward_run Mean                2.4126
expl/env_infos/reward_run Std                 1.03062
expl/env_infos/reward_run Max                 5.28335
expl/env_infos/reward_run Min                -0.728958
expl/env_infos/final/reward_ctrl Mean        -0.551265
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.551265
expl/env_infos/final/reward_ctrl Min         -0.551265
expl/env_infos/initial/reward_ctrl Mean      -0.0588199
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0588199
expl/env_infos/initial/reward_ctrl Min       -0.0588199
expl/env_infos/reward_ctrl Mean              -0.372873
expl/env_infos/reward_ctrl Std                0.096472
expl/env_infos/reward_ctrl Max               -0.0588199
expl/env_infos/reward_ctrl Min               -0.587305
eval/num steps total                     165000
eval/num paths total                        165
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.94696
eval/Rewards Std                              1.25897
eval/Rewards Max                              5.27167
eval/Rewards Min                             -1.65681
eval/Returns Mean                          1946.96
eval/Returns Std                            285.077
eval/Returns Max                           2147.7
eval/Returns Min                           1383.85
eval/Actions Mean                             0.0738752
eval/Actions Std                              0.782163
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                       1946.96
eval/env_infos/final/reward_run Mean          1.48922
eval/env_infos/final/reward_run Std           1.3962
eval/env_infos/final/reward_run Max           3.15052
eval/env_infos/final/reward_run Min          -0.437399
eval/env_infos/initial/reward_run Mean        0.167999
eval/env_infos/initial/reward_run Std         0.092879
eval/env_infos/initial/reward_run Max         0.30064
eval/env_infos/initial/reward_run Min         0.0375375
eval/env_infos/reward_run Mean                2.31731
eval/env_infos/reward_run Std                 1.27145
eval/env_infos/reward_run Max                 5.73259
eval/env_infos/reward_run Min                -1.24813
eval/env_infos/final/reward_ctrl Mean        -0.382877
eval/env_infos/final/reward_ctrl Std          0.0924441
eval/env_infos/final/reward_ctrl Max         -0.262264
eval/env_infos/final/reward_ctrl Min         -0.515935
eval/env_infos/initial/reward_ctrl Mean      -0.0309992
eval/env_infos/initial/reward_ctrl Std        0.00764577
eval/env_infos/initial/reward_ctrl Max       -0.0239899
eval/env_infos/initial/reward_ctrl Min       -0.0452481
eval/env_infos/reward_ctrl Mean              -0.370342
eval/env_infos/reward_ctrl Std                0.0984834
eval/env_infos/reward_ctrl Max               -0.0239899
eval/env_infos/reward_ctrl Min               -0.597731
time/data storing (s)                         0.00508868
time/evaluation sampling (s)                  2.06506
time/exploration sampling (s)                 0.55379
time/logging (s)                              0.0139381
time/sac training (s)                         7.93268
time/saving (s)                               0.00381587
time/training (s)                             3.5437e-05
time/epoch (s)                               10.5744
time/total (s)                              356.376
Epoch                                        32
---------------------------------------  ---------------
2021-11-24 00:35:18.052322 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 33 finished
---------------------------------------  ---------------
epoch                                        33
replay_buffer/size                        35000
trainer/num train calls                   34000
trainer/QF1 Loss                              2.25766
trainer/QF2 Loss                              2.55241
trainer/Policy Loss                         -40.1984
trainer/Q1 Predictions Mean                  39.8363
trainer/Q1 Predictions Std                   25.8203
trainer/Q1 Predictions Max                   90.2709
trainer/Q1 Predictions Min                    6.48458
trainer/Q2 Predictions Mean                  39.9759
trainer/Q2 Predictions Std                   25.9439
trainer/Q2 Predictions Max                   89.9574
trainer/Q2 Predictions Min                    6.71813
trainer/Q Targets Mean                       39.7689
trainer/Q Targets Std                        25.9469
trainer/Q Targets Max                        92.1779
trainer/Q Targets Min                         5.8779
trainer/Log Pis Mean                          6.01166
trainer/Log Pis Std                           5.35525
trainer/Log Pis Max                          28.7145
trainer/Log Pis Min                          -6.70804
trainer/policy/mean Mean                      0.038787
trainer/policy/mean Std                       0.738634
trainer/policy/mean Max                       0.999989
trainer/policy/mean Min                      -0.999957
trainer/policy/normal/std Mean                0.425613
trainer/policy/normal/std Std                 0.14521
trainer/policy/normal/std Max                 1.47707
trainer/policy/normal/std Min                 0.0993893
trainer/policy/normal/log_std Mean           -0.912688
trainer/policy/normal/log_std Std             0.346899
trainer/policy/normal/log_std Max             0.390057
trainer/policy/normal/log_std Min            -2.30871
trainer/Alpha                                 0.025464
trainer/Alpha Loss                            0.0427849
expl/num steps total                      35000
expl/num paths total                         35
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.16829
expl/Rewards Std                              1.04305
expl/Rewards Max                              4.8318
expl/Rewards Min                             -1.49283
expl/Returns Mean                          2168.29
expl/Returns Std                              0
expl/Returns Max                           2168.29
expl/Returns Min                           2168.29
expl/Actions Mean                             0.0170342
expl/Actions Std                              0.801953
expl/Actions Max                              1
expl/Actions Min                             -0.999995
expl/Num Paths                                1
expl/Average Returns                       2168.29
expl/env_infos/final/reward_run Mean          3.24249
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.24249
expl/env_infos/final/reward_run Min           3.24249
expl/env_infos/initial/reward_run Mean        0.329956
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.329956
expl/env_infos/initial/reward_run Min         0.329956
expl/env_infos/reward_run Mean                2.55434
expl/env_infos/reward_run Std                 1.05451
expl/env_infos/reward_run Max                 5.15763
expl/env_infos/reward_run Min                -1.08802
expl/env_infos/final/reward_ctrl Mean        -0.596362
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.596362
expl/env_infos/final/reward_ctrl Min         -0.596362
expl/env_infos/initial/reward_ctrl Mean      -0.041611
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.041611
expl/env_infos/initial/reward_ctrl Min       -0.041611
expl/env_infos/reward_ctrl Mean              -0.386052
expl/env_infos/reward_ctrl Std                0.100054
expl/env_infos/reward_ctrl Max               -0.041611
expl/env_infos/reward_ctrl Min               -0.596362
eval/num steps total                     170000
eval/num paths total                        170
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.94575
eval/Rewards Std                              1.33824
eval/Rewards Max                              5.68294
eval/Rewards Min                             -1.77478
eval/Returns Mean                          1945.75
eval/Returns Std                            759.483
eval/Returns Max                           2541.8
eval/Returns Min                            454.503
eval/Actions Mean                             0.00665768
eval/Actions Std                              0.792829
eval/Actions Max                              0.999999
eval/Actions Min                             -0.999996
eval/Num Paths                                5
eval/Average Returns                       1945.75
eval/env_infos/final/reward_run Mean          1.82793
eval/env_infos/final/reward_run Std           1.32179
eval/env_infos/final/reward_run Max           4.22847
eval/env_infos/final/reward_run Min           0.260008
eval/env_infos/initial/reward_run Mean        0.0258846
eval/env_infos/initial/reward_run Std         0.206991
eval/env_infos/initial/reward_run Max         0.435081
eval/env_infos/initial/reward_run Min        -0.112274
eval/env_infos/reward_run Mean                2.32292
eval/env_infos/reward_run Std                 1.35271
eval/env_infos/reward_run Max                 6.10143
eval/env_infos/reward_run Min                -1.30586
eval/env_infos/final/reward_ctrl Mean        -0.434257
eval/env_infos/final/reward_ctrl Std          0.0744103
eval/env_infos/final/reward_ctrl Max         -0.362445
eval/env_infos/final/reward_ctrl Min         -0.569258
eval/env_infos/initial/reward_ctrl Mean      -0.0407823
eval/env_infos/initial/reward_ctrl Std        0.0297484
eval/env_infos/initial/reward_ctrl Max       -0.0106665
eval/env_infos/initial/reward_ctrl Min       -0.0917453
eval/env_infos/reward_ctrl Mean              -0.377173
eval/env_infos/reward_ctrl Std                0.0979303
eval/env_infos/reward_ctrl Max               -0.0106665
eval/env_infos/reward_ctrl Min               -0.596559
time/data storing (s)                         0.00449381
time/evaluation sampling (s)                  2.1025
time/exploration sampling (s)                 0.547931
time/logging (s)                              0.0146836
time/sac training (s)                         8.01532
time/saving (s)                               0.00389854
time/training (s)                             4.5485e-05
time/epoch (s)                               10.6889
time/total (s)                              367.387
Epoch                                        33
---------------------------------------  ---------------
2021-11-24 00:35:28.570465 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 34 finished
---------------------------------------  ---------------
epoch                                        34
replay_buffer/size                        36000
trainer/num train calls                   35000
trainer/QF1 Loss                              2.59028
trainer/QF2 Loss                              2.56512
trainer/Policy Loss                         -38.8384
trainer/Q1 Predictions Mean                  38.6413
trainer/Q1 Predictions Std                   27.2046
trainer/Q1 Predictions Max                   96.2864
trainer/Q1 Predictions Min                    6.07242
trainer/Q2 Predictions Mean                  38.6147
trainer/Q2 Predictions Std                   27.195
trainer/Q2 Predictions Max                   96.9166
trainer/Q2 Predictions Min                    5.79292
trainer/Q Targets Mean                       38.6486
trainer/Q Targets Std                        27.1346
trainer/Q Targets Max                        97.2653
trainer/Q Targets Min                         5.28334
trainer/Log Pis Mean                          5.66205
trainer/Log Pis Std                           5.13897
trainer/Log Pis Max                          22.3264
trainer/Log Pis Min                          -5.80282
trainer/policy/mean Mean                      0.0532114
trainer/policy/mean Std                       0.740497
trainer/policy/mean Max                       0.999925
trainer/policy/mean Min                      -0.99993
trainer/policy/normal/std Mean                0.446922
trainer/policy/normal/std Std                 0.132886
trainer/policy/normal/std Max                 1.26695
trainer/policy/normal/std Min                 0.128666
trainer/policy/normal/log_std Mean           -0.851805
trainer/policy/normal/log_std Std             0.311803
trainer/policy/normal/log_std Max             0.236611
trainer/policy/normal/log_std Min            -2.05054
trainer/Alpha                                 0.0278371
trainer/Alpha Loss                           -1.21034
expl/num steps total                      36000
expl/num paths total                         36
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.403047
expl/Rewards Std                              1.22856
expl/Rewards Max                              5.15169
expl/Rewards Min                             -1.87834
expl/Returns Mean                           403.047
expl/Returns Std                              0
expl/Returns Max                            403.047
expl/Returns Min                            403.047
expl/Actions Mean                             0.0106018
expl/Actions Std                              0.767143
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999999
expl/Num Paths                                1
expl/Average Returns                        403.047
expl/env_infos/final/reward_run Mean          0.0655253
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.0655253
expl/env_infos/final/reward_run Min           0.0655253
expl/env_infos/initial/reward_run Mean       -0.177651
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.177651
expl/env_infos/initial/reward_run Min        -0.177651
expl/env_infos/reward_run Mean                0.756219
expl/env_infos/reward_run Std                 1.24859
expl/env_infos/reward_run Max                 5.54922
expl/env_infos/reward_run Min                -1.47277
expl/env_infos/final/reward_ctrl Mean        -0.433806
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.433806
expl/env_infos/final/reward_ctrl Min         -0.433806
expl/env_infos/initial/reward_ctrl Mean      -0.0561289
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0561289
expl/env_infos/initial/reward_ctrl Min       -0.0561289
expl/env_infos/reward_ctrl Mean              -0.353172
expl/env_infos/reward_ctrl Std                0.0937349
expl/env_infos/reward_ctrl Max               -0.0561289
expl/env_infos/reward_ctrl Min               -0.594879
eval/num steps total                     175000
eval/num paths total                        175
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.46209
eval/Rewards Std                              1.10829
eval/Rewards Max                              5.53977
eval/Rewards Min                             -1.87387
eval/Returns Mean                          2462.09
eval/Returns Std                            253.566
eval/Returns Max                           2700.05
eval/Returns Min                           2026.02
eval/Actions Mean                             0.0321294
eval/Actions Std                              0.833728
eval/Actions Max                              0.999999
eval/Actions Min                             -0.999989
eval/Num Paths                                5
eval/Average Returns                       2462.09
eval/env_infos/final/reward_run Mean          2.95864
eval/env_infos/final/reward_run Std           1.14699
eval/env_infos/final/reward_run Max           4.31763
eval/env_infos/final/reward_run Min           0.838281
eval/env_infos/initial/reward_run Mean        0.0376954
eval/env_infos/initial/reward_run Std         0.0806976
eval/env_infos/initial/reward_run Max         0.132078
eval/env_infos/initial/reward_run Min        -0.0973369
eval/env_infos/reward_run Mean                2.87977
eval/env_infos/reward_run Std                 1.12505
eval/env_infos/reward_run Max                 6.04839
eval/env_infos/reward_run Min                -1.34039
eval/env_infos/final/reward_ctrl Mean        -0.421772
eval/env_infos/final/reward_ctrl Std          0.0800405
eval/env_infos/final/reward_ctrl Max         -0.370857
eval/env_infos/final/reward_ctrl Min         -0.579655
eval/env_infos/initial/reward_ctrl Mean      -0.0572333
eval/env_infos/initial/reward_ctrl Std        0.0202242
eval/env_infos/initial/reward_ctrl Max       -0.0382287
eval/env_infos/initial/reward_ctrl Min       -0.0915908
eval/env_infos/reward_ctrl Mean              -0.417681
eval/env_infos/reward_ctrl Std                0.0979843
eval/env_infos/reward_ctrl Max               -0.0382287
eval/env_infos/reward_ctrl Min               -0.59789
time/data storing (s)                         0.00498533
time/evaluation sampling (s)                  1.97992
time/exploration sampling (s)                 0.526811
time/logging (s)                              0.0145518
time/sac training (s)                         7.66769
time/saving (s)                               0.0038757
time/training (s)                             5.8512e-05
time/epoch (s)                               10.1979
time/total (s)                              377.89
Epoch                                        34
---------------------------------------  ---------------
2021-11-24 00:35:39.152182 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 35 finished
---------------------------------------  ---------------
epoch                                        35
replay_buffer/size                        37000
trainer/num train calls                   36000
trainer/QF1 Loss                              2.95484
trainer/QF2 Loss                              2.52984
trainer/Policy Loss                         -42.0935
trainer/Q1 Predictions Mean                  41.706
trainer/Q1 Predictions Std                   29.6636
trainer/Q1 Predictions Max                  104.265
trainer/Q1 Predictions Min                    7.65537
trainer/Q2 Predictions Mean                  41.6245
trainer/Q2 Predictions Std                   29.4758
trainer/Q2 Predictions Max                  102.39
trainer/Q2 Predictions Min                    7.6956
trainer/Q Targets Mean                       41.1859
trainer/Q Targets Std                        29.4672
trainer/Q Targets Max                       103.67
trainer/Q Targets Min                         6.70763
trainer/Log Pis Mean                          5.52048
trainer/Log Pis Std                           5.31412
trainer/Log Pis Max                          25.8785
trainer/Log Pis Min                          -5.14381
trainer/policy/mean Mean                      0.0761893
trainer/policy/mean Std                       0.741612
trainer/policy/mean Max                       0.999993
trainer/policy/mean Min                      -0.999976
trainer/policy/normal/std Mean                0.477128
trainer/policy/normal/std Std                 0.142895
trainer/policy/normal/std Max                 1.19077
trainer/policy/normal/std Min                 0.149426
trainer/policy/normal/log_std Mean           -0.785368
trainer/policy/normal/log_std Std             0.305318
trainer/policy/normal/log_std Max             0.174604
trainer/policy/normal/log_std Min            -1.90096
trainer/Alpha                                 0.0285968
trainer/Alpha Loss                           -1.70444
expl/num steps total                      37000
expl/num paths total                         37
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.04451
expl/Rewards Std                              1.10966
expl/Rewards Max                              4.935
expl/Rewards Min                             -1.49978
expl/Returns Mean                          2044.51
expl/Returns Std                              0
expl/Returns Max                           2044.51
expl/Returns Min                           2044.51
expl/Actions Mean                             0.0390179
expl/Actions Std                              0.828478
expl/Actions Max                              1
expl/Actions Min                             -0.999993
expl/Num Paths                                1
expl/Average Returns                       2044.51
expl/env_infos/final/reward_run Mean          1.95636
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.95636
expl/env_infos/final/reward_run Min           1.95636
expl/env_infos/initial/reward_run Mean        0.168891
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.168891
expl/env_infos/initial/reward_run Min         0.168891
expl/env_infos/reward_run Mean                2.45725
expl/env_infos/reward_run Std                 1.11893
expl/env_infos/reward_run Max                 5.46379
expl/env_infos/reward_run Min                -1.17488
expl/env_infos/final/reward_ctrl Mean        -0.489057
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.489057
expl/env_infos/final/reward_ctrl Min         -0.489057
expl/env_infos/initial/reward_ctrl Mean      -0.0461762
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0461762
expl/env_infos/initial/reward_ctrl Min       -0.0461762
expl/env_infos/reward_ctrl Mean              -0.412739
expl/env_infos/reward_ctrl Std                0.0954664
expl/env_infos/reward_ctrl Max               -0.0461762
expl/env_infos/reward_ctrl Min               -0.597817
eval/num steps total                     180000
eval/num paths total                        180
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.32609
eval/Rewards Std                              1.09341
eval/Rewards Max                              5.30367
eval/Rewards Min                             -1.95312
eval/Returns Mean                          2326.09
eval/Returns Std                             88.1408
eval/Returns Max                           2424.19
eval/Returns Min                           2173.44
eval/Actions Mean                             0.0484434
eval/Actions Std                              0.835577
eval/Actions Max                              0.999999
eval/Actions Min                             -0.999973
eval/Num Paths                                5
eval/Average Returns                       2326.09
eval/env_infos/final/reward_run Mean          2.15816
eval/env_infos/final/reward_run Std           1.42621
eval/env_infos/final/reward_run Max           4.0629
eval/env_infos/final/reward_run Min           0.275469
eval/env_infos/initial/reward_run Mean       -0.0195697
eval/env_infos/initial/reward_run Std         0.119224
eval/env_infos/initial/reward_run Max         0.208936
eval/env_infos/initial/reward_run Min        -0.133288
eval/env_infos/reward_run Mean                2.74642
eval/env_infos/reward_run Std                 1.10736
eval/env_infos/reward_run Max                 5.89639
eval/env_infos/reward_run Min                -1.51238
eval/env_infos/final/reward_ctrl Mean        -0.453284
eval/env_infos/final/reward_ctrl Std          0.0751696
eval/env_infos/final/reward_ctrl Max         -0.325106
eval/env_infos/final/reward_ctrl Min         -0.555644
eval/env_infos/initial/reward_ctrl Mean      -0.0532589
eval/env_infos/initial/reward_ctrl Std        0.0269338
eval/env_infos/initial/reward_ctrl Max       -0.018442
eval/env_infos/initial/reward_ctrl Min       -0.0943016
eval/env_infos/reward_ctrl Mean              -0.420322
eval/env_infos/reward_ctrl Std                0.0974358
eval/env_infos/reward_ctrl Max               -0.018442
eval/env_infos/reward_ctrl Min               -0.598869
time/data storing (s)                         0.00450622
time/evaluation sampling (s)                  2.01399
time/exploration sampling (s)                 0.528476
time/logging (s)                              0.0141275
time/sac training (s)                         7.69434
time/saving (s)                               0.00383676
time/training (s)                             3.3949e-05
time/epoch (s)                               10.2593
time/total (s)                              388.457
Epoch                                        35
---------------------------------------  ---------------
2021-11-24 00:35:50.790551 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 36 finished
---------------------------------------  ---------------
epoch                                        36
replay_buffer/size                        38000
trainer/num train calls                   37000
trainer/QF1 Loss                              3.28272
trainer/QF2 Loss                              3.633
trainer/Policy Loss                         -43.2089
trainer/Q1 Predictions Mean                  43.1283
trainer/Q1 Predictions Std                   30.7054
trainer/Q1 Predictions Max                  105.357
trainer/Q1 Predictions Min                    6.92666
trainer/Q2 Predictions Mean                  42.9447
trainer/Q2 Predictions Std                   30.5431
trainer/Q2 Predictions Max                  103.198
trainer/Q2 Predictions Min                    7.48708
trainer/Q Targets Mean                       43.1991
trainer/Q Targets Std                        30.9013
trainer/Q Targets Max                       103.271
trainer/Q Targets Min                         5.81233
trainer/Log Pis Mean                          6.2509
trainer/Log Pis Std                           5.3398
trainer/Log Pis Max                          27.6836
trainer/Log Pis Min                          -4.88182
trainer/policy/mean Mean                      0.0501696
trainer/policy/mean Std                       0.746994
trainer/policy/mean Max                       0.99998
trainer/policy/mean Min                      -0.999964
trainer/policy/normal/std Mean                0.459205
trainer/policy/normal/std Std                 0.138554
trainer/policy/normal/std Max                 1.11881
trainer/policy/normal/std Min                 0.110596
trainer/policy/normal/log_std Mean           -0.826143
trainer/policy/normal/log_std Std             0.316506
trainer/policy/normal/log_std Max             0.112266
trainer/policy/normal/log_std Min            -2.20187
trainer/Alpha                                 0.0289914
trainer/Alpha Loss                            0.888374
expl/num steps total                      38000
expl/num paths total                         38
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.69466
expl/Rewards Std                              1.5053
expl/Rewards Max                              4.62087
expl/Rewards Min                             -2.35163
expl/Returns Mean                          1694.66
expl/Returns Std                              0
expl/Returns Max                           1694.66
expl/Returns Min                           1694.66
expl/Actions Mean                             0.0791573
expl/Actions Std                              0.804697
expl/Actions Max                              0.999997
expl/Actions Min                             -0.999985
expl/Num Paths                                1
expl/Average Returns                       1694.66
expl/env_infos/final/reward_run Mean          0.475814
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.475814
expl/env_infos/final/reward_run Min           0.475814
expl/env_infos/initial/reward_run Mean        0.090272
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.090272
expl/env_infos/initial/reward_run Min         0.090272
expl/env_infos/reward_run Mean                2.08695
expl/env_infos/reward_run Std                 1.54287
expl/env_infos/reward_run Max                 5.11851
expl/env_infos/reward_run Min                -1.90913
expl/env_infos/final/reward_ctrl Mean        -0.35804
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.35804
expl/env_infos/final/reward_ctrl Min         -0.35804
expl/env_infos/initial/reward_ctrl Mean      -0.115971
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.115971
expl/env_infos/initial/reward_ctrl Min       -0.115971
expl/env_infos/reward_ctrl Mean              -0.392282
expl/env_infos/reward_ctrl Std                0.101084
expl/env_infos/reward_ctrl Max               -0.115971
expl/env_infos/reward_ctrl Min               -0.598754
eval/num steps total                     185000
eval/num paths total                        185
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.17327
eval/Rewards Std                              1.31562
eval/Rewards Max                              5.28788
eval/Rewards Min                             -2.44998
eval/Returns Mean                          2173.27
eval/Returns Std                            455.196
eval/Returns Max                           2474.31
eval/Returns Min                           1271.02
eval/Actions Mean                             0.0428427
eval/Actions Std                              0.824249
eval/Actions Max                              1
eval/Actions Min                             -0.999992
eval/Num Paths                                5
eval/Average Returns                       2173.27
eval/env_infos/final/reward_run Mean          2.56263
eval/env_infos/final/reward_run Std           1.86477
eval/env_infos/final/reward_run Max           4.72489
eval/env_infos/final/reward_run Min          -0.796771
eval/env_infos/initial/reward_run Mean        0.23571
eval/env_infos/initial/reward_run Std         0.2369
eval/env_infos/initial/reward_run Max         0.562472
eval/env_infos/initial/reward_run Min        -0.111237
eval/env_infos/reward_run Mean                2.582
eval/env_infos/reward_run Std                 1.34895
eval/env_infos/reward_run Max                 5.87696
eval/env_infos/reward_run Min                -2.16262
eval/env_infos/final/reward_ctrl Mean        -0.420209
eval/env_infos/final/reward_ctrl Std          0.080795
eval/env_infos/final/reward_ctrl Max         -0.271014
eval/env_infos/final/reward_ctrl Min         -0.516683
eval/env_infos/initial/reward_ctrl Mean      -0.0536279
eval/env_infos/initial/reward_ctrl Std        0.019175
eval/env_infos/initial/reward_ctrl Max       -0.0291951
eval/env_infos/initial/reward_ctrl Min       -0.0816025
eval/env_infos/reward_ctrl Mean              -0.408733
eval/env_infos/reward_ctrl Std                0.104344
eval/env_infos/reward_ctrl Max               -0.0291951
eval/env_infos/reward_ctrl Min               -0.599096
time/data storing (s)                         0.00445369
time/evaluation sampling (s)                  2.04906
time/exploration sampling (s)                 0.537306
time/logging (s)                              0.0144186
time/sac training (s)                         8.65953
time/saving (s)                               0.00416104
time/training (s)                             7.4186e-05
time/epoch (s)                               11.269
time/total (s)                              400.079
Epoch                                        36
---------------------------------------  ---------------
2021-11-24 00:36:01.713147 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 37 finished
---------------------------------------  ---------------
epoch                                        37
replay_buffer/size                        39000
trainer/num train calls                   38000
trainer/QF1 Loss                              3.19094
trainer/QF2 Loss                              3.59156
trainer/Policy Loss                         -50.2876
trainer/Q1 Predictions Mean                  50.1564
trainer/Q1 Predictions Std                   34.6138
trainer/Q1 Predictions Max                  108.733
trainer/Q1 Predictions Min                    7.52215
trainer/Q2 Predictions Mean                  50.0013
trainer/Q2 Predictions Std                   34.5337
trainer/Q2 Predictions Max                  109.146
trainer/Q2 Predictions Min                    6.78907
trainer/Q Targets Mean                       50.0952
trainer/Q Targets Std                        34.6116
trainer/Q Targets Max                       109.282
trainer/Q Targets Min                         6.62407
trainer/Log Pis Mean                          6.55336
trainer/Log Pis Std                           5.49885
trainer/Log Pis Max                          24.0976
trainer/Log Pis Min                          -7.38913
trainer/policy/mean Mean                      0.0353917
trainer/policy/mean Std                       0.753802
trainer/policy/mean Max                       0.999967
trainer/policy/mean Min                      -0.999969
trainer/policy/normal/std Mean                0.44737
trainer/policy/normal/std Std                 0.133114
trainer/policy/normal/std Max                 1.4922
trainer/policy/normal/std Min                 0.150543
trainer/policy/normal/log_std Mean           -0.849622
trainer/policy/normal/log_std Std             0.305912
trainer/policy/normal/log_std Max             0.400255
trainer/policy/normal/log_std Min            -1.8935
trainer/Alpha                                 0.0282008
trainer/Alpha Loss                            1.97463
expl/num steps total                      39000
expl/num paths total                         39
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.46028
expl/Rewards Std                              1.15935
expl/Rewards Max                              5.16947
expl/Rewards Min                             -0.900898
expl/Returns Mean                          2460.28
expl/Returns Std                              0
expl/Returns Max                           2460.28
expl/Returns Min                           2460.28
expl/Actions Mean                             0.0199036
expl/Actions Std                              0.836309
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999989
expl/Num Paths                                1
expl/Average Returns                       2460.28
expl/env_infos/final/reward_run Mean          1.87589
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.87589
expl/env_infos/final/reward_run Min           1.87589
expl/env_infos/initial/reward_run Mean        0.330583
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.330583
expl/env_infos/initial/reward_run Min         0.330583
expl/env_infos/reward_run Mean                2.88017
expl/env_infos/reward_run Std                 1.17952
expl/env_infos/reward_run Max                 5.71733
expl/env_infos/reward_run Min                -0.480075
expl/env_infos/final/reward_ctrl Mean        -0.443968
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.443968
expl/env_infos/final/reward_ctrl Min         -0.443968
expl/env_infos/initial/reward_ctrl Mean      -0.0649298
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0649298
expl/env_infos/initial/reward_ctrl Min       -0.0649298
expl/env_infos/reward_ctrl Mean              -0.419886
expl/env_infos/reward_ctrl Std                0.0938891
expl/env_infos/reward_ctrl Max               -0.0649298
expl/env_infos/reward_ctrl Min               -0.595348
eval/num steps total                     190000
eval/num paths total                        190
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.35117
eval/Rewards Std                              1.33518
eval/Rewards Max                              5.69979
eval/Rewards Min                             -1.54821
eval/Returns Mean                          2351.17
eval/Returns Std                            550.349
eval/Returns Max                           2756.62
eval/Returns Min                           1267.19
eval/Actions Mean                             0.00733768
eval/Actions Std                              0.831395
eval/Actions Max                              0.999998
eval/Actions Min                             -0.99997
eval/Num Paths                                5
eval/Average Returns                       2351.17
eval/env_infos/final/reward_run Mean          2.52193
eval/env_infos/final/reward_run Std           1.5791
eval/env_infos/final/reward_run Max           4.0085
eval/env_infos/final/reward_run Min          -0.406629
eval/env_infos/initial/reward_run Mean       -0.0783308
eval/env_infos/initial/reward_run Std         0.151957
eval/env_infos/initial/reward_run Max         0.145741
eval/env_infos/initial/reward_run Min        -0.286079
eval/env_infos/reward_run Mean                2.76593
eval/env_infos/reward_run Std                 1.37114
eval/env_infos/reward_run Max                 6.20792
eval/env_infos/reward_run Min                -1.25111
eval/env_infos/final/reward_ctrl Mean        -0.469826
eval/env_infos/final/reward_ctrl Std          0.0704354
eval/env_infos/final/reward_ctrl Max         -0.39376
eval/env_infos/final/reward_ctrl Min         -0.56943
eval/env_infos/initial/reward_ctrl Mean      -0.0584397
eval/env_infos/initial/reward_ctrl Std        0.0619486
eval/env_infos/initial/reward_ctrl Max       -0.0170929
eval/env_infos/initial/reward_ctrl Min       -0.181121
eval/env_infos/reward_ctrl Mean              -0.414763
eval/env_infos/reward_ctrl Std                0.100259
eval/env_infos/reward_ctrl Max               -0.0170929
eval/env_infos/reward_ctrl Min               -0.596079
time/data storing (s)                         0.00446615
time/evaluation sampling (s)                  2.04627
time/exploration sampling (s)                 0.529026
time/logging (s)                              0.0155358
time/sac training (s)                         7.98036
time/saving (s)                               0.00388165
time/training (s)                             6.0082e-05
time/epoch (s)                               10.5796
time/total (s)                              410.987
Epoch                                        37
---------------------------------------  ---------------
2021-11-24 00:36:12.706102 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 38 finished
---------------------------------------  ----------------
epoch                                        38
replay_buffer/size                        40000
trainer/num train calls                   39000
trainer/QF1 Loss                              3.40234
trainer/QF2 Loss                              3.09173
trainer/Policy Loss                         -49.0227
trainer/Q1 Predictions Mean                  48.5895
trainer/Q1 Predictions Std                   35.7694
trainer/Q1 Predictions Max                  110.124
trainer/Q1 Predictions Min                    6.11511
trainer/Q2 Predictions Mean                  48.6687
trainer/Q2 Predictions Std                   35.7743
trainer/Q2 Predictions Max                  110.604
trainer/Q2 Predictions Min                    6.39206
trainer/Q Targets Mean                       48.8979
trainer/Q Targets Std                        35.8563
trainer/Q Targets Max                       112.222
trainer/Q Targets Min                         5.95086
trainer/Log Pis Mean                          6.28555
trainer/Log Pis Std                           5.8023
trainer/Log Pis Max                          24.0319
trainer/Log Pis Min                          -4.31082
trainer/policy/mean Mean                      0.0269961
trainer/policy/mean Std                       0.744267
trainer/policy/mean Max                       0.999981
trainer/policy/mean Min                      -0.999931
trainer/policy/normal/std Mean                0.443088
trainer/policy/normal/std Std                 0.137665
trainer/policy/normal/std Max                 1.1051
trainer/policy/normal/std Min                 0.129078
trainer/policy/normal/log_std Mean           -0.865182
trainer/policy/normal/log_std Std             0.327893
trainer/policy/normal/log_std Max             0.0999323
trainer/policy/normal/log_std Min            -2.04734
trainer/Alpha                                 0.0294539
trainer/Alpha Loss                            1.00653
expl/num steps total                      40000
expl/num paths total                         40
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.55819
expl/Rewards Std                              0.961792
expl/Rewards Max                              4.96094
expl/Rewards Min                             -0.23916
expl/Returns Mean                          2558.19
expl/Returns Std                              0
expl/Returns Max                           2558.19
expl/Returns Min                           2558.19
expl/Actions Mean                            -0.00269335
expl/Actions Std                              0.823916
expl/Actions Max                              0.999992
expl/Actions Min                             -0.999982
expl/Num Paths                                1
expl/Average Returns                       2558.19
expl/env_infos/final/reward_run Mean          1.90647
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.90647
expl/env_infos/final/reward_run Min           1.90647
expl/env_infos/initial/reward_run Mean        0.00361627
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.00361627
expl/env_infos/initial/reward_run Min         0.00361627
expl/env_infos/reward_run Mean                2.9655
expl/env_infos/reward_run Std                 0.981599
expl/env_infos/reward_run Max                 5.33878
expl/env_infos/reward_run Min                 0.00361627
expl/env_infos/final/reward_ctrl Mean        -0.459465
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.459465
expl/env_infos/final/reward_ctrl Min         -0.459465
expl/env_infos/initial/reward_ctrl Mean      -0.0344718
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0344718
expl/env_infos/initial/reward_ctrl Min       -0.0344718
expl/env_infos/reward_ctrl Mean              -0.407307
expl/env_infos/reward_ctrl Std                0.10072
expl/env_infos/reward_ctrl Max               -0.0344718
expl/env_infos/reward_ctrl Min               -0.594625
eval/num steps total                     195000
eval/num paths total                        195
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.08773
eval/Rewards Std                              1.40245
eval/Rewards Max                              5.44391
eval/Rewards Min                             -1.88706
eval/Returns Mean                          2087.73
eval/Returns Std                            786.953
eval/Returns Max                           2607.9
eval/Returns Min                            527.396
eval/Actions Mean                             0.0162415
eval/Actions Std                              0.807565
eval/Actions Max                              1
eval/Actions Min                             -0.999991
eval/Num Paths                                5
eval/Average Returns                       2087.73
eval/env_infos/final/reward_run Mean          1.60167
eval/env_infos/final/reward_run Std           0.941675
eval/env_infos/final/reward_run Max           3.04897
eval/env_infos/final/reward_run Min           0.696605
eval/env_infos/initial/reward_run Mean        0.109537
eval/env_infos/initial/reward_run Std         0.0916905
eval/env_infos/initial/reward_run Max         0.229704
eval/env_infos/initial/reward_run Min        -0.019294
eval/env_infos/reward_run Mean                2.47919
eval/env_infos/reward_run Std                 1.44104
eval/env_infos/reward_run Max                 5.94069
eval/env_infos/reward_run Min                -1.47542
eval/env_infos/final/reward_ctrl Mean        -0.318677
eval/env_infos/final/reward_ctrl Std          0.103646
eval/env_infos/final/reward_ctrl Max         -0.133028
eval/env_infos/final/reward_ctrl Min         -0.427599
eval/env_infos/initial/reward_ctrl Mean      -0.0359137
eval/env_infos/initial/reward_ctrl Std        0.0216303
eval/env_infos/initial/reward_ctrl Max       -0.00424034
eval/env_infos/initial/reward_ctrl Min       -0.0700706
eval/env_infos/reward_ctrl Mean              -0.391455
eval/env_infos/reward_ctrl Std                0.107893
eval/env_infos/reward_ctrl Max               -0.00424034
eval/env_infos/reward_ctrl Min               -0.595639
time/data storing (s)                         0.00453635
time/evaluation sampling (s)                  2.1135
time/exploration sampling (s)                 0.563734
time/logging (s)                              0.0139451
time/sac training (s)                         7.96522
time/saving (s)                               0.00386914
time/training (s)                             5.81041e-05
time/epoch (s)                               10.6649
time/total (s)                              421.964
Epoch                                        38
---------------------------------------  ----------------
2021-11-24 00:36:23.101654 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 39 finished
---------------------------------------  ---------------
epoch                                        39
replay_buffer/size                        41000
trainer/num train calls                   40000
trainer/QF1 Loss                              3.47993
trainer/QF2 Loss                              3.46973
trainer/Policy Loss                         -55.72
trainer/Q1 Predictions Mean                  55.6569
trainer/Q1 Predictions Std                   38.7368
trainer/Q1 Predictions Max                  119.161
trainer/Q1 Predictions Min                    6.09851
trainer/Q2 Predictions Mean                  55.612
trainer/Q2 Predictions Std                   38.7868
trainer/Q2 Predictions Max                  120.707
trainer/Q2 Predictions Min                    5.64599
trainer/Q Targets Mean                       55.7675
trainer/Q Targets Std                        38.8095
trainer/Q Targets Max                       119.974
trainer/Q Targets Min                         6.55129
trainer/Log Pis Mean                          6.52103
trainer/Log Pis Std                           5.6444
trainer/Log Pis Max                          24.0384
trainer/Log Pis Min                          -6.12829
trainer/policy/mean Mean                      0.0867411
trainer/policy/mean Std                       0.754343
trainer/policy/mean Max                       0.999992
trainer/policy/mean Min                      -0.999788
trainer/policy/normal/std Mean                0.44512
trainer/policy/normal/std Std                 0.130627
trainer/policy/normal/std Max                 1.28452
trainer/policy/normal/std Min                 0.143308
trainer/policy/normal/log_std Mean           -0.85404
trainer/policy/normal/log_std Std             0.30448
trainer/policy/normal/log_std Max             0.250388
trainer/policy/normal/log_std Min            -1.94276
trainer/Alpha                                 0.0306537
trainer/Alpha Loss                            1.8158
expl/num steps total                      41000
expl/num paths total                         41
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.86434
expl/Rewards Std                              1.23058
expl/Rewards Max                              5.05994
expl/Rewards Min                             -1.94717
expl/Returns Mean                          1864.34
expl/Returns Std                              0
expl/Returns Max                           1864.34
expl/Returns Min                           1864.34
expl/Actions Mean                             0.0491323
expl/Actions Std                              0.814528
expl/Actions Max                              0.999998
expl/Actions Min                             -0.99999
expl/Num Paths                                1
expl/Average Returns                       1864.34
expl/env_infos/final/reward_run Mean          1.03784
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.03784
expl/env_infos/final/reward_run Min           1.03784
expl/env_infos/initial/reward_run Mean        0.0265362
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0265362
expl/env_infos/initial/reward_run Min         0.0265362
expl/env_infos/reward_run Mean                2.26386
expl/env_infos/reward_run Std                 1.25053
expl/env_infos/reward_run Max                 5.52082
expl/env_infos/reward_run Min                -1.46703
expl/env_infos/final/reward_ctrl Mean        -0.125879
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.125879
expl/env_infos/final/reward_ctrl Min         -0.125879
expl/env_infos/initial/reward_ctrl Mean      -0.13116
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.13116
expl/env_infos/initial/reward_ctrl Min       -0.13116
expl/env_infos/reward_ctrl Mean              -0.399522
expl/env_infos/reward_ctrl Std                0.102343
expl/env_infos/reward_ctrl Max               -0.0502745
expl/env_infos/reward_ctrl Min               -0.59416
eval/num steps total                     200000
eval/num paths total                        200
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.52178
eval/Rewards Std                              1.14216
eval/Rewards Max                              5.58242
eval/Rewards Min                             -1.47924
eval/Returns Mean                          2521.78
eval/Returns Std                             35.6996
eval/Returns Max                           2565.07
eval/Returns Min                           2476.67
eval/Actions Mean                             0.0369184
eval/Actions Std                              0.84148
eval/Actions Max                              0.999997
eval/Actions Min                             -0.999952
eval/Num Paths                                5
eval/Average Returns                       2521.78
eval/env_infos/final/reward_run Mean          3.13519
eval/env_infos/final/reward_run Std           1.33048
eval/env_infos/final/reward_run Max           4.72706
eval/env_infos/final/reward_run Min           0.768563
eval/env_infos/initial/reward_run Mean        0.0721846
eval/env_infos/initial/reward_run Std         0.120784
eval/env_infos/initial/reward_run Max         0.296106
eval/env_infos/initial/reward_run Min        -0.0558822
eval/env_infos/reward_run Mean                2.94745
eval/env_infos/reward_run Std                 1.15328
eval/env_infos/reward_run Max                 6.11062
eval/env_infos/reward_run Min                -1.01398
eval/env_infos/final/reward_ctrl Mean        -0.424291
eval/env_infos/final/reward_ctrl Std          0.0916667
eval/env_infos/final/reward_ctrl Max         -0.272419
eval/env_infos/final/reward_ctrl Min         -0.558068
eval/env_infos/initial/reward_ctrl Mean      -0.0599188
eval/env_infos/initial/reward_ctrl Std        0.0203061
eval/env_infos/initial/reward_ctrl Max       -0.0267042
eval/env_infos/initial/reward_ctrl Min       -0.0874168
eval/env_infos/reward_ctrl Mean              -0.425671
eval/env_infos/reward_ctrl Std                0.0935352
eval/env_infos/reward_ctrl Max               -0.0267042
eval/env_infos/reward_ctrl Min               -0.59684
time/data storing (s)                         0.00673895
time/evaluation sampling (s)                  2.0494
time/exploration sampling (s)                 0.542923
time/logging (s)                              0.0139359
time/sac training (s)                         7.47621
time/saving (s)                               0.00384335
time/training (s)                             3.5175e-05
time/epoch (s)                               10.0931
time/total (s)                              432.346
Epoch                                        39
---------------------------------------  ---------------
2021-11-24 00:36:33.405214 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 40 finished
---------------------------------------  ----------------
epoch                                        40
replay_buffer/size                        42000
trainer/num train calls                   41000
trainer/QF1 Loss                              4.90344
trainer/QF2 Loss                              4.94594
trainer/Policy Loss                         -57.5447
trainer/Q1 Predictions Mean                  57.1915
trainer/Q1 Predictions Std                   40.9991
trainer/Q1 Predictions Max                  129.168
trainer/Q1 Predictions Min                    5.51152
trainer/Q2 Predictions Mean                  57.3328
trainer/Q2 Predictions Std                   41.0484
trainer/Q2 Predictions Max                  128.831
trainer/Q2 Predictions Min                    5.90434
trainer/Q Targets Mean                       56.8998
trainer/Q Targets Std                        40.6797
trainer/Q Targets Max                       125.614
trainer/Q Targets Min                         5.77807
trainer/Log Pis Mean                          6.67891
trainer/Log Pis Std                           5.542
trainer/Log Pis Max                          24.8516
trainer/Log Pis Min                          -4.1451
trainer/policy/mean Mean                      0.0232688
trainer/policy/mean Std                       0.759326
trainer/policy/mean Max                       0.999974
trainer/policy/mean Min                      -0.999965
trainer/policy/normal/std Mean                0.448268
trainer/policy/normal/std Std                 0.132669
trainer/policy/normal/std Max                 1.02665
trainer/policy/normal/std Min                 0.1626
trainer/policy/normal/log_std Mean           -0.848688
trainer/policy/normal/log_std Std             0.311375
trainer/policy/normal/log_std Max             0.0263016
trainer/policy/normal/log_std Min            -1.81646
trainer/Alpha                                 0.0307251
trainer/Alpha Loss                            2.36441
expl/num steps total                      42000
expl/num paths total                         42
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.59009
expl/Rewards Std                              0.988036
expl/Rewards Max                              5.10146
expl/Rewards Min                             -0.354028
expl/Returns Mean                          2590.09
expl/Returns Std                              0
expl/Returns Max                           2590.09
expl/Returns Min                           2590.09
expl/Actions Mean                            -0.00527449
expl/Actions Std                              0.823662
expl/Actions Max                              0.99999
expl/Actions Min                             -0.999938
expl/Num Paths                                1
expl/Average Returns                       2590.09
expl/env_infos/final/reward_run Mean          3.81712
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.81712
expl/env_infos/final/reward_run Min           3.81712
expl/env_infos/initial/reward_run Mean        0.0937247
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0937247
expl/env_infos/initial/reward_run Min         0.0937247
expl/env_infos/reward_run Mean                2.99716
expl/env_infos/reward_run Std                 1.01145
expl/env_infos/reward_run Max                 5.66031
expl/env_infos/reward_run Min                 0.0937247
expl/env_infos/final/reward_ctrl Mean        -0.331082
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.331082
expl/env_infos/final/reward_ctrl Min         -0.331082
expl/env_infos/initial/reward_ctrl Mean      -0.0878133
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0878133
expl/env_infos/initial/reward_ctrl Min       -0.0878133
expl/env_infos/reward_ctrl Mean              -0.407068
expl/env_infos/reward_ctrl Std                0.0956443
expl/env_infos/reward_ctrl Max               -0.0878133
expl/env_infos/reward_ctrl Min               -0.596717
eval/num steps total                     205000
eval/num paths total                        205
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.00528
eval/Rewards Std                              1.37761
eval/Rewards Max                              5.26387
eval/Rewards Min                             -1.8507
eval/Returns Mean                          2005.28
eval/Returns Std                            650.918
eval/Returns Max                           2598.15
eval/Returns Min                            735.444
eval/Actions Mean                            -0.000598159
eval/Actions Std                              0.807315
eval/Actions Max                              0.999994
eval/Actions Min                             -0.999886
eval/Num Paths                                5
eval/Average Returns                       2005.28
eval/env_infos/final/reward_run Mean          1.31435
eval/env_infos/final/reward_run Std           0.966589
eval/env_infos/final/reward_run Max           2.3624
eval/env_infos/final/reward_run Min          -0.515419
eval/env_infos/initial/reward_run Mean       -0.0528829
eval/env_infos/initial/reward_run Std         0.116865
eval/env_infos/initial/reward_run Max         0.117637
eval/env_infos/initial/reward_run Min        -0.201904
eval/env_infos/reward_run Mean                2.39634
eval/env_infos/reward_run Std                 1.41837
eval/env_infos/reward_run Max                 5.80305
eval/env_infos/reward_run Min                -1.36697
eval/env_infos/final/reward_ctrl Mean        -0.35986
eval/env_infos/final/reward_ctrl Std          0.107055
eval/env_infos/final/reward_ctrl Max         -0.246158
eval/env_infos/final/reward_ctrl Min         -0.485778
eval/env_infos/initial/reward_ctrl Mean      -0.073597
eval/env_infos/initial/reward_ctrl Std        0.0273301
eval/env_infos/initial/reward_ctrl Max       -0.0303484
eval/env_infos/initial/reward_ctrl Min       -0.112498
eval/env_infos/reward_ctrl Mean              -0.391055
eval/env_infos/reward_ctrl Std                0.108197
eval/env_infos/reward_ctrl Max               -0.0303484
eval/env_infos/reward_ctrl Min               -0.596008
time/data storing (s)                         0.00449213
time/evaluation sampling (s)                  2.02468
time/exploration sampling (s)                 0.539066
time/logging (s)                              0.0138134
time/sac training (s)                         7.41952
time/saving (s)                               0.00380187
time/training (s)                             3.49e-05
time/epoch (s)                               10.0054
time/total (s)                              442.637
Epoch                                        40
---------------------------------------  ----------------
2021-11-24 00:36:43.691981 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 41 finished
---------------------------------------  ---------------
epoch                                        41
replay_buffer/size                        43000
trainer/num train calls                   42000
trainer/QF1 Loss                              3.9336
trainer/QF2 Loss                              4.24224
trainer/Policy Loss                         -55.744
trainer/Q1 Predictions Mean                  55.7618
trainer/Q1 Predictions Std                   41.4803
trainer/Q1 Predictions Max                  132.488
trainer/Q1 Predictions Min                    6.42175
trainer/Q2 Predictions Mean                  55.334
trainer/Q2 Predictions Std                   41.2703
trainer/Q2 Predictions Max                  132.439
trainer/Q2 Predictions Min                    5.9786
trainer/Q Targets Mean                       55.3571
trainer/Q Targets Std                        41.0436
trainer/Q Targets Max                       130.132
trainer/Q Targets Min                         5.02393
trainer/Log Pis Mean                          5.699
trainer/Log Pis Std                           5.91277
trainer/Log Pis Max                          30.6327
trainer/Log Pis Min                          -5.27694
trainer/policy/mean Mean                      0.0552624
trainer/policy/mean Std                       0.733667
trainer/policy/mean Max                       0.999998
trainer/policy/mean Min                      -0.999731
trainer/policy/normal/std Mean                0.449922
trainer/policy/normal/std Std                 0.134195
trainer/policy/normal/std Max                 1.46134
trainer/policy/normal/std Min                 0.169934
trainer/policy/normal/log_std Mean           -0.84332
trainer/policy/normal/log_std Std             0.302939
trainer/policy/normal/log_std Max             0.379353
trainer/policy/normal/log_std Min            -1.77235
trainer/Alpha                                 0.0321252
trainer/Alpha Loss                           -1.03487
expl/num steps total                      43000
expl/num paths total                         43
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.636492
expl/Rewards Std                              1.35585
expl/Rewards Max                              4.65265
expl/Rewards Min                             -2.0108
expl/Returns Mean                           636.492
expl/Returns Std                              0
expl/Returns Max                            636.492
expl/Returns Min                            636.492
expl/Actions Mean                             0.0779143
expl/Actions Std                              0.733889
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999918
expl/Num Paths                                1
expl/Average Returns                        636.492
expl/env_infos/final/reward_run Mean          0.594084
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.594084
expl/env_infos/final/reward_run Min           0.594084
expl/env_infos/initial/reward_run Mean        0.186852
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.186852
expl/env_infos/initial/reward_run Min         0.186852
expl/env_infos/reward_run Mean                0.963291
expl/env_infos/reward_run Std                 1.39138
expl/env_infos/reward_run Max                 5.06972
expl/env_infos/reward_run Min                -1.69191
expl/env_infos/final/reward_ctrl Mean        -0.238838
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.238838
expl/env_infos/final/reward_ctrl Min         -0.238838
expl/env_infos/initial/reward_ctrl Mean      -0.10072
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.10072
expl/env_infos/initial/reward_ctrl Min       -0.10072
expl/env_infos/reward_ctrl Mean              -0.326799
expl/env_infos/reward_ctrl Std                0.0984634
expl/env_infos/reward_ctrl Max               -0.0700783
expl/env_infos/reward_ctrl Min               -0.585436
eval/num steps total                     210000
eval/num paths total                        210
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.67496
eval/Rewards Std                              1.02265
eval/Rewards Max                              5.54038
eval/Rewards Min                             -0.965337
eval/Returns Mean                          2674.96
eval/Returns Std                            170.475
eval/Returns Max                           2836.05
eval/Returns Min                           2361.67
eval/Actions Mean                             0.0156456
eval/Actions Std                              0.840699
eval/Actions Max                              1
eval/Actions Min                             -0.99992
eval/Num Paths                                5
eval/Average Returns                       2674.96
eval/env_infos/final/reward_run Mean          3.48233
eval/env_infos/final/reward_run Std           1.17494
eval/env_infos/final/reward_run Max           5.31534
eval/env_infos/final/reward_run Min           1.68684
eval/env_infos/initial/reward_run Mean        0.0365964
eval/env_infos/initial/reward_run Std         0.0995981
eval/env_infos/initial/reward_run Max         0.213591
eval/env_infos/initial/reward_run Min        -0.0660768
eval/env_infos/reward_run Mean                3.09917
eval/env_infos/reward_run Std                 1.0341
eval/env_infos/reward_run Max                 6.01264
eval/env_infos/reward_run Min                -0.524206
eval/env_infos/final/reward_ctrl Mean        -0.407055
eval/env_infos/final/reward_ctrl Std          0.0453498
eval/env_infos/final/reward_ctrl Max         -0.337477
eval/env_infos/final/reward_ctrl Min         -0.467895
eval/env_infos/initial/reward_ctrl Mean      -0.0559251
eval/env_infos/initial/reward_ctrl Std        0.0282712
eval/env_infos/initial/reward_ctrl Max       -0.0196973
eval/env_infos/initial/reward_ctrl Min       -0.0822931
eval/env_infos/reward_ctrl Mean              -0.424212
eval/env_infos/reward_ctrl Std                0.0906387
eval/env_infos/reward_ctrl Max               -0.0196973
eval/env_infos/reward_ctrl Min               -0.598109
time/data storing (s)                         0.00446115
time/evaluation sampling (s)                  2.01689
time/exploration sampling (s)                 0.537457
time/logging (s)                              0.013758
time/sac training (s)                         7.41498
time/saving (s)                               0.00378181
time/training (s)                             3.3984e-05
time/epoch (s)                                9.99135
time/total (s)                              452.911
Epoch                                        41
---------------------------------------  ---------------
2021-11-24 00:36:53.987332 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 42 finished
---------------------------------------  ---------------
epoch                                        42
replay_buffer/size                        44000
trainer/num train calls                   43000
trainer/QF1 Loss                              3.16814
trainer/QF2 Loss                              2.75701
trainer/Policy Loss                         -56.8083
trainer/Q1 Predictions Mean                  56.4731
trainer/Q1 Predictions Std                   45.195
trainer/Q1 Predictions Max                  137.174
trainer/Q1 Predictions Min                    6.54962
trainer/Q2 Predictions Mean                  56.6458
trainer/Q2 Predictions Std                   45.1898
trainer/Q2 Predictions Max                  134.092
trainer/Q2 Predictions Min                    6.48639
trainer/Q Targets Mean                       56.2308
trainer/Q Targets Std                        45.0517
trainer/Q Targets Max                       136.784
trainer/Q Targets Min                         4.73941
trainer/Log Pis Mean                          5.66557
trainer/Log Pis Std                           5.4929
trainer/Log Pis Max                          21.756
trainer/Log Pis Min                          -7.88824
trainer/policy/mean Mean                      0.0840336
trainer/policy/mean Std                       0.738528
trainer/policy/mean Max                       0.999977
trainer/policy/mean Min                      -0.99963
trainer/policy/normal/std Mean                0.463553
trainer/policy/normal/std Std                 0.127757
trainer/policy/normal/std Max                 1.1191
trainer/policy/normal/std Min                 0.131169
trainer/policy/normal/log_std Mean           -0.810041
trainer/policy/normal/log_std Std             0.295903
trainer/policy/normal/log_std Max             0.112527
trainer/policy/normal/log_std Min            -2.03127
trainer/Alpha                                 0.0325006
trainer/Alpha Loss                           -1.14591
expl/num steps total                      44000
expl/num paths total                         44
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.710652
expl/Rewards Std                              1.33678
expl/Rewards Max                              5.02899
expl/Rewards Min                             -1.82738
expl/Returns Mean                           710.652
expl/Returns Std                              0
expl/Returns Max                            710.652
expl/Returns Min                            710.652
expl/Actions Mean                             0.0453359
expl/Actions Std                              0.719933
expl/Actions Max                              0.999949
expl/Actions Min                             -0.999957
expl/Num Paths                                1
expl/Average Returns                        710.652
expl/env_infos/final/reward_run Mean          0.550796
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.550796
expl/env_infos/final/reward_run Min           0.550796
expl/env_infos/initial/reward_run Mean        0.0136886
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0136886
expl/env_infos/initial/reward_run Min         0.0136886
expl/env_infos/reward_run Mean                1.02287
expl/env_infos/reward_run Std                 1.36818
expl/env_infos/reward_run Max                 5.56174
expl/env_infos/reward_run Min                -1.45215
expl/env_infos/final/reward_ctrl Mean        -0.277721
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.277721
expl/env_infos/final/reward_ctrl Min         -0.277721
expl/env_infos/initial/reward_ctrl Mean      -0.0422475
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0422475
expl/env_infos/initial/reward_ctrl Min       -0.0422475
expl/env_infos/reward_ctrl Mean              -0.312215
expl/env_infos/reward_ctrl Std                0.0992455
expl/env_infos/reward_ctrl Max               -0.0422475
expl/env_infos/reward_ctrl Min               -0.581335
eval/num steps total                     215000
eval/num paths total                        215
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.69898
eval/Rewards Std                              1.04011
eval/Rewards Max                              5.47581
eval/Rewards Min                             -1.37519
eval/Returns Mean                          2698.98
eval/Returns Std                             14.103
eval/Returns Max                           2716.41
eval/Returns Min                           2679.63
eval/Actions Mean                             0.0593848
eval/Actions Std                              0.834818
eval/Actions Max                              0.999997
eval/Actions Min                             -0.99999
eval/Num Paths                                5
eval/Average Returns                       2698.98
eval/env_infos/final/reward_run Mean          3.43397
eval/env_infos/final/reward_run Std           0.815062
eval/env_infos/final/reward_run Max           4.67946
eval/env_infos/final/reward_run Min           2.35135
eval/env_infos/initial/reward_run Mean       -0.00684416
eval/env_infos/initial/reward_run Std         0.0344256
eval/env_infos/initial/reward_run Max         0.0333596
eval/env_infos/initial/reward_run Min        -0.0501985
eval/env_infos/reward_run Mean                3.11924
eval/env_infos/reward_run Std                 1.05434
eval/env_infos/reward_run Max                 6.05752
eval/env_infos/reward_run Min                -1.16461
eval/env_infos/final/reward_ctrl Mean        -0.458135
eval/env_infos/final/reward_ctrl Std          0.0939356
eval/env_infos/final/reward_ctrl Max         -0.360628
eval/env_infos/final/reward_ctrl Min         -0.570813
eval/env_infos/initial/reward_ctrl Mean      -0.0430492
eval/env_infos/initial/reward_ctrl Std        0.0262833
eval/env_infos/initial/reward_ctrl Max       -0.0172527
eval/env_infos/initial/reward_ctrl Min       -0.0868088
eval/env_infos/reward_ctrl Mean              -0.420269
eval/env_infos/reward_ctrl Std                0.09036
eval/env_infos/reward_ctrl Max               -0.0172527
eval/env_infos/reward_ctrl Min               -0.592733
time/data storing (s)                         0.00456301
time/evaluation sampling (s)                  2.0464
time/exploration sampling (s)                 0.537169
time/logging (s)                              0.0139022
time/sac training (s)                         7.39482
time/saving (s)                               0.00389582
time/training (s)                             3.5597e-05
time/epoch (s)                               10.0008
time/total (s)                              463.193
Epoch                                        42
---------------------------------------  ---------------
2021-11-24 00:37:04.295250 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 43 finished
---------------------------------------  ----------------
epoch                                        43
replay_buffer/size                        45000
trainer/num train calls                   44000
trainer/QF1 Loss                              4.71996
trainer/QF2 Loss                              5.19806
trainer/Policy Loss                         -63.6977
trainer/Q1 Predictions Mean                  63.3715
trainer/Q1 Predictions Std                   43.8162
trainer/Q1 Predictions Max                  137.032
trainer/Q1 Predictions Min                    5.42972
trainer/Q2 Predictions Mean                  63.4186
trainer/Q2 Predictions Std                   43.8879
trainer/Q2 Predictions Max                  135.698
trainer/Q2 Predictions Min                    4.9182
trainer/Q Targets Mean                       63.2339
trainer/Q Targets Std                        43.8542
trainer/Q Targets Max                       136.571
trainer/Q Targets Min                         3.60629
trainer/Log Pis Mean                          6.28346
trainer/Log Pis Std                           5.79146
trainer/Log Pis Max                          27.1344
trainer/Log Pis Min                          -5.56322
trainer/policy/mean Mean                      0.0632097
trainer/policy/mean Std                       0.75164
trainer/policy/mean Max                       0.999941
trainer/policy/mean Min                      -0.999758
trainer/policy/normal/std Mean                0.453745
trainer/policy/normal/std Std                 0.13019
trainer/policy/normal/std Max                 1.25824
trainer/policy/normal/std Min                 0.12686
trainer/policy/normal/log_std Mean           -0.831285
trainer/policy/normal/log_std Std             0.289819
trainer/policy/normal/log_std Max             0.229713
trainer/policy/normal/log_std Min            -2.06467
trainer/Alpha                                 0.0321031
trainer/Alpha Loss                            0.974766
expl/num steps total                      45000
expl/num paths total                         45
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.63903
expl/Rewards Std                              1.03337
expl/Rewards Max                              4.89782
expl/Rewards Min                             -1.13657
expl/Returns Mean                          2639.03
expl/Returns Std                              0
expl/Returns Max                           2639.03
expl/Returns Min                           2639.03
expl/Actions Mean                             0.00336418
expl/Actions Std                              0.842871
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999999
expl/Num Paths                                1
expl/Average Returns                       2639.03
expl/env_infos/final/reward_run Mean          2.49524
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.49524
expl/env_infos/final/reward_run Min           2.49524
expl/env_infos/initial/reward_run Mean       -0.216549
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.216549
expl/env_infos/initial/reward_run Min        -0.216549
expl/env_infos/reward_run Mean                3.06529
expl/env_infos/reward_run Std                 1.04375
expl/env_infos/reward_run Max                 5.34101
expl/env_infos/reward_run Min                -0.704608
expl/env_infos/final/reward_ctrl Mean        -0.379875
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.379875
expl/env_infos/final/reward_ctrl Min         -0.379875
expl/env_infos/initial/reward_ctrl Mean      -0.105683
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.105683
expl/env_infos/initial/reward_ctrl Min       -0.105683
expl/env_infos/reward_ctrl Mean              -0.426266
expl/env_infos/reward_ctrl Std                0.0863664
expl/env_infos/reward_ctrl Max               -0.105683
expl/env_infos/reward_ctrl Min               -0.597909
eval/num steps total                     220000
eval/num paths total                        220
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.04032
eval/Rewards Std                              1.44093
eval/Rewards Max                              5.60511
eval/Rewards Min                             -1.95179
eval/Returns Mean                          2040.32
eval/Returns Std                            690.954
eval/Returns Max                           2601.09
eval/Returns Min                            815.707
eval/Actions Mean                             0.000193889
eval/Actions Std                              0.813942
eval/Actions Max                              1
eval/Actions Min                             -0.999995
eval/Num Paths                                5
eval/Average Returns                       2040.32
eval/env_infos/final/reward_run Mean          1.61456
eval/env_infos/final/reward_run Std           1.28681
eval/env_infos/final/reward_run Max           3.3278
eval/env_infos/final/reward_run Min          -0.275812
eval/env_infos/initial/reward_run Mean        0.0449395
eval/env_infos/initial/reward_run Std         0.0694349
eval/env_infos/initial/reward_run Max         0.0909758
eval/env_infos/initial/reward_run Min        -0.0929238
eval/env_infos/reward_run Mean                2.43782
eval/env_infos/reward_run Std                 1.48774
eval/env_infos/reward_run Max                 6.07184
eval/env_infos/reward_run Min                -1.36881
eval/env_infos/final/reward_ctrl Mean        -0.358589
eval/env_infos/final/reward_ctrl Std          0.159341
eval/env_infos/final/reward_ctrl Max         -0.102501
eval/env_infos/final/reward_ctrl Min         -0.583927
eval/env_infos/initial/reward_ctrl Mean      -0.0541794
eval/env_infos/initial/reward_ctrl Std        0.0260002
eval/env_infos/initial/reward_ctrl Max       -0.021973
eval/env_infos/initial/reward_ctrl Min       -0.0971645
eval/env_infos/reward_ctrl Mean              -0.397501
eval/env_infos/reward_ctrl Std                0.110041
eval/env_infos/reward_ctrl Max               -0.021973
eval/env_infos/reward_ctrl Min               -0.595002
time/data storing (s)                         0.0044781
time/evaluation sampling (s)                  2.02146
time/exploration sampling (s)                 0.538678
time/logging (s)                              0.0138101
time/sac training (s)                         7.42798
time/saving (s)                               0.00380042
time/training (s)                             4.23469e-05
time/epoch (s)                               10.0103
time/total (s)                              473.488
Epoch                                        43
---------------------------------------  ----------------
2021-11-24 00:37:14.659322 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 44 finished
---------------------------------------  ---------------
epoch                                        44
replay_buffer/size                        46000
trainer/num train calls                   45000
trainer/QF1 Loss                              4.4825
trainer/QF2 Loss                              4.76415
trainer/Policy Loss                         -68.6009
trainer/Q1 Predictions Mean                  68.3923
trainer/Q1 Predictions Std                   48.3314
trainer/Q1 Predictions Max                  142.591
trainer/Q1 Predictions Min                    6.01069
trainer/Q2 Predictions Mean                  68.3949
trainer/Q2 Predictions Std                   48.3215
trainer/Q2 Predictions Max                  141.034
trainer/Q2 Predictions Min                    5.71381
trainer/Q Targets Mean                       68.3507
trainer/Q Targets Std                        48.1822
trainer/Q Targets Max                       142.614
trainer/Q Targets Min                         4.92856
trainer/Log Pis Mean                          6.77603
trainer/Log Pis Std                           6.54799
trainer/Log Pis Max                          36.6562
trainer/Log Pis Min                          -6.2881
trainer/policy/mean Mean                      0.033336
trainer/policy/mean Std                       0.755344
trainer/policy/mean Max                       0.999951
trainer/policy/mean Min                      -0.999772
trainer/policy/normal/std Mean                0.441145
trainer/policy/normal/std Std                 0.125331
trainer/policy/normal/std Max                 1.10378
trainer/policy/normal/std Min                 0.108725
trainer/policy/normal/log_std Mean           -0.861409
trainer/policy/normal/log_std Std             0.301154
trainer/policy/normal/log_std Max             0.0987377
trainer/policy/normal/log_std Min            -2.21893
trainer/Alpha                                 0.0334216
trainer/Alpha Loss                            2.63737
expl/num steps total                      46000
expl/num paths total                         46
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.71801
expl/Rewards Std                              1.05345
expl/Rewards Max                              5.13384
expl/Rewards Min                             -0.78335
expl/Returns Mean                          2718.01
expl/Returns Std                              0
expl/Returns Max                           2718.01
expl/Returns Min                           2718.01
expl/Actions Mean                             0.0540337
expl/Actions Std                              0.843089
expl/Actions Max                              0.999953
expl/Actions Min                             -0.999997
expl/Num Paths                                1
expl/Average Returns                       2718.01
expl/env_infos/final/reward_run Mean          3.42684
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.42684
expl/env_infos/final/reward_run Min           3.42684
expl/env_infos/initial/reward_run Mean        0.0404722
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0404722
expl/env_infos/initial/reward_run Min         0.0404722
expl/env_infos/reward_run Mean                3.14624
expl/env_infos/reward_run Std                 1.06754
expl/env_infos/reward_run Max                 5.70998
expl/env_infos/reward_run Min                -0.559218
expl/env_infos/final/reward_ctrl Mean        -0.387975
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.387975
expl/env_infos/final/reward_ctrl Min         -0.387975
expl/env_infos/initial/reward_ctrl Mean      -0.112157
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.112157
expl/env_infos/initial/reward_ctrl Min       -0.112157
expl/env_infos/reward_ctrl Mean              -0.428231
expl/env_infos/reward_ctrl Std                0.0841291
expl/env_infos/reward_ctrl Max               -0.112157
expl/env_infos/reward_ctrl Min               -0.592751
eval/num steps total                     225000
eval/num paths total                        225
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.59389
eval/Rewards Std                              1.15593
eval/Rewards Max                              5.60894
eval/Rewards Min                             -1.3377
eval/Returns Mean                          2593.89
eval/Returns Std                            177.953
eval/Returns Max                           2755.27
eval/Returns Min                           2261.16
eval/Actions Mean                             0.0315382
eval/Actions Std                              0.846505
eval/Actions Max                              0.999985
eval/Actions Min                             -0.999962
eval/Num Paths                                5
eval/Average Returns                       2593.89
eval/env_infos/final/reward_run Mean          3.3373
eval/env_infos/final/reward_run Std           0.748066
eval/env_infos/final/reward_run Max           4.00782
eval/env_infos/final/reward_run Min           2.32604
eval/env_infos/initial/reward_run Mean       -0.0530193
eval/env_infos/initial/reward_run Std         0.0806515
eval/env_infos/initial/reward_run Max         0.026661
eval/env_infos/initial/reward_run Min        -0.190669
eval/env_infos/reward_run Mean                3.02443
eval/env_infos/reward_run Std                 1.17781
eval/env_infos/reward_run Max                 6.18947
eval/env_infos/reward_run Min                -1.01678
eval/env_infos/final/reward_ctrl Mean        -0.38778
eval/env_infos/final/reward_ctrl Std          0.111188
eval/env_infos/final/reward_ctrl Max         -0.210884
eval/env_infos/final/reward_ctrl Min         -0.549423
eval/env_infos/initial/reward_ctrl Mean      -0.0882677
eval/env_infos/initial/reward_ctrl Std        0.0100304
eval/env_infos/initial/reward_ctrl Max       -0.0724522
eval/env_infos/initial/reward_ctrl Min       -0.0992498
eval/env_infos/reward_ctrl Mean              -0.43054
eval/env_infos/reward_ctrl Std                0.090457
eval/env_infos/reward_ctrl Max               -0.0604142
eval/env_infos/reward_ctrl Min               -0.59594
time/data storing (s)                         0.00450517
time/evaluation sampling (s)                  2.04135
time/exploration sampling (s)                 0.543588
time/logging (s)                              0.0143613
time/sac training (s)                         7.45868
time/saving (s)                               0.00382805
time/training (s)                             5.612e-05
time/epoch (s)                               10.0664
time/total (s)                              483.84
Epoch                                        44
---------------------------------------  ---------------
2021-11-24 00:37:25.020903 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 45 finished
---------------------------------------  ---------------
epoch                                        45
replay_buffer/size                        47000
trainer/num train calls                   46000
trainer/QF1 Loss                              3.29688
trainer/QF2 Loss                              3.68894
trainer/Policy Loss                         -67.4538
trainer/Q1 Predictions Mean                  67.3
trainer/Q1 Predictions Std                   51.3039
trainer/Q1 Predictions Max                  145.475
trainer/Q1 Predictions Min                    5.64578
trainer/Q2 Predictions Mean                  67.2637
trainer/Q2 Predictions Std                   51.2891
trainer/Q2 Predictions Max                  145.926
trainer/Q2 Predictions Min                    6.11266
trainer/Q Targets Mean                       67.4009
trainer/Q Targets Std                        51.2814
trainer/Q Targets Max                       147.08
trainer/Q Targets Min                         5.31998
trainer/Log Pis Mean                          5.94252
trainer/Log Pis Std                           5.38372
trainer/Log Pis Max                          22.3025
trainer/Log Pis Min                          -5.52224
trainer/policy/mean Mean                      0.0424428
trainer/policy/mean Std                       0.751045
trainer/policy/mean Max                       0.999952
trainer/policy/mean Min                      -0.9999
trainer/policy/normal/std Mean                0.449386
trainer/policy/normal/std Std                 0.130772
trainer/policy/normal/std Max                 1.11971
trainer/policy/normal/std Min                 0.143125
trainer/policy/normal/log_std Mean           -0.845131
trainer/policy/normal/log_std Std             0.308679
trainer/policy/normal/log_std Max             0.113069
trainer/policy/normal/log_std Min            -1.94404
trainer/Alpha                                 0.0333589
trainer/Alpha Loss                           -0.195465
expl/num steps total                      47000
expl/num paths total                         47
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.89765
expl/Rewards Std                              0.941827
expl/Rewards Max                              5.21386
expl/Rewards Min                             -0.31894
expl/Returns Mean                          2897.65
expl/Returns Std                              0
expl/Returns Max                           2897.65
expl/Returns Min                           2897.65
expl/Actions Mean                             0.0342398
expl/Actions Std                              0.823064
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999944
expl/Num Paths                                1
expl/Average Returns                       2897.65
expl/env_infos/final/reward_run Mean          4.559
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.559
expl/env_infos/final/reward_run Min           4.559
expl/env_infos/initial/reward_run Mean        0.202836
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.202836
expl/env_infos/initial/reward_run Min         0.202836
expl/env_infos/reward_run Mean                3.30481
expl/env_infos/reward_run Std                 0.953309
expl/env_infos/reward_run Max                 5.61522
expl/env_infos/reward_run Min                -0.0358031
expl/env_infos/final/reward_ctrl Mean        -0.560104
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.560104
expl/env_infos/final/reward_ctrl Min         -0.560104
expl/env_infos/initial/reward_ctrl Mean      -0.0986345
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0986345
expl/env_infos/initial/reward_ctrl Min       -0.0986345
expl/env_infos/reward_ctrl Mean              -0.407164
expl/env_infos/reward_ctrl Std                0.0917259
expl/env_infos/reward_ctrl Max               -0.0986345
expl/env_infos/reward_ctrl Min               -0.593862
eval/num steps total                     230000
eval/num paths total                        230
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.04441
eval/Rewards Std                              1.50462
eval/Rewards Max                              5.53324
eval/Rewards Min                             -2.38749
eval/Returns Mean                          2044.41
eval/Returns Std                            726.765
eval/Returns Max                           2684.48
eval/Returns Min                            758.683
eval/Actions Mean                             0.0345964
eval/Actions Std                              0.786654
eval/Actions Max                              0.999999
eval/Actions Min                             -0.999982
eval/Num Paths                                5
eval/Average Returns                       2044.41
eval/env_infos/final/reward_run Mean          1.77515
eval/env_infos/final/reward_run Std           1.03306
eval/env_infos/final/reward_run Max           2.71642
eval/env_infos/final/reward_run Min          -0.0727069
eval/env_infos/initial/reward_run Mean       -0.0657645
eval/env_infos/initial/reward_run Std         0.0591446
eval/env_infos/initial/reward_run Max         0.0443652
eval/env_infos/initial/reward_run Min        -0.130608
eval/env_infos/reward_run Mean                2.41642
eval/env_infos/reward_run Std                 1.5538
eval/env_infos/reward_run Max                 6.04479
eval/env_infos/reward_run Min                -1.94962
eval/env_infos/final/reward_ctrl Mean        -0.282066
eval/env_infos/final/reward_ctrl Std          0.0441618
eval/env_infos/final/reward_ctrl Max         -0.238041
eval/env_infos/final/reward_ctrl Min         -0.344839
eval/env_infos/initial/reward_ctrl Mean      -0.0743368
eval/env_infos/initial/reward_ctrl Std        0.0121693
eval/env_infos/initial/reward_ctrl Max       -0.0567848
eval/env_infos/initial/reward_ctrl Min       -0.0944342
eval/env_infos/reward_ctrl Mean              -0.372013
eval/env_infos/reward_ctrl Std                0.111721
eval/env_infos/reward_ctrl Max               -0.0179889
eval/env_infos/reward_ctrl Min               -0.595401
time/data storing (s)                         0.00447972
time/evaluation sampling (s)                  2.03524
time/exploration sampling (s)                 0.534884
time/logging (s)                              0.0137694
time/sac training (s)                         7.46987
time/saving (s)                               0.00376352
time/training (s)                             3.7523e-05
time/epoch (s)                               10.0621
time/total (s)                              494.188
Epoch                                        45
---------------------------------------  ---------------
2021-11-24 00:37:35.400239 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 46 finished
---------------------------------------  ---------------
epoch                                        46
replay_buffer/size                        48000
trainer/num train calls                   47000
trainer/QF1 Loss                              4.50609
trainer/QF2 Loss                              4.59403
trainer/Policy Loss                         -64.6128
trainer/Q1 Predictions Mean                  64.5349
trainer/Q1 Predictions Std                   51.9857
trainer/Q1 Predictions Max                  148.3
trainer/Q1 Predictions Min                    5.52448
trainer/Q2 Predictions Mean                  64.4179
trainer/Q2 Predictions Std                   52.0166
trainer/Q2 Predictions Max                  148.561
trainer/Q2 Predictions Min                    3.59834
trainer/Q Targets Mean                       65.0288
trainer/Q Targets Std                        52.5401
trainer/Q Targets Max                       151.493
trainer/Q Targets Min                         4.75155
trainer/Log Pis Mean                          5.71841
trainer/Log Pis Std                           5.84901
trainer/Log Pis Max                          27.9898
trainer/Log Pis Min                          -6.01726
trainer/policy/mean Mean                      0.0699655
trainer/policy/mean Std                       0.734985
trainer/policy/mean Max                       0.999984
trainer/policy/mean Min                      -0.999787
trainer/policy/normal/std Mean                0.465572
trainer/policy/normal/std Std                 0.139489
trainer/policy/normal/std Max                 1.73416
trainer/policy/normal/std Min                 0.14007
trainer/policy/normal/log_std Mean           -0.811108
trainer/policy/normal/log_std Std             0.31219
trainer/policy/normal/log_std Max             0.550521
trainer/policy/normal/log_std Min            -1.96561
trainer/Alpha                                 0.0344663
trainer/Alpha Loss                           -0.948329
expl/num steps total                      48000
expl/num paths total                         48
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.9039
expl/Rewards Std                              1.17956
expl/Rewards Max                              5.98605
expl/Rewards Min                             -0.562295
expl/Returns Mean                          2903.9
expl/Returns Std                              0
expl/Returns Max                           2903.9
expl/Returns Min                           2903.9
expl/Actions Mean                             0.063957
expl/Actions Std                              0.835473
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999999
expl/Num Paths                                1
expl/Average Returns                       2903.9
expl/env_infos/final/reward_run Mean          5.39751
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.39751
expl/env_infos/final/reward_run Min           5.39751
expl/env_infos/initial/reward_run Mean       -0.0359967
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0359967
expl/env_infos/initial/reward_run Min        -0.0359967
expl/env_infos/reward_run Mean                3.32516
expl/env_infos/reward_run Std                 1.19624
expl/env_infos/reward_run Max                 6.46433
expl/env_infos/reward_run Min                -0.0931223
expl/env_infos/final/reward_ctrl Mean        -0.502121
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.502121
expl/env_infos/final/reward_ctrl Min         -0.502121
expl/env_infos/initial/reward_ctrl Mean      -0.103686
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.103686
expl/env_infos/initial/reward_ctrl Min       -0.103686
expl/env_infos/reward_ctrl Mean              -0.421263
expl/env_infos/reward_ctrl Std                0.0856425
expl/env_infos/reward_ctrl Max               -0.103686
expl/env_infos/reward_ctrl Min               -0.587858
eval/num steps total                     235000
eval/num paths total                        235
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.40166
eval/Rewards Std                              1.48575
eval/Rewards Max                              5.73023
eval/Rewards Min                             -1.72344
eval/Returns Mean                          2401.66
eval/Returns Std                            781.156
eval/Returns Max                           3186.67
eval/Returns Min                           1221.35
eval/Actions Mean                             0.0682649
eval/Actions Std                              0.811619
eval/Actions Max                              0.999998
eval/Actions Min                             -0.999998
eval/Num Paths                                5
eval/Average Returns                       2401.66
eval/env_infos/final/reward_run Mean          2.64288
eval/env_infos/final/reward_run Std           1.72434
eval/env_infos/final/reward_run Max           4.55903
eval/env_infos/final/reward_run Min          -0.128753
eval/env_infos/initial/reward_run Mean       -0.0522217
eval/env_infos/initial/reward_run Std         0.13502
eval/env_infos/initial/reward_run Max         0.177679
eval/env_infos/initial/reward_run Min        -0.223726
eval/env_infos/reward_run Mean                2.79969
eval/env_infos/reward_run Std                 1.54072
eval/env_infos/reward_run Max                 6.27511
eval/env_infos/reward_run Min                -1.30099
eval/env_infos/final/reward_ctrl Mean        -0.326896
eval/env_infos/final/reward_ctrl Std          0.076181
eval/env_infos/final/reward_ctrl Max         -0.229471
eval/env_infos/final/reward_ctrl Min         -0.427955
eval/env_infos/initial/reward_ctrl Mean      -0.0751341
eval/env_infos/initial/reward_ctrl Std        0.0235547
eval/env_infos/initial/reward_ctrl Max       -0.0354871
eval/env_infos/initial/reward_ctrl Min       -0.104978
eval/env_infos/reward_ctrl Mean              -0.398031
eval/env_infos/reward_ctrl Std                0.106192
eval/env_infos/reward_ctrl Max               -0.0354871
eval/env_infos/reward_ctrl Min               -0.591122
time/data storing (s)                         0.00448417
time/evaluation sampling (s)                  2.04031
time/exploration sampling (s)                 0.534884
time/logging (s)                              0.0137841
time/sac training (s)                         7.48167
time/saving (s)                               0.00376692
time/training (s)                             3.7081e-05
time/epoch (s)                               10.0789
time/total (s)                              504.554
Epoch                                        46
---------------------------------------  ---------------
2021-11-24 00:37:45.826319 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 47 finished
---------------------------------------  ---------------
epoch                                        47
replay_buffer/size                        49000
trainer/num train calls                   48000
trainer/QF1 Loss                              6.48854
trainer/QF2 Loss                              6.20627
trainer/Policy Loss                         -72.0957
trainer/Q1 Predictions Mean                  71.8454
trainer/Q1 Predictions Std                   54.3841
trainer/Q1 Predictions Max                  154.879
trainer/Q1 Predictions Min                    3.93268
trainer/Q2 Predictions Mean                  71.8784
trainer/Q2 Predictions Std                   54.4555
trainer/Q2 Predictions Max                  155.76
trainer/Q2 Predictions Min                    4.23006
trainer/Q Targets Mean                       71.8324
trainer/Q Targets Std                        54.3242
trainer/Q Targets Max                       154.368
trainer/Q Targets Min                         3.44595
trainer/Log Pis Mean                          5.55695
trainer/Log Pis Std                           5.35873
trainer/Log Pis Max                          28.2029
trainer/Log Pis Min                          -6.39525
trainer/policy/mean Mean                      0.100617
trainer/policy/mean Std                       0.743011
trainer/policy/mean Max                       0.99999
trainer/policy/mean Min                      -0.999661
trainer/policy/normal/std Mean                0.456602
trainer/policy/normal/std Std                 0.132297
trainer/policy/normal/std Max                 0.976332
trainer/policy/normal/std Min                 0.132061
trainer/policy/normal/log_std Mean           -0.828919
trainer/policy/normal/log_std Std             0.307912
trainer/policy/normal/log_std Max            -0.0239529
trainer/policy/normal/log_std Min            -2.02449
trainer/Alpha                                 0.0354656
trainer/Alpha Loss                           -1.47944
expl/num steps total                      49000
expl/num paths total                         49
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.92518
expl/Rewards Std                              1.06602
expl/Rewards Max                              5.40214
expl/Rewards Min                             -0.711167
expl/Returns Mean                          2925.18
expl/Returns Std                              0
expl/Returns Max                           2925.18
expl/Returns Min                           2925.18
expl/Actions Mean                             0.0613226
expl/Actions Std                              0.826839
expl/Actions Max                              0.999997
expl/Actions Min                             -0.99995
expl/Num Paths                                1
expl/Average Returns                       2925.18
expl/env_infos/final/reward_run Mean          3.18809
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.18809
expl/env_infos/final/reward_run Min           3.18809
expl/env_infos/initial/reward_run Mean        0.0667032
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0667032
expl/env_infos/initial/reward_run Min         0.0667032
expl/env_infos/reward_run Mean                3.33763
expl/env_infos/reward_run Std                 1.0848
expl/env_infos/reward_run Max                 5.93516
expl/env_infos/reward_run Min                -0.238432
expl/env_infos/final/reward_ctrl Mean        -0.420968
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.420968
expl/env_infos/final/reward_ctrl Min         -0.420968
expl/env_infos/initial/reward_ctrl Mean      -0.0893421
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0893421
expl/env_infos/initial/reward_ctrl Min       -0.0893421
expl/env_infos/reward_ctrl Mean              -0.412454
expl/env_infos/reward_ctrl Std                0.0892116
expl/env_infos/reward_ctrl Max               -0.0893421
expl/env_infos/reward_ctrl Min               -0.588786
eval/num steps total                     240000
eval/num paths total                        240
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.55779
eval/Rewards Std                              1.39629
eval/Rewards Max                              5.48681
eval/Rewards Min                             -1.69029
eval/Returns Mean                          2557.79
eval/Returns Std                            695.848
eval/Returns Max                           3025.8
eval/Returns Min                           1172.58
eval/Actions Mean                             0.0822419
eval/Actions Std                              0.813504
eval/Actions Max                              0.999996
eval/Actions Min                             -0.99997
eval/Num Paths                                5
eval/Average Returns                       2557.79
eval/env_infos/final/reward_run Mean          2.42476
eval/env_infos/final/reward_run Std           0.89762
eval/env_infos/final/reward_run Max           3.68777
eval/env_infos/final/reward_run Min           1.03052
eval/env_infos/initial/reward_run Mean       -0.0461459
eval/env_infos/initial/reward_run Std         0.196519
eval/env_infos/initial/reward_run Max         0.230944
eval/env_infos/initial/reward_run Min        -0.327384
eval/env_infos/reward_run Mean                2.95892
eval/env_infos/reward_run Std                 1.44231
eval/env_infos/reward_run Max                 5.9968
eval/env_infos/reward_run Min                -1.32255
eval/env_infos/final/reward_ctrl Mean        -0.393496
eval/env_infos/final/reward_ctrl Std          0.0913296
eval/env_infos/final/reward_ctrl Max         -0.218179
eval/env_infos/final/reward_ctrl Min         -0.474066
eval/env_infos/initial/reward_ctrl Mean      -0.0757291
eval/env_infos/initial/reward_ctrl Std        0.0254797
eval/env_infos/initial/reward_ctrl Max       -0.0406025
eval/env_infos/initial/reward_ctrl Min       -0.11758
eval/env_infos/reward_ctrl Mean              -0.401131
eval/env_infos/reward_ctrl Std                0.103466
eval/env_infos/reward_ctrl Max               -0.0205973
eval/env_infos/reward_ctrl Min               -0.586179
time/data storing (s)                         0.00502745
time/evaluation sampling (s)                  2.04215
time/exploration sampling (s)                 0.536329
time/logging (s)                              0.0139164
time/sac training (s)                         7.5207
time/saving (s)                               0.00383166
time/training (s)                             4.045e-05
time/epoch (s)                               10.122
time/total (s)                              514.968
Epoch                                        47
---------------------------------------  ---------------
2021-11-24 00:37:56.107731 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 48 finished
---------------------------------------  ----------------
epoch                                        48
replay_buffer/size                        50000
trainer/num train calls                   49000
trainer/QF1 Loss                              4.09019
trainer/QF2 Loss                              3.47755
trainer/Policy Loss                         -78.0355
trainer/Q1 Predictions Mean                  77.6189
trainer/Q1 Predictions Std                   56.4415
trainer/Q1 Predictions Max                  161.807
trainer/Q1 Predictions Min                    4.23041
trainer/Q2 Predictions Mean                  77.7782
trainer/Q2 Predictions Std                   56.5921
trainer/Q2 Predictions Max                  162.714
trainer/Q2 Predictions Min                    4.60713
trainer/Q Targets Mean                       77.9569
trainer/Q Targets Std                        56.6689
trainer/Q Targets Max                       163.078
trainer/Q Targets Min                         3.57967
trainer/Log Pis Mean                          5.69026
trainer/Log Pis Std                           5.83176
trainer/Log Pis Max                          24.0984
trainer/Log Pis Min                          -7.30139
trainer/policy/mean Mean                      0.0848712
trainer/policy/mean Std                       0.748906
trainer/policy/mean Max                       1
trainer/policy/mean Min                      -0.999811
trainer/policy/normal/std Mean                0.485771
trainer/policy/normal/std Std                 0.134586
trainer/policy/normal/std Max                 2.04571
trainer/policy/normal/std Min                 0.172727
trainer/policy/normal/log_std Mean           -0.75997
trainer/policy/normal/log_std Std             0.27955
trainer/policy/normal/log_std Max             0.715744
trainer/policy/normal/log_std Min            -1.75604
trainer/Alpha                                 0.0373291
trainer/Alpha Loss                           -1.01843
expl/num steps total                      50000
expl/num paths total                         50
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.87244
expl/Rewards Std                              1.10307
expl/Rewards Max                              5.51054
expl/Rewards Min                             -0.852374
expl/Returns Mean                          2872.44
expl/Returns Std                              0
expl/Returns Max                           2872.44
expl/Returns Min                           2872.44
expl/Actions Mean                             0.0803469
expl/Actions Std                              0.834279
expl/Actions Max                              1
expl/Actions Min                             -0.999948
expl/Num Paths                                1
expl/Average Returns                       2872.44
expl/env_infos/final/reward_run Mean          2.51458
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.51458
expl/env_infos/final/reward_run Min           2.51458
expl/env_infos/initial/reward_run Mean       -0.000778542
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.000778542
expl/env_infos/initial/reward_run Min        -0.000778542
expl/env_infos/reward_run Mean                3.29393
expl/env_infos/reward_run Std                 1.11471
expl/env_infos/reward_run Max                 5.99479
expl/env_infos/reward_run Min                -0.484867
expl/env_infos/final/reward_ctrl Mean        -0.499126
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.499126
expl/env_infos/final/reward_ctrl Min         -0.499126
expl/env_infos/initial/reward_ctrl Mean      -0.122565
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.122565
expl/env_infos/initial/reward_ctrl Min       -0.122565
expl/env_infos/reward_ctrl Mean              -0.421487
expl/env_infos/reward_ctrl Std                0.0858147
expl/env_infos/reward_ctrl Max               -0.122565
expl/env_infos/reward_ctrl Min               -0.592676
eval/num steps total                     245000
eval/num paths total                        245
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.47979
eval/Rewards Std                              1.56003
eval/Rewards Max                              5.74074
eval/Rewards Min                             -1.82462
eval/Returns Mean                          2479.79
eval/Returns Std                            940.628
eval/Returns Max                           3340.84
eval/Returns Min                            806.436
eval/Actions Mean                             0.0799268
eval/Actions Std                              0.81283
eval/Actions Max                              0.999987
eval/Actions Min                             -0.999977
eval/Num Paths                                5
eval/Average Returns                       2479.79
eval/env_infos/final/reward_run Mean          2.14042
eval/env_infos/final/reward_run Std           1.51238
eval/env_infos/final/reward_run Max           4.64089
eval/env_infos/final/reward_run Min           0.152441
eval/env_infos/initial/reward_run Mean       -0.0558404
eval/env_infos/initial/reward_run Std         0.0790233
eval/env_infos/initial/reward_run Max         0.0599392
eval/env_infos/initial/reward_run Min        -0.142825
eval/env_infos/reward_run Mean                2.88004
eval/env_infos/reward_run Std                 1.62203
eval/env_infos/reward_run Max                 6.19288
eval/env_infos/reward_run Min                -1.61247
eval/env_infos/final/reward_ctrl Mean        -0.395169
eval/env_infos/final/reward_ctrl Std          0.109951
eval/env_infos/final/reward_ctrl Max         -0.241836
eval/env_infos/final/reward_ctrl Min         -0.562221
eval/env_infos/initial/reward_ctrl Mean      -0.0542949
eval/env_infos/initial/reward_ctrl Std        0.0115467
eval/env_infos/initial/reward_ctrl Max       -0.0337045
eval/env_infos/initial/reward_ctrl Min       -0.0695325
eval/env_infos/reward_ctrl Mean              -0.400249
eval/env_infos/reward_ctrl Std                0.109948
eval/env_infos/reward_ctrl Max               -0.0337045
eval/env_infos/reward_ctrl Min               -0.590465
time/data storing (s)                         0.00449265
time/evaluation sampling (s)                  2.02062
time/exploration sampling (s)                 0.540148
time/logging (s)                              0.0138961
time/sac training (s)                         7.40079
time/saving (s)                               0.00383954
time/training (s)                             4.2745e-05
time/epoch (s)                                9.98383
time/total (s)                              525.236
Epoch                                        48
---------------------------------------  ----------------
2021-11-24 00:38:06.484663 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 49 finished
---------------------------------------  ---------------
epoch                                        49
replay_buffer/size                        51000
trainer/num train calls                   50000
trainer/QF1 Loss                              5.61602
trainer/QF2 Loss                              5.89123
trainer/Policy Loss                         -81.8558
trainer/Q1 Predictions Mean                  81.5385
trainer/Q1 Predictions Std                   56.1613
trainer/Q1 Predictions Max                  161.536
trainer/Q1 Predictions Min                    4.26454
trainer/Q2 Predictions Mean                  81.6551
trainer/Q2 Predictions Std                   56.1701
trainer/Q2 Predictions Max                  161.209
trainer/Q2 Predictions Min                    4.07146
trainer/Q Targets Mean                       81.2325
trainer/Q Targets Std                        55.8076
trainer/Q Targets Max                       160.335
trainer/Q Targets Min                         2.64087
trainer/Log Pis Mean                          6.43453
trainer/Log Pis Std                           5.70667
trainer/Log Pis Max                          23.1865
trainer/Log Pis Min                          -4.66357
trainer/policy/mean Mean                      0.0850419
trainer/policy/mean Std                       0.756317
trainer/policy/mean Max                       0.999997
trainer/policy/mean Min                      -0.999874
trainer/policy/normal/std Mean                0.472114
trainer/policy/normal/std Std                 0.132023
trainer/policy/normal/std Max                 1.6075
trainer/policy/normal/std Min                 0.133365
trainer/policy/normal/log_std Mean           -0.789829
trainer/policy/normal/log_std Std             0.284234
trainer/policy/normal/log_std Max             0.474681
trainer/policy/normal/log_std Min            -2.01466
trainer/Alpha                                 0.038147
trainer/Alpha Loss                            1.4193
expl/num steps total                      51000
expl/num paths total                         51
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.469418
expl/Rewards Std                              0.959736
expl/Rewards Max                              3.6908
expl/Rewards Min                             -1.70627
expl/Returns Mean                           469.418
expl/Returns Std                              0
expl/Returns Max                            469.418
expl/Returns Min                            469.418
expl/Actions Mean                             0.019834
expl/Actions Std                              0.712372
expl/Actions Max                              0.999983
expl/Actions Min                             -0.999934
expl/Num Paths                                1
expl/Average Returns                        469.418
expl/env_infos/final/reward_run Mean          0.0307153
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.0307153
expl/env_infos/final/reward_run Min           0.0307153
expl/env_infos/initial/reward_run Mean       -0.127637
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.127637
expl/env_infos/initial/reward_run Min        -0.127637
expl/env_infos/reward_run Mean                0.774138
expl/env_infos/reward_run Std                 0.954366
expl/env_infos/reward_run Max                 4.0751
expl/env_infos/reward_run Min                -1.28843
expl/env_infos/final/reward_ctrl Mean        -0.29025
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.29025
expl/env_infos/final/reward_ctrl Min         -0.29025
expl/env_infos/initial/reward_ctrl Mean      -0.0465672
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0465672
expl/env_infos/initial/reward_ctrl Min       -0.0465672
expl/env_infos/reward_ctrl Mean              -0.30472
expl/env_infos/reward_ctrl Std                0.0918546
expl/env_infos/reward_ctrl Max               -0.0465672
expl/env_infos/reward_ctrl Min               -0.580945
eval/num steps total                     250000
eval/num paths total                        250
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.29017
eval/Rewards Std                              1.48799
eval/Rewards Max                              5.47937
eval/Rewards Min                             -2.22387
eval/Returns Mean                          2290.17
eval/Returns Std                            863.651
eval/Returns Max                           3085.3
eval/Returns Min                           1162.74
eval/Actions Mean                             0.0324536
eval/Actions Std                              0.807041
eval/Actions Max                              0.999966
eval/Actions Min                             -0.999967
eval/Num Paths                                5
eval/Average Returns                       2290.17
eval/env_infos/final/reward_run Mean          2.13857
eval/env_infos/final/reward_run Std           1.77238
eval/env_infos/final/reward_run Max           4.45154
eval/env_infos/final/reward_run Min          -0.386409
eval/env_infos/initial/reward_run Mean        0.00610297
eval/env_infos/initial/reward_run Std         0.170045
eval/env_infos/initial/reward_run Max         0.211101
eval/env_infos/initial/reward_run Min        -0.238009
eval/env_infos/reward_run Mean                2.68159
eval/env_infos/reward_run Std                 1.54632
eval/env_infos/reward_run Max                 5.98583
eval/env_infos/reward_run Min                -1.75044
eval/env_infos/final/reward_ctrl Mean        -0.386677
eval/env_infos/final/reward_ctrl Std          0.0819569
eval/env_infos/final/reward_ctrl Max         -0.30446
eval/env_infos/final/reward_ctrl Min         -0.541725
eval/env_infos/initial/reward_ctrl Mean      -0.0697858
eval/env_infos/initial/reward_ctrl Std        0.0229506
eval/env_infos/initial/reward_ctrl Max       -0.0449076
eval/env_infos/initial/reward_ctrl Min       -0.101948
eval/env_infos/reward_ctrl Mean              -0.391421
eval/env_infos/reward_ctrl Std                0.111323
eval/env_infos/reward_ctrl Max               -0.0449076
eval/env_infos/reward_ctrl Min               -0.59494
time/data storing (s)                         0.00449827
time/evaluation sampling (s)                  2.02803
time/exploration sampling (s)                 0.558078
time/logging (s)                              0.014123
time/sac training (s)                         7.47065
time/saving (s)                               0.00383319
time/training (s)                             3.6447e-05
time/epoch (s)                               10.0792
time/total (s)                              535.6
Epoch                                        49
---------------------------------------  ---------------
2021-11-24 00:38:16.919377 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 50 finished
---------------------------------------  ---------------
epoch                                        50
replay_buffer/size                        52000
trainer/num train calls                   51000
trainer/QF1 Loss                              6.37454
trainer/QF2 Loss                              5.53784
trainer/Policy Loss                         -79.254
trainer/Q1 Predictions Mean                  78.8919
trainer/Q1 Predictions Std                   57.6268
trainer/Q1 Predictions Max                  164.01
trainer/Q1 Predictions Min                    3.3142
trainer/Q2 Predictions Mean                  78.9463
trainer/Q2 Predictions Std                   57.7374
trainer/Q2 Predictions Max                  165.31
trainer/Q2 Predictions Min                    3.91875
trainer/Q Targets Mean                       78.9502
trainer/Q Targets Std                        57.7511
trainer/Q Targets Max                       167.833
trainer/Q Targets Min                         3.3683
trainer/Log Pis Mean                          5.95891
trainer/Log Pis Std                           6.18506
trainer/Log Pis Max                          34.3837
trainer/Log Pis Min                          -6.32166
trainer/policy/mean Mean                      0.0766304
trainer/policy/mean Std                       0.749179
trainer/policy/mean Max                       0.999997
trainer/policy/mean Min                      -0.999999
trainer/policy/normal/std Mean                0.466902
trainer/policy/normal/std Std                 0.126146
trainer/policy/normal/std Max                 1.23153
trainer/policy/normal/std Min                 0.134842
trainer/policy/normal/log_std Mean           -0.798937
trainer/policy/normal/log_std Std             0.277415
trainer/policy/normal/log_std Max             0.208254
trainer/policy/normal/log_std Min            -2.00365
trainer/Alpha                                 0.037757
trainer/Alpha Loss                           -0.134639
expl/num steps total                      52000
expl/num paths total                         52
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.91569
expl/Rewards Std                              0.986283
expl/Rewards Max                              5.43034
expl/Rewards Min                             -1.30764
expl/Returns Mean                          2915.69
expl/Returns Std                              0
expl/Returns Max                           2915.69
expl/Returns Min                           2915.69
expl/Actions Mean                             0.04419
expl/Actions Std                              0.8267
expl/Actions Max                              0.999986
expl/Actions Min                             -0.999989
expl/Num Paths                                1
expl/Average Returns                       2915.69
expl/env_infos/final/reward_run Mean          4.81799
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.81799
expl/env_infos/final/reward_run Min           4.81799
expl/env_infos/initial/reward_run Mean       -0.419244
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.419244
expl/env_infos/initial/reward_run Min        -0.419244
expl/env_infos/reward_run Mean                3.32692
expl/env_infos/reward_run Std                 0.995593
expl/env_infos/reward_run Max                 5.79991
expl/env_infos/reward_run Min                -0.784456
expl/env_infos/final/reward_ctrl Mean        -0.478179
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.478179
expl/env_infos/final/reward_ctrl Min         -0.478179
expl/env_infos/initial/reward_ctrl Mean      -0.193017
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.193017
expl/env_infos/initial/reward_ctrl Min       -0.193017
expl/env_infos/reward_ctrl Mean              -0.411232
expl/env_infos/reward_ctrl Std                0.0867144
expl/env_infos/reward_ctrl Max               -0.0937867
expl/env_infos/reward_ctrl Min               -0.589073
eval/num steps total                     255000
eval/num paths total                        255
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.92162
eval/Rewards Std                              1.09876
eval/Rewards Max                              5.65512
eval/Rewards Min                             -1.14921
eval/Returns Mean                          2921.62
eval/Returns Std                             92.0693
eval/Returns Max                           3031.19
eval/Returns Min                           2752.19
eval/Actions Mean                             0.0291102
eval/Actions Std                              0.837239
eval/Actions Max                              0.999976
eval/Actions Min                             -0.999984
eval/Num Paths                                5
eval/Average Returns                       2921.62
eval/env_infos/final/reward_run Mean          3.2434
eval/env_infos/final/reward_run Std           0.979077
eval/env_infos/final/reward_run Max           4.88494
eval/env_infos/final/reward_run Min           1.96077
eval/env_infos/initial/reward_run Mean       -0.10286
eval/env_infos/initial/reward_run Std         0.101904
eval/env_infos/initial/reward_run Max         0.0101406
eval/env_infos/initial/reward_run Min        -0.284271
eval/env_infos/reward_run Mean                3.34271
eval/env_infos/reward_run Std                 1.11407
eval/env_infos/reward_run Max                 6.14783
eval/env_infos/reward_run Min                -0.69163
eval/env_infos/final/reward_ctrl Mean        -0.430877
eval/env_infos/final/reward_ctrl Std          0.0639508
eval/env_infos/final/reward_ctrl Max         -0.353614
eval/env_infos/final/reward_ctrl Min         -0.53106
eval/env_infos/initial/reward_ctrl Mean      -0.0867433
eval/env_infos/initial/reward_ctrl Std        0.0220966
eval/env_infos/initial/reward_ctrl Max       -0.0619754
eval/env_infos/initial/reward_ctrl Min       -0.123076
eval/env_infos/reward_ctrl Mean              -0.42109
eval/env_infos/reward_ctrl Std                0.0863265
eval/env_infos/reward_ctrl Max               -0.0619754
eval/env_infos/reward_ctrl Min               -0.589623
time/data storing (s)                         0.00450352
time/evaluation sampling (s)                  2.09413
time/exploration sampling (s)                 0.551556
time/logging (s)                              0.0138007
time/sac training (s)                         7.46817
time/saving (s)                               0.00383067
time/training (s)                             3.9031e-05
time/epoch (s)                               10.136
time/total (s)                              546.022
Epoch                                        50
---------------------------------------  ---------------
2021-11-24 00:38:27.218916 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 51 finished
---------------------------------------  ---------------
epoch                                        51
replay_buffer/size                        53000
trainer/num train calls                   52000
trainer/QF1 Loss                              3.59513
trainer/QF2 Loss                              4.35603
trainer/Policy Loss                         -79.7074
trainer/Q1 Predictions Mean                  79.3562
trainer/Q1 Predictions Std                   61.3219
trainer/Q1 Predictions Max                  174.609
trainer/Q1 Predictions Min                    3.35893
trainer/Q2 Predictions Mean                  79.3697
trainer/Q2 Predictions Std                   61.373
trainer/Q2 Predictions Max                  174.278
trainer/Q2 Predictions Min                    3.08203
trainer/Q Targets Mean                       79.2253
trainer/Q Targets Std                        61.548
trainer/Q Targets Max                       175.547
trainer/Q Targets Min                         2.63149
trainer/Log Pis Mean                          5.18787
trainer/Log Pis Std                           4.99275
trainer/Log Pis Max                          24.6248
trainer/Log Pis Min                          -6.90159
trainer/policy/mean Mean                      0.087151
trainer/policy/mean Std                       0.740441
trainer/policy/mean Max                       0.999889
trainer/policy/mean Min                      -0.998383
trainer/policy/normal/std Mean                0.476445
trainer/policy/normal/std Std                 0.124897
trainer/policy/normal/std Max                 1.05398
trainer/policy/normal/std Min                 0.152742
trainer/policy/normal/log_std Mean           -0.777744
trainer/policy/normal/log_std Std             0.275638
trainer/policy/normal/log_std Max             0.0525745
trainer/policy/normal/log_std Min            -1.87901
trainer/Alpha                                 0.0390071
trainer/Alpha Loss                           -2.63457
expl/num steps total                      53000
expl/num paths total                         53
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.25224
expl/Rewards Std                              1.00488
expl/Rewards Max                              5.57685
expl/Rewards Min                             -0.232112
expl/Returns Mean                          3252.24
expl/Returns Std                              0
expl/Returns Max                           3252.24
expl/Returns Min                           3252.24
expl/Actions Mean                             0.00814942
expl/Actions Std                              0.848433
expl/Actions Max                              0.999989
expl/Actions Min                             -0.999992
expl/Num Paths                                1
expl/Average Returns                       3252.24
expl/env_infos/final/reward_run Mean          2.1193
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.1193
expl/env_infos/final/reward_run Min           2.1193
expl/env_infos/initial/reward_run Mean       -0.0929427
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0929427
expl/env_infos/initial/reward_run Min        -0.0929427
expl/env_infos/reward_run Mean                3.68418
expl/env_infos/reward_run Std                 1.01476
expl/env_infos/reward_run Max                 6.10447
expl/env_infos/reward_run Min                -0.0929427
expl/env_infos/final/reward_ctrl Mean        -0.285419
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.285419
expl/env_infos/final/reward_ctrl Min         -0.285419
expl/env_infos/initial/reward_ctrl Mean      -0.139169
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.139169
expl/env_infos/initial/reward_ctrl Min       -0.139169
expl/env_infos/reward_ctrl Mean              -0.431943
expl/env_infos/reward_ctrl Std                0.0804691
expl/env_infos/reward_ctrl Max               -0.139169
expl/env_infos/reward_ctrl Min               -0.588418
eval/num steps total                     260000
eval/num paths total                        260
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             1.90601
eval/Rewards Std                              1.65022
eval/Rewards Max                              5.55409
eval/Rewards Min                             -1.62899
eval/Returns Mean                          1906.01
eval/Returns Std                           1122.66
eval/Returns Max                           3249.78
eval/Returns Min                            627.718
eval/Actions Mean                             0.0366675
eval/Actions Std                              0.778854
eval/Actions Max                              0.999996
eval/Actions Min                             -0.999952
eval/Num Paths                                5
eval/Average Returns                       1906.01
eval/env_infos/final/reward_run Mean          0.754294
eval/env_infos/final/reward_run Std           1.3214
eval/env_infos/final/reward_run Max           2.97388
eval/env_infos/final/reward_run Min          -0.726044
eval/env_infos/initial/reward_run Mean        0.00800927
eval/env_infos/initial/reward_run Std         0.0759869
eval/env_infos/initial/reward_run Max         0.0750327
eval/env_infos/initial/reward_run Min        -0.137301
eval/env_infos/reward_run Mean                2.27078
eval/env_infos/reward_run Std                 1.70889
eval/env_infos/reward_run Max                 6.07041
eval/env_infos/reward_run Min                -1.34973
eval/env_infos/final/reward_ctrl Mean        -0.283333
eval/env_infos/final/reward_ctrl Std          0.0614265
eval/env_infos/final/reward_ctrl Max         -0.205733
eval/env_infos/final/reward_ctrl Min         -0.382701
eval/env_infos/initial/reward_ctrl Mean      -0.0677189
eval/env_infos/initial/reward_ctrl Std        0.0372474
eval/env_infos/initial/reward_ctrl Max       -0.0081065
eval/env_infos/initial/reward_ctrl Min       -0.107684
eval/env_infos/reward_ctrl Mean              -0.364775
eval/env_infos/reward_ctrl Std                0.113
eval/env_infos/reward_ctrl Max               -0.0081065
eval/env_infos/reward_ctrl Min               -0.588999
time/data storing (s)                         0.00450105
time/evaluation sampling (s)                  2.03455
time/exploration sampling (s)                 0.535418
time/logging (s)                              0.0137323
time/sac training (s)                         7.41095
time/saving (s)                               0.00378143
time/training (s)                             3.7661e-05
time/epoch (s)                               10.003
time/total (s)                              556.308
Epoch                                        51
---------------------------------------  ---------------
2021-11-24 00:38:37.663441 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 52 finished
---------------------------------------  ---------------
epoch                                        52
replay_buffer/size                        54000
trainer/num train calls                   53000
trainer/QF1 Loss                              4.25874
trainer/QF2 Loss                              3.83192
trainer/Policy Loss                         -83.6262
trainer/Q1 Predictions Mean                  83.5455
trainer/Q1 Predictions Std                   63.6523
trainer/Q1 Predictions Max                  171.91
trainer/Q1 Predictions Min                    2.81315
trainer/Q2 Predictions Mean                  83.3262
trainer/Q2 Predictions Std                   63.5294
trainer/Q2 Predictions Max                  172.866
trainer/Q2 Predictions Min                    2.5064
trainer/Q Targets Mean                       83.8072
trainer/Q Targets Std                        63.8187
trainer/Q Targets Max                       174.341
trainer/Q Targets Min                         2.5264
trainer/Log Pis Mean                          5.8574
trainer/Log Pis Std                           5.80734
trainer/Log Pis Max                          23.0602
trainer/Log Pis Min                          -8.17375
trainer/policy/mean Mean                      0.00549736
trainer/policy/mean Std                       0.760167
trainer/policy/mean Max                       0.999699
trainer/policy/mean Min                      -0.999398
trainer/policy/normal/std Mean                0.469216
trainer/policy/normal/std Std                 0.12419
trainer/policy/normal/std Max                 1.41933
trainer/policy/normal/std Min                 0.148446
trainer/policy/normal/log_std Mean           -0.794335
trainer/policy/normal/log_std Std             0.282421
trainer/policy/normal/log_std Max             0.350183
trainer/policy/normal/log_std Min            -1.90753
trainer/Alpha                                 0.0402737
trainer/Alpha Loss                           -0.458041
expl/num steps total                      54000
expl/num paths total                         54
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             0.750136
expl/Rewards Std                              1.22259
expl/Rewards Max                              5.00411
expl/Rewards Min                             -1.57986
expl/Returns Mean                           750.136
expl/Returns Std                              0
expl/Returns Max                            750.136
expl/Returns Min                            750.136
expl/Actions Mean                            -0.0314461
expl/Actions Std                              0.723836
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999932
expl/Num Paths                                1
expl/Average Returns                        750.136
expl/env_infos/final/reward_run Mean          0.441774
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           0.441774
expl/env_infos/final/reward_run Min           0.441774
expl/env_infos/initial/reward_run Mean       -0.0754145
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0754145
expl/env_infos/initial/reward_run Min        -0.0754145
expl/env_infos/reward_run Mean                1.06509
expl/env_infos/reward_run Std                 1.24412
expl/env_infos/reward_run Max                 5.42209
expl/env_infos/reward_run Min                -1.234
expl/env_infos/final/reward_ctrl Mean        -0.326477
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.326477
expl/env_infos/final/reward_ctrl Min         -0.326477
expl/env_infos/initial/reward_ctrl Mean      -0.101135
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.101135
expl/env_infos/initial/reward_ctrl Min       -0.101135
expl/env_infos/reward_ctrl Mean              -0.314957
expl/env_infos/reward_ctrl Std                0.0970503
expl/env_infos/reward_ctrl Max               -0.063779
expl/env_infos/reward_ctrl Min               -0.58689
eval/num steps total                     265000
eval/num paths total                        265
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.6908
eval/Rewards Std                              1.34103
eval/Rewards Max                              5.51706
eval/Rewards Min                             -1.40777
eval/Returns Mean                          2690.8
eval/Returns Std                            603.881
eval/Returns Max                           3154.41
eval/Returns Min                           1510.82
eval/Actions Mean                             0.00514557
eval/Actions Std                              0.830081
eval/Actions Max                              0.999998
eval/Actions Min                             -0.999931
eval/Num Paths                                5
eval/Average Returns                       2690.8
eval/env_infos/final/reward_run Mean          3.13414
eval/env_infos/final/reward_run Std           1.31155
eval/env_infos/final/reward_run Max           5.05484
eval/env_infos/final/reward_run Min           0.984751
eval/env_infos/initial/reward_run Mean       -0.156601
eval/env_infos/initial/reward_run Std         0.0604413
eval/env_infos/initial/reward_run Max        -0.0980907
eval/env_infos/initial/reward_run Min        -0.243461
eval/env_infos/reward_run Mean                3.10423
eval/env_infos/reward_run Std                 1.37936
eval/env_infos/reward_run Max                 6.0682
eval/env_infos/reward_run Min                -1.17836
eval/env_infos/final/reward_ctrl Mean        -0.324609
eval/env_infos/final/reward_ctrl Std          0.0554824
eval/env_infos/final/reward_ctrl Max         -0.232735
eval/env_infos/final/reward_ctrl Min         -0.384799
eval/env_infos/initial/reward_ctrl Mean      -0.0677584
eval/env_infos/initial/reward_ctrl Std        0.0297573
eval/env_infos/initial/reward_ctrl Max       -0.0143929
eval/env_infos/initial/reward_ctrl Min       -0.103039
eval/env_infos/reward_ctrl Mean              -0.413437
eval/env_infos/reward_ctrl Std                0.0989521
eval/env_infos/reward_ctrl Max               -0.0143929
eval/env_infos/reward_ctrl Min               -0.596038
time/data storing (s)                         0.00592318
time/evaluation sampling (s)                  2.08526
time/exploration sampling (s)                 0.542322
time/logging (s)                              0.0138173
time/sac training (s)                         7.49405
time/saving (s)                               0.0037802
time/training (s)                             3.4383e-05
time/epoch (s)                               10.1452
time/total (s)                              566.74
Epoch                                        52
---------------------------------------  ---------------
2021-11-24 00:38:47.956968 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 53 finished
---------------------------------------  ---------------
epoch                                        53
replay_buffer/size                        55000
trainer/num train calls                   54000
trainer/QF1 Loss                              4.78059
trainer/QF2 Loss                              5.38746
trainer/Policy Loss                         -91.0001
trainer/Q1 Predictions Mean                  90.8147
trainer/Q1 Predictions Std                   64.8437
trainer/Q1 Predictions Max                  176.555
trainer/Q1 Predictions Min                    2.81997
trainer/Q2 Predictions Mean                  90.6196
trainer/Q2 Predictions Std                   64.7415
trainer/Q2 Predictions Max                  176.556
trainer/Q2 Predictions Min                    3.08631
trainer/Q Targets Mean                       90.7314
trainer/Q Targets Std                        64.8559
trainer/Q Targets Max                       176.405
trainer/Q Targets Min                         2.84376
trainer/Log Pis Mean                          6.19884
trainer/Log Pis Std                           5.96507
trainer/Log Pis Max                          31.2487
trainer/Log Pis Min                          -6.02122
trainer/policy/mean Mean                      0.040186
trainer/policy/mean Std                       0.75892
trainer/policy/mean Max                       0.999953
trainer/policy/mean Min                      -1
trainer/policy/normal/std Mean                0.462855
trainer/policy/normal/std Std                 0.119903
trainer/policy/normal/std Max                 1.19852
trainer/policy/normal/std Min                 0.119254
trainer/policy/normal/log_std Mean           -0.805451
trainer/policy/normal/log_std Std             0.271306
trainer/policy/normal/log_std Max             0.181085
trainer/policy/normal/log_std Min            -2.1265
trainer/Alpha                                 0.0401602
trainer/Alpha Loss                            0.639256
expl/num steps total                      55000
expl/num paths total                         55
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.15743
expl/Rewards Std                              1.03207
expl/Rewards Max                              5.67752
expl/Rewards Min                             -0.310331
expl/Returns Mean                          3157.43
expl/Returns Std                              0
expl/Returns Max                           3157.43
expl/Returns Min                           3157.43
expl/Actions Mean                             0.0496241
expl/Actions Std                              0.854986
expl/Actions Max                              0.999991
expl/Actions Min                             -0.999982
expl/Num Paths                                1
expl/Average Returns                       3157.43
expl/env_infos/final/reward_run Mean          5.70267
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.70267
expl/env_infos/final/reward_run Min           5.70267
expl/env_infos/initial/reward_run Mean       -0.0806833
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0806833
expl/env_infos/initial/reward_run Min        -0.0806833
expl/env_infos/reward_run Mean                3.59751
expl/env_infos/reward_run Std                 1.04038
expl/env_infos/reward_run Max                 6.19756
expl/env_infos/reward_run Min                -0.0806833
expl/env_infos/final/reward_ctrl Mean        -0.408859
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.408859
expl/env_infos/final/reward_ctrl Min         -0.408859
expl/env_infos/initial/reward_ctrl Mean      -0.0680808
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0680808
expl/env_infos/initial/reward_ctrl Min       -0.0680808
expl/env_infos/reward_ctrl Mean              -0.440078
expl/env_infos/reward_ctrl Std                0.0859281
expl/env_infos/reward_ctrl Max               -0.0680808
expl/env_infos/reward_ctrl Min               -0.592326
eval/num steps total                     270000
eval/num paths total                        270
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.15982
eval/Rewards Std                              1.10688
eval/Rewards Max                              5.96856
eval/Rewards Min                             -1.17051
eval/Returns Mean                          3159.82
eval/Returns Std                             77.0053
eval/Returns Max                           3228.16
eval/Returns Min                           3016.53
eval/Actions Mean                             0.0421958
eval/Actions Std                              0.86114
eval/Actions Max                              0.999955
eval/Actions Min                             -0.999972
eval/Num Paths                                5
eval/Average Returns                       3159.82
eval/env_infos/final/reward_run Mean          4.35944
eval/env_infos/final/reward_run Std           1.35735
eval/env_infos/final/reward_run Max           5.47206
eval/env_infos/final/reward_run Min           1.86215
eval/env_infos/initial/reward_run Mean       -0.12203
eval/env_infos/initial/reward_run Std         0.096502
eval/env_infos/initial/reward_run Max        -0.00877774
eval/env_infos/initial/reward_run Min        -0.294376
eval/env_infos/reward_run Mean                3.60582
eval/env_infos/reward_run Std                 1.11754
eval/env_infos/reward_run Max                 6.53027
eval/env_infos/reward_run Min                -0.728684
eval/env_infos/final/reward_ctrl Mean        -0.406725
eval/env_infos/final/reward_ctrl Std          0.0757116
eval/env_infos/final/reward_ctrl Max         -0.297054
eval/env_infos/final/reward_ctrl Min         -0.509515
eval/env_infos/initial/reward_ctrl Mean      -0.0857844
eval/env_infos/initial/reward_ctrl Std        0.0382591
eval/env_infos/initial/reward_ctrl Max       -0.0412664
eval/env_infos/initial/reward_ctrl Min       -0.156853
eval/env_infos/reward_ctrl Mean              -0.446006
eval/env_infos/reward_ctrl Std                0.0856071
eval/env_infos/reward_ctrl Max               -0.0412664
eval/env_infos/reward_ctrl Min               -0.594813
time/data storing (s)                         0.0045333
time/evaluation sampling (s)                  2.02123
time/exploration sampling (s)                 0.535166
time/logging (s)                              0.0139437
time/sac training (s)                         7.41742
time/saving (s)                               0.00386226
time/training (s)                             4.0318e-05
time/epoch (s)                                9.99619
time/total (s)                              577.02
Epoch                                        53
---------------------------------------  ---------------
2021-11-24 00:38:58.376956 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 54 finished
---------------------------------------  ---------------
epoch                                        54
replay_buffer/size                        56000
trainer/num train calls                   55000
trainer/QF1 Loss                              4.77158
trainer/QF2 Loss                              4.37645
trainer/Policy Loss                         -90.6854
trainer/Q1 Predictions Mean                  90.5825
trainer/Q1 Predictions Std                   68.5357
trainer/Q1 Predictions Max                  186.376
trainer/Q1 Predictions Min                    0.313463
trainer/Q2 Predictions Mean                  90.6215
trainer/Q2 Predictions Std                   68.6371
trainer/Q2 Predictions Max                  187.42
trainer/Q2 Predictions Min                    0.929694
trainer/Q Targets Mean                       90.7573
trainer/Q Targets Std                        68.5367
trainer/Q Targets Max                       183.878
trainer/Q Targets Min                         2.29342
trainer/Log Pis Mean                          5.36845
trainer/Log Pis Std                           5.52952
trainer/Log Pis Max                          22.2289
trainer/Log Pis Min                          -7.67955
trainer/policy/mean Mean                      0.0338114
trainer/policy/mean Std                       0.758543
trainer/policy/mean Max                       0.999929
trainer/policy/mean Min                      -0.999839
trainer/policy/normal/std Mean                0.474387
trainer/policy/normal/std Std                 0.121713
trainer/policy/normal/std Max                 0.930617
trainer/policy/normal/std Min                 0.164159
trainer/policy/normal/log_std Mean           -0.779999
trainer/policy/normal/log_std Std             0.266199
trainer/policy/normal/log_std Max            -0.0719074
trainer/policy/normal/log_std Min            -1.80692
trainer/Alpha                                 0.0408863
trainer/Alpha Loss                           -2.01904
expl/num steps total                      56000
expl/num paths total                         56
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.16982
expl/Rewards Std                              0.979113
expl/Rewards Max                              5.34146
expl/Rewards Min                             -0.694128
expl/Returns Mean                          3169.82
expl/Returns Std                              0
expl/Returns Max                           3169.82
expl/Returns Min                           3169.82
expl/Actions Mean                             0.00848894
expl/Actions Std                              0.835893
expl/Actions Max                              0.999911
expl/Actions Min                             -0.999942
expl/Num Paths                                1
expl/Average Returns                       3169.82
expl/env_infos/final/reward_run Mean          4.36367
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.36367
expl/env_infos/final/reward_run Min           4.36367
expl/env_infos/initial/reward_run Mean       -0.0505976
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0505976
expl/env_infos/initial/reward_run Min        -0.0505976
expl/env_infos/reward_run Mean                3.58909
expl/env_infos/reward_run Std                 0.992056
expl/env_infos/reward_run Max                 5.78006
expl/env_infos/reward_run Min                -0.310668
expl/env_infos/final/reward_ctrl Mean        -0.321203
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.321203
expl/env_infos/final/reward_ctrl Min         -0.321203
expl/env_infos/initial/reward_ctrl Mean      -0.0553744
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0553744
expl/env_infos/initial/reward_ctrl Min       -0.0553744
expl/env_infos/reward_ctrl Mean              -0.419273
expl/env_infos/reward_ctrl Std                0.0853429
expl/env_infos/reward_ctrl Max               -0.0553744
expl/env_infos/reward_ctrl Min               -0.593124
eval/num steps total                     275000
eval/num paths total                        275
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.73774
eval/Rewards Std                              1.32293
eval/Rewards Max                              5.9971
eval/Rewards Min                             -1.61223
eval/Returns Mean                          2737.74
eval/Returns Std                            592.814
eval/Returns Max                           3102.39
eval/Returns Min                           1559.12
eval/Actions Mean                             0.0140666
eval/Actions Std                              0.829372
eval/Actions Max                              0.999998
eval/Actions Min                             -0.999975
eval/Num Paths                                5
eval/Average Returns                       2737.74
eval/env_infos/final/reward_run Mean          3.07953
eval/env_infos/final/reward_run Std           1.04511
eval/env_infos/final/reward_run Max           3.97337
eval/env_infos/final/reward_run Min           1.20929
eval/env_infos/initial/reward_run Mean       -0.142283
eval/env_infos/initial/reward_run Std         0.178468
eval/env_infos/initial/reward_run Max         0.183178
eval/env_infos/initial/reward_run Min        -0.328892
eval/env_infos/reward_run Mean                3.15058
eval/env_infos/reward_run Std                 1.35556
eval/env_infos/reward_run Max                 6.49859
eval/env_infos/reward_run Min                -1.2647
eval/env_infos/final/reward_ctrl Mean        -0.421561
eval/env_infos/final/reward_ctrl Std          0.114879
eval/env_infos/final/reward_ctrl Max         -0.1944
eval/env_infos/final/reward_ctrl Min         -0.506168
eval/env_infos/initial/reward_ctrl Mean      -0.0869191
eval/env_infos/initial/reward_ctrl Std        0.0213261
eval/env_infos/initial/reward_ctrl Max       -0.0691592
eval/env_infos/initial/reward_ctrl Min       -0.128131
eval/env_infos/reward_ctrl Mean              -0.412834
eval/env_infos/reward_ctrl Std                0.0913257
eval/env_infos/reward_ctrl Max               -0.0661544
eval/env_infos/reward_ctrl Min               -0.596482
time/data storing (s)                         0.00451404
time/evaluation sampling (s)                  2.02148
time/exploration sampling (s)                 0.522993
time/logging (s)                              0.0144981
time/sac training (s)                         7.5444
time/saving (s)                               0.00384864
time/training (s)                             6.0594e-05
time/epoch (s)                               10.1118
time/total (s)                              587.427
Epoch                                        54
---------------------------------------  ---------------
2021-11-24 00:39:08.984910 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 55 finished
---------------------------------------  ---------------
epoch                                        55
replay_buffer/size                        57000
trainer/num train calls                   56000
trainer/QF1 Loss                              6.25666
trainer/QF2 Loss                              5.76062
trainer/Policy Loss                         -95.3149
trainer/Q1 Predictions Mean                  95.0693
trainer/Q1 Predictions Std                   66.8546
trainer/Q1 Predictions Max                  183.391
trainer/Q1 Predictions Min                    3.09216
trainer/Q2 Predictions Mean                  95.2325
trainer/Q2 Predictions Std                   66.9767
trainer/Q2 Predictions Max                  185.842
trainer/Q2 Predictions Min                    3.34682
trainer/Q Targets Mean                       94.5599
trainer/Q Targets Std                        66.6771
trainer/Q Targets Max                       185.447
trainer/Q Targets Min                         2.98735
trainer/Log Pis Mean                          5.97068
trainer/Log Pis Std                           5.94892
trainer/Log Pis Max                          31.9538
trainer/Log Pis Min                          -4.99444
trainer/policy/mean Mean                      0.0791069
trainer/policy/mean Std                       0.759222
trainer/policy/mean Max                       0.999996
trainer/policy/mean Min                      -0.999976
trainer/policy/normal/std Mean                0.459224
trainer/policy/normal/std Std                 0.121345
trainer/policy/normal/std Max                 1.09373
trainer/policy/normal/std Min                 0.0870382
trainer/policy/normal/log_std Mean           -0.815735
trainer/policy/normal/log_std Std             0.281767
trainer/policy/normal/log_std Max             0.0895919
trainer/policy/normal/log_std Min            -2.44141
trainer/Alpha                                 0.0411165
trainer/Alpha Loss                           -0.0935692
expl/num steps total                      57000
expl/num paths total                         57
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             1.51438
expl/Rewards Std                              1.60044
expl/Rewards Max                              5.47107
expl/Rewards Min                             -1.84158
expl/Returns Mean                          1514.38
expl/Returns Std                              0
expl/Returns Max                           1514.38
expl/Returns Min                           1514.38
expl/Actions Mean                             0.0461426
expl/Actions Std                              0.762232
expl/Actions Max                              0.999996
expl/Actions Min                             -0.999974
expl/Num Paths                                1
expl/Average Returns                       1514.38
expl/env_infos/final/reward_run Mean          2.23935
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.23935
expl/env_infos/final/reward_run Min           2.23935
expl/env_infos/initial/reward_run Mean       -0.140016
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.140016
expl/env_infos/initial/reward_run Min        -0.140016
expl/env_infos/reward_run Mean                1.86426
expl/env_infos/reward_run Std                 1.64926
expl/env_infos/reward_run Max                 5.92255
expl/env_infos/reward_run Min                -1.48399
expl/env_infos/final/reward_ctrl Mean        -0.230432
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.230432
expl/env_infos/final/reward_ctrl Min         -0.230432
expl/env_infos/initial/reward_ctrl Mean      -0.0154784
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0154784
expl/env_infos/initial/reward_ctrl Min       -0.0154784
expl/env_infos/reward_ctrl Mean              -0.349876
expl/env_infos/reward_ctrl Std                0.104288
expl/env_infos/reward_ctrl Max               -0.0154784
expl/env_infos/reward_ctrl Min               -0.591825
eval/num steps total                     280000
eval/num paths total                        280
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.42823
eval/Rewards Std                              1.50838
eval/Rewards Max                              5.64279
eval/Rewards Min                             -1.58754
eval/Returns Mean                          2428.23
eval/Returns Std                            947.402
eval/Returns Max                           3196.68
eval/Returns Min                            799.797
eval/Actions Mean                             0.0484748
eval/Actions Std                              0.809325
eval/Actions Max                              0.999996
eval/Actions Min                             -0.999976
eval/Num Paths                                5
eval/Average Returns                       2428.23
eval/env_infos/final/reward_run Mean          2.10372
eval/env_infos/final/reward_run Std           1.83719
eval/env_infos/final/reward_run Max           4.72398
eval/env_infos/final/reward_run Min           0.00861865
eval/env_infos/initial/reward_run Mean       -0.121014
eval/env_infos/initial/reward_run Std         0.0683419
eval/env_infos/initial/reward_run Max        -0.040422
eval/env_infos/initial/reward_run Min        -0.24741
eval/env_infos/reward_run Mean                2.82265
eval/env_infos/reward_run Std                 1.55908
eval/env_infos/reward_run Max                 6.03943
eval/env_infos/reward_run Min                -1.20771
eval/env_infos/final/reward_ctrl Mean        -0.370685
eval/env_infos/final/reward_ctrl Std          0.111685
eval/env_infos/final/reward_ctrl Max         -0.218359
eval/env_infos/final/reward_ctrl Min         -0.522995
eval/env_infos/initial/reward_ctrl Mean      -0.0703278
eval/env_infos/initial/reward_ctrl Std        0.0466784
eval/env_infos/initial/reward_ctrl Max       -0.0270712
eval/env_infos/initial/reward_ctrl Min       -0.155009
eval/env_infos/reward_ctrl Mean              -0.394414
eval/env_infos/reward_ctrl Std                0.10267
eval/env_infos/reward_ctrl Max               -0.0211056
eval/env_infos/reward_ctrl Min               -0.592927
time/data storing (s)                         0.00447514
time/evaluation sampling (s)                  2.02424
time/exploration sampling (s)                 0.54103
time/logging (s)                              0.0137659
time/sac training (s)                         7.69391
time/saving (s)                               0.00379802
time/training (s)                             3.557e-05
time/epoch (s)                               10.2813
time/total (s)                              598.02
Epoch                                        55
---------------------------------------  ---------------
2021-11-24 00:39:19.575474 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 56 finished
---------------------------------------  ---------------
epoch                                        56
replay_buffer/size                        58000
trainer/num train calls                   57000
trainer/QF1 Loss                              5.36637
trainer/QF2 Loss                              6.12793
trainer/Policy Loss                        -107.212
trainer/Q1 Predictions Mean                 107.122
trainer/Q1 Predictions Std                   65.8078
trainer/Q1 Predictions Max                  187.19
trainer/Q1 Predictions Min                    3.2746
trainer/Q2 Predictions Mean                 106.868
trainer/Q2 Predictions Std                   65.6875
trainer/Q2 Predictions Max                  186.636
trainer/Q2 Predictions Min                    3.92998
trainer/Q Targets Mean                      107.224
trainer/Q Targets Std                        66.0412
trainer/Q Targets Max                       187.347
trainer/Q Targets Min                         3.31332
trainer/Log Pis Mean                          6.69913
trainer/Log Pis Std                           5.80775
trainer/Log Pis Max                          25.0778
trainer/Log Pis Min                          -6.80465
trainer/policy/mean Mean                      0.0902663
trainer/policy/mean Std                       0.768494
trainer/policy/mean Max                       0.999961
trainer/policy/mean Min                      -0.999746
trainer/policy/normal/std Mean                0.454347
trainer/policy/normal/std Std                 0.125205
trainer/policy/normal/std Max                 0.951608
trainer/policy/normal/std Min                 0.15634
trainer/policy/normal/log_std Mean           -0.827949
trainer/policy/normal/log_std Std             0.283611
trainer/policy/normal/log_std Max            -0.0496016
trainer/policy/normal/log_std Min            -1.85572
trainer/Alpha                                 0.0420688
trainer/Alpha Loss                            2.21516
expl/num steps total                      58000
expl/num paths total                         58
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             2.93899
expl/Rewards Std                              1.15598
expl/Rewards Max                              5.33962
expl/Rewards Min                             -1.18204
expl/Returns Mean                          2938.99
expl/Returns Std                              0
expl/Returns Max                           2938.99
expl/Returns Min                           2938.99
expl/Actions Mean                             0.0682267
expl/Actions Std                              0.832164
expl/Actions Max                              0.999985
expl/Actions Min                             -0.99997
expl/Num Paths                                1
expl/Average Returns                       2938.99
expl/env_infos/final/reward_run Mean          4.51266
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.51266
expl/env_infos/final/reward_run Min           4.51266
expl/env_infos/initial/reward_run Mean       -0.207987
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.207987
expl/env_infos/initial/reward_run Min        -0.207987
expl/env_infos/reward_run Mean                3.35728
expl/env_infos/reward_run Std                 1.16786
expl/env_infos/reward_run Max                 5.82355
expl/env_infos/reward_run Min                -0.822542
expl/env_infos/final/reward_ctrl Mean        -0.584128
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.584128
expl/env_infos/final/reward_ctrl Min         -0.584128
expl/env_infos/initial/reward_ctrl Mean      -0.0789567
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0789567
expl/env_infos/initial/reward_ctrl Min       -0.0789567
expl/env_infos/reward_ctrl Mean              -0.418291
expl/env_infos/reward_ctrl Std                0.0959289
expl/env_infos/reward_ctrl Max               -0.0789567
expl/env_infos/reward_ctrl Min               -0.595286
eval/num steps total                     285000
eval/num paths total                        285
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.82524
eval/Rewards Std                              1.48944
eval/Rewards Max                              5.87225
eval/Rewards Min                             -1.60138
eval/Returns Mean                          2825.24
eval/Returns Std                            809.018
eval/Returns Max                           3436.81
eval/Returns Min                           1293.43
eval/Actions Mean                             0.0762457
eval/Actions Std                              0.827179
eval/Actions Max                              0.99999
eval/Actions Min                             -0.999962
eval/Num Paths                                5
eval/Average Returns                       2825.24
eval/env_infos/final/reward_run Mean          2.88695
eval/env_infos/final/reward_run Std           1.89216
eval/env_infos/final/reward_run Max           5.03555
eval/env_infos/final/reward_run Min           0.551516
eval/env_infos/initial/reward_run Mean       -0.0352391
eval/env_infos/initial/reward_run Std         0.164978
eval/env_infos/initial/reward_run Max         0.1065
eval/env_infos/initial/reward_run Min        -0.322821
eval/env_infos/reward_run Mean                3.23927
eval/env_infos/reward_run Std                 1.52456
eval/env_infos/reward_run Max                 6.39247
eval/env_infos/reward_run Min                -1.23325
eval/env_infos/final/reward_ctrl Mean        -0.425093
eval/env_infos/final/reward_ctrl Std          0.0958513
eval/env_infos/final/reward_ctrl Max         -0.276502
eval/env_infos/final/reward_ctrl Min         -0.567838
eval/env_infos/initial/reward_ctrl Mean      -0.0481741
eval/env_infos/initial/reward_ctrl Std        0.0341388
eval/env_infos/initial/reward_ctrl Max       -0.0124364
eval/env_infos/initial/reward_ctrl Min       -0.0987175
eval/env_infos/reward_ctrl Mean              -0.414023
eval/env_infos/reward_ctrl Std                0.102131
eval/env_infos/reward_ctrl Max               -0.0124364
eval/env_infos/reward_ctrl Min               -0.595845
time/data storing (s)                         0.00449962
time/evaluation sampling (s)                  2.01874
time/exploration sampling (s)                 0.521411
time/logging (s)                              0.0138893
time/sac training (s)                         7.70054
time/saving (s)                               0.00373141
time/training (s)                             3.429e-05
time/epoch (s)                               10.2628
time/total (s)                              608.595
Epoch                                        56
---------------------------------------  ---------------
2021-11-24 00:39:30.304346 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 57 finished
---------------------------------------  ---------------
epoch                                        57
replay_buffer/size                        59000
trainer/num train calls                   58000
trainer/QF1 Loss                              8.81244
trainer/QF2 Loss                              8.13504
trainer/Policy Loss                        -105.945
trainer/Q1 Predictions Mean                 105.644
trainer/Q1 Predictions Std                   68.5728
trainer/Q1 Predictions Max                  187.46
trainer/Q1 Predictions Min                    2.67081
trainer/Q2 Predictions Mean                 105.805
trainer/Q2 Predictions Std                   68.6814
trainer/Q2 Predictions Max                  189.263
trainer/Q2 Predictions Min                    2.50075
trainer/Q Targets Mean                      105.784
trainer/Q Targets Std                        68.9705
trainer/Q Targets Max                       189.993
trainer/Q Targets Min                         2.59518
trainer/Log Pis Mean                          6.61659
trainer/Log Pis Std                           5.75542
trainer/Log Pis Max                          29.3618
trainer/Log Pis Min                          -3.8742
trainer/policy/mean Mean                      0.0729453
trainer/policy/mean Std                       0.769675
trainer/policy/mean Max                       0.999984
trainer/policy/mean Min                      -0.999664
trainer/policy/normal/std Mean                0.471265
trainer/policy/normal/std Std                 0.127522
trainer/policy/normal/std Max                 1.0262
trainer/policy/normal/std Min                 0.142711
trainer/policy/normal/log_std Mean           -0.789999
trainer/policy/normal/log_std Std             0.278844
trainer/policy/normal/log_std Max             0.0258669
trainer/policy/normal/log_std Min            -1.94693
trainer/Alpha                                 0.04258
trainer/Alpha Loss                            1.94618
expl/num steps total                      59000
expl/num paths total                         59
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.03704
expl/Rewards Std                              0.976825
expl/Rewards Max                              5.21396
expl/Rewards Min                             -1.31962
expl/Returns Mean                          3037.04
expl/Returns Std                              0
expl/Returns Max                           3037.04
expl/Returns Min                           3037.04
expl/Actions Mean                             0.0248865
expl/Actions Std                              0.833513
expl/Actions Max                              0.999938
expl/Actions Min                             -0.999857
expl/Num Paths                                1
expl/Average Returns                       3037.04
expl/env_infos/final/reward_run Mean          3.99122
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.99122
expl/env_infos/final/reward_run Min           3.99122
expl/env_infos/initial/reward_run Mean       -0.188211
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.188211
expl/env_infos/initial/reward_run Min        -0.188211
expl/env_infos/reward_run Mean                3.45426
expl/env_infos/reward_run Std                 0.999723
expl/env_infos/reward_run Max                 5.74113
expl/env_infos/reward_run Min                -0.833412
expl/env_infos/final/reward_ctrl Mean        -0.510629
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.510629
expl/env_infos/final/reward_ctrl Min         -0.510629
expl/env_infos/initial/reward_ctrl Mean      -0.0880887
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0880887
expl/env_infos/initial/reward_ctrl Min       -0.0880887
expl/env_infos/reward_ctrl Mean              -0.417218
expl/env_infos/reward_ctrl Std                0.0885048
expl/env_infos/reward_ctrl Max               -0.0880887
expl/env_infos/reward_ctrl Min               -0.596631
eval/num steps total                     290000
eval/num paths total                        290
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.8548
eval/Rewards Std                              1.29573
eval/Rewards Max                              6.00426
eval/Rewards Min                             -1.09943
eval/Returns Mean                          2854.8
eval/Returns Std                            372.989
eval/Returns Max                           3339.84
eval/Returns Min                           2250.41
eval/Actions Mean                             0.0114653
eval/Actions Std                              0.828976
eval/Actions Max                              0.999997
eval/Actions Min                             -0.999897
eval/Num Paths                                5
eval/Average Returns                       2854.8
eval/env_infos/final/reward_run Mean          2.80362
eval/env_infos/final/reward_run Std           2.04076
eval/env_infos/final/reward_run Max           5.68276
eval/env_infos/final/reward_run Min          -0.353745
eval/env_infos/initial/reward_run Mean       -0.0500186
eval/env_infos/initial/reward_run Std         0.0955848
eval/env_infos/initial/reward_run Max         0.0651172
eval/env_infos/initial/reward_run Min        -0.221627
eval/env_infos/reward_run Mean                3.2672
eval/env_infos/reward_run Std                 1.33389
eval/env_infos/reward_run Max                 6.52786
eval/env_infos/reward_run Min                -0.781385
eval/env_infos/final/reward_ctrl Mean        -0.41555
eval/env_infos/final/reward_ctrl Std          0.130562
eval/env_infos/final/reward_ctrl Max         -0.246824
eval/env_infos/final/reward_ctrl Min         -0.574274
eval/env_infos/initial/reward_ctrl Mean      -0.05252
eval/env_infos/initial/reward_ctrl Std        0.0229191
eval/env_infos/initial/reward_ctrl Max       -0.0154157
eval/env_infos/initial/reward_ctrl Min       -0.0801081
eval/env_infos/reward_ctrl Mean              -0.412399
eval/env_infos/reward_ctrl Std                0.0950109
eval/env_infos/reward_ctrl Max               -0.0154157
eval/env_infos/reward_ctrl Min               -0.593833
time/data storing (s)                         0.00479251
time/evaluation sampling (s)                  2.03127
time/exploration sampling (s)                 0.540825
time/logging (s)                              0.015592
time/sac training (s)                         7.80188
time/saving (s)                               0.00537394
time/training (s)                             4.1852e-05
time/epoch (s)                               10.3998
time/total (s)                              619.311
Epoch                                        57
---------------------------------------  ---------------
2021-11-24 00:39:40.955445 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 58 finished
---------------------------------------  ----------------
epoch                                        58
replay_buffer/size                        60000
trainer/num train calls                   59000
trainer/QF1 Loss                              6.25172
trainer/QF2 Loss                              5.38242
trainer/Policy Loss                        -100.945
trainer/Q1 Predictions Mean                 100.756
trainer/Q1 Predictions Std                   72.3565
trainer/Q1 Predictions Max                  192.234
trainer/Q1 Predictions Min                    4.16506
trainer/Q2 Predictions Mean                 100.844
trainer/Q2 Predictions Std                   72.3518
trainer/Q2 Predictions Max                  193.843
trainer/Q2 Predictions Min                    3.78429
trainer/Q Targets Mean                      100.606
trainer/Q Targets Std                        72.2253
trainer/Q Targets Max                       193.004
trainer/Q Targets Min                         3.98191
trainer/Log Pis Mean                          5.55716
trainer/Log Pis Std                           5.48066
trainer/Log Pis Max                          25.6624
trainer/Log Pis Min                          -6.67854
trainer/policy/mean Mean                      0.0398799
trainer/policy/mean Std                       0.751708
trainer/policy/mean Max                       0.999795
trainer/policy/mean Min                      -0.999003
trainer/policy/normal/std Mean                0.459676
trainer/policy/normal/std Std                 0.121209
trainer/policy/normal/std Max                 0.918254
trainer/policy/normal/std Min                 0.159448
trainer/policy/normal/log_std Mean           -0.81405
trainer/policy/normal/log_std Std             0.277134
trainer/policy/normal/log_std Max            -0.0852808
trainer/policy/normal/log_std Min            -1.83604
trainer/Alpha                                 0.0432248
trainer/Alpha Loss                           -1.3911
expl/num steps total                      60000
expl/num paths total                         60
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.07337
expl/Rewards Std                              1.03272
expl/Rewards Max                              5.31483
expl/Rewards Min                             -0.343885
expl/Returns Mean                          3073.37
expl/Returns Std                              0
expl/Returns Max                           3073.37
expl/Returns Min                           3073.37
expl/Actions Mean                             0.0148753
expl/Actions Std                              0.834644
expl/Actions Max                              0.999922
expl/Actions Min                             -0.999975
expl/Num Paths                                1
expl/Average Returns                       3073.37
expl/env_infos/final/reward_run Mean          4.848
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.848
expl/env_infos/final/reward_run Min           4.848
expl/env_infos/initial/reward_run Mean       -0.243229
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.243229
expl/env_infos/initial/reward_run Min        -0.243229
expl/env_infos/reward_run Mean                3.49148
expl/env_infos/reward_run Std                 1.03811
expl/env_infos/reward_run Max                 5.87018
expl/env_infos/reward_run Min                -0.243229
expl/env_infos/final/reward_ctrl Mean        -0.565092
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.565092
expl/env_infos/final/reward_ctrl Min         -0.565092
expl/env_infos/initial/reward_ctrl Mean      -0.0462956
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0462956
expl/env_infos/initial/reward_ctrl Min       -0.0462956
expl/env_infos/reward_ctrl Mean              -0.418111
expl/env_infos/reward_ctrl Std                0.0841699
expl/env_infos/reward_ctrl Max               -0.0462956
expl/env_infos/reward_ctrl Min               -0.586233
eval/num steps total                     295000
eval/num paths total                        295
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.27197
eval/Rewards Std                              1.0569
eval/Rewards Max                              5.773
eval/Rewards Min                             -0.762374
eval/Returns Mean                          3271.97
eval/Returns Std                             55.3474
eval/Returns Max                           3345.81
eval/Returns Min                           3186.78
eval/Actions Mean                             8.81936e-05
eval/Actions Std                              0.845978
eval/Actions Max                              0.999964
eval/Actions Min                             -0.999923
eval/Num Paths                                5
eval/Average Returns                       3271.97
eval/env_infos/final/reward_run Mean          3.94954
eval/env_infos/final/reward_run Std           0.418874
eval/env_infos/final/reward_run Max           4.43393
eval/env_infos/final/reward_run Min           3.37033
eval/env_infos/initial/reward_run Mean       -0.17453
eval/env_infos/initial/reward_run Std         0.0682824
eval/env_infos/initial/reward_run Max        -0.0887329
eval/env_infos/initial/reward_run Min        -0.279106
eval/env_infos/reward_run Mean                3.70138
eval/env_infos/reward_run Std                 1.06035
eval/env_infos/reward_run Max                 6.234
eval/env_infos/reward_run Min                -0.446095
eval/env_infos/final/reward_ctrl Mean        -0.401418
eval/env_infos/final/reward_ctrl Std          0.0460579
eval/env_infos/final/reward_ctrl Max         -0.322054
eval/env_infos/final/reward_ctrl Min         -0.457558
eval/env_infos/initial/reward_ctrl Mean      -0.0853701
eval/env_infos/initial/reward_ctrl Std        0.0646209
eval/env_infos/initial/reward_ctrl Max       -0.0119274
eval/env_infos/initial/reward_ctrl Min       -0.206127
eval/env_infos/reward_ctrl Mean              -0.429407
eval/env_infos/reward_ctrl Std                0.0832469
eval/env_infos/reward_ctrl Max               -0.0119274
eval/env_infos/reward_ctrl Min               -0.597763
time/data storing (s)                         0.00452285
time/evaluation sampling (s)                  2.02105
time/exploration sampling (s)                 0.549331
time/logging (s)                              0.0139759
time/sac training (s)                         7.72584
time/saving (s)                               0.00374152
time/training (s)                             3.4705e-05
time/epoch (s)                               10.3185
time/total (s)                              629.945
Epoch                                        58
---------------------------------------  ----------------
2021-11-24 00:39:51.547063 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 59 finished
---------------------------------------  ---------------
epoch                                        59
replay_buffer/size                        61000
trainer/num train calls                   60000
trainer/QF1 Loss                              4.94866
trainer/QF2 Loss                              4.50607
trainer/Policy Loss                        -113.68
trainer/Q1 Predictions Mean                 113.663
trainer/Q1 Predictions Std                   73.1472
trainer/Q1 Predictions Max                  199.067
trainer/Q1 Predictions Min                    3.25949
trainer/Q2 Predictions Mean                 113.854
trainer/Q2 Predictions Std                   73.2451
trainer/Q2 Predictions Max                  201.238
trainer/Q2 Predictions Min                    3.13262
trainer/Q Targets Mean                      113.581
trainer/Q Targets Std                        73.2385
trainer/Q Targets Max                       202.187
trainer/Q Targets Min                         3.3802
trainer/Log Pis Mean                          6.93216
trainer/Log Pis Std                           6.15778
trainer/Log Pis Max                          27.8989
trainer/Log Pis Min                          -4.83741
trainer/policy/mean Mean                      0.00585733
trainer/policy/mean Std                       0.779205
trainer/policy/mean Max                       0.999907
trainer/policy/mean Min                      -0.999929
trainer/policy/normal/std Mean                0.456452
trainer/policy/normal/std Std                 0.121302
trainer/policy/normal/std Max                 1.00157
trainer/policy/normal/std Min                 0.144879
trainer/policy/normal/log_std Mean           -0.820815
trainer/policy/normal/log_std Std             0.274687
trainer/policy/normal/log_std Max             0.00156376
trainer/policy/normal/log_std Min            -1.93186
trainer/Alpha                                 0.0441281
trainer/Alpha Loss                            2.90895
expl/num steps total                      61000
expl/num paths total                         61
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.01206
expl/Rewards Std                              0.981604
expl/Rewards Max                              5.44929
expl/Rewards Min                             -1.74335
expl/Returns Mean                          3012.06
expl/Returns Std                              0
expl/Returns Max                           3012.06
expl/Returns Min                           3012.06
expl/Actions Mean                            -0.0182181
expl/Actions Std                              0.835799
expl/Actions Max                              0.999968
expl/Actions Min                             -0.99999
expl/Num Paths                                1
expl/Average Returns                       3012.06
expl/env_infos/final/reward_run Mean          5.08427
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.08427
expl/env_infos/final/reward_run Min           5.08427
expl/env_infos/initial/reward_run Mean       -0.308913
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.308913
expl/env_infos/initial/reward_run Min        -0.308913
expl/env_infos/reward_run Mean                3.4314
expl/env_infos/reward_run Std                 0.984657
expl/env_infos/reward_run Max                 5.90775
expl/env_infos/reward_run Min                -1.15896
expl/env_infos/final/reward_ctrl Mean        -0.542433
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.542433
expl/env_infos/final/reward_ctrl Min         -0.542433
expl/env_infos/initial/reward_ctrl Mean      -0.149491
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.149491
expl/env_infos/initial/reward_ctrl Min       -0.149491
expl/env_infos/reward_ctrl Mean              -0.419335
expl/env_infos/reward_ctrl Std                0.085379
expl/env_infos/reward_ctrl Max               -0.132101
expl/env_infos/reward_ctrl Min               -0.595522
eval/num steps total                     300000
eval/num paths total                        300
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.00366
eval/Rewards Std                              1.00717
eval/Rewards Max                              5.71127
eval/Rewards Min                             -1.34788
eval/Returns Mean                          3003.66
eval/Returns Std                            113.509
eval/Returns Max                           3129.29
eval/Returns Min                           2848
eval/Actions Mean                            -0.0338325
eval/Actions Std                              0.839585
eval/Actions Max                              0.999987
eval/Actions Min                             -0.999977
eval/Num Paths                                5
eval/Average Returns                       3003.66
eval/env_infos/final/reward_run Mean          3.63722
eval/env_infos/final/reward_run Std           0.44188
eval/env_infos/final/reward_run Max           4.21834
eval/env_infos/final/reward_run Min           3.12771
eval/env_infos/initial/reward_run Mean       -0.16799
eval/env_infos/initial/reward_run Std         0.0934537
eval/env_infos/initial/reward_run Max        -0.05243
eval/env_infos/initial/reward_run Min        -0.300302
eval/env_infos/reward_run Mean                3.42729
eval/env_infos/reward_run Std                 1.01268
eval/env_infos/reward_run Max                 6.21207
eval/env_infos/reward_run Min                -0.864184
eval/env_infos/final/reward_ctrl Mean        -0.347496
eval/env_infos/final/reward_ctrl Std          0.0659538
eval/env_infos/final/reward_ctrl Max         -0.278088
eval/env_infos/final/reward_ctrl Min         -0.465203
eval/env_infos/initial/reward_ctrl Mean      -0.157686
eval/env_infos/initial/reward_ctrl Std        0.0532178
eval/env_infos/initial/reward_ctrl Max       -0.0878369
eval/env_infos/initial/reward_ctrl Min       -0.252666
eval/env_infos/reward_ctrl Mean              -0.423628
eval/env_infos/reward_ctrl Std                0.0875513
eval/env_infos/reward_ctrl Max               -0.0782062
eval/env_infos/reward_ctrl Min               -0.596545
time/data storing (s)                         0.00448694
time/evaluation sampling (s)                  2.03172
time/exploration sampling (s)                 0.528867
time/logging (s)                              0.0137955
time/sac training (s)                         7.68611
time/saving (s)                               0.0037307
time/training (s)                             3.7793e-05
time/epoch (s)                               10.2687
time/total (s)                              640.522
Epoch                                        59
---------------------------------------  ---------------
2021-11-24 00:40:02.291472 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 60 finished
---------------------------------------  ---------------
epoch                                        60
replay_buffer/size                        62000
trainer/num train calls                   61000
trainer/QF1 Loss                              6.39031
trainer/QF2 Loss                              6.53868
trainer/Policy Loss                        -109.054
trainer/Q1 Predictions Mean                 108.824
trainer/Q1 Predictions Std                   72.6612
trainer/Q1 Predictions Max                  193.044
trainer/Q1 Predictions Min                    3.20767
trainer/Q2 Predictions Mean                 108.955
trainer/Q2 Predictions Std                   72.7615
trainer/Q2 Predictions Max                  193.517
trainer/Q2 Predictions Min                    2.60234
trainer/Q Targets Mean                      109.046
trainer/Q Targets Std                        72.8711
trainer/Q Targets Max                       194.296
trainer/Q Targets Min                         2.61032
trainer/Log Pis Mean                          6.33833
trainer/Log Pis Std                           5.57193
trainer/Log Pis Max                          21.1543
trainer/Log Pis Min                          -6.71708
trainer/policy/mean Mean                      0.0437235
trainer/policy/mean Std                       0.764095
trainer/policy/mean Max                       0.99997
trainer/policy/mean Min                      -0.99957
trainer/policy/normal/std Mean                0.461512
trainer/policy/normal/std Std                 0.125768
trainer/policy/normal/std Max                 0.993208
trainer/policy/normal/std Min                 0.145488
trainer/policy/normal/log_std Mean           -0.812183
trainer/policy/normal/log_std Std             0.28463
trainer/policy/normal/log_std Max            -0.0068147
trainer/policy/normal/log_std Min            -1.92766
trainer/Alpha                                 0.0450603
trainer/Alpha Loss                            1.04875
expl/num steps total                      62000
expl/num paths total                         62
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.22213
expl/Rewards Std                              1.01218
expl/Rewards Max                              5.54558
expl/Rewards Min                             -0.413161
expl/Returns Mean                          3222.13
expl/Returns Std                              0
expl/Returns Max                           3222.13
expl/Returns Min                           3222.13
expl/Actions Mean                             0.0316917
expl/Actions Std                              0.841569
expl/Actions Max                              0.999998
expl/Actions Min                             -0.999936
expl/Num Paths                                1
expl/Average Returns                       3222.13
expl/env_infos/final/reward_run Mean          3.44697
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.44697
expl/env_infos/final/reward_run Min           3.44697
expl/env_infos/initial/reward_run Mean        0.0123096
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0123096
expl/env_infos/initial/reward_run Min         0.0123096
expl/env_infos/reward_run Mean                3.64767
expl/env_infos/reward_run Std                 1.00956
expl/env_infos/reward_run Max                 6.06069
expl/env_infos/reward_run Min                 0.0123096
expl/env_infos/final/reward_ctrl Mean        -0.426524
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.426524
expl/env_infos/final/reward_ctrl Min         -0.426524
expl/env_infos/initial/reward_ctrl Mean      -0.0908609
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0908609
expl/env_infos/initial/reward_ctrl Min       -0.0908609
expl/env_infos/reward_ctrl Mean              -0.425545
expl/env_infos/reward_ctrl Std                0.0857707
expl/env_infos/reward_ctrl Max               -0.0390812
expl/env_infos/reward_ctrl Min               -0.591055
eval/num steps total                     305000
eval/num paths total                        305
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.87668
eval/Rewards Std                              1.396
eval/Rewards Max                              5.91106
eval/Rewards Min                             -1.5551
eval/Returns Mean                          2876.68
eval/Returns Std                            625.297
eval/Returns Max                           3372.05
eval/Returns Min                           1657.62
eval/Actions Mean                             0.0191521
eval/Actions Std                              0.83155
eval/Actions Max                              0.999998
eval/Actions Min                             -0.999863
eval/Num Paths                                5
eval/Average Returns                       2876.68
eval/env_infos/final/reward_run Mean          2.3966
eval/env_infos/final/reward_run Std           1.43144
eval/env_infos/final/reward_run Max           3.87146
eval/env_infos/final/reward_run Min          -0.304798
eval/env_infos/initial/reward_run Mean       -0.100796
eval/env_infos/initial/reward_run Std         0.133225
eval/env_infos/initial/reward_run Max         0.0170078
eval/env_infos/initial/reward_run Min        -0.340469
eval/env_infos/reward_run Mean                3.29179
eval/env_infos/reward_run Std                 1.42413
eval/env_infos/reward_run Max                 6.3778
eval/env_infos/reward_run Min                -1.19153
eval/env_infos/final/reward_ctrl Mean        -0.368837
eval/env_infos/final/reward_ctrl Std          0.130679
eval/env_infos/final/reward_ctrl Max         -0.198229
eval/env_infos/final/reward_ctrl Min         -0.513289
eval/env_infos/initial/reward_ctrl Mean      -0.160364
eval/env_infos/initial/reward_ctrl Std        0.0574416
eval/env_infos/initial/reward_ctrl Max       -0.086874
eval/env_infos/initial/reward_ctrl Min       -0.244344
eval/env_infos/reward_ctrl Mean              -0.415105
eval/env_infos/reward_ctrl Std                0.095432
eval/env_infos/reward_ctrl Max               -0.0510957
eval/env_infos/reward_ctrl Min               -0.594693
time/data storing (s)                         0.00457774
time/evaluation sampling (s)                  2.02348
time/exploration sampling (s)                 0.532623
time/logging (s)                              0.0144219
time/sac training (s)                         7.8325
time/saving (s)                               0.00390163
time/training (s)                             5.998e-05
time/epoch (s)                               10.4116
time/total (s)                              651.252
Epoch                                        60
---------------------------------------  ---------------
2021-11-24 00:40:12.911538 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 61 finished
---------------------------------------  ---------------
epoch                                        61
replay_buffer/size                        63000
trainer/num train calls                   62000
trainer/QF1 Loss                             11.3733
trainer/QF2 Loss                             10.3096
trainer/Policy Loss                        -106.657
trainer/Q1 Predictions Mean                 106.28
trainer/Q1 Predictions Std                   73.9948
trainer/Q1 Predictions Max                  194.615
trainer/Q1 Predictions Min                    3.49038
trainer/Q2 Predictions Mean                 106.405
trainer/Q2 Predictions Std                   74.1159
trainer/Q2 Predictions Max                  194.112
trainer/Q2 Predictions Min                    3.25398
trainer/Q Targets Mean                      105.799
trainer/Q Targets Std                        73.8666
trainer/Q Targets Max                       195.351
trainer/Q Targets Min                         2.38757
trainer/Log Pis Mean                          5.6116
trainer/Log Pis Std                           5.54291
trainer/Log Pis Max                          21.903
trainer/Log Pis Min                          -5.63953
trainer/policy/mean Mean                      0.0728196
trainer/policy/mean Std                       0.757612
trainer/policy/mean Max                       0.999881
trainer/policy/mean Min                      -0.999988
trainer/policy/normal/std Mean                0.475303
trainer/policy/normal/std Std                 0.137722
trainer/policy/normal/std Max                 1.14234
trainer/policy/normal/std Min                 0.11031
trainer/policy/normal/log_std Mean           -0.787035
trainer/policy/normal/log_std Std             0.299362
trainer/policy/normal/log_std Max             0.133076
trainer/policy/normal/log_std Min            -2.20446
trainer/Alpha                                 0.0445775
trainer/Alpha Loss                           -1.20811
expl/num steps total                      63000
expl/num paths total                         63
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.1876
expl/Rewards Std                              1.05719
expl/Rewards Max                              5.57174
expl/Rewards Min                             -0.568348
expl/Returns Mean                          3187.6
expl/Returns Std                              0
expl/Returns Max                           3187.6
expl/Returns Min                           3187.6
expl/Actions Mean                             0.00964188
expl/Actions Std                              0.821563
expl/Actions Max                              0.999925
expl/Actions Min                             -0.999907
expl/Num Paths                                1
expl/Average Returns                       3187.6
expl/env_infos/final/reward_run Mean          4.21551
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.21551
expl/env_infos/final/reward_run Min           4.21551
expl/env_infos/initial/reward_run Mean       -0.336082
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.336082
expl/env_infos/initial/reward_run Min        -0.336082
expl/env_infos/reward_run Mean                3.59264
expl/env_infos/reward_run Std                 1.04532
expl/env_infos/reward_run Max                 5.95879
expl/env_infos/reward_run Min                -0.336082
expl/env_infos/final/reward_ctrl Mean        -0.338495
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.338495
expl/env_infos/final/reward_ctrl Min         -0.338495
expl/env_infos/initial/reward_ctrl Mean      -0.140726
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.140726
expl/env_infos/initial/reward_ctrl Min       -0.140726
expl/env_infos/reward_ctrl Mean              -0.405035
expl/env_infos/reward_ctrl Std                0.0866432
expl/env_infos/reward_ctrl Max               -0.140726
expl/env_infos/reward_ctrl Min               -0.589613
eval/num steps total                     310000
eval/num paths total                        310
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.15369
eval/Rewards Std                              1.05395
eval/Rewards Max                              5.99516
eval/Rewards Min                             -0.99723
eval/Returns Mean                          3153.69
eval/Returns Std                            103.365
eval/Returns Max                           3297.28
eval/Returns Min                           3005.98
eval/Actions Mean                             0.012211
eval/Actions Std                              0.829057
eval/Actions Max                              0.999995
eval/Actions Min                             -0.999807
eval/Num Paths                                5
eval/Average Returns                       3153.69
eval/env_infos/final/reward_run Mean          3.56937
eval/env_infos/final/reward_run Std           0.983248
eval/env_infos/final/reward_run Max           4.98519
eval/env_infos/final/reward_run Min           2.16834
eval/env_infos/initial/reward_run Mean       -0.0424518
eval/env_infos/initial/reward_run Std         0.048669
eval/env_infos/initial/reward_run Max        -0.00880672
eval/env_infos/initial/reward_run Min        -0.139082
eval/env_infos/reward_run Mean                3.56618
eval/env_infos/reward_run Std                 1.04118
eval/env_infos/reward_run Max                 6.44604
eval/env_infos/reward_run Min                -0.454732
eval/env_infos/final/reward_ctrl Mean        -0.405324
eval/env_infos/final/reward_ctrl Std          0.0565751
eval/env_infos/final/reward_ctrl Max         -0.311727
eval/env_infos/final/reward_ctrl Min         -0.467253
eval/env_infos/initial/reward_ctrl Mean      -0.0971147
eval/env_infos/initial/reward_ctrl Std        0.0325292
eval/env_infos/initial/reward_ctrl Max       -0.0521053
eval/env_infos/initial/reward_ctrl Min       -0.135143
eval/env_infos/reward_ctrl Mean              -0.412491
eval/env_infos/reward_ctrl Std                0.089069
eval/env_infos/reward_ctrl Max               -0.0437638
eval/env_infos/reward_ctrl Min               -0.590242
time/data storing (s)                         0.00454419
time/evaluation sampling (s)                  2.01956
time/exploration sampling (s)                 0.545011
time/logging (s)                              0.0140034
time/sac training (s)                         7.70769
time/saving (s)                               0.00381561
time/training (s)                             3.4326e-05
time/epoch (s)                               10.2947
time/total (s)                              661.856
Epoch                                        61
---------------------------------------  ---------------
2021-11-24 00:40:23.482757 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 62 finished
---------------------------------------  ---------------
epoch                                        62
replay_buffer/size                        64000
trainer/num train calls                   63000
trainer/QF1 Loss                              6.27884
trainer/QF2 Loss                              5.35508
trainer/Policy Loss                        -115.233
trainer/Q1 Predictions Mean                 114.949
trainer/Q1 Predictions Std                   74.165
trainer/Q1 Predictions Max                  202.447
trainer/Q1 Predictions Min                    2.64272
trainer/Q2 Predictions Mean                 115.339
trainer/Q2 Predictions Std                   74.3508
trainer/Q2 Predictions Max                  202.285
trainer/Q2 Predictions Min                    1.7891
trainer/Q Targets Mean                      115.286
trainer/Q Targets Std                        74.3293
trainer/Q Targets Max                       204.472
trainer/Q Targets Min                         2.20238
trainer/Log Pis Mean                          6.48678
trainer/Log Pis Std                           5.82918
trainer/Log Pis Max                          24.0964
trainer/Log Pis Min                          -5.3292
trainer/policy/mean Mean                     -0.00877672
trainer/policy/mean Std                       0.778703
trainer/policy/mean Max                       0.999947
trainer/policy/mean Min                      -0.999878
trainer/policy/normal/std Mean                0.462513
trainer/policy/normal/std Std                 0.1229
trainer/policy/normal/std Max                 1.02075
trainer/policy/normal/std Min                 0.172204
trainer/policy/normal/log_std Mean           -0.807728
trainer/policy/normal/log_std Std             0.275283
trainer/policy/normal/log_std Max             0.02054
trainer/policy/normal/log_std Min            -1.75908
trainer/Alpha                                 0.0457171
trainer/Alpha Loss                            1.50187
expl/num steps total                      64000
expl/num paths total                         64
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.1971
expl/Rewards Std                              1.06847
expl/Rewards Max                              5.5824
expl/Rewards Min                             -1.06989
expl/Returns Mean                          3197.1
expl/Returns Std                              0
expl/Returns Max                           3197.1
expl/Returns Min                           3197.1
expl/Actions Mean                            -0.0274436
expl/Actions Std                              0.839614
expl/Actions Max                              0.999997
expl/Actions Min                             -0.999938
expl/Num Paths                                1
expl/Average Returns                       3197.1
expl/env_infos/final/reward_run Mean          3.74713
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.74713
expl/env_infos/final/reward_run Min           3.74713
expl/env_infos/initial/reward_run Mean       -0.0902351
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0902351
expl/env_infos/initial/reward_run Min        -0.0902351
expl/env_infos/reward_run Mean                3.62053
expl/env_infos/reward_run Std                 1.07181
expl/env_infos/reward_run Max                 5.97592
expl/env_infos/reward_run Min                -0.688708
expl/env_infos/final/reward_ctrl Mean        -0.467766
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.467766
expl/env_infos/final/reward_ctrl Min         -0.467766
expl/env_infos/initial/reward_ctrl Mean      -0.128959
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.128959
expl/env_infos/initial/reward_ctrl Min       -0.128959
expl/env_infos/reward_ctrl Mean              -0.423423
expl/env_infos/reward_ctrl Std                0.0910054
expl/env_infos/reward_ctrl Max               -0.0966504
expl/env_infos/reward_ctrl Min               -0.592042
eval/num steps total                     315000
eval/num paths total                        315
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.17827
eval/Rewards Std                              1.00851
eval/Rewards Max                              5.57558
eval/Rewards Min                             -0.644572
eval/Returns Mean                          3178.27
eval/Returns Std                             69.9737
eval/Returns Max                           3253.54
eval/Returns Min                           3053.81
eval/Actions Mean                            -0.0202418
eval/Actions Std                              0.844099
eval/Actions Max                              0.999978
eval/Actions Min                             -0.999999
eval/Num Paths                                5
eval/Average Returns                       3178.27
eval/env_infos/final/reward_run Mean          3.88899
eval/env_infos/final/reward_run Std           0.751291
eval/env_infos/final/reward_run Max           4.94884
eval/env_infos/final/reward_run Min           2.91329
eval/env_infos/initial/reward_run Mean       -0.14829
eval/env_infos/initial/reward_run Std         0.129192
eval/env_infos/initial/reward_run Max         0.0109676
eval/env_infos/initial/reward_run Min        -0.328164
eval/env_infos/reward_run Mean                3.60602
eval/env_infos/reward_run Std                 1.00398
eval/env_infos/reward_run Max                 5.99899
eval/env_infos/reward_run Min                -0.328164
eval/env_infos/final/reward_ctrl Mean        -0.41993
eval/env_infos/final/reward_ctrl Std          0.0923824
eval/env_infos/final/reward_ctrl Max         -0.316165
eval/env_infos/final/reward_ctrl Min         -0.574669
eval/env_infos/initial/reward_ctrl Mean      -0.135972
eval/env_infos/initial/reward_ctrl Std        0.0724997
eval/env_infos/initial/reward_ctrl Max       -0.0362784
eval/env_infos/initial/reward_ctrl Min       -0.219296
eval/env_infos/reward_ctrl Mean              -0.427748
eval/env_infos/reward_ctrl Std                0.0902835
eval/env_infos/reward_ctrl Max               -0.0362784
eval/env_infos/reward_ctrl Min               -0.594838
time/data storing (s)                         0.00448427
time/evaluation sampling (s)                  2.00809
time/exploration sampling (s)                 0.534217
time/logging (s)                              0.0138189
time/sac training (s)                         7.68743
time/saving (s)                               0.00379463
time/training (s)                             3.433e-05
time/epoch (s)                               10.2519
time/total (s)                              672.413
Epoch                                        62
---------------------------------------  ---------------
2021-11-24 00:40:34.074339 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 63 finished
---------------------------------------  ---------------
epoch                                        63
replay_buffer/size                        65000
trainer/num train calls                   64000
trainer/QF1 Loss                              6.67864
trainer/QF2 Loss                              5.39289
trainer/Policy Loss                        -121.921
trainer/Q1 Predictions Mean                 121.671
trainer/Q1 Predictions Std                   75.0851
trainer/Q1 Predictions Max                  208.441
trainer/Q1 Predictions Min                    2.64856
trainer/Q2 Predictions Mean                 121.911
trainer/Q2 Predictions Std                   75.2207
trainer/Q2 Predictions Max                  210.3
trainer/Q2 Predictions Min                    1.93814
trainer/Q Targets Mean                      121.898
trainer/Q Targets Std                        75.2061
trainer/Q Targets Max                       209.483
trainer/Q Targets Min                         3.02689
trainer/Log Pis Mean                          5.83804
trainer/Log Pis Std                           4.91717
trainer/Log Pis Max                          17.7921
trainer/Log Pis Min                          -4.6304
trainer/policy/mean Mean                      0.0246357
trainer/policy/mean Std                       0.76833
trainer/policy/mean Max                       0.99989
trainer/policy/mean Min                      -0.999359
trainer/policy/normal/std Mean                0.461256
trainer/policy/normal/std Std                 0.123108
trainer/policy/normal/std Max                 0.935466
trainer/policy/normal/std Min                 0.151915
trainer/policy/normal/log_std Mean           -0.810775
trainer/policy/normal/log_std Std             0.276406
trainer/policy/normal/log_std Max            -0.0667104
trainer/policy/normal/log_std Min            -1.88444
trainer/Alpha                                 0.0457414
trainer/Alpha Loss                           -0.499599
expl/num steps total                      65000
expl/num paths total                         65
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.28441
expl/Rewards Std                              0.973894
expl/Rewards Max                              5.53424
expl/Rewards Min                             -0.424786
expl/Returns Mean                          3284.41
expl/Returns Std                              0
expl/Returns Max                           3284.41
expl/Returns Min                           3284.41
expl/Actions Mean                            -0.00188518
expl/Actions Std                              0.82877
expl/Actions Max                              0.999989
expl/Actions Min                             -0.999824
expl/Num Paths                                1
expl/Average Returns                       3284.41
expl/env_infos/final/reward_run Mean          2.84899
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.84899
expl/env_infos/final/reward_run Min           2.84899
expl/env_infos/initial/reward_run Mean       -0.246335
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.246335
expl/env_infos/initial/reward_run Min        -0.246335
expl/env_infos/reward_run Mean                3.69653
expl/env_infos/reward_run Std                 0.979956
expl/env_infos/reward_run Max                 6.02615
expl/env_infos/reward_run Min                -0.246335
expl/env_infos/final/reward_ctrl Mean        -0.198642
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.198642
expl/env_infos/final/reward_ctrl Min         -0.198642
expl/env_infos/initial/reward_ctrl Mean      -0.0845956
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0845956
expl/env_infos/initial/reward_ctrl Min       -0.0845956
expl/env_infos/reward_ctrl Mean              -0.412118
expl/env_infos/reward_ctrl Std                0.0903061
expl/env_infos/reward_ctrl Max               -0.0845956
expl/env_infos/reward_ctrl Min               -0.595877
eval/num steps total                     320000
eval/num paths total                        320
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             2.54496
eval/Rewards Std                              1.63343
eval/Rewards Max                              6.19653
eval/Rewards Min                             -1.60453
eval/Returns Mean                          2544.96
eval/Returns Std                           1093.87
eval/Returns Max                           3517.39
eval/Returns Min                           1035.3
eval/Actions Mean                             0.0177536
eval/Actions Std                              0.804069
eval/Actions Max                              0.999985
eval/Actions Min                             -0.999737
eval/Num Paths                                5
eval/Average Returns                       2544.96
eval/env_infos/final/reward_run Mean          2.78376
eval/env_infos/final/reward_run Std           2.39774
eval/env_infos/final/reward_run Max           5.08276
eval/env_infos/final/reward_run Min          -0.515852
eval/env_infos/initial/reward_run Mean       -0.204499
eval/env_infos/initial/reward_run Std         0.110628
eval/env_infos/initial/reward_run Max        -0.0576795
eval/env_infos/initial/reward_run Min        -0.371044
eval/env_infos/reward_run Mean                2.93307
eval/env_infos/reward_run Std                 1.66974
eval/env_infos/reward_run Max                 6.65566
eval/env_infos/reward_run Min                -1.22587
eval/env_infos/final/reward_ctrl Mean        -0.450482
eval/env_infos/final/reward_ctrl Std          0.0567671
eval/env_infos/final/reward_ctrl Max         -0.376818
eval/env_infos/final/reward_ctrl Min         -0.545024
eval/env_infos/initial/reward_ctrl Mean      -0.102776
eval/env_infos/initial/reward_ctrl Std        0.0209918
eval/env_infos/initial/reward_ctrl Max       -0.0658877
eval/env_infos/initial/reward_ctrl Min       -0.123417
eval/env_infos/reward_ctrl Mean              -0.388105
eval/env_infos/reward_ctrl Std                0.0962441
eval/env_infos/reward_ctrl Max               -0.0658877
eval/env_infos/reward_ctrl Min               -0.594767
time/data storing (s)                         0.00453759
time/evaluation sampling (s)                  2.01984
time/exploration sampling (s)                 0.531203
time/logging (s)                              0.0140603
time/sac training (s)                         7.69571
time/saving (s)                               0.00384613
time/training (s)                             4.3563e-05
time/epoch (s)                               10.2692
time/total (s)                              682.99
Epoch                                        63
---------------------------------------  ---------------
2021-11-24 00:40:44.743471 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 64 finished
---------------------------------------  ---------------
epoch                                        64
replay_buffer/size                        66000
trainer/num train calls                   65000
trainer/QF1 Loss                              7.14036
trainer/QF2 Loss                              5.93378
trainer/Policy Loss                        -121.356
trainer/Q1 Predictions Mean                 121.376
trainer/Q1 Predictions Std                   75.9789
trainer/Q1 Predictions Max                  212.951
trainer/Q1 Predictions Min                    3.68044
trainer/Q2 Predictions Mean                 121.38
trainer/Q2 Predictions Std                   75.9648
trainer/Q2 Predictions Max                  209.59
trainer/Q2 Predictions Min                    2.91877
trainer/Q Targets Mean                      121.684
trainer/Q Targets Std                        76.1871
trainer/Q Targets Max                       212.769
trainer/Q Targets Min                         3.17637
trainer/Log Pis Mean                          5.96576
trainer/Log Pis Std                           5.30257
trainer/Log Pis Max                          23.7497
trainer/Log Pis Min                          -5.58206
trainer/policy/mean Mean                      0.0234922
trainer/policy/mean Std                       0.76504
trainer/policy/mean Max                       0.999971
trainer/policy/mean Min                      -0.999426
trainer/policy/normal/std Mean                0.459487
trainer/policy/normal/std Std                 0.121078
trainer/policy/normal/std Max                 0.926722
trainer/policy/normal/std Min                 0.190968
trainer/policy/normal/log_std Mean           -0.813836
trainer/policy/normal/log_std Std             0.273692
trainer/policy/normal/log_std Max            -0.0761021
trainer/policy/normal/log_std Min            -1.65565
trainer/Alpha                                 0.0465953
trainer/Alpha Loss                           -0.105002
expl/num steps total                      66000
expl/num paths total                         66
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.2456
expl/Rewards Std                              1.01025
expl/Rewards Max                              5.75597
expl/Rewards Min                             -0.423543
expl/Returns Mean                          3245.6
expl/Returns Std                              0
expl/Returns Max                           3245.6
expl/Returns Min                           3245.6
expl/Actions Mean                             0.00953751
expl/Actions Std                              0.836936
expl/Actions Max                              0.999999
expl/Actions Min                             -0.999908
expl/Num Paths                                1
expl/Average Returns                       3245.6
expl/env_infos/final/reward_run Mean          2.38512
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.38512
expl/env_infos/final/reward_run Min           2.38512
expl/env_infos/initial/reward_run Mean       -0.152415
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.152415
expl/env_infos/initial/reward_run Min        -0.152415
expl/env_infos/reward_run Mean                3.66593
expl/env_infos/reward_run Std                 1.02358
expl/env_infos/reward_run Max                 6.17477
expl/env_infos/reward_run Min                -0.152415
expl/env_infos/final/reward_ctrl Mean        -0.396382
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.396382
expl/env_infos/final/reward_ctrl Min         -0.396382
expl/env_infos/initial/reward_ctrl Mean      -0.0693151
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0693151
expl/env_infos/initial/reward_ctrl Min       -0.0693151
expl/env_infos/reward_ctrl Mean              -0.420332
expl/env_infos/reward_ctrl Std                0.0833766
expl/env_infos/reward_ctrl Max               -0.0693151
expl/env_infos/reward_ctrl Min               -0.593047
eval/num steps total                     325000
eval/num paths total                        325
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.25019
eval/Rewards Std                              1.08437
eval/Rewards Max                              5.81535
eval/Rewards Min                             -0.98581
eval/Returns Mean                          3250.19
eval/Returns Std                            184.172
eval/Returns Max                           3465.54
eval/Returns Min                           2921.07
eval/Actions Mean                            -0.00862731
eval/Actions Std                              0.839654
eval/Actions Max                              0.999966
eval/Actions Min                             -0.999796
eval/Num Paths                                5
eval/Average Returns                       3250.19
eval/env_infos/final/reward_run Mean          3.91184
eval/env_infos/final/reward_run Std           1.21501
eval/env_infos/final/reward_run Max           5.11442
eval/env_infos/final/reward_run Min           2.40355
eval/env_infos/initial/reward_run Mean        0.00746649
eval/env_infos/initial/reward_run Std         0.128651
eval/env_infos/initial/reward_run Max         0.23234
eval/env_infos/initial/reward_run Min        -0.135822
eval/env_infos/reward_run Mean                3.67324
eval/env_infos/reward_run Std                 1.10031
eval/env_infos/reward_run Max                 6.29021
eval/env_infos/reward_run Min                -0.737702
eval/env_infos/final/reward_ctrl Mean        -0.411048
eval/env_infos/final/reward_ctrl Std          0.0775407
eval/env_infos/final/reward_ctrl Max         -0.293078
eval/env_infos/final/reward_ctrl Min         -0.491931
eval/env_infos/initial/reward_ctrl Mean      -0.108128
eval/env_infos/initial/reward_ctrl Std        0.0504905
eval/env_infos/initial/reward_ctrl Max       -0.0493541
eval/env_infos/initial/reward_ctrl Min       -0.169231
eval/env_infos/reward_ctrl Mean              -0.423056
eval/env_infos/reward_ctrl Std                0.0844723
eval/env_infos/reward_ctrl Max               -0.0493541
eval/env_infos/reward_ctrl Min               -0.592718
time/data storing (s)                         0.0045209
time/evaluation sampling (s)                  2.02369
time/exploration sampling (s)                 0.53343
time/logging (s)                              0.0139111
time/sac training (s)                         7.7594
time/saving (s)                               0.00432511
time/training (s)                             4.4445e-05
time/epoch (s)                               10.3393
time/total (s)                              693.644
Epoch                                        64
---------------------------------------  ---------------
2021-11-24 00:40:55.355522 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 65 finished
---------------------------------------  ---------------
epoch                                        65
replay_buffer/size                        67000
trainer/num train calls                   66000
trainer/QF1 Loss                              8.44032
trainer/QF2 Loss                              6.91125
trainer/Policy Loss                        -123.164
trainer/Q1 Predictions Mean                 122.887
trainer/Q1 Predictions Std                   77.2248
trainer/Q1 Predictions Max                  212.211
trainer/Q1 Predictions Min                    1.46344
trainer/Q2 Predictions Mean                 123.195
trainer/Q2 Predictions Std                   77.3488
trainer/Q2 Predictions Max                  211.889
trainer/Q2 Predictions Min                    3.70478
trainer/Q Targets Mean                      123.546
trainer/Q Targets Std                        77.5211
trainer/Q Targets Max                       214.6
trainer/Q Targets Min                         2.09954
trainer/Log Pis Mean                          6.39656
trainer/Log Pis Std                           5.56907
trainer/Log Pis Max                          22.8753
trainer/Log Pis Min                          -5.8292
trainer/policy/mean Mean                      0.0278954
trainer/policy/mean Std                       0.769842
trainer/policy/mean Max                       0.999897
trainer/policy/mean Min                      -0.999996
trainer/policy/normal/std Mean                0.462893
trainer/policy/normal/std Std                 0.135913
trainer/policy/normal/std Max                 1.29647
trainer/policy/normal/std Min                 0.157756
trainer/policy/normal/log_std Mean           -0.814854
trainer/policy/normal/log_std Std             0.304004
trainer/policy/normal/log_std Max             0.259646
trainer/policy/normal/log_std Min            -1.8467
trainer/Alpha                                 0.0476716
trainer/Alpha Loss                            1.20689
expl/num steps total                      67000
expl/num paths total                         67
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.08849
expl/Rewards Std                              1.08472
expl/Rewards Max                              5.37228
expl/Rewards Min                             -1.59254
expl/Returns Mean                          3088.49
expl/Returns Std                              0
expl/Returns Max                           3088.49
expl/Returns Min                           3088.49
expl/Actions Mean                             0.0207564
expl/Actions Std                              0.834719
expl/Actions Max                              0.999924
expl/Actions Min                             -0.999911
expl/Num Paths                                1
expl/Average Returns                       3088.49
expl/env_infos/final/reward_run Mean          2.93347
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.93347
expl/env_infos/final/reward_run Min           2.93347
expl/env_infos/initial/reward_run Mean       -0.237654
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.237654
expl/env_infos/initial/reward_run Min        -0.237654
expl/env_infos/reward_run Mean                3.5068
expl/env_infos/reward_run Std                 1.0845
expl/env_infos/reward_run Max                 5.86875
expl/env_infos/reward_run Min                -1.09728
expl/env_infos/final/reward_ctrl Mean        -0.330917
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.330917
expl/env_infos/final/reward_ctrl Min         -0.330917
expl/env_infos/initial/reward_ctrl Mean      -0.154421
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.154421
expl/env_infos/initial/reward_ctrl Min       -0.154421
expl/env_infos/reward_ctrl Mean              -0.418312
expl/env_infos/reward_ctrl Std                0.0855012
expl/env_infos/reward_ctrl Max               -0.118802
expl/env_infos/reward_ctrl Min               -0.596067
eval/num steps total                     330000
eval/num paths total                        330
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.08997
eval/Rewards Std                              1.43258
eval/Rewards Max                              6.13736
eval/Rewards Min                             -1.35055
eval/Returns Mean                          3089.97
eval/Returns Std                            837.105
eval/Returns Max                           3659.75
eval/Returns Min                           1426.24
eval/Actions Mean                             0.0252064
eval/Actions Std                              0.831003
eval/Actions Max                              0.999949
eval/Actions Min                             -0.999782
eval/Num Paths                                5
eval/Average Returns                       3089.97
eval/env_infos/final/reward_run Mean          3.75323
eval/env_infos/final/reward_run Std           1.62587
eval/env_infos/final/reward_run Max           5.79951
eval/env_infos/final/reward_run Min           0.870784
eval/env_infos/initial/reward_run Mean       -0.132672
eval/env_infos/initial/reward_run Std         0.101728
eval/env_infos/initial/reward_run Max         0.0113423
eval/env_infos/initial/reward_run Min        -0.286235
eval/env_infos/reward_run Mean                3.50469
eval/env_infos/reward_run Std                 1.46114
eval/env_infos/reward_run Max                 6.5779
eval/env_infos/reward_run Min                -1.00754
eval/env_infos/final/reward_ctrl Mean        -0.356237
eval/env_infos/final/reward_ctrl Std          0.0910359
eval/env_infos/final/reward_ctrl Max         -0.207006
eval/env_infos/final/reward_ctrl Min         -0.437252
eval/env_infos/initial/reward_ctrl Mean      -0.118217
eval/env_infos/initial/reward_ctrl Std        0.0257861
eval/env_infos/initial/reward_ctrl Max       -0.092079
eval/env_infos/initial/reward_ctrl Min       -0.166797
eval/env_infos/reward_ctrl Mean              -0.414721
eval/env_infos/reward_ctrl Std                0.0947704
eval/env_infos/reward_ctrl Max               -0.0820472
eval/env_infos/reward_ctrl Min               -0.592556
time/data storing (s)                         0.00454041
time/evaluation sampling (s)                  2.01253
time/exploration sampling (s)                 0.535464
time/logging (s)                              0.0140806
time/sac training (s)                         7.71644
time/saving (s)                               0.00378062
time/training (s)                             3.4221e-05
time/epoch (s)                               10.2869
time/total (s)                              704.242
Epoch                                        65
---------------------------------------  ---------------
2021-11-24 00:41:05.937282 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 66 finished
---------------------------------------  ---------------
epoch                                        66
replay_buffer/size                        68000
trainer/num train calls                   67000
trainer/QF1 Loss                              7.4405
trainer/QF2 Loss                              7.32294
trainer/Policy Loss                        -125.985
trainer/Q1 Predictions Mean                 125.81
trainer/Q1 Predictions Std                   80.6962
trainer/Q1 Predictions Max                  217.09
trainer/Q1 Predictions Min                    3.22973
trainer/Q2 Predictions Mean                 125.632
trainer/Q2 Predictions Std                   80.6526
trainer/Q2 Predictions Max                  217.039
trainer/Q2 Predictions Min                    2.35108
trainer/Q Targets Mean                      125.881
trainer/Q Targets Std                        80.8785
trainer/Q Targets Max                       218.332
trainer/Q Targets Min                         2.56856
trainer/Log Pis Mean                          6.12083
trainer/Log Pis Std                           5.36253
trainer/Log Pis Max                          22.3794
trainer/Log Pis Min                          -5.85349
trainer/policy/mean Mean                      0.0270839
trainer/policy/mean Std                       0.778407
trainer/policy/mean Max                       0.999851
trainer/policy/mean Min                      -0.999619
trainer/policy/normal/std Mean                0.46929
trainer/policy/normal/std Std                 0.122363
trainer/policy/normal/std Max                 0.904893
trainer/policy/normal/std Min                 0.131635
trainer/policy/normal/log_std Mean           -0.792908
trainer/policy/normal/log_std Std             0.276385
trainer/policy/normal/log_std Max            -0.0999389
trainer/policy/normal/log_std Min            -2.02772
trainer/Alpha                                 0.0480421
trainer/Alpha Loss                            0.3668
expl/num steps total                      68000
expl/num paths total                         68
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.29148
expl/Rewards Std                              1.2019
expl/Rewards Max                              5.8917
expl/Rewards Min                             -0.743716
expl/Returns Mean                          3291.48
expl/Returns Std                              0
expl/Returns Max                           3291.48
expl/Returns Min                           3291.48
expl/Actions Mean                             0.0049527
expl/Actions Std                              0.829287
expl/Actions Max                              0.999994
expl/Actions Min                             -0.999805
expl/Num Paths                                1
expl/Average Returns                       3291.48
expl/env_infos/final/reward_run Mean          3.12893
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.12893
expl/env_infos/final/reward_run Min           3.12893
expl/env_infos/initial/reward_run Mean       -0.0212531
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0212531
expl/env_infos/initial/reward_run Min        -0.0212531
expl/env_infos/reward_run Mean                3.70412
expl/env_infos/reward_run Std                 1.20785
expl/env_infos/reward_run Max                 6.36017
expl/env_infos/reward_run Min                -0.26598
expl/env_infos/final/reward_ctrl Mean        -0.553373
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.553373
expl/env_infos/final/reward_ctrl Min         -0.553373
expl/env_infos/initial/reward_ctrl Mean      -0.108516
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.108516
expl/env_infos/initial/reward_ctrl Min       -0.108516
expl/env_infos/reward_ctrl Mean              -0.412645
expl/env_infos/reward_ctrl Std                0.0852689
expl/env_infos/reward_ctrl Max               -0.067935
expl/env_infos/reward_ctrl Min               -0.595879
eval/num steps total                     335000
eval/num paths total                        335
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.53617
eval/Rewards Std                              1.09178
eval/Rewards Max                              6.15334
eval/Rewards Min                             -0.960404
eval/Returns Mean                          3536.17
eval/Returns Std                            103.681
eval/Returns Max                           3663.24
eval/Returns Min                           3359.11
eval/Actions Mean                             0.0144697
eval/Actions Std                              0.844153
eval/Actions Max                              0.999995
eval/Actions Min                             -0.999772
eval/Num Paths                                5
eval/Average Returns                       3536.17
eval/env_infos/final/reward_run Mean          3.26135
eval/env_infos/final/reward_run Std           0.803969
eval/env_infos/final/reward_run Max           4.40593
eval/env_infos/final/reward_run Min           2.12114
eval/env_infos/initial/reward_run Mean        0.0232693
eval/env_infos/initial/reward_run Std         0.108299
eval/env_infos/initial/reward_run Max         0.160096
eval/env_infos/initial/reward_run Min        -0.144037
eval/env_infos/reward_run Mean                3.96386
eval/env_infos/reward_run Std                 1.09494
eval/env_infos/reward_run Max                 6.664
eval/env_infos/reward_run Min                -0.425921
eval/env_infos/final/reward_ctrl Mean        -0.365129
eval/env_infos/final/reward_ctrl Std          0.0775821
eval/env_infos/final/reward_ctrl Max         -0.283474
eval/env_infos/final/reward_ctrl Min         -0.485807
eval/env_infos/initial/reward_ctrl Mean      -0.125751
eval/env_infos/initial/reward_ctrl Std        0.0376554
eval/env_infos/initial/reward_ctrl Max       -0.0617467
eval/env_infos/initial/reward_ctrl Min       -0.180077
eval/env_infos/reward_ctrl Mean              -0.427683
eval/env_infos/reward_ctrl Std                0.0851727
eval/env_infos/reward_ctrl Max               -0.0617467
eval/env_infos/reward_ctrl Min               -0.590712
time/data storing (s)                         0.00453698
time/evaluation sampling (s)                  2.01598
time/exploration sampling (s)                 0.531204
time/logging (s)                              0.014494
time/sac training (s)                         7.68725
time/saving (s)                               0.00386987
time/training (s)                             3.9722e-05
time/epoch (s)                               10.2574
time/total (s)                              714.81
Epoch                                        66
---------------------------------------  ---------------
2021-11-24 00:41:16.568111 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 67 finished
---------------------------------------  ---------------
epoch                                        67
replay_buffer/size                        69000
trainer/num train calls                   68000
trainer/QF1 Loss                              7.74576
trainer/QF2 Loss                              6.26176
trainer/Policy Loss                        -125.511
trainer/Q1 Predictions Mean                 125.693
trainer/Q1 Predictions Std                   81.0159
trainer/Q1 Predictions Max                  217.035
trainer/Q1 Predictions Min                    2.23646
trainer/Q2 Predictions Mean                 125.59
trainer/Q2 Predictions Std                   80.9481
trainer/Q2 Predictions Max                  215.812
trainer/Q2 Predictions Min                    2.33115
trainer/Q Targets Mean                      125.702
trainer/Q Targets Std                        81.003
trainer/Q Targets Max                       217.333
trainer/Q Targets Min                         1.87881
trainer/Log Pis Mean                          5.79716
trainer/Log Pis Std                           5.02419
trainer/Log Pis Max                          20.207
trainer/Log Pis Min                          -6.03128
trainer/policy/mean Mean                      0.0444953
trainer/policy/mean Std                       0.756115
trainer/policy/mean Max                       0.999516
trainer/policy/mean Min                      -0.999592
trainer/policy/normal/std Mean                0.46705
trainer/policy/normal/std Std                 0.128812
trainer/policy/normal/std Max                 1.13626
trainer/policy/normal/std Min                 0.146988
trainer/policy/normal/log_std Mean           -0.80096
trainer/policy/normal/log_std Std             0.28721
trainer/policy/normal/log_std Max             0.127744
trainer/policy/normal/log_std Min            -1.9174
trainer/Alpha                                 0.0487508
trainer/Alpha Loss                           -0.612771
expl/num steps total                      69000
expl/num paths total                         69
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.36555
expl/Rewards Std                              0.973103
expl/Rewards Max                              5.64249
expl/Rewards Min                             -0.444591
expl/Returns Mean                          3365.55
expl/Returns Std                              0
expl/Returns Max                           3365.55
expl/Returns Min                           3365.55
expl/Actions Mean                             0.0158595
expl/Actions Std                              0.833648
expl/Actions Max                              0.999969
expl/Actions Min                             -0.999919
expl/Num Paths                                1
expl/Average Returns                       3365.55
expl/env_infos/final/reward_run Mean          3.83538
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.83538
expl/env_infos/final/reward_run Min           3.83538
expl/env_infos/initial/reward_run Mean        0.030049
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.030049
expl/env_infos/initial/reward_run Min         0.030049
expl/env_infos/reward_run Mean                3.78269
expl/env_infos/reward_run Std                 0.968191
expl/env_infos/reward_run Max                 6.11669
expl/env_infos/reward_run Min                -0.0923097
expl/env_infos/final/reward_ctrl Mean        -0.476611
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.476611
expl/env_infos/final/reward_ctrl Min         -0.476611
expl/env_infos/initial/reward_ctrl Mean      -0.146303
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.146303
expl/env_infos/initial/reward_ctrl Min       -0.146303
expl/env_infos/reward_ctrl Mean              -0.417132
expl/env_infos/reward_ctrl Std                0.0855943
expl/env_infos/reward_ctrl Max               -0.120969
expl/env_infos/reward_ctrl Min               -0.595291
eval/num steps total                     340000
eval/num paths total                        340
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.44931
eval/Rewards Std                              1.08409
eval/Rewards Max                              6.05928
eval/Rewards Min                             -0.747639
eval/Returns Mean                          3449.31
eval/Returns Std                             34.1707
eval/Returns Max                           3494.38
eval/Returns Min                           3396.78
eval/Actions Mean                             0.0164011
eval/Actions Std                              0.839283
eval/Actions Max                              0.999969
eval/Actions Min                             -0.999592
eval/Num Paths                                5
eval/Average Returns                       3449.31
eval/env_infos/final/reward_run Mean          4.01654
eval/env_infos/final/reward_run Std           0.871712
eval/env_infos/final/reward_run Max           5.35086
eval/env_infos/final/reward_run Min           3.0004
eval/env_infos/initial/reward_run Mean        0.0277342
eval/env_infos/initial/reward_run Std         0.116809
eval/env_infos/initial/reward_run Max         0.231031
eval/env_infos/initial/reward_run Min        -0.0829655
eval/env_infos/reward_run Mean                3.8721
eval/env_infos/reward_run Std                 1.08574
eval/env_infos/reward_run Max                 6.54484
eval/env_infos/reward_run Min                -0.395636
eval/env_infos/final/reward_ctrl Mean        -0.508934
eval/env_infos/final/reward_ctrl Std          0.0593982
eval/env_infos/final/reward_ctrl Max         -0.421953
eval/env_infos/final/reward_ctrl Min         -0.576569
eval/env_infos/initial/reward_ctrl Mean      -0.0568262
eval/env_infos/initial/reward_ctrl Std        0.0179459
eval/env_infos/initial/reward_ctrl Max       -0.0377396
eval/env_infos/initial/reward_ctrl Min       -0.0874886
eval/env_infos/reward_ctrl Mean              -0.422799
eval/env_infos/reward_ctrl Std                0.0872538
eval/env_infos/reward_ctrl Max               -0.0377396
eval/env_infos/reward_ctrl Min               -0.592341
time/data storing (s)                         0.0044862
time/evaluation sampling (s)                  2.0389
time/exploration sampling (s)                 0.531846
time/logging (s)                              0.0139811
time/sac training (s)                         7.7118
time/saving (s)                               0.00426289
time/training (s)                             5.1732e-05
time/epoch (s)                               10.3053
time/total (s)                              725.425
Epoch                                        67
---------------------------------------  ---------------
2021-11-24 00:41:27.180303 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 68 finished
---------------------------------------  ---------------
epoch                                        68
replay_buffer/size                        70000
trainer/num train calls                   69000
trainer/QF1 Loss                             11.5962
trainer/QF2 Loss                             11.4344
trainer/Policy Loss                        -138.155
trainer/Q1 Predictions Mean                 138.246
trainer/Q1 Predictions Std                   77.3243
trainer/Q1 Predictions Max                  219.799
trainer/Q1 Predictions Min                    3.41811
trainer/Q2 Predictions Mean                 138.179
trainer/Q2 Predictions Std                   77.2874
trainer/Q2 Predictions Max                  220.656
trainer/Q2 Predictions Min                    3.77003
trainer/Q Targets Mean                      137.978
trainer/Q Targets Std                        77.2826
trainer/Q Targets Max                       219.904
trainer/Q Targets Min                         2.94862
trainer/Log Pis Mean                          6.37952
trainer/Log Pis Std                           5.10629
trainer/Log Pis Max                          20.7817
trainer/Log Pis Min                          -7.81669
trainer/policy/mean Mean                      0.0497173
trainer/policy/mean Std                       0.771346
trainer/policy/mean Max                       0.999877
trainer/policy/mean Min                      -0.99972
trainer/policy/normal/std Mean                0.464268
trainer/policy/normal/std Std                 0.11984
trainer/policy/normal/std Max                 0.970661
trainer/policy/normal/std Min                 0.177363
trainer/policy/normal/log_std Mean           -0.801773
trainer/policy/normal/log_std Std             0.26639
trainer/policy/normal/log_std Max            -0.0297781
trainer/policy/normal/log_std Min            -1.72955
trainer/Alpha                                 0.0494954
trainer/Alpha Loss                            1.14078
expl/num steps total                      70000
expl/num paths total                         70
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.4493
expl/Rewards Std                              1.10467
expl/Rewards Max                              5.79024
expl/Rewards Min                             -0.270357
expl/Returns Mean                          3449.3
expl/Returns Std                              0
expl/Returns Max                           3449.3
expl/Returns Min                           3449.3
expl/Actions Mean                            -0.00251606
expl/Actions Std                              0.829039
expl/Actions Max                              0.999876
expl/Actions Min                             -0.999961
expl/Num Paths                                1
expl/Average Returns                       3449.3
expl/env_infos/final/reward_run Mean          4.00084
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.00084
expl/env_infos/final/reward_run Min           4.00084
expl/env_infos/initial/reward_run Mean       -0.0659125
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0659125
expl/env_infos/initial/reward_run Min        -0.0659125
expl/env_infos/reward_run Mean                3.86169
expl/env_infos/reward_run Std                 1.11139
expl/env_infos/reward_run Max                 6.2946
expl/env_infos/reward_run Min                -0.0659125
expl/env_infos/final/reward_ctrl Mean        -0.331244
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.331244
expl/env_infos/final/reward_ctrl Min         -0.331244
expl/env_infos/initial/reward_ctrl Mean      -0.0289777
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0289777
expl/env_infos/initial/reward_ctrl Min       -0.0289777
expl/env_infos/reward_ctrl Mean              -0.412387
expl/env_infos/reward_ctrl Std                0.0845058
expl/env_infos/reward_ctrl Max               -0.0289777
expl/env_infos/reward_ctrl Min               -0.587694
eval/num steps total                     345000
eval/num paths total                        345
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.71593
eval/Rewards Std                              1.16904
eval/Rewards Max                              6.2426
eval/Rewards Min                             -1.56474
eval/Returns Mean                          3715.93
eval/Returns Std                             87.276
eval/Returns Max                           3833.85
eval/Returns Min                           3600.47
eval/Actions Mean                             0.00713026
eval/Actions Std                              0.845481
eval/Actions Max                              0.999979
eval/Actions Min                             -0.999568
eval/Num Paths                                5
eval/Average Returns                       3715.93
eval/env_infos/final/reward_run Mean          4.00781
eval/env_infos/final/reward_run Std           0.822831
eval/env_infos/final/reward_run Max           5.15202
eval/env_infos/final/reward_run Min           2.90492
eval/env_infos/initial/reward_run Mean       -0.167341
eval/env_infos/initial/reward_run Std         0.101693
eval/env_infos/initial/reward_run Max        -0.0143488
eval/env_infos/initial/reward_run Min        -0.282629
eval/env_infos/reward_run Mean                4.14486
eval/env_infos/reward_run Std                 1.17098
eval/env_infos/reward_run Max                 6.77796
eval/env_infos/reward_run Min                -1.14713
eval/env_infos/final/reward_ctrl Mean        -0.363857
eval/env_infos/final/reward_ctrl Std          0.0658819
eval/env_infos/final/reward_ctrl Max         -0.273841
eval/env_infos/final/reward_ctrl Min         -0.462058
eval/env_infos/initial/reward_ctrl Mean      -0.124506
eval/env_infos/initial/reward_ctrl Std        0.02573
eval/env_infos/initial/reward_ctrl Max       -0.0905973
eval/env_infos/initial/reward_ctrl Min       -0.155416
eval/env_infos/reward_ctrl Mean              -0.428934
eval/env_infos/reward_ctrl Std                0.0815864
eval/env_infos/reward_ctrl Max               -0.0905973
eval/env_infos/reward_ctrl Min               -0.59082
time/data storing (s)                         0.00448114
time/evaluation sampling (s)                  2.03411
time/exploration sampling (s)                 0.534216
time/logging (s)                              0.0137637
time/sac training (s)                         7.69692
time/saving (s)                               0.00380168
time/training (s)                             3.4517e-05
time/epoch (s)                               10.2873
time/total (s)                              736.022
Epoch                                        68
---------------------------------------  ---------------
2021-11-24 00:41:37.821159 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 69 finished
---------------------------------------  ---------------
epoch                                        69
replay_buffer/size                        71000
trainer/num train calls                   70000
trainer/QF1 Loss                              5.64598
trainer/QF2 Loss                              5.49008
trainer/Policy Loss                        -129.074
trainer/Q1 Predictions Mean                 129
trainer/Q1 Predictions Std                   83.1941
trainer/Q1 Predictions Max                  222.677
trainer/Q1 Predictions Min                    2.71263
trainer/Q2 Predictions Mean                 129.014
trainer/Q2 Predictions Std                   83.1507
trainer/Q2 Predictions Max                  221.653
trainer/Q2 Predictions Min                    2.90906
trainer/Q Targets Mean                      129.416
trainer/Q Targets Std                        83.3492
trainer/Q Targets Max                       222.176
trainer/Q Targets Min                         2.32867
trainer/Log Pis Mean                          5.66092
trainer/Log Pis Std                           4.9304
trainer/Log Pis Max                          22.1637
trainer/Log Pis Min                          -4.40575
trainer/policy/mean Mean                      0.0559111
trainer/policy/mean Std                       0.756535
trainer/policy/mean Max                       0.9998
trainer/policy/mean Min                      -0.999739
trainer/policy/normal/std Mean                0.460591
trainer/policy/normal/std Std                 0.125941
trainer/policy/normal/std Max                 0.844846
trainer/policy/normal/std Min                 0.171769
trainer/policy/normal/log_std Mean           -0.814584
trainer/policy/normal/log_std Std             0.285746
trainer/policy/normal/log_std Max            -0.1686
trainer/policy/normal/log_std Min            -1.7616
trainer/Alpha                                 0.0499349
trainer/Alpha Loss                           -1.01624
expl/num steps total                      71000
expl/num paths total                         71
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.22864
expl/Rewards Std                              1.11309
expl/Rewards Max                              5.76507
expl/Rewards Min                             -0.828917
expl/Returns Mean                          3228.64
expl/Returns Std                              0
expl/Returns Max                           3228.64
expl/Returns Min                           3228.64
expl/Actions Mean                             0.0031136
expl/Actions Std                              0.828326
expl/Actions Max                              0.999984
expl/Actions Min                             -0.999798
expl/Num Paths                                1
expl/Average Returns                       3228.64
expl/env_infos/final/reward_run Mean          2.70979
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.70979
expl/env_infos/final/reward_run Min           2.70979
expl/env_infos/initial/reward_run Mean       -0.01762
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.01762
expl/env_infos/initial/reward_run Min        -0.01762
expl/env_infos/reward_run Mean                3.64033
expl/env_infos/reward_run Std                 1.11968
expl/env_infos/reward_run Max                 6.24912
expl/env_infos/reward_run Min                -0.338288
expl/env_infos/final/reward_ctrl Mean        -0.499348
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.499348
expl/env_infos/final/reward_ctrl Min         -0.499348
expl/env_infos/initial/reward_ctrl Mean      -0.0153899
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0153899
expl/env_infos/initial/reward_ctrl Min       -0.0153899
expl/env_infos/reward_ctrl Mean              -0.411681
expl/env_infos/reward_ctrl Std                0.086572
expl/env_infos/reward_ctrl Max               -0.0153899
expl/env_infos/reward_ctrl Min               -0.586968
eval/num steps total                     350000
eval/num paths total                        350
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.70205
eval/Rewards Std                              1.07837
eval/Rewards Max                              6.22454
eval/Rewards Min                             -0.925855
eval/Returns Mean                          3702.05
eval/Returns Std                             99.268
eval/Returns Max                           3867.27
eval/Returns Min                           3563.5
eval/Actions Mean                             0.0120813
eval/Actions Std                              0.847138
eval/Actions Max                              0.999917
eval/Actions Min                             -0.999634
eval/Num Paths                                5
eval/Average Returns                       3702.05
eval/env_infos/final/reward_run Mean          3.59658
eval/env_infos/final/reward_run Std           1.65349
eval/env_infos/final/reward_run Max           5.94624
eval/env_infos/final/reward_run Min           0.904962
eval/env_infos/initial/reward_run Mean        0.0345044
eval/env_infos/initial/reward_run Std         0.165862
eval/env_infos/initial/reward_run Max         0.333385
eval/env_infos/initial/reward_run Min        -0.132769
eval/env_infos/reward_run Mean                4.13272
eval/env_infos/reward_run Std                 1.08207
eval/env_infos/reward_run Max                 6.70181
eval/env_infos/reward_run Min                -0.420393
eval/env_infos/final/reward_ctrl Mean        -0.404293
eval/env_infos/final/reward_ctrl Std          0.0792481
eval/env_infos/final/reward_ctrl Max         -0.294263
eval/env_infos/final/reward_ctrl Min         -0.531936
eval/env_infos/initial/reward_ctrl Mean      -0.0664686
eval/env_infos/initial/reward_ctrl Std        0.022567
eval/env_infos/initial/reward_ctrl Max       -0.0331429
eval/env_infos/initial/reward_ctrl Min       -0.0958986
eval/env_infos/reward_ctrl Mean              -0.430674
eval/env_infos/reward_ctrl Std                0.0808563
eval/env_infos/reward_ctrl Max               -0.0331429
eval/env_infos/reward_ctrl Min               -0.590709
time/data storing (s)                         0.00451309
time/evaluation sampling (s)                  2.03624
time/exploration sampling (s)                 0.537614
time/logging (s)                              0.0144064
time/sac training (s)                         7.72066
time/saving (s)                               0.00389451
time/training (s)                             3.758e-05
time/epoch (s)                               10.3174
time/total (s)                              746.649
Epoch                                        69
---------------------------------------  ---------------
2021-11-24 00:41:48.432050 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 70 finished
---------------------------------------  ---------------
epoch                                        70
replay_buffer/size                        72000
trainer/num train calls                   71000
trainer/QF1 Loss                              5.26912
trainer/QF2 Loss                              4.54968
trainer/Policy Loss                        -130.617
trainer/Q1 Predictions Mean                 130.478
trainer/Q1 Predictions Std                   83.6343
trainer/Q1 Predictions Max                  231.051
trainer/Q1 Predictions Min                    3.8013
trainer/Q2 Predictions Mean                 130.591
trainer/Q2 Predictions Std                   83.7234
trainer/Q2 Predictions Max                  230.821
trainer/Q2 Predictions Min                    4.03877
trainer/Q Targets Mean                      130.664
trainer/Q Targets Std                        83.7798
trainer/Q Targets Max                       233.131
trainer/Q Targets Min                         3.17263
trainer/Log Pis Mean                          5.75082
trainer/Log Pis Std                           5.08153
trainer/Log Pis Max                          23.2756
trainer/Log Pis Min                          -4.30689
trainer/policy/mean Mean                      0.0287791
trainer/policy/mean Std                       0.763635
trainer/policy/mean Max                       0.999997
trainer/policy/mean Min                      -0.999954
trainer/policy/normal/std Mean                0.47181
trainer/policy/normal/std Std                 0.126349
trainer/policy/normal/std Max                 0.906921
trainer/policy/normal/std Min                 0.114298
trainer/policy/normal/log_std Mean           -0.789536
trainer/policy/normal/log_std Std             0.283944
trainer/policy/normal/log_std Max            -0.0977003
trainer/policy/normal/log_std Min            -2.16894
trainer/Alpha                                 0.0503221
trainer/Alpha Loss                           -0.744867
expl/num steps total                      72000
expl/num paths total                         72
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.47944
expl/Rewards Std                              1.14949
expl/Rewards Max                              6.22077
expl/Rewards Min                             -0.462112
expl/Returns Mean                          3479.44
expl/Returns Std                              0
expl/Returns Max                           3479.44
expl/Returns Min                           3479.44
expl/Actions Mean                             0.014805
expl/Actions Std                              0.825165
expl/Actions Max                              0.9999
expl/Actions Min                             -0.999939
expl/Num Paths                                1
expl/Average Returns                       3479.44
expl/env_infos/final/reward_run Mean          5.20041
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.20041
expl/env_infos/final/reward_run Min           5.20041
expl/env_infos/initial/reward_run Mean       -0.312198
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.312198
expl/env_infos/initial/reward_run Min        -0.312198
expl/env_infos/reward_run Mean                3.88811
expl/env_infos/reward_run Std                 1.14245
expl/env_infos/reward_run Max                 6.67063
expl/env_infos/reward_run Min                -0.312198
expl/env_infos/final/reward_ctrl Mean        -0.431113
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.431113
expl/env_infos/final/reward_ctrl Min         -0.431113
expl/env_infos/initial/reward_ctrl Mean      -0.149914
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.149914
expl/env_infos/initial/reward_ctrl Min       -0.149914
expl/env_infos/reward_ctrl Mean              -0.40867
expl/env_infos/reward_ctrl Std                0.0893512
expl/env_infos/reward_ctrl Max               -0.103644
expl/env_infos/reward_ctrl Min               -0.58896
eval/num steps total                     355000
eval/num paths total                        355
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.6748
eval/Rewards Std                              1.10891
eval/Rewards Max                              6.43593
eval/Rewards Min                             -0.744029
eval/Returns Mean                          3674.8
eval/Returns Std                             75.2481
eval/Returns Max                           3793.52
eval/Returns Min                           3571.85
eval/Actions Mean                             0.00421237
eval/Actions Std                              0.83523
eval/Actions Max                              0.999839
eval/Actions Min                             -0.999867
eval/Num Paths                                5
eval/Average Returns                       3674.8
eval/env_infos/final/reward_run Mean          3.68665
eval/env_infos/final/reward_run Std           0.845084
eval/env_infos/final/reward_run Max           4.9732
eval/env_infos/final/reward_run Min           2.57335
eval/env_infos/initial/reward_run Mean       -0.269442
eval/env_infos/initial/reward_run Std         0.0455305
eval/env_infos/initial/reward_run Max        -0.193265
eval/env_infos/initial/reward_run Min        -0.331043
eval/env_infos/reward_run Mean                4.09338
eval/env_infos/reward_run Std                 1.10281
eval/env_infos/reward_run Max                 6.85296
eval/env_infos/reward_run Min                -0.426102
eval/env_infos/final/reward_ctrl Mean        -0.368484
eval/env_infos/final/reward_ctrl Std          0.0922426
eval/env_infos/final/reward_ctrl Max         -0.26573
eval/env_infos/final/reward_ctrl Min         -0.495953
eval/env_infos/initial/reward_ctrl Mean      -0.116133
eval/env_infos/initial/reward_ctrl Std        0.0404199
eval/env_infos/initial/reward_ctrl Max       -0.0753609
eval/env_infos/initial/reward_ctrl Min       -0.189924
eval/env_infos/reward_ctrl Mean              -0.418576
eval/env_infos/reward_ctrl Std                0.0878406
eval/env_infos/reward_ctrl Max               -0.0726022
eval/env_infos/reward_ctrl Min               -0.593015
time/data storing (s)                         0.00454108
time/evaluation sampling (s)                  2.00416
time/exploration sampling (s)                 0.539797
time/logging (s)                              0.0153737
time/sac training (s)                         7.71969
time/saving (s)                               0.00382658
time/training (s)                             4.7134e-05
time/epoch (s)                               10.2874
time/total (s)                              757.246
Epoch                                        70
---------------------------------------  ---------------
2021-11-24 00:41:59.165690 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 71 finished
---------------------------------------  ---------------
epoch                                        71
replay_buffer/size                        73000
trainer/num train calls                   72000
trainer/QF1 Loss                              7.11792
trainer/QF2 Loss                              5.57497
trainer/Policy Loss                        -139.758
trainer/Q1 Predictions Mean                 139.572
trainer/Q1 Predictions Std                   81.7742
trainer/Q1 Predictions Max                  228.756
trainer/Q1 Predictions Min                    4.58654
trainer/Q2 Predictions Mean                 139.576
trainer/Q2 Predictions Std                   81.7591
trainer/Q2 Predictions Max                  227.198
trainer/Q2 Predictions Min                    4.61469
trainer/Q Targets Mean                      139.443
trainer/Q Targets Std                        81.6541
trainer/Q Targets Max                       226.897
trainer/Q Targets Min                         4.07026
trainer/Log Pis Mean                          5.76371
trainer/Log Pis Std                           5.25748
trainer/Log Pis Max                          19.1126
trainer/Log Pis Min                          -6.1329
trainer/policy/mean Mean                      0.00818226
trainer/policy/mean Std                       0.767116
trainer/policy/mean Max                       0.999342
trainer/policy/mean Min                      -0.999441
trainer/policy/normal/std Mean                0.45769
trainer/policy/normal/std Std                 0.125464
trainer/policy/normal/std Max                 0.994283
trainer/policy/normal/std Min                 0.150176
trainer/policy/normal/log_std Mean           -0.821096
trainer/policy/normal/log_std Std             0.287071
trainer/policy/normal/log_std Max            -0.00573302
trainer/policy/normal/log_std Min            -1.89595
trainer/Alpha                                 0.0515041
trainer/Alpha Loss                           -0.700865
expl/num steps total                      73000
expl/num paths total                         73
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.44656
expl/Rewards Std                              1.1132
expl/Rewards Max                              5.62535
expl/Rewards Min                             -0.361985
expl/Returns Mean                          3446.56
expl/Returns Std                              0
expl/Returns Max                           3446.56
expl/Returns Min                           3446.56
expl/Actions Mean                            -0.00346949
expl/Actions Std                              0.830413
expl/Actions Max                              0.999929
expl/Actions Min                             -0.999869
expl/Num Paths                                1
expl/Average Returns                       3446.56
expl/env_infos/final/reward_run Mean          4.02815
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.02815
expl/env_infos/final/reward_run Min           4.02815
expl/env_infos/initial/reward_run Mean       -0.0957997
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0957997
expl/env_infos/initial/reward_run Min        -0.0957997
expl/env_infos/reward_run Mean                3.86031
expl/env_infos/reward_run Std                 1.11959
expl/env_infos/reward_run Max                 6.1563
expl/env_infos/reward_run Min                -0.0957997
expl/env_infos/final/reward_ctrl Mean        -0.521372
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.521372
expl/env_infos/final/reward_ctrl Min         -0.521372
expl/env_infos/initial/reward_ctrl Mean      -0.133212
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.133212
expl/env_infos/initial/reward_ctrl Min       -0.133212
expl/env_infos/reward_ctrl Mean              -0.413759
expl/env_infos/reward_ctrl Std                0.0903532
expl/env_infos/reward_ctrl Max               -0.0925392
expl/env_infos/reward_ctrl Min               -0.590522
eval/num steps total                     360000
eval/num paths total                        360
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.62697
eval/Rewards Std                              1.14947
eval/Rewards Max                              6.25536
eval/Rewards Min                             -1.11
eval/Returns Mean                          3626.97
eval/Returns Std                             89.8544
eval/Returns Max                           3746.56
eval/Returns Min                           3467.78
eval/Actions Mean                            -0.0177495
eval/Actions Std                              0.840389
eval/Actions Max                              0.999929
eval/Actions Min                             -0.999804
eval/Num Paths                                5
eval/Average Returns                       3626.97
eval/env_infos/final/reward_run Mean          4.00656
eval/env_infos/final/reward_run Std           0.986855
eval/env_infos/final/reward_run Max           5.49102
eval/env_infos/final/reward_run Min           2.42018
eval/env_infos/initial/reward_run Mean       -0.030022
eval/env_infos/initial/reward_run Std         0.257887
eval/env_infos/initial/reward_run Max         0.265517
eval/env_infos/initial/reward_run Min        -0.478742
eval/env_infos/reward_run Mean                4.05091
eval/env_infos/reward_run Std                 1.1535
eval/env_infos/reward_run Max                 6.74627
eval/env_infos/reward_run Min                -0.741309
eval/env_infos/final/reward_ctrl Mean        -0.475885
eval/env_infos/final/reward_ctrl Std          0.0850166
eval/env_infos/final/reward_ctrl Max         -0.371243
eval/env_infos/final/reward_ctrl Min         -0.574442
eval/env_infos/initial/reward_ctrl Mean      -0.11699
eval/env_infos/initial/reward_ctrl Std        0.0690801
eval/env_infos/initial/reward_ctrl Max       -0.0409661
eval/env_infos/initial/reward_ctrl Min       -0.233879
eval/env_infos/reward_ctrl Mean              -0.423941
eval/env_infos/reward_ctrl Std                0.0888125
eval/env_infos/reward_ctrl Max               -0.0409661
eval/env_infos/reward_ctrl Min               -0.590296
time/data storing (s)                         0.0044788
time/evaluation sampling (s)                  2.00354
time/exploration sampling (s)                 0.522485
time/logging (s)                              0.0139272
time/sac training (s)                         7.85075
time/saving (s)                               0.00385579
time/training (s)                             3.5339e-05
time/epoch (s)                               10.3991
time/total (s)                              767.963
Epoch                                        71
---------------------------------------  ---------------
2021-11-24 00:42:09.913122 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 72 finished
---------------------------------------  ---------------
epoch                                        72
replay_buffer/size                        74000
trainer/num train calls                   73000
trainer/QF1 Loss                              6.35416
trainer/QF2 Loss                              7.25055
trainer/Policy Loss                        -136.397
trainer/Q1 Predictions Mean                 136.563
trainer/Q1 Predictions Std                   85.2899
trainer/Q1 Predictions Max                  234.307
trainer/Q1 Predictions Min                    5.21196
trainer/Q2 Predictions Mean                 136.295
trainer/Q2 Predictions Std                   85.0689
trainer/Q2 Predictions Max                  234.447
trainer/Q2 Predictions Min                    4.83591
trainer/Q Targets Mean                      136.525
trainer/Q Targets Std                        85.3873
trainer/Q Targets Max                       236.457
trainer/Q Targets Min                         3.79644
trainer/Log Pis Mean                          6.08979
trainer/Log Pis Std                           5.56417
trainer/Log Pis Max                          26.1174
trainer/Log Pis Min                          -5.81244
trainer/policy/mean Mean                      0.0526125
trainer/policy/mean Std                       0.765566
trainer/policy/mean Max                       0.999783
trainer/policy/mean Min                      -0.999402
trainer/policy/normal/std Mean                0.461691
trainer/policy/normal/std Std                 0.128354
trainer/policy/normal/std Max                 1.01188
trainer/policy/normal/std Min                 0.147907
trainer/policy/normal/log_std Mean           -0.814062
trainer/policy/normal/log_std Std             0.293799
trainer/policy/normal/log_std Max             0.0118078
trainer/policy/normal/log_std Min            -1.91117
trainer/Alpha                                 0.0517405
trainer/Alpha Loss                            0.265918
expl/num steps total                      74000
expl/num paths total                         74
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.41087
expl/Rewards Std                              1.13351
expl/Rewards Max                              6.15984
expl/Rewards Min                             -0.394814
expl/Returns Mean                          3410.87
expl/Returns Std                              0
expl/Returns Max                           3410.87
expl/Returns Min                           3410.87
expl/Actions Mean                             0.0115625
expl/Actions Std                              0.827879
expl/Actions Max                              0.999858
expl/Actions Min                             -0.999961
expl/Num Paths                                1
expl/Average Returns                       3410.87
expl/env_infos/final/reward_run Mean          4.14886
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.14886
expl/env_infos/final/reward_run Min           4.14886
expl/env_infos/initial/reward_run Mean       -0.24581
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.24581
expl/env_infos/initial/reward_run Min        -0.24581
expl/env_infos/reward_run Mean                3.82218
expl/env_infos/reward_run Std                 1.12576
expl/env_infos/reward_run Max                 6.55723
expl/env_infos/reward_run Min                -0.24581
expl/env_infos/final/reward_ctrl Mean        -0.322765
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.322765
expl/env_infos/final/reward_ctrl Min         -0.322765
expl/env_infos/initial/reward_ctrl Mean      -0.149003
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.149003
expl/env_infos/initial/reward_ctrl Min       -0.149003
expl/env_infos/reward_ctrl Mean              -0.41131
expl/env_infos/reward_ctrl Std                0.0908196
expl/env_infos/reward_ctrl Max               -0.0302761
expl/env_infos/reward_ctrl Min               -0.594404
eval/num steps total                     365000
eval/num paths total                        365
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.7742
eval/Rewards Std                              1.09472
eval/Rewards Max                              6.28456
eval/Rewards Min                             -1.07138
eval/Returns Mean                          3774.2
eval/Returns Std                             59.4679
eval/Returns Max                           3836.15
eval/Returns Min                           3662.39
eval/Actions Mean                             0.0082531
eval/Actions Std                              0.842297
eval/Actions Max                              0.999704
eval/Actions Min                             -0.999825
eval/Num Paths                                5
eval/Average Returns                       3774.2
eval/env_infos/final/reward_run Mean          4.08977
eval/env_infos/final/reward_run Std           0.691947
eval/env_infos/final/reward_run Max           5.18818
eval/env_infos/final/reward_run Min           3.05252
eval/env_infos/initial/reward_run Mean       -0.270334
eval/env_infos/initial/reward_run Std         0.143891
eval/env_infos/initial/reward_run Max        -0.0225605
eval/env_infos/initial/reward_run Min        -0.385165
eval/env_infos/reward_run Mean                4.19992
eval/env_infos/reward_run Std                 1.0815
eval/env_infos/reward_run Max                 6.7426
eval/env_infos/reward_run Min                -0.634973
eval/env_infos/final/reward_ctrl Mean        -0.421927
eval/env_infos/final/reward_ctrl Std          0.0897477
eval/env_infos/final/reward_ctrl Max         -0.252437
eval/env_infos/final/reward_ctrl Min         -0.493608
eval/env_infos/initial/reward_ctrl Mean      -0.158926
eval/env_infos/initial/reward_ctrl Std        0.0714643
eval/env_infos/initial/reward_ctrl Max       -0.0571521
eval/env_infos/initial/reward_ctrl Min       -0.255066
eval/env_infos/reward_ctrl Mean              -0.425719
eval/env_infos/reward_ctrl Std                0.0855757
eval/env_infos/reward_ctrl Max               -0.0571521
eval/env_infos/reward_ctrl Min               -0.593489
time/data storing (s)                         0.00453185
time/evaluation sampling (s)                  2.12472
time/exploration sampling (s)                 0.536505
time/logging (s)                              0.0144396
time/sac training (s)                         7.73798
time/saving (s)                               0.00389071
time/training (s)                             5.3544e-05
time/epoch (s)                               10.4221
time/total (s)                              778.697
Epoch                                        72
---------------------------------------  ---------------
2021-11-24 00:42:20.674090 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 73 finished
---------------------------------------  ---------------
epoch                                        73
replay_buffer/size                        75000
trainer/num train calls                   74000
trainer/QF1 Loss                              6.99927
trainer/QF2 Loss                              6.72425
trainer/Policy Loss                        -146.27
trainer/Q1 Predictions Mean                 146.134
trainer/Q1 Predictions Std                   80.9112
trainer/Q1 Predictions Max                  240.975
trainer/Q1 Predictions Min                    3.14807
trainer/Q2 Predictions Mean                 146.078
trainer/Q2 Predictions Std                   80.994
trainer/Q2 Predictions Max                  240.38
trainer/Q2 Predictions Min                    3.54063
trainer/Q Targets Mean                      146.179
trainer/Q Targets Std                        81.0343
trainer/Q Targets Max                       239.65
trainer/Q Targets Min                         3.40587
trainer/Log Pis Mean                          6.5159
trainer/Log Pis Std                           5.23437
trainer/Log Pis Max                          29.2838
trainer/Log Pis Min                          -7.19719
trainer/policy/mean Mean                      0.0486513
trainer/policy/mean Std                       0.776601
trainer/policy/mean Max                       0.999904
trainer/policy/mean Min                      -0.999747
trainer/policy/normal/std Mean                0.466223
trainer/policy/normal/std Std                 0.131563
trainer/policy/normal/std Max                 1.1068
trainer/policy/normal/std Min                 0.153649
trainer/policy/normal/log_std Mean           -0.80373
trainer/policy/normal/log_std Std             0.288973
trainer/policy/normal/log_std Max             0.101476
trainer/policy/normal/log_std Min            -1.87309
trainer/Alpha                                 0.0525561
trainer/Alpha Loss                            1.51978
expl/num steps total                      75000
expl/num paths total                         75
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.71241
expl/Rewards Std                              1.10017
expl/Rewards Max                              5.85821
expl/Rewards Min                             -0.603484
expl/Returns Mean                          3712.41
expl/Returns Std                              0
expl/Returns Max                           3712.41
expl/Returns Min                           3712.41
expl/Actions Mean                             0.0228961
expl/Actions Std                              0.83566
expl/Actions Max                              0.999982
expl/Actions Min                             -0.999881
expl/Num Paths                                1
expl/Average Returns                       3712.41
expl/env_infos/final/reward_run Mean          5.40729
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.40729
expl/env_infos/final/reward_run Min           5.40729
expl/env_infos/initial/reward_run Mean       -0.086931
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.086931
expl/env_infos/initial/reward_run Min        -0.086931
expl/env_infos/reward_run Mean                4.13172
expl/env_infos/reward_run Std                 1.10307
expl/env_infos/reward_run Max                 6.34799
expl/env_infos/reward_run Min                -0.401992
expl/env_infos/final/reward_ctrl Mean        -0.422891
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.422891
expl/env_infos/final/reward_ctrl Min         -0.422891
expl/env_infos/initial/reward_ctrl Mean      -0.129634
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.129634
expl/env_infos/initial/reward_ctrl Min       -0.129634
expl/env_infos/reward_ctrl Mean              -0.419311
expl/env_infos/reward_ctrl Std                0.0851559
expl/env_infos/reward_ctrl Max               -0.129634
expl/env_infos/reward_ctrl Min               -0.588995
eval/num steps total                     370000
eval/num paths total                        370
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.68684
eval/Rewards Std                              1.14226
eval/Rewards Max                              6.24999
eval/Rewards Min                             -0.6787
eval/Returns Mean                          3686.84
eval/Returns Std                             93.1358
eval/Returns Max                           3853.32
eval/Returns Min                           3599.28
eval/Actions Mean                             0.0222802
eval/Actions Std                              0.845268
eval/Actions Max                              0.999955
eval/Actions Min                             -0.999739
eval/Num Paths                                5
eval/Average Returns                       3686.84
eval/env_infos/final/reward_run Mean          4.2035
eval/env_infos/final/reward_run Std           0.883099
eval/env_infos/final/reward_run Max           5.30439
eval/env_infos/final/reward_run Min           2.97046
eval/env_infos/initial/reward_run Mean       -0.111565
eval/env_infos/initial/reward_run Std         0.0730463
eval/env_infos/initial/reward_run Max        -0.0022114
eval/env_infos/initial/reward_run Min        -0.208317
eval/env_infos/reward_run Mean                4.11583
eval/env_infos/reward_run Std                 1.14642
eval/env_infos/reward_run Max                 6.76695
eval/env_infos/reward_run Min                -0.423414
eval/env_infos/final/reward_ctrl Mean        -0.416887
eval/env_infos/final/reward_ctrl Std          0.0508102
eval/env_infos/final/reward_ctrl Max         -0.349477
eval/env_infos/final/reward_ctrl Min         -0.484023
eval/env_infos/initial/reward_ctrl Mean      -0.106691
eval/env_infos/initial/reward_ctrl Std        0.021659
eval/env_infos/initial/reward_ctrl Max       -0.0791552
eval/env_infos/initial/reward_ctrl Min       -0.142342
eval/env_infos/reward_ctrl Mean              -0.428984
eval/env_infos/reward_ctrl Std                0.0829891
eval/env_infos/reward_ctrl Max               -0.0791552
eval/env_infos/reward_ctrl Min               -0.587933
time/data storing (s)                         0.0045327
time/evaluation sampling (s)                  2.04175
time/exploration sampling (s)                 0.56818
time/logging (s)                              0.0144614
time/sac training (s)                         7.79836
time/saving (s)                               0.00388759
time/training (s)                             5.068e-05
time/epoch (s)                               10.4312
time/total (s)                              789.443
Epoch                                        73
---------------------------------------  ---------------
2021-11-24 00:42:31.310852 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 74 finished
---------------------------------------  ---------------
epoch                                        74
replay_buffer/size                        76000
trainer/num train calls                   75000
trainer/QF1 Loss                              8.66987
trainer/QF2 Loss                              7.03014
trainer/Policy Loss                        -141.464
trainer/Q1 Predictions Mean                 141.494
trainer/Q1 Predictions Std                   86.2547
trainer/Q1 Predictions Max                  235.719
trainer/Q1 Predictions Min                    4.82592
trainer/Q2 Predictions Mean                 141.236
trainer/Q2 Predictions Std                   86.1299
trainer/Q2 Predictions Max                  233.973
trainer/Q2 Predictions Min                    4.63813
trainer/Q Targets Mean                      141.59
trainer/Q Targets Std                        86.5535
trainer/Q Targets Max                       237.651
trainer/Q Targets Min                         4.79685
trainer/Log Pis Mean                          5.9466
trainer/Log Pis Std                           5.62261
trainer/Log Pis Max                          21.1532
trainer/Log Pis Min                          -5.8894
trainer/policy/mean Mean                      0.00607906
trainer/policy/mean Std                       0.768818
trainer/policy/mean Max                       0.999963
trainer/policy/mean Min                      -0.999599
trainer/policy/normal/std Mean                0.458926
trainer/policy/normal/std Std                 0.12309
trainer/policy/normal/std Max                 0.965268
trainer/policy/normal/std Min                 0.153845
trainer/policy/normal/log_std Mean           -0.817314
trainer/policy/normal/log_std Std             0.284194
trainer/policy/normal/log_std Max            -0.0353498
trainer/policy/normal/log_std Min            -1.87181
trainer/Alpha                                 0.0531353
trainer/Alpha Loss                           -0.156731
expl/num steps total                      76000
expl/num paths total                         76
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.81711
expl/Rewards Std                              1.08923
expl/Rewards Max                              6.36086
expl/Rewards Min                             -0.511415
expl/Returns Mean                          3817.11
expl/Returns Std                              0
expl/Returns Max                           3817.11
expl/Returns Min                           3817.11
expl/Actions Mean                            -0.00095708
expl/Actions Std                              0.841001
expl/Actions Max                              0.999794
expl/Actions Min                             -0.999878
expl/Num Paths                                1
expl/Average Returns                       3817.11
expl/env_infos/final/reward_run Mean          4.96529
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.96529
expl/env_infos/final/reward_run Min           4.96529
expl/env_infos/initial/reward_run Mean        0.141135
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.141135
expl/env_infos/initial/reward_run Min         0.141135
expl/env_infos/reward_run Mean                4.24148
expl/env_infos/reward_run Std                 1.08749
expl/env_infos/reward_run Max                 6.76057
expl/env_infos/reward_run Min                 0.0208347
expl/env_infos/final/reward_ctrl Mean        -0.409796
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.409796
expl/env_infos/final/reward_ctrl Min         -0.409796
expl/env_infos/initial/reward_ctrl Mean      -0.107484
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.107484
expl/env_infos/initial/reward_ctrl Min       -0.107484
expl/env_infos/reward_ctrl Mean              -0.42437
expl/env_infos/reward_ctrl Std                0.0820269
expl/env_infos/reward_ctrl Max               -0.107484
expl/env_infos/reward_ctrl Min               -0.595246
eval/num steps total                     375000
eval/num paths total                        375
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.81427
eval/Rewards Std                              1.11792
eval/Rewards Max                              6.33428
eval/Rewards Min                             -0.646241
eval/Returns Mean                          3814.27
eval/Returns Std                             48.5684
eval/Returns Max                           3885.61
eval/Returns Min                           3735.85
eval/Actions Mean                             0.0112988
eval/Actions Std                              0.855466
eval/Actions Max                              0.999591
eval/Actions Min                             -0.999604
eval/Num Paths                                5
eval/Average Returns                       3814.27
eval/env_infos/final/reward_run Mean          4.58393
eval/env_infos/final/reward_run Std           1.22923
eval/env_infos/final/reward_run Max           6.25015
eval/env_infos/final/reward_run Min           2.56379
eval/env_infos/initial/reward_run Mean       -0.0605007
eval/env_infos/initial/reward_run Std         0.118549
eval/env_infos/initial/reward_run Max         0.0823637
eval/env_infos/initial/reward_run Min        -0.212662
eval/env_infos/reward_run Mean                4.25344
eval/env_infos/reward_run Std                 1.11535
eval/env_infos/reward_run Max                 6.88408
eval/env_infos/reward_run Min                -0.283497
eval/env_infos/final/reward_ctrl Mean        -0.437963
eval/env_infos/final/reward_ctrl Std          0.15905
eval/env_infos/final/reward_ctrl Max         -0.143287
eval/env_infos/final/reward_ctrl Min         -0.55496
eval/env_infos/initial/reward_ctrl Mean      -0.111481
eval/env_infos/initial/reward_ctrl Std        0.0407616
eval/env_infos/initial/reward_ctrl Max       -0.0669811
eval/env_infos/initial/reward_ctrl Min       -0.187009
eval/env_infos/reward_ctrl Mean              -0.43917
eval/env_infos/reward_ctrl Std                0.0778202
eval/env_infos/reward_ctrl Max               -0.0669811
eval/env_infos/reward_ctrl Min               -0.589739
time/data storing (s)                         0.00449325
time/evaluation sampling (s)                  2.01587
time/exploration sampling (s)                 0.521577
time/logging (s)                              0.0139419
time/sac training (s)                         7.74954
time/saving (s)                               0.0037627
time/training (s)                             3.4715e-05
time/epoch (s)                               10.3092
time/total (s)                              800.064
Epoch                                        74
---------------------------------------  ---------------
2021-11-24 00:42:42.044206 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 75 finished
---------------------------------------  ---------------
epoch                                        75
replay_buffer/size                        77000
trainer/num train calls                   76000
trainer/QF1 Loss                              6.14362
trainer/QF2 Loss                              6.71803
trainer/Policy Loss                        -152.398
trainer/Q1 Predictions Mean                 152.29
trainer/Q1 Predictions Std                   82.4031
trainer/Q1 Predictions Max                  239.923
trainer/Q1 Predictions Min                    3.61648
trainer/Q2 Predictions Mean                 152.422
trainer/Q2 Predictions Std                   82.5236
trainer/Q2 Predictions Max                  240.941
trainer/Q2 Predictions Min                    5.66035
trainer/Q Targets Mean                      152.414
trainer/Q Targets Std                        82.3553
trainer/Q Targets Max                       238.229
trainer/Q Targets Min                         5.57548
trainer/Log Pis Mean                          6.39206
trainer/Log Pis Std                           5.84083
trainer/Log Pis Max                          25.4706
trainer/Log Pis Min                          -9.14419
trainer/policy/mean Mean                      0.0544679
trainer/policy/mean Std                       0.770053
trainer/policy/mean Max                       0.999678
trainer/policy/mean Min                      -0.999773
trainer/policy/normal/std Mean                0.477083
trainer/policy/normal/std Std                 0.129787
trainer/policy/normal/std Max                 1.01438
trainer/policy/normal/std Min                 0.131152
trainer/policy/normal/log_std Mean           -0.779339
trainer/policy/normal/log_std Std             0.286838
trainer/policy/normal/log_std Max             0.0142759
trainer/policy/normal/log_std Min            -2.0314
trainer/Alpha                                 0.0548638
trainer/Alpha Loss                            1.13811
expl/num steps total                      77000
expl/num paths total                         77
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.67234
expl/Rewards Std                              1.14003
expl/Rewards Max                              6.49505
expl/Rewards Min                             -0.367701
expl/Returns Mean                          3672.34
expl/Returns Std                              0
expl/Returns Max                           3672.34
expl/Returns Min                           3672.34
expl/Actions Mean                             0.0254086
expl/Actions Std                              0.836228
expl/Actions Max                              0.999926
expl/Actions Min                             -0.999738
expl/Num Paths                                1
expl/Average Returns                       3672.34
expl/env_infos/final/reward_run Mean          3.87722
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.87722
expl/env_infos/final/reward_run Min           3.87722
expl/env_infos/initial/reward_run Mean        0.0540857
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0540857
expl/env_infos/initial/reward_run Min         0.0540857
expl/env_infos/reward_run Mean                4.09229
expl/env_infos/reward_run Std                 1.15094
expl/env_infos/reward_run Max                 6.95614
expl/env_infos/reward_run Min                 0.00813292
expl/env_infos/final/reward_ctrl Mean        -0.349
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.349
expl/env_infos/final/reward_ctrl Min         -0.349
expl/env_infos/initial/reward_ctrl Mean      -0.112573
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.112573
expl/env_infos/initial/reward_ctrl Min       -0.112573
expl/env_infos/reward_ctrl Mean              -0.419954
expl/env_infos/reward_ctrl Std                0.0832376
expl/env_infos/reward_ctrl Max               -0.0646482
expl/env_infos/reward_ctrl Min               -0.589696
eval/num steps total                     380000
eval/num paths total                        380
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.96492
eval/Rewards Std                              1.11679
eval/Rewards Max                              6.70486
eval/Rewards Min                             -1.17441
eval/Returns Mean                          3964.92
eval/Returns Std                             64.0124
eval/Returns Max                           4075.96
eval/Returns Min                           3879.51
eval/Actions Mean                             0.0447967
eval/Actions Std                              0.85189
eval/Actions Max                              0.999867
eval/Actions Min                             -0.999865
eval/Num Paths                                5
eval/Average Returns                       3964.92
eval/env_infos/final/reward_run Mean          3.99159
eval/env_infos/final/reward_run Std           0.782251
eval/env_infos/final/reward_run Max           5.04246
eval/env_infos/final/reward_run Min           2.75355
eval/env_infos/initial/reward_run Mean       -0.0529609
eval/env_infos/initial/reward_run Std         0.122816
eval/env_infos/initial/reward_run Max         0.118926
eval/env_infos/initial/reward_run Min        -0.207139
eval/env_infos/reward_run Mean                4.40155
eval/env_infos/reward_run Std                 1.12262
eval/env_infos/reward_run Max                 7.26391
eval/env_infos/reward_run Min                -0.66708
eval/env_infos/final/reward_ctrl Mean        -0.429312
eval/env_infos/final/reward_ctrl Std          0.0958937
eval/env_infos/final/reward_ctrl Max         -0.279553
eval/env_infos/final/reward_ctrl Min         -0.580738
eval/env_infos/initial/reward_ctrl Mean      -0.136719
eval/env_infos/initial/reward_ctrl Std        0.0241796
eval/env_infos/initial/reward_ctrl Max       -0.101427
eval/env_infos/initial/reward_ctrl Min       -0.172623
eval/env_infos/reward_ctrl Mean              -0.436634
eval/env_infos/reward_ctrl Std                0.0824136
eval/env_infos/reward_ctrl Max               -0.101427
eval/env_infos/reward_ctrl Min               -0.589329
time/data storing (s)                         0.00499115
time/evaluation sampling (s)                  2.00981
time/exploration sampling (s)                 0.538722
time/logging (s)                              0.0138936
time/sac training (s)                         7.83219
time/saving (s)                               0.00432262
time/training (s)                             4.1083e-05
time/epoch (s)                               10.404
time/total (s)                              810.783
Epoch                                        75
---------------------------------------  ---------------
2021-11-24 00:42:52.710164 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 76 finished
---------------------------------------  ---------------
epoch                                        76
replay_buffer/size                        78000
trainer/num train calls                   77000
trainer/QF1 Loss                              6.98197
trainer/QF2 Loss                              7.35794
trainer/Policy Loss                        -148.354
trainer/Q1 Predictions Mean                 148.191
trainer/Q1 Predictions Std                   87.9977
trainer/Q1 Predictions Max                  243.043
trainer/Q1 Predictions Min                    4.48793
trainer/Q2 Predictions Mean                 148.428
trainer/Q2 Predictions Std                   88.0903
trainer/Q2 Predictions Max                  244.382
trainer/Q2 Predictions Min                    5.09144
trainer/Q Targets Mean                      147.539
trainer/Q Targets Std                        87.8625
trainer/Q Targets Max                       246.852
trainer/Q Targets Min                         3.36136
trainer/Log Pis Mean                          6.03291
trainer/Log Pis Std                           5.33264
trainer/Log Pis Max                          23.7325
trainer/Log Pis Min                          -5.27527
trainer/policy/mean Mean                      0.0261012
trainer/policy/mean Std                       0.762206
trainer/policy/mean Max                       0.999705
trainer/policy/mean Min                      -0.999745
trainer/policy/normal/std Mean                0.461293
trainer/policy/normal/std Std                 0.128035
trainer/policy/normal/std Max                 0.969736
trainer/policy/normal/std Min                 0.165978
trainer/policy/normal/log_std Mean           -0.814142
trainer/policy/normal/log_std Std             0.289795
trainer/policy/normal/log_std Max            -0.0307316
trainer/policy/normal/log_std Min            -1.7959
trainer/Alpha                                 0.0562902
trainer/Alpha Loss                            0.0946823
expl/num steps total                      78000
expl/num paths total                         78
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.63814
expl/Rewards Std                              1.10906
expl/Rewards Max                              6.07663
expl/Rewards Min                             -1.13879
expl/Returns Mean                          3638.14
expl/Returns Std                              0
expl/Returns Max                           3638.14
expl/Returns Min                           3638.14
expl/Actions Mean                             0.0118594
expl/Actions Std                              0.830657
expl/Actions Max                              0.999937
expl/Actions Min                             -0.999901
expl/Num Paths                                1
expl/Average Returns                       3638.14
expl/env_infos/final/reward_run Mean          4.58146
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.58146
expl/env_infos/final/reward_run Min           4.58146
expl/env_infos/initial/reward_run Mean       -0.368571
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.368571
expl/env_infos/initial/reward_run Min        -0.368571
expl/env_infos/reward_run Mean                4.05222
expl/env_infos/reward_run Std                 1.10896
expl/env_infos/reward_run Max                 6.64628
expl/env_infos/reward_run Min                -0.725783
expl/env_infos/final/reward_ctrl Mean        -0.583206
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.583206
expl/env_infos/final/reward_ctrl Min         -0.583206
expl/env_infos/initial/reward_ctrl Mean      -0.269432
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.269432
expl/env_infos/initial/reward_ctrl Min       -0.269432
expl/env_infos/reward_ctrl Mean              -0.414079
expl/env_infos/reward_ctrl Std                0.0868013
expl/env_infos/reward_ctrl Max               -0.125265
expl/env_infos/reward_ctrl Min               -0.586568
eval/num steps total                     385000
eval/num paths total                        385
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.77786
eval/Rewards Std                              1.10833
eval/Rewards Max                              6.42909
eval/Rewards Min                             -0.877105
eval/Returns Mean                          3777.86
eval/Returns Std                             39.565
eval/Returns Max                           3833.09
eval/Returns Min                           3710.56
eval/Actions Mean                             0.0136534
eval/Actions Std                              0.840342
eval/Actions Max                              0.99999
eval/Actions Min                             -0.999738
eval/Num Paths                                5
eval/Average Returns                       3777.86
eval/env_infos/final/reward_run Mean          4.32036
eval/env_infos/final/reward_run Std           1.44952
eval/env_infos/final/reward_run Max           6.19125
eval/env_infos/final/reward_run Min           2.192
eval/env_infos/initial/reward_run Mean        0.0574674
eval/env_infos/initial/reward_run Std         0.090393
eval/env_infos/initial/reward_run Max         0.153131
eval/env_infos/initial/reward_run Min        -0.092468
eval/env_infos/reward_run Mean                4.20168
eval/env_infos/reward_run Std                 1.10791
eval/env_infos/reward_run Max                 6.9491
eval/env_infos/reward_run Min                -0.417964
eval/env_infos/final/reward_ctrl Mean        -0.394839
eval/env_infos/final/reward_ctrl Std          0.049972
eval/env_infos/final/reward_ctrl Max         -0.320483
eval/env_infos/final/reward_ctrl Min         -0.474899
eval/env_infos/initial/reward_ctrl Mean      -0.115523
eval/env_infos/initial/reward_ctrl Std        0.0353013
eval/env_infos/initial/reward_ctrl Max       -0.0713008
eval/env_infos/initial/reward_ctrl Min       -0.16849
eval/env_infos/reward_ctrl Mean              -0.423817
eval/env_infos/reward_ctrl Std                0.0859208
eval/env_infos/reward_ctrl Max               -0.0568891
eval/env_infos/reward_ctrl Min               -0.587876
time/data storing (s)                         0.00450568
time/evaluation sampling (s)                  2.03082
time/exploration sampling (s)                 0.530176
time/logging (s)                              0.0143655
time/sac training (s)                         7.75617
time/saving (s)                               0.00390211
time/training (s)                             5.4469e-05
time/epoch (s)                               10.34
time/total (s)                              821.434
Epoch                                        76
---------------------------------------  ---------------
2021-11-24 00:43:03.317998 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 77 finished
---------------------------------------  ----------------
epoch                                        77
replay_buffer/size                        79000
trainer/num train calls                   78000
trainer/QF1 Loss                              6.77486
trainer/QF2 Loss                              6.87694
trainer/Policy Loss                        -151.544
trainer/Q1 Predictions Mean                 151.212
trainer/Q1 Predictions Std                   85.8975
trainer/Q1 Predictions Max                  253.224
trainer/Q1 Predictions Min                    5.30516
trainer/Q2 Predictions Mean                 151.629
trainer/Q2 Predictions Std                   86.0781
trainer/Q2 Predictions Max                  252.856
trainer/Q2 Predictions Min                    5.64811
trainer/Q Targets Mean                      151.275
trainer/Q Targets Std                        85.9264
trainer/Q Targets Max                       254.802
trainer/Q Targets Min                         3.82733
trainer/Log Pis Mean                          5.94262
trainer/Log Pis Std                           5.72662
trainer/Log Pis Max                          21.1129
trainer/Log Pis Min                          -7.39905
trainer/policy/mean Mean                      0.00645383
trainer/policy/mean Std                       0.769074
trainer/policy/mean Max                       0.999833
trainer/policy/mean Min                      -0.999712
trainer/policy/normal/std Mean                0.469739
trainer/policy/normal/std Std                 0.130022
trainer/policy/normal/std Max                 1.00087
trainer/policy/normal/std Min                 0.153957
trainer/policy/normal/log_std Mean           -0.797062
trainer/policy/normal/log_std Std             0.29622
trainer/policy/normal/log_std Max             0.000868897
trainer/policy/normal/log_std Min            -1.87108
trainer/Alpha                                 0.0568233
trainer/Alpha Loss                           -0.164543
expl/num steps total                      79000
expl/num paths total                         79
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.81346
expl/Rewards Std                              1.10398
expl/Rewards Max                              6.35424
expl/Rewards Min                             -0.740363
expl/Returns Mean                          3813.46
expl/Returns Std                              0
expl/Returns Max                           3813.46
expl/Returns Min                           3813.46
expl/Actions Mean                             0.00978639
expl/Actions Std                              0.836429
expl/Actions Max                              0.999954
expl/Actions Min                             -0.999859
expl/Num Paths                                1
expl/Average Returns                       3813.46
expl/env_infos/final/reward_run Mean          5.31878
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.31878
expl/env_infos/final/reward_run Min           5.31878
expl/env_infos/initial/reward_run Mean       -0.197254
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.197254
expl/env_infos/initial/reward_run Min        -0.197254
expl/env_infos/reward_run Mean                4.23329
expl/env_infos/reward_run Std                 1.09845
expl/env_infos/reward_run Max                 6.82814
expl/env_infos/reward_run Min                -0.290403
expl/env_infos/final/reward_ctrl Mean        -0.422947
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.422947
expl/env_infos/final/reward_ctrl Min         -0.422947
expl/env_infos/initial/reward_ctrl Mean      -0.164375
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.164375
expl/env_infos/initial/reward_ctrl Min       -0.164375
expl/env_infos/reward_ctrl Mean              -0.419825
expl/env_infos/reward_ctrl Std                0.0863645
expl/env_infos/reward_ctrl Max               -0.13187
expl/env_infos/reward_ctrl Min               -0.591219
eval/num steps total                     390000
eval/num paths total                        390
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.00629
eval/Rewards Std                              1.14811
eval/Rewards Max                              6.49557
eval/Rewards Min                             -0.832909
eval/Returns Mean                          4006.29
eval/Returns Std                            123.527
eval/Returns Max                           4124.39
eval/Returns Min                           3792.74
eval/Actions Mean                             0.0173219
eval/Actions Std                              0.854139
eval/Actions Max                              0.999818
eval/Actions Min                             -0.999813
eval/Num Paths                                5
eval/Average Returns                       4006.29
eval/env_infos/final/reward_run Mean          4.78728
eval/env_infos/final/reward_run Std           1.36971
eval/env_infos/final/reward_run Max           6.43994
eval/env_infos/final/reward_run Min           3.00751
eval/env_infos/initial/reward_run Mean        0.0721735
eval/env_infos/initial/reward_run Std         0.109629
eval/env_infos/initial/reward_run Max         0.178167
eval/env_infos/initial/reward_run Min        -0.0907687
eval/env_infos/reward_run Mean                4.4442
eval/env_infos/reward_run Std                 1.14849
eval/env_infos/reward_run Max                 7.06767
eval/env_infos/reward_run Min                -0.370277
eval/env_infos/final/reward_ctrl Mean        -0.445
eval/env_infos/final/reward_ctrl Std          0.0596172
eval/env_infos/final/reward_ctrl Max         -0.384398
eval/env_infos/final/reward_ctrl Min         -0.559103
eval/env_infos/initial/reward_ctrl Mean      -0.160252
eval/env_infos/initial/reward_ctrl Std        0.00942517
eval/env_infos/initial/reward_ctrl Max       -0.148005
eval/env_infos/initial/reward_ctrl Min       -0.170234
eval/env_infos/reward_ctrl Mean              -0.437912
eval/env_infos/reward_ctrl Std                0.0862154
eval/env_infos/reward_ctrl Max               -0.0941779
eval/env_infos/reward_ctrl Min               -0.589721
time/data storing (s)                         0.00449346
time/evaluation sampling (s)                  2.01136
time/exploration sampling (s)                 0.532173
time/logging (s)                              0.013727
time/sac training (s)                         7.71705
time/saving (s)                               0.00379463
time/training (s)                             3.388e-05
time/epoch (s)                               10.2826
time/total (s)                              832.027
Epoch                                        77
---------------------------------------  ----------------
2021-11-24 00:43:13.956288 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 78 finished
---------------------------------------  ---------------
epoch                                        78
replay_buffer/size                        80000
trainer/num train calls                   79000
trainer/QF1 Loss                              5.75947
trainer/QF2 Loss                              5.61681
trainer/Policy Loss                        -147.158
trainer/Q1 Predictions Mean                 147.207
trainer/Q1 Predictions Std                   92.8661
trainer/Q1 Predictions Max                  258.299
trainer/Q1 Predictions Min                    4.85098
trainer/Q2 Predictions Mean                 147.421
trainer/Q2 Predictions Std                   92.9857
trainer/Q2 Predictions Max                  255.778
trainer/Q2 Predictions Min                    4.81052
trainer/Q Targets Mean                      147.523
trainer/Q Targets Std                        92.9878
trainer/Q Targets Max                       257.117
trainer/Q Targets Min                         5.26475
trainer/Log Pis Mean                          5.94451
trainer/Log Pis Std                           5.46651
trainer/Log Pis Max                          33.7437
trainer/Log Pis Min                          -4.75874
trainer/policy/mean Mean                      0.0180188
trainer/policy/mean Std                       0.771926
trainer/policy/mean Max                       0.999941
trainer/policy/mean Min                      -0.999935
trainer/policy/normal/std Mean                0.473941
trainer/policy/normal/std Std                 0.130567
trainer/policy/normal/std Max                 1.10304
trainer/policy/normal/std Min                 0.152006
trainer/policy/normal/log_std Mean           -0.787501
trainer/policy/normal/log_std Std             0.293722
trainer/policy/normal/log_std Max             0.0980743
trainer/policy/normal/log_std Min            -1.88383
trainer/Alpha                                 0.0583607
trainer/Alpha Loss                           -0.157653
expl/num steps total                      80000
expl/num paths total                         80
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.85215
expl/Rewards Std                              1.02763
expl/Rewards Max                              6.1132
expl/Rewards Min                             -0.0992484
expl/Returns Mean                          3852.15
expl/Returns Std                              0
expl/Returns Max                           3852.15
expl/Returns Min                           3852.15
expl/Actions Mean                             0.0394884
expl/Actions Std                              0.831012
expl/Actions Max                              0.999891
expl/Actions Min                             -0.999665
expl/Num Paths                                1
expl/Average Returns                       3852.15
expl/env_infos/final/reward_run Mean          5.01813
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.01813
expl/env_infos/final/reward_run Min           5.01813
expl/env_infos/initial/reward_run Mean        0.181742
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.181742
expl/env_infos/initial/reward_run Min         0.181742
expl/env_infos/reward_run Mean                4.26743
expl/env_infos/reward_run Std                 1.03442
expl/env_infos/reward_run Max                 6.58275
expl/env_infos/reward_run Min                 0.181742
expl/env_infos/final/reward_ctrl Mean        -0.369033
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.369033
expl/env_infos/final/reward_ctrl Min         -0.369033
expl/env_infos/initial/reward_ctrl Mean      -0.115909
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.115909
expl/env_infos/initial/reward_ctrl Min       -0.115909
expl/env_infos/reward_ctrl Mean              -0.415285
expl/env_infos/reward_ctrl Std                0.0823475
expl/env_infos/reward_ctrl Max               -0.115909
expl/env_infos/reward_ctrl Min               -0.586791
eval/num steps total                     395000
eval/num paths total                        395
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.97035
eval/Rewards Std                              1.09146
eval/Rewards Max                              6.62144
eval/Rewards Min                             -0.830388
eval/Returns Mean                          3970.35
eval/Returns Std                             84.3916
eval/Returns Max                           4067.4
eval/Returns Min                           3826.85
eval/Actions Mean                             0.0296567
eval/Actions Std                              0.842166
eval/Actions Max                              0.999976
eval/Actions Min                             -0.999916
eval/Num Paths                                5
eval/Average Returns                       3970.35
eval/env_infos/final/reward_run Mean          5.53755
eval/env_infos/final/reward_run Std           0.364815
eval/env_infos/final/reward_run Max           6.01427
eval/env_infos/final/reward_run Min           5.14174
eval/env_infos/initial/reward_run Mean        0.0706367
eval/env_infos/initial/reward_run Std         0.313061
eval/env_infos/initial/reward_run Max         0.667594
eval/env_infos/initial/reward_run Min        -0.162268
eval/env_infos/reward_run Mean                4.39643
eval/env_infos/reward_run Std                 1.10075
eval/env_infos/reward_run Max                 7.12647
eval/env_infos/reward_run Min                -0.486345
eval/env_infos/final/reward_ctrl Mean        -0.430393
eval/env_infos/final/reward_ctrl Std          0.0852786
eval/env_infos/final/reward_ctrl Max         -0.313638
eval/env_infos/final/reward_ctrl Min         -0.578663
eval/env_infos/initial/reward_ctrl Mean      -0.150698
eval/env_infos/initial/reward_ctrl Std        0.0153554
eval/env_infos/initial/reward_ctrl Max       -0.131771
eval/env_infos/initial/reward_ctrl Min       -0.172481
eval/env_infos/reward_ctrl Mean              -0.426074
eval/env_infos/reward_ctrl Std                0.0774056
eval/env_infos/reward_ctrl Max               -0.129231
eval/env_infos/reward_ctrl Min               -0.585504
time/data storing (s)                         0.00450222
time/evaluation sampling (s)                  2.01362
time/exploration sampling (s)                 0.532735
time/logging (s)                              0.0144226
time/sac training (s)                         7.74339
time/saving (s)                               0.00388607
time/training (s)                             4.2942e-05
time/epoch (s)                               10.3126
time/total (s)                              842.652
Epoch                                        78
---------------------------------------  ---------------
2021-11-24 00:43:24.798192 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 79 finished
---------------------------------------  ---------------
epoch                                        79
replay_buffer/size                        81000
trainer/num train calls                   80000
trainer/QF1 Loss                              8.4816
trainer/QF2 Loss                              7.31024
trainer/Policy Loss                        -152.486
trainer/Q1 Predictions Mean                 152.51
trainer/Q1 Predictions Std                   88.4851
trainer/Q1 Predictions Max                  251.527
trainer/Q1 Predictions Min                    6.27658
trainer/Q2 Predictions Mean                 152.249
trainer/Q2 Predictions Std                   88.4138
trainer/Q2 Predictions Max                  250.963
trainer/Q2 Predictions Min                    5.8675
trainer/Q Targets Mean                      152.549
trainer/Q Targets Std                        88.6814
trainer/Q Targets Max                       253.877
trainer/Q Targets Min                         5.65282
trainer/Log Pis Mean                          6.3068
trainer/Log Pis Std                           5.69355
trainer/Log Pis Max                          22.5561
trainer/Log Pis Min                          -4.9284
trainer/policy/mean Mean                      0.0374651
trainer/policy/mean Std                       0.779567
trainer/policy/mean Max                       0.9998
trainer/policy/mean Min                      -0.999154
trainer/policy/normal/std Mean                0.470995
trainer/policy/normal/std Std                 0.124193
trainer/policy/normal/std Max                 0.96846
trainer/policy/normal/std Min                 0.11759
trainer/policy/normal/log_std Mean           -0.790817
trainer/policy/normal/log_std Std             0.284216
trainer/policy/normal/log_std Max            -0.0320483
trainer/policy/normal/log_std Min            -2.14055
trainer/Alpha                                 0.0590504
trainer/Alpha Loss                            0.868043
expl/num steps total                      81000
expl/num paths total                         81
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.8584
expl/Rewards Std                              1.02016
expl/Rewards Max                              5.82886
expl/Rewards Min                             -0.411032
expl/Returns Mean                          3858.4
expl/Returns Std                              0
expl/Returns Max                           3858.4
expl/Returns Min                           3858.4
expl/Actions Mean                            -0.00525191
expl/Actions Std                              0.843996
expl/Actions Max                              0.999942
expl/Actions Min                             -0.999852
expl/Num Paths                                1
expl/Average Returns                       3858.4
expl/env_infos/final/reward_run Mean          4.68077
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.68077
expl/env_infos/final/reward_run Min           4.68077
expl/env_infos/initial/reward_run Mean        0.0303686
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0303686
expl/env_infos/initial/reward_run Min         0.0303686
expl/env_infos/reward_run Mean                4.28581
expl/env_infos/reward_run Std                 1.01488
expl/env_infos/reward_run Max                 6.33814
expl/env_infos/reward_run Min                -0.172605
expl/env_infos/final/reward_ctrl Mean        -0.397134
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.397134
expl/env_infos/final/reward_ctrl Min         -0.397134
expl/env_infos/initial/reward_ctrl Mean      -0.177905
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.177905
expl/env_infos/initial/reward_ctrl Min       -0.177905
expl/env_infos/reward_ctrl Mean              -0.427414
expl/env_infos/reward_ctrl Std                0.0829301
expl/env_infos/reward_ctrl Max               -0.163703
expl/env_infos/reward_ctrl Min               -0.585235
eval/num steps total                     400000
eval/num paths total                        400
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.00599
eval/Rewards Std                              1.10919
eval/Rewards Max                              6.32849
eval/Rewards Min                             -0.612392
eval/Returns Mean                          4005.99
eval/Returns Std                            120.297
eval/Returns Max                           4173.14
eval/Returns Min                           3838.21
eval/Actions Mean                            -0.0055741
eval/Actions Std                              0.855578
eval/Actions Max                              0.99991
eval/Actions Min                             -0.999889
eval/Num Paths                                5
eval/Average Returns                       4005.99
eval/env_infos/final/reward_run Mean          3.949
eval/env_infos/final/reward_run Std           0.926395
eval/env_infos/final/reward_run Max           5.00091
eval/env_infos/final/reward_run Min           2.59769
eval/env_infos/initial/reward_run Mean       -0.0338218
eval/env_infos/initial/reward_run Std         0.130416
eval/env_infos/initial/reward_run Max         0.153809
eval/env_infos/initial/reward_run Min        -0.228096
eval/env_infos/reward_run Mean                4.44522
eval/env_infos/reward_run Std                 1.10492
eval/env_infos/reward_run Max                 6.80887
eval/env_infos/reward_run Min                -0.353025
eval/env_infos/final/reward_ctrl Mean        -0.447795
eval/env_infos/final/reward_ctrl Std          0.117689
eval/env_infos/final/reward_ctrl Max         -0.215853
eval/env_infos/final/reward_ctrl Min         -0.530992
eval/env_infos/initial/reward_ctrl Mean      -0.179198
eval/env_infos/initial/reward_ctrl Std        0.0135342
eval/env_infos/initial/reward_ctrl Max       -0.164268
eval/env_infos/initial/reward_ctrl Min       -0.204197
eval/env_infos/reward_ctrl Mean              -0.439227
eval/env_infos/reward_ctrl Std                0.0804869
eval/env_infos/reward_ctrl Max               -0.0916659
eval/env_infos/reward_ctrl Min               -0.591511
time/data storing (s)                         0.00450725
time/evaluation sampling (s)                  2.0442
time/exploration sampling (s)                 0.585455
time/logging (s)                              0.0141038
time/sac training (s)                         7.85535
time/saving (s)                               0.00383692
time/training (s)                             4.3524e-05
time/epoch (s)                               10.5075
time/total (s)                              853.478
Epoch                                        79
---------------------------------------  ---------------
2021-11-24 00:43:35.413141 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 80 finished
---------------------------------------  ---------------
epoch                                        80
replay_buffer/size                        82000
trainer/num train calls                   81000
trainer/QF1 Loss                              8.61592
trainer/QF2 Loss                              5.82238
trainer/Policy Loss                        -151.34
trainer/Q1 Predictions Mean                 151.397
trainer/Q1 Predictions Std                   92.7539
trainer/Q1 Predictions Max                  254.621
trainer/Q1 Predictions Min                    6.08018
trainer/Q2 Predictions Mean                 151.23
trainer/Q2 Predictions Std                   92.6233
trainer/Q2 Predictions Max                  254.994
trainer/Q2 Predictions Min                    6.181
trainer/Q Targets Mean                      151.746
trainer/Q Targets Std                        92.8579
trainer/Q Targets Max                       256.117
trainer/Q Targets Min                         5.82581
trainer/Log Pis Mean                          5.56011
trainer/Log Pis Std                           5.19398
trainer/Log Pis Max                          31.185
trainer/Log Pis Min                          -5.7853
trainer/policy/mean Mean                      0.0342111
trainer/policy/mean Std                       0.759212
trainer/policy/mean Max                       0.999835
trainer/policy/mean Min                      -0.999974
trainer/policy/normal/std Mean                0.469289
trainer/policy/normal/std Std                 0.132638
trainer/policy/normal/std Max                 1.0295
trainer/policy/normal/std Min                 0.0903132
trainer/policy/normal/log_std Mean           -0.800269
trainer/policy/normal/log_std Std             0.30603
trainer/policy/normal/log_std Max             0.0290779
trainer/policy/normal/log_std Min            -2.40447
trainer/Alpha                                 0.0604933
trainer/Alpha Loss                           -1.234
expl/num steps total                      82000
expl/num paths total                         82
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.02858
expl/Rewards Std                              1.09526
expl/Rewards Max                              6.3473
expl/Rewards Min                             -0.826968
expl/Returns Mean                          4028.58
expl/Returns Std                              0
expl/Returns Max                           4028.58
expl/Returns Min                           4028.58
expl/Actions Mean                             0.0485808
expl/Actions Std                              0.838829
expl/Actions Max                              0.999973
expl/Actions Min                             -0.999612
expl/Num Paths                                1
expl/Average Returns                       4028.58
expl/env_infos/final/reward_run Mean          6.06245
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.06245
expl/env_infos/final/reward_run Min           6.06245
expl/env_infos/initial/reward_run Mean        0.202522
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.202522
expl/env_infos/initial/reward_run Min         0.202522
expl/env_infos/reward_run Mean                4.45217
expl/env_infos/reward_run Std                 1.10669
expl/env_infos/reward_run Max                 6.84064
expl/env_infos/reward_run Min                -0.338946
expl/env_infos/final/reward_ctrl Mean        -0.513822
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.513822
expl/env_infos/final/reward_ctrl Min         -0.513822
expl/env_infos/initial/reward_ctrl Mean      -0.18113
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.18113
expl/env_infos/initial/reward_ctrl Min       -0.18113
expl/env_infos/reward_ctrl Mean              -0.423596
expl/env_infos/reward_ctrl Std                0.0783655
expl/env_infos/reward_ctrl Max               -0.112384
expl/env_infos/reward_ctrl Min               -0.584864
eval/num steps total                     405000
eval/num paths total                        405
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.9779
eval/Rewards Std                              1.17876
eval/Rewards Max                              6.45349
eval/Rewards Min                             -0.666329
eval/Returns Mean                          3977.9
eval/Returns Std                            120.9
eval/Returns Max                           4067.72
eval/Returns Min                           3743.11
eval/Actions Mean                             0.0419261
eval/Actions Std                              0.849219
eval/Actions Max                              0.999792
eval/Actions Min                             -0.999762
eval/Num Paths                                5
eval/Average Returns                       3977.9
eval/env_infos/final/reward_run Mean          4.88324
eval/env_infos/final/reward_run Std           0.967604
eval/env_infos/final/reward_run Max           5.94375
eval/env_infos/final/reward_run Min           3.33857
eval/env_infos/initial/reward_run Mean        0.0152204
eval/env_infos/initial/reward_run Std         0.181442
eval/env_infos/initial/reward_run Max         0.261674
eval/env_infos/initial/reward_run Min        -0.19334
eval/env_infos/reward_run Mean                4.41166
eval/env_infos/reward_run Std                 1.19355
eval/env_infos/reward_run Max                 7.00589
eval/env_infos/reward_run Min                -0.204678
eval/env_infos/final/reward_ctrl Mean        -0.457137
eval/env_infos/final/reward_ctrl Std          0.0462858
eval/env_infos/final/reward_ctrl Max         -0.415339
eval/env_infos/final/reward_ctrl Min         -0.521624
eval/env_infos/initial/reward_ctrl Mean      -0.17499
eval/env_infos/initial/reward_ctrl Std        0.031202
eval/env_infos/initial/reward_ctrl Max       -0.133165
eval/env_infos/initial/reward_ctrl Min       -0.21646
eval/env_infos/reward_ctrl Mean              -0.433758
eval/env_infos/reward_ctrl Std                0.0777254
eval/env_infos/reward_ctrl Max               -0.118223
eval/env_infos/reward_ctrl Min               -0.58506
time/data storing (s)                         0.00447245
time/evaluation sampling (s)                  2.00829
time/exploration sampling (s)                 0.517947
time/logging (s)                              0.0139798
time/sac training (s)                         7.74064
time/saving (s)                               0.00380826
time/training (s)                             3.6375e-05
time/epoch (s)                               10.2892
time/total (s)                              864.078
Epoch                                        80
---------------------------------------  ---------------
2021-11-24 00:43:46.080463 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 81 finished
---------------------------------------  ---------------
epoch                                        81
replay_buffer/size                        83000
trainer/num train calls                   82000
trainer/QF1 Loss                              7.02913
trainer/QF2 Loss                              5.29863
trainer/Policy Loss                        -156.599
trainer/Q1 Predictions Mean                 156.761
trainer/Q1 Predictions Std                   93.6291
trainer/Q1 Predictions Max                  264.492
trainer/Q1 Predictions Min                    3.20394
trainer/Q2 Predictions Mean                 156.491
trainer/Q2 Predictions Std                   93.3941
trainer/Q2 Predictions Max                  263.923
trainer/Q2 Predictions Min                    4.21382
trainer/Q Targets Mean                      156.302
trainer/Q Targets Std                        93.1547
trainer/Q Targets Max                       264.986
trainer/Q Targets Min                         3.58435
trainer/Log Pis Mean                          5.56237
trainer/Log Pis Std                           5.23311
trainer/Log Pis Max                          21.8976
trainer/Log Pis Min                          -5.16325
trainer/policy/mean Mean                      0.0115431
trainer/policy/mean Std                       0.762116
trainer/policy/mean Max                       0.999778
trainer/policy/mean Min                      -0.999202
trainer/policy/normal/std Mean                0.47864
trainer/policy/normal/std Std                 0.12741
trainer/policy/normal/std Max                 0.988111
trainer/policy/normal/std Min                 0.118158
trainer/policy/normal/log_std Mean           -0.776213
trainer/policy/normal/log_std Std             0.291182
trainer/policy/normal/log_std Max            -0.0119599
trainer/policy/normal/log_std Min            -2.13573
trainer/Alpha                                 0.0618036
trainer/Alpha Loss                           -1.21827
expl/num steps total                      83000
expl/num paths total                         83
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.0846
expl/Rewards Std                              1.15704
expl/Rewards Max                              6.70019
expl/Rewards Min                             -1.00972
expl/Returns Mean                          4084.6
expl/Returns Std                              0
expl/Returns Max                           4084.6
expl/Returns Min                           4084.6
expl/Actions Mean                             0.0544365
expl/Actions Std                              0.834004
expl/Actions Max                              0.999891
expl/Actions Min                             -0.999636
expl/Num Paths                                1
expl/Average Returns                       4084.6
expl/env_infos/final/reward_run Mean          3.08453
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.08453
expl/env_infos/final/reward_run Min           3.08453
expl/env_infos/initial/reward_run Mean       -0.163899
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.163899
expl/env_infos/initial/reward_run Min        -0.163899
expl/env_infos/reward_run Mean                4.50372
expl/env_infos/reward_run Std                 1.16096
expl/env_infos/reward_run Max                 7.27366
expl/env_infos/reward_run Min                -0.638066
expl/env_infos/final/reward_ctrl Mean        -0.569886
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.569886
expl/env_infos/final/reward_ctrl Min         -0.569886
expl/env_infos/initial/reward_ctrl Mean      -0.233461
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.233461
expl/env_infos/initial/reward_ctrl Min       -0.233461
expl/env_infos/reward_ctrl Mean              -0.419116
expl/env_infos/reward_ctrl Std                0.0847363
expl/env_infos/reward_ctrl Max               -0.155931
expl/env_infos/reward_ctrl Min               -0.584192
eval/num steps total                     410000
eval/num paths total                        410
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.04277
eval/Rewards Std                              1.13332
eval/Rewards Max                              6.48401
eval/Rewards Min                             -1.11923
eval/Returns Mean                          4042.77
eval/Returns Std                            170.5
eval/Returns Max                           4300.65
eval/Returns Min                           3820.59
eval/Actions Mean                             0.0517517
eval/Actions Std                              0.850073
eval/Actions Max                              0.999972
eval/Actions Min                             -0.999766
eval/Num Paths                                5
eval/Average Returns                       4042.77
eval/env_infos/final/reward_run Mean          4.13242
eval/env_infos/final/reward_run Std           1.21131
eval/env_infos/final/reward_run Max           5.89644
eval/env_infos/final/reward_run Min           2.72946
eval/env_infos/initial/reward_run Mean        0.0643179
eval/env_infos/initial/reward_run Std         0.206345
eval/env_infos/initial/reward_run Max         0.301455
eval/env_infos/initial/reward_run Min        -0.175686
eval/env_infos/reward_run Mean                4.47796
eval/env_infos/reward_run Std                 1.13945
eval/env_infos/reward_run Max                 7.04552
eval/env_infos/reward_run Min                -0.532668
eval/env_infos/final/reward_ctrl Mean        -0.458268
eval/env_infos/final/reward_ctrl Std          0.0897006
eval/env_infos/final/reward_ctrl Max         -0.321891
eval/env_infos/final/reward_ctrl Min         -0.572215
eval/env_infos/initial/reward_ctrl Mean      -0.191612
eval/env_infos/initial/reward_ctrl Std        0.0257085
eval/env_infos/initial/reward_ctrl Max       -0.153378
eval/env_infos/initial/reward_ctrl Min       -0.232504
eval/env_infos/reward_ctrl Mean              -0.435181
eval/env_infos/reward_ctrl Std                0.0816705
eval/env_infos/reward_ctrl Max               -0.100307
eval/env_infos/reward_ctrl Min               -0.588234
time/data storing (s)                         0.00450065
time/evaluation sampling (s)                  2.00777
time/exploration sampling (s)                 0.535244
time/logging (s)                              0.0145447
time/sac training (s)                         7.77661
time/saving (s)                               0.00379023
time/training (s)                             4.2731e-05
time/epoch (s)                               10.3425
time/total (s)                              874.731
Epoch                                        81
---------------------------------------  ---------------
2021-11-24 00:43:56.826383 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 82 finished
---------------------------------------  ---------------
epoch                                        82
replay_buffer/size                        84000
trainer/num train calls                   83000
trainer/QF1 Loss                              6.19217
trainer/QF2 Loss                              5.91155
trainer/Policy Loss                        -157.035
trainer/Q1 Predictions Mean                 157.065
trainer/Q1 Predictions Std                   91.9478
trainer/Q1 Predictions Max                  258.214
trainer/Q1 Predictions Min                    4.94586
trainer/Q2 Predictions Mean                 156.87
trainer/Q2 Predictions Std                   91.7415
trainer/Q2 Predictions Max                  257.894
trainer/Q2 Predictions Min                    5.6322
trainer/Q Targets Mean                      157.255
trainer/Q Targets Std                        91.9028
trainer/Q Targets Max                       260.033
trainer/Q Targets Min                         4.779
trainer/Log Pis Mean                          6.38588
trainer/Log Pis Std                           5.55558
trainer/Log Pis Max                          17.7465
trainer/Log Pis Min                          -6.42285
trainer/policy/mean Mean                      0.004312
trainer/policy/mean Std                       0.766305
trainer/policy/mean Max                       0.999706
trainer/policy/mean Min                      -0.999883
trainer/policy/normal/std Mean                0.47544
trainer/policy/normal/std Std                 0.133729
trainer/policy/normal/std Max                 1.11808
trainer/policy/normal/std Min                 0.143064
trainer/policy/normal/log_std Mean           -0.785723
trainer/policy/normal/log_std Std             0.298286
trainer/policy/normal/log_std Max             0.111609
trainer/policy/normal/log_std Min            -1.94446
trainer/Alpha                                 0.0632352
trainer/Alpha Loss                            1.06537
expl/num steps total                      84000
expl/num paths total                         84
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.85967
expl/Rewards Std                              1.10676
expl/Rewards Max                              6.36137
expl/Rewards Min                             -0.584899
expl/Returns Mean                          3859.67
expl/Returns Std                              0
expl/Returns Max                           3859.67
expl/Returns Min                           3859.67
expl/Actions Mean                            -0.00336298
expl/Actions Std                              0.842892
expl/Actions Max                              0.999898
expl/Actions Min                             -0.999838
expl/Num Paths                                1
expl/Average Returns                       3859.67
expl/env_infos/final/reward_run Mean          3.41949
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.41949
expl/env_infos/final/reward_run Min           3.41949
expl/env_infos/initial/reward_run Mean        0.151567
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.151567
expl/env_infos/initial/reward_run Min         0.151567
expl/env_infos/reward_run Mean                4.28596
expl/env_infos/reward_run Std                 1.10252
expl/env_infos/reward_run Max                 6.79282
expl/env_infos/reward_run Min                -0.147212
expl/env_infos/final/reward_ctrl Mean        -0.331375
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.331375
expl/env_infos/final/reward_ctrl Min         -0.331375
expl/env_infos/initial/reward_ctrl Mean      -0.165871
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.165871
expl/env_infos/initial/reward_ctrl Min       -0.165871
expl/env_infos/reward_ctrl Mean              -0.426287
expl/env_infos/reward_ctrl Std                0.0830895
expl/env_infos/reward_ctrl Max               -0.133373
expl/env_infos/reward_ctrl Min               -0.592663
eval/num steps total                     415000
eval/num paths total                        415
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.34169
eval/Rewards Std                              1.73963
eval/Rewards Max                              6.55424
eval/Rewards Min                             -1.4181
eval/Returns Mean                          3341.69
eval/Returns Std                           1329.14
eval/Returns Max                           4184.55
eval/Returns Min                            690.51
eval/Actions Mean                             0.0165874
eval/Actions Std                              0.825263
eval/Actions Max                              0.999954
eval/Actions Min                             -0.999772
eval/Num Paths                                5
eval/Average Returns                       3341.69
eval/env_infos/final/reward_run Mean          3.91656
eval/env_infos/final/reward_run Std           1.10814
eval/env_infos/final/reward_run Max           5.28644
eval/env_infos/final/reward_run Min           2.49896
eval/env_infos/initial/reward_run Mean       -0.112357
eval/env_infos/initial/reward_run Std         0.150194
eval/env_infos/initial/reward_run Max         0.177734
eval/env_infos/initial/reward_run Min        -0.252122
eval/env_infos/reward_run Mean                3.75049
eval/env_infos/reward_run Std                 1.78495
eval/env_infos/reward_run Max                 7.05832
eval/env_infos/reward_run Min                -1.11165
eval/env_infos/final/reward_ctrl Mean        -0.365045
eval/env_infos/final/reward_ctrl Std          0.12674
eval/env_infos/final/reward_ctrl Max         -0.134082
eval/env_infos/final/reward_ctrl Min         -0.485704
eval/env_infos/initial/reward_ctrl Mean      -0.19521
eval/env_infos/initial/reward_ctrl Std        0.0323969
eval/env_infos/initial/reward_ctrl Max       -0.141127
eval/env_infos/initial/reward_ctrl Min       -0.231199
eval/env_infos/reward_ctrl Mean              -0.4088
eval/env_infos/reward_ctrl Std                0.103016
eval/env_infos/reward_ctrl Max               -0.0969265
eval/env_infos/reward_ctrl Min               -0.593352
time/data storing (s)                         0.00451788
time/evaluation sampling (s)                  2.04245
time/exploration sampling (s)                 0.526397
time/logging (s)                              0.0138273
time/sac training (s)                         7.82463
time/saving (s)                               0.0038749
time/training (s)                             5.6279e-05
time/epoch (s)                               10.4157
time/total (s)                              885.462
Epoch                                        82
---------------------------------------  ---------------
2021-11-24 00:44:07.494295 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 83 finished
---------------------------------------  ---------------
epoch                                        83
replay_buffer/size                        85000
trainer/num train calls                   84000
trainer/QF1 Loss                              8.71402
trainer/QF2 Loss                              6.48929
trainer/Policy Loss                        -165.554
trainer/Q1 Predictions Mean                 165.32
trainer/Q1 Predictions Std                   91.0576
trainer/Q1 Predictions Max                  262.618
trainer/Q1 Predictions Min                    6.19911
trainer/Q2 Predictions Mean                 165.612
trainer/Q2 Predictions Std                   91.2701
trainer/Q2 Predictions Max                  264.239
trainer/Q2 Predictions Min                    6.85571
trainer/Q Targets Mean                      165.667
trainer/Q Targets Std                        91.5211
trainer/Q Targets Max                       267.718
trainer/Q Targets Min                         6.22786
trainer/Log Pis Mean                          6.15006
trainer/Log Pis Std                           5.42839
trainer/Log Pis Max                          22.2798
trainer/Log Pis Min                          -5.679
trainer/policy/mean Mean                      0.0112851
trainer/policy/mean Std                       0.767243
trainer/policy/mean Max                       0.999847
trainer/policy/mean Min                      -0.998543
trainer/policy/normal/std Mean                0.468104
trainer/policy/normal/std Std                 0.132771
trainer/policy/normal/std Max                 1.03371
trainer/policy/normal/std Min                 0.113725
trainer/policy/normal/log_std Mean           -0.802999
trainer/policy/normal/log_std Std             0.306013
trainer/policy/normal/log_std Max             0.0331544
trainer/policy/normal/log_std Min            -2.17397
trainer/Alpha                                 0.0640643
trainer/Alpha Loss                            0.412345
expl/num steps total                      85000
expl/num paths total                         85
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.87977
expl/Rewards Std                              1.14776
expl/Rewards Max                              6.13674
expl/Rewards Min                             -0.632391
expl/Returns Mean                          3879.77
expl/Returns Std                              0
expl/Returns Max                           3879.77
expl/Returns Min                           3879.77
expl/Actions Mean                             0.0512189
expl/Actions Std                              0.836699
expl/Actions Max                              0.999762
expl/Actions Min                             -0.99988
expl/Num Paths                                1
expl/Average Returns                       3879.77
expl/env_infos/final/reward_run Mean          3.73659
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.73659
expl/env_infos/final/reward_run Min           3.73659
expl/env_infos/initial/reward_run Mean       -0.105658
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.105658
expl/env_infos/initial/reward_run Min        -0.105658
expl/env_infos/reward_run Mean                4.30138
expl/env_infos/reward_run Std                 1.14437
expl/env_infos/reward_run Max                 6.70237
expl/env_infos/reward_run Min                -0.21389
expl/env_infos/final/reward_ctrl Mean        -0.350355
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.350355
expl/env_infos/final/reward_ctrl Min         -0.350355
expl/env_infos/initial/reward_ctrl Mean      -0.158635
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.158635
expl/env_infos/initial/reward_ctrl Min       -0.158635
expl/env_infos/reward_ctrl Mean              -0.421613
expl/env_infos/reward_ctrl Std                0.0784001
expl/env_infos/reward_ctrl Max               -0.158635
expl/env_infos/reward_ctrl Min               -0.582434
eval/num steps total                     420000
eval/num paths total                        420
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.04378
eval/Rewards Std                              1.1432
eval/Rewards Max                              6.44233
eval/Rewards Min                             -0.637827
eval/Returns Mean                          4043.78
eval/Returns Std                            126.324
eval/Returns Max                           4241.04
eval/Returns Min                           3896.73
eval/Actions Mean                             0.0402871
eval/Actions Std                              0.848919
eval/Actions Max                              0.999437
eval/Actions Min                             -0.999225
eval/Num Paths                                5
eval/Average Returns                       4043.78
eval/env_infos/final/reward_run Mean          4.55965
eval/env_infos/final/reward_run Std           0.489855
eval/env_infos/final/reward_run Max           5.10795
eval/env_infos/final/reward_run Min           3.69238
eval/env_infos/initial/reward_run Mean        0.103261
eval/env_infos/initial/reward_run Std         0.0933977
eval/env_infos/initial/reward_run Max         0.162078
eval/env_infos/initial/reward_run Min        -0.0827059
eval/env_infos/reward_run Mean                4.47715
eval/env_infos/reward_run Std                 1.13917
eval/env_infos/reward_run Max                 7.00612
eval/env_infos/reward_run Min                -0.189035
eval/env_infos/final/reward_ctrl Mean        -0.355419
eval/env_infos/final/reward_ctrl Std          0.0991096
eval/env_infos/final/reward_ctrl Max         -0.197097
eval/env_infos/final/reward_ctrl Min         -0.465982
eval/env_infos/initial/reward_ctrl Mean      -0.185126
eval/env_infos/initial/reward_ctrl Std        0.0293868
eval/env_infos/initial/reward_ctrl Max       -0.164964
eval/env_infos/initial/reward_ctrl Min       -0.243
eval/env_infos/reward_ctrl Mean              -0.433372
eval/env_infos/reward_ctrl Std                0.0780181
eval/env_infos/reward_ctrl Max               -0.113019
eval/env_infos/reward_ctrl Min               -0.59204
time/data storing (s)                         0.00448106
time/evaluation sampling (s)                  2.02416
time/exploration sampling (s)                 0.533544
time/logging (s)                              0.0139772
time/sac training (s)                         7.76073
time/saving (s)                               0.00379285
time/training (s)                             3.537e-05
time/epoch (s)                               10.3407
time/total (s)                              896.115
Epoch                                        83
---------------------------------------  ---------------
2021-11-24 00:44:18.253444 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 84 finished
---------------------------------------  ---------------
epoch                                        84
replay_buffer/size                        86000
trainer/num train calls                   85000
trainer/QF1 Loss                              9.82739
trainer/QF2 Loss                              8.31456
trainer/Policy Loss                        -182.352
trainer/Q1 Predictions Mean                 182.181
trainer/Q1 Predictions Std                   83.8521
trainer/Q1 Predictions Max                  270.789
trainer/Q1 Predictions Min                    6.41825
trainer/Q2 Predictions Mean                 182.475
trainer/Q2 Predictions Std                   83.9341
trainer/Q2 Predictions Max                  270.987
trainer/Q2 Predictions Min                    6.36521
trainer/Q Targets Mean                      181.982
trainer/Q Targets Std                        83.7842
trainer/Q Targets Max                       274.263
trainer/Q Targets Min                         5.61977
trainer/Log Pis Mean                          6.42142
trainer/Log Pis Std                           5.02023
trainer/Log Pis Max                          20.5813
trainer/Log Pis Min                          -6.11934
trainer/policy/mean Mean                      0.00779571
trainer/policy/mean Std                       0.778947
trainer/policy/mean Max                       0.999995
trainer/policy/mean Min                      -0.999698
trainer/policy/normal/std Mean                0.461735
trainer/policy/normal/std Std                 0.129017
trainer/policy/normal/std Max                 0.979332
trainer/policy/normal/std Min                 0.139135
trainer/policy/normal/log_std Mean           -0.814341
trainer/policy/normal/log_std Std             0.296344
trainer/policy/normal/log_std Max            -0.0208841
trainer/policy/normal/log_std Min            -1.97231
trainer/Alpha                                 0.0651197
trainer/Alpha Loss                            1.15112
expl/num steps total                      86000
expl/num paths total                         86
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.88087
expl/Rewards Std                              1.14797
expl/Rewards Max                              6.15186
expl/Rewards Min                             -0.742736
expl/Returns Mean                          3880.87
expl/Returns Std                              0
expl/Returns Max                           3880.87
expl/Returns Min                           3880.87
expl/Actions Mean                             0.0523851
expl/Actions Std                              0.834961
expl/Actions Max                              0.999948
expl/Actions Min                             -0.999942
expl/Num Paths                                1
expl/Average Returns                       3880.87
expl/env_infos/final/reward_run Mean          1.85742
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.85742
expl/env_infos/final/reward_run Min           1.85742
expl/env_infos/initial/reward_run Mean        0.0844202
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0844202
expl/env_infos/initial/reward_run Min         0.0844202
expl/env_infos/reward_run Mean                4.30081
expl/env_infos/reward_run Std                 1.15359
expl/env_infos/reward_run Max                 6.60087
expl/env_infos/reward_run Min                -0.284089
expl/env_infos/final/reward_ctrl Mean        -0.250021
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.250021
expl/env_infos/final/reward_ctrl Min         -0.250021
expl/env_infos/initial/reward_ctrl Mean      -0.221076
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.221076
expl/env_infos/initial/reward_ctrl Min       -0.221076
expl/env_infos/reward_ctrl Mean              -0.419942
expl/env_infos/reward_ctrl Std                0.0841479
expl/env_infos/reward_ctrl Max               -0.154562
expl/env_infos/reward_ctrl Min               -0.586669
eval/num steps total                     425000
eval/num paths total                        425
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.02383
eval/Rewards Std                              1.11457
eval/Rewards Max                              6.40616
eval/Rewards Min                             -0.932459
eval/Returns Mean                          4023.83
eval/Returns Std                             56.1937
eval/Returns Max                           4119.43
eval/Returns Min                           3944.37
eval/Actions Mean                             0.0390913
eval/Actions Std                              0.846562
eval/Actions Max                              0.99989
eval/Actions Min                             -0.999591
eval/Num Paths                                5
eval/Average Returns                       4023.83
eval/env_infos/final/reward_run Mean          4.29904
eval/env_infos/final/reward_run Std           1.08855
eval/env_infos/final/reward_run Max           5.97299
eval/env_infos/final/reward_run Min           3.14864
eval/env_infos/initial/reward_run Mean       -0.142249
eval/env_infos/initial/reward_run Std         0.253212
eval/env_infos/initial/reward_run Max         0.337457
eval/env_infos/initial/reward_run Min        -0.379859
eval/env_infos/reward_run Mean                4.45474
eval/env_infos/reward_run Std                 1.12053
eval/env_infos/reward_run Max                 6.97383
eval/env_infos/reward_run Min                -0.443099
eval/env_infos/final/reward_ctrl Mean        -0.419389
eval/env_infos/final/reward_ctrl Std          0.0864164
eval/env_infos/final/reward_ctrl Max         -0.321168
eval/env_infos/final/reward_ctrl Min         -0.576564
eval/env_infos/initial/reward_ctrl Mean      -0.215957
eval/env_infos/initial/reward_ctrl Std        0.0202899
eval/env_infos/initial/reward_ctrl Max       -0.190088
eval/env_infos/initial/reward_ctrl Min       -0.250219
eval/env_infos/reward_ctrl Mean              -0.430917
eval/env_infos/reward_ctrl Std                0.0821664
eval/env_infos/reward_ctrl Max               -0.122534
eval/env_infos/reward_ctrl Min               -0.58998
time/data storing (s)                         0.00452953
time/evaluation sampling (s)                  1.99404
time/exploration sampling (s)                 0.539887
time/logging (s)                              0.0144283
time/sac training (s)                         7.86762
time/saving (s)                               0.00391962
time/training (s)                             4.4171e-05
time/epoch (s)                               10.4245
time/total (s)                              906.859
Epoch                                        84
---------------------------------------  ---------------
2021-11-24 00:44:29.099415 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 85 finished
---------------------------------------  ---------------
epoch                                        85
replay_buffer/size                        87000
trainer/num train calls                   86000
trainer/QF1 Loss                              8.18883
trainer/QF2 Loss                              6.43479
trainer/Policy Loss                        -170.52
trainer/Q1 Predictions Mean                 170.514
trainer/Q1 Predictions Std                   88.6944
trainer/Q1 Predictions Max                  271.616
trainer/Q1 Predictions Min                    6.1495
trainer/Q2 Predictions Mean                 170.402
trainer/Q2 Predictions Std                   88.6883
trainer/Q2 Predictions Max                  268.433
trainer/Q2 Predictions Min                    6.39842
trainer/Q Targets Mean                      170.765
trainer/Q Targets Std                        88.9311
trainer/Q Targets Max                       270.9
trainer/Q Targets Min                         5.66313
trainer/Log Pis Mean                          6.17625
trainer/Log Pis Std                           5.29594
trainer/Log Pis Max                          27.194
trainer/Log Pis Min                          -5.46705
trainer/policy/mean Mean                     -0.0141106
trainer/policy/mean Std                       0.766675
trainer/policy/mean Max                       0.999736
trainer/policy/mean Min                      -0.999426
trainer/policy/normal/std Mean                0.458225
trainer/policy/normal/std Std                 0.129016
trainer/policy/normal/std Max                 0.861863
trainer/policy/normal/std Min                 0.128724
trainer/policy/normal/log_std Mean           -0.823904
trainer/policy/normal/log_std Std             0.305264
trainer/policy/normal/log_std Max            -0.148659
trainer/policy/normal/log_std Min            -2.05009
trainer/Alpha                                 0.0650648
trainer/Alpha Loss                            0.481583
expl/num steps total                      87000
expl/num paths total                         87
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.83273
expl/Rewards Std                              1.13338
expl/Rewards Max                              6.20755
expl/Rewards Min                             -0.534283
expl/Returns Mean                          3832.73
expl/Returns Std                              0
expl/Returns Max                           3832.73
expl/Returns Min                           3832.73
expl/Actions Mean                             0.00144284
expl/Actions Std                              0.830807
expl/Actions Max                              0.999727
expl/Actions Min                             -0.999697
expl/Num Paths                                1
expl/Average Returns                       3832.73
expl/env_infos/final/reward_run Mean          6.18893
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.18893
expl/env_infos/final/reward_run Min           6.18893
expl/env_infos/initial/reward_run Mean       -0.0162157
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0162157
expl/env_infos/initial/reward_run Min        -0.0162157
expl/env_infos/reward_run Mean                4.24688
expl/env_infos/reward_run Std                 1.13107
expl/env_infos/reward_run Max                 6.67756
expl/env_infos/reward_run Min                -0.0619554
expl/env_infos/final/reward_ctrl Mean        -0.541963
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.541963
expl/env_infos/final/reward_ctrl Min         -0.541963
expl/env_infos/initial/reward_ctrl Mean      -0.248373
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.248373
expl/env_infos/initial/reward_ctrl Min       -0.248373
expl/env_infos/reward_ctrl Mean              -0.414146
expl/env_infos/reward_ctrl Std                0.0830804
expl/env_infos/reward_ctrl Max               -0.14402
expl/env_infos/reward_ctrl Min               -0.588862
eval/num steps total                     430000
eval/num paths total                        430
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.1493
eval/Rewards Std                              1.09365
eval/Rewards Max                              6.38145
eval/Rewards Min                             -0.654897
eval/Returns Mean                          4149.3
eval/Returns Std                             55.7547
eval/Returns Max                           4249.74
eval/Returns Min                           4101.65
eval/Actions Mean                             0.0135886
eval/Actions Std                              0.85324
eval/Actions Max                              0.999937
eval/Actions Min                             -0.999546
eval/Num Paths                                5
eval/Average Returns                       4149.3
eval/env_infos/final/reward_run Mean          4.34912
eval/env_infos/final/reward_run Std           0.968572
eval/env_infos/final/reward_run Max           5.40596
eval/env_infos/final/reward_run Min           2.85438
eval/env_infos/initial/reward_run Mean        0.0657004
eval/env_infos/initial/reward_run Std         0.1111
eval/env_infos/initial/reward_run Max         0.217902
eval/env_infos/initial/reward_run Min        -0.0501648
eval/env_infos/reward_run Mean                4.58622
eval/env_infos/reward_run Std                 1.09325
eval/env_infos/reward_run Max                 6.87717
eval/env_infos/reward_run Min                -0.365235
eval/env_infos/final/reward_ctrl Mean        -0.362208
eval/env_infos/final/reward_ctrl Std          0.0978863
eval/env_infos/final/reward_ctrl Max         -0.199675
eval/env_infos/final/reward_ctrl Min         -0.461135
eval/env_infos/initial/reward_ctrl Mean      -0.18717
eval/env_infos/initial/reward_ctrl Std        0.0160132
eval/env_infos/initial/reward_ctrl Max       -0.160143
eval/env_infos/initial/reward_ctrl Min       -0.207771
eval/env_infos/reward_ctrl Mean              -0.436921
eval/env_infos/reward_ctrl Std                0.075446
eval/env_infos/reward_ctrl Max               -0.160143
eval/env_infos/reward_ctrl Min               -0.590411
time/data storing (s)                         0.00450051
time/evaluation sampling (s)                  2.09469
time/exploration sampling (s)                 0.549638
time/logging (s)                              0.014085
time/sac training (s)                         7.8425
time/saving (s)                               0.00379974
time/training (s)                             3.3931e-05
time/epoch (s)                               10.5093
time/total (s)                              917.689
Epoch                                        85
---------------------------------------  ---------------
2021-11-24 00:44:39.840546 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 86 finished
---------------------------------------  ---------------
epoch                                        86
replay_buffer/size                        88000
trainer/num train calls                   87000
trainer/QF1 Loss                              7.12121
trainer/QF2 Loss                              5.8745
trainer/Policy Loss                        -167.382
trainer/Q1 Predictions Mean                 167.119
trainer/Q1 Predictions Std                   95.2527
trainer/Q1 Predictions Max                  269.66
trainer/Q1 Predictions Min                    7.65123
trainer/Q2 Predictions Mean                 167.382
trainer/Q2 Predictions Std                   95.3385
trainer/Q2 Predictions Max                  271.04
trainer/Q2 Predictions Min                    7.58493
trainer/Q Targets Mean                      167.077
trainer/Q Targets Std                        95.0752
trainer/Q Targets Max                       272.62
trainer/Q Targets Min                         6.06828
trainer/Log Pis Mean                          5.78876
trainer/Log Pis Std                           5.00488
trainer/Log Pis Max                          23.6549
trainer/Log Pis Min                          -6.30029
trainer/policy/mean Mean                      0.00962766
trainer/policy/mean Std                       0.772171
trainer/policy/mean Max                       0.999232
trainer/policy/mean Min                      -0.999988
trainer/policy/normal/std Mean                0.470149
trainer/policy/normal/std Std                 0.137176
trainer/policy/normal/std Max                 1.18936
trainer/policy/normal/std Min                 0.123134
trainer/policy/normal/log_std Mean           -0.801693
trainer/policy/normal/log_std Std             0.318614
trainer/policy/normal/log_std Max             0.173415
trainer/policy/normal/log_std Min            -2.09448
trainer/Alpha                                 0.0662418
trainer/Alpha Loss                           -0.573405
expl/num steps total                      88000
expl/num paths total                         88
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             3.94083
expl/Rewards Std                              1.11413
expl/Rewards Max                              6.29142
expl/Rewards Min                             -0.677466
expl/Returns Mean                          3940.83
expl/Returns Std                              0
expl/Returns Max                           3940.83
expl/Returns Min                           3940.83
expl/Actions Mean                             0.025323
expl/Actions Std                              0.832683
expl/Actions Max                              0.999981
expl/Actions Min                             -0.999193
expl/Num Paths                                1
expl/Average Returns                       3940.83
expl/env_infos/final/reward_run Mean          3.9294
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.9294
expl/env_infos/final/reward_run Min           3.9294
expl/env_infos/initial/reward_run Mean       -0.228009
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.228009
expl/env_infos/initial/reward_run Min        -0.228009
expl/env_infos/reward_run Mean                4.35724
expl/env_infos/reward_run Std                 1.11272
expl/env_infos/reward_run Max                 6.76742
expl/env_infos/reward_run Min                -0.333561
expl/env_infos/final/reward_ctrl Mean        -0.453585
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.453585
expl/env_infos/final/reward_ctrl Min         -0.453585
expl/env_infos/initial/reward_ctrl Mean      -0.208229
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.208229
expl/env_infos/initial/reward_ctrl Min       -0.208229
expl/env_infos/reward_ctrl Mean              -0.416402
expl/env_infos/reward_ctrl Std                0.0793262
expl/env_infos/reward_ctrl Max               -0.148357
expl/env_infos/reward_ctrl Min               -0.585534
eval/num steps total                     435000
eval/num paths total                        435
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.15272
eval/Rewards Std                              1.11465
eval/Rewards Max                              6.38965
eval/Rewards Min                             -0.846134
eval/Returns Mean                          4152.72
eval/Returns Std                             18.2641
eval/Returns Max                           4172.57
eval/Returns Min                           4124.61
eval/Actions Mean                             0.0287962
eval/Actions Std                              0.848739
eval/Actions Max                              0.999674
eval/Actions Min                             -0.999775
eval/Num Paths                                5
eval/Average Returns                       4152.72
eval/env_infos/final/reward_run Mean          3.87594
eval/env_infos/final/reward_run Std           0.436663
eval/env_infos/final/reward_run Max           4.51188
eval/env_infos/final/reward_run Min           3.35611
eval/env_infos/initial/reward_run Mean        0.033206
eval/env_infos/initial/reward_run Std         0.192427
eval/env_infos/initial/reward_run Max         0.23079
eval/env_infos/initial/reward_run Min        -0.320505
eval/env_infos/reward_run Mean                4.58543
eval/env_infos/reward_run Std                 1.11695
eval/env_infos/reward_run Max                 6.94863
eval/env_infos/reward_run Min                -0.552247
eval/env_infos/final/reward_ctrl Mean        -0.362922
eval/env_infos/final/reward_ctrl Std          0.0726504
eval/env_infos/final/reward_ctrl Max         -0.255621
eval/env_infos/final/reward_ctrl Min         -0.478288
eval/env_infos/initial/reward_ctrl Mean      -0.200022
eval/env_infos/initial/reward_ctrl Std        0.0189173
eval/env_infos/initial/reward_ctrl Max       -0.166549
eval/env_infos/initial/reward_ctrl Min       -0.224766
eval/env_infos/reward_ctrl Mean              -0.432712
eval/env_infos/reward_ctrl Std                0.0734302
eval/env_infos/reward_ctrl Max               -0.138625
eval/env_infos/reward_ctrl Min               -0.585552
time/data storing (s)                         0.00472603
time/evaluation sampling (s)                  2.07708
time/exploration sampling (s)                 0.535609
time/logging (s)                              0.0144261
time/sac training (s)                         7.77563
time/saving (s)                               0.00387208
time/training (s)                             4.4299e-05
time/epoch (s)                               10.4114
time/total (s)                              928.416
Epoch                                        86
---------------------------------------  ---------------
2021-11-24 00:44:50.564699 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 87 finished
---------------------------------------  ---------------
epoch                                        87
replay_buffer/size                        89000
trainer/num train calls                   88000
trainer/QF1 Loss                              8.02003
trainer/QF2 Loss                              6.74171
trainer/Policy Loss                        -173.865
trainer/Q1 Predictions Mean                 174.02
trainer/Q1 Predictions Std                   94.5481
trainer/Q1 Predictions Max                  275.049
trainer/Q1 Predictions Min                    7.55259
trainer/Q2 Predictions Mean                 173.683
trainer/Q2 Predictions Std                   94.3498
trainer/Q2 Predictions Max                  276.052
trainer/Q2 Predictions Min                    6.9127
trainer/Q Targets Mean                      174.084
trainer/Q Targets Std                        94.4619
trainer/Q Targets Max                       276.685
trainer/Q Targets Min                         6.5971
trainer/Log Pis Mean                          5.29578
trainer/Log Pis Std                           5.02278
trainer/Log Pis Max                          19.0353
trainer/Log Pis Min                          -6.43425
trainer/policy/mean Mean                      0.0329405
trainer/policy/mean Std                       0.758773
trainer/policy/mean Max                       0.99995
trainer/policy/mean Min                      -0.997339
trainer/policy/normal/std Mean                0.464924
trainer/policy/normal/std Std                 0.130902
trainer/policy/normal/std Max                 0.948616
trainer/policy/normal/std Min                 0.135012
trainer/policy/normal/log_std Mean           -0.810238
trainer/policy/normal/log_std Std             0.309891
trainer/policy/normal/log_std Max            -0.0527511
trainer/policy/normal/log_std Min            -2.00239
trainer/Alpha                                 0.0677959
trainer/Alpha Loss                           -1.89524
expl/num steps total                      89000
expl/num paths total                         89
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.08476
expl/Rewards Std                              1.07906
expl/Rewards Max                              6.21377
expl/Rewards Min                             -0.191833
expl/Returns Mean                          4084.76
expl/Returns Std                              0
expl/Returns Max                           4084.76
expl/Returns Min                           4084.76
expl/Actions Mean                             0.0661353
expl/Actions Std                              0.832152
expl/Actions Max                              0.999909
expl/Actions Min                             -0.999391
expl/Num Paths                                1
expl/Average Returns                       4084.76
expl/env_infos/final/reward_run Mean          2.5221
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.5221
expl/env_infos/final/reward_run Min           2.5221
expl/env_infos/initial/reward_run Mean        0.347195
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.347195
expl/env_infos/initial/reward_run Min         0.347195
expl/env_infos/reward_run Mean                4.50287
expl/env_infos/reward_run Std                 1.0831
expl/env_infos/reward_run Max                 6.68046
expl/env_infos/reward_run Min                 0.0885749
expl/env_infos/final/reward_ctrl Mean        -0.317752
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.317752
expl/env_infos/final/reward_ctrl Min         -0.317752
expl/env_infos/initial/reward_ctrl Mean      -0.302233
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.302233
expl/env_infos/initial/reward_ctrl Min       -0.302233
expl/env_infos/reward_ctrl Mean              -0.41811
expl/env_infos/reward_ctrl Std                0.0808768
expl/env_infos/reward_ctrl Max               -0.145501
expl/env_infos/reward_ctrl Min               -0.579095
eval/num steps total                     440000
eval/num paths total                        440
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.98646
eval/Rewards Std                              1.13235
eval/Rewards Max                              6.52743
eval/Rewards Min                             -1.26139
eval/Returns Mean                          3986.46
eval/Returns Std                            129.857
eval/Returns Max                           4094.06
eval/Returns Min                           3735.52
eval/Actions Mean                             0.06499
eval/Actions Std                              0.842285
eval/Actions Max                              0.999732
eval/Actions Min                             -0.999473
eval/Num Paths                                5
eval/Average Returns                       3986.46
eval/env_infos/final/reward_run Mean          3.42053
eval/env_infos/final/reward_run Std           1.042
eval/env_infos/final/reward_run Max           5.27328
eval/env_infos/final/reward_run Min           2.35076
eval/env_infos/initial/reward_run Mean        0.00329865
eval/env_infos/initial/reward_run Std         0.183386
eval/env_infos/initial/reward_run Max         0.368991
eval/env_infos/initial/reward_run Min        -0.105638
eval/env_infos/reward_run Mean                4.41466
eval/env_infos/reward_run Std                 1.13592
eval/env_infos/reward_run Max                 7.02148
eval/env_infos/reward_run Min                -0.714895
eval/env_infos/final/reward_ctrl Mean        -0.434431
eval/env_infos/final/reward_ctrl Std          0.149463
eval/env_infos/final/reward_ctrl Max         -0.144732
eval/env_infos/final/reward_ctrl Min         -0.576357
eval/env_infos/initial/reward_ctrl Mean      -0.20878
eval/env_infos/initial/reward_ctrl Std        0.0605942
eval/env_infos/initial/reward_ctrl Max       -0.143147
eval/env_infos/initial/reward_ctrl Min       -0.320356
eval/env_infos/reward_ctrl Mean              -0.428201
eval/env_infos/reward_ctrl Std                0.0801075
eval/env_infos/reward_ctrl Max               -0.122306
eval/env_infos/reward_ctrl Min               -0.58409
time/data storing (s)                         0.00478864
time/evaluation sampling (s)                  2.0444
time/exploration sampling (s)                 0.547681
time/logging (s)                              0.0137717
time/sac training (s)                         7.77796
time/saving (s)                               0.00429929
time/training (s)                             3.9614e-05
time/epoch (s)                               10.3929
time/total (s)                              939.124
Epoch                                        87
---------------------------------------  ---------------
2021-11-24 00:45:01.296572 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 88 finished
---------------------------------------  ---------------
epoch                                        88
replay_buffer/size                        90000
trainer/num train calls                   89000
trainer/QF1 Loss                             10.3385
trainer/QF2 Loss                              8.60573
trainer/Policy Loss                        -188.191
trainer/Q1 Predictions Mean                 188.047
trainer/Q1 Predictions Std                   86.5301
trainer/Q1 Predictions Max                  274.906
trainer/Q1 Predictions Min                    5.88959
trainer/Q2 Predictions Mean                 188.095
trainer/Q2 Predictions Std                   86.4451
trainer/Q2 Predictions Max                  279.575
trainer/Q2 Predictions Min                    8.4072
trainer/Q Targets Mean                      188.2
trainer/Q Targets Std                        86.7065
trainer/Q Targets Max                       281.526
trainer/Q Targets Min                         8.37384
trainer/Log Pis Mean                          6.33531
trainer/Log Pis Std                           5.19084
trainer/Log Pis Max                          27.5682
trainer/Log Pis Min                          -4.63103
trainer/policy/mean Mean                      0.0444453
trainer/policy/mean Std                       0.780951
trainer/policy/mean Max                       0.999935
trainer/policy/mean Min                      -0.999962
trainer/policy/normal/std Mean                0.456731
trainer/policy/normal/std Std                 0.12506
trainer/policy/normal/std Max                 0.932032
trainer/policy/normal/std Min                 0.123855
trainer/policy/normal/log_std Mean           -0.825043
trainer/policy/normal/log_std Std             0.298276
trainer/policy/normal/log_std Max            -0.0703885
trainer/policy/normal/log_std Min            -2.08864
trainer/Alpha                                 0.0695966
trainer/Alpha Loss                            0.893605
expl/num steps total                      90000
expl/num paths total                         90
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.08831
expl/Rewards Std                              1.09294
expl/Rewards Max                              6.0548
expl/Rewards Min                             -0.953015
expl/Returns Mean                          4088.31
expl/Returns Std                              0
expl/Returns Max                           4088.31
expl/Returns Min                           4088.31
expl/Actions Mean                             0.0722451
expl/Actions Std                              0.841936
expl/Actions Max                              0.999965
expl/Actions Min                             -0.999596
expl/Num Paths                                1
expl/Average Returns                       4088.31
expl/env_infos/final/reward_run Mean          4.07523
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.07523
expl/env_infos/final/reward_run Min           4.07523
expl/env_infos/initial/reward_run Mean       -0.0854897
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0854897
expl/env_infos/initial/reward_run Min        -0.0854897
expl/env_infos/reward_run Mean                4.51676
expl/env_infos/reward_run Std                 1.09906
expl/env_infos/reward_run Max                 6.59338
expl/env_infos/reward_run Min                -0.480691
expl/env_infos/final/reward_ctrl Mean        -0.372499
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.372499
expl/env_infos/final/reward_ctrl Min         -0.372499
expl/env_infos/initial/reward_ctrl Mean      -0.235919
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.235919
expl/env_infos/initial/reward_ctrl Min       -0.235919
expl/env_infos/reward_ctrl Mean              -0.428445
expl/env_infos/reward_ctrl Std                0.0774295
expl/env_infos/reward_ctrl Max               -0.0991224
expl/env_infos/reward_ctrl Min               -0.578026
eval/num steps total                     445000
eval/num paths total                        445
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.25791
eval/Rewards Std                              1.11569
eval/Rewards Max                              6.64537
eval/Rewards Min                             -1.0525
eval/Returns Mean                          4257.91
eval/Returns Std                             67.1686
eval/Returns Max                           4317.16
eval/Returns Min                           4136.39
eval/Actions Mean                             0.0665705
eval/Actions Std                              0.851551
eval/Actions Max                              0.999947
eval/Actions Min                             -0.999812
eval/Num Paths                                5
eval/Average Returns                       4257.91
eval/env_infos/final/reward_run Mean          4.6876
eval/env_infos/final/reward_run Std           0.704578
eval/env_infos/final/reward_run Max           5.84042
eval/env_infos/final/reward_run Min           3.81505
eval/env_infos/initial/reward_run Mean        0.162202
eval/env_infos/initial/reward_run Std         0.213103
eval/env_infos/initial/reward_run Max         0.524121
eval/env_infos/initial/reward_run Min        -0.0905162
eval/env_infos/reward_run Mean                4.69566
eval/env_infos/reward_run Std                 1.13005
eval/env_infos/reward_run Max                 7.18956
eval/env_infos/reward_run Min                -0.68891
eval/env_infos/final/reward_ctrl Mean        -0.45628
eval/env_infos/final/reward_ctrl Std          0.0790942
eval/env_infos/final/reward_ctrl Max         -0.335729
eval/env_infos/final/reward_ctrl Min         -0.573659
eval/env_infos/initial/reward_ctrl Mean      -0.21326
eval/env_infos/initial/reward_ctrl Std        0.0538559
eval/env_infos/initial/reward_ctrl Max       -0.150682
eval/env_infos/initial/reward_ctrl Min       -0.288464
eval/env_infos/reward_ctrl Mean              -0.437742
eval/env_infos/reward_ctrl Std                0.0772018
eval/env_infos/reward_ctrl Max               -0.11596
eval/env_infos/reward_ctrl Min               -0.591356
time/data storing (s)                         0.00450626
time/evaluation sampling (s)                  2.00948
time/exploration sampling (s)                 0.551069
time/logging (s)                              0.0136374
time/sac training (s)                         7.815
time/saving (s)                               0.00378944
time/training (s)                             3.4805e-05
time/epoch (s)                               10.3975
time/total (s)                              949.841
Epoch                                        88
---------------------------------------  ---------------
2021-11-24 00:45:11.955318 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 89 finished
---------------------------------------  ---------------
epoch                                        89
replay_buffer/size                        91000
trainer/num train calls                   90000
trainer/QF1 Loss                             12.0316
trainer/QF2 Loss                              7.7473
trainer/Policy Loss                        -177.395
trainer/Q1 Predictions Mean                 177.469
trainer/Q1 Predictions Std                   96.0563
trainer/Q1 Predictions Max                  289.394
trainer/Q1 Predictions Min                    5.32022
trainer/Q2 Predictions Mean                 177.253
trainer/Q2 Predictions Std                   95.8754
trainer/Q2 Predictions Max                  287.291
trainer/Q2 Predictions Min                    7.67015
trainer/Q Targets Mean                      176.872
trainer/Q Targets Std                        95.5949
trainer/Q Targets Max                       291.136
trainer/Q Targets Min                         6.64499
trainer/Log Pis Mean                          6.11385
trainer/Log Pis Std                           5.20035
trainer/Log Pis Max                          25.4933
trainer/Log Pis Min                          -7.97643
trainer/policy/mean Mean                      0.00801757
trainer/policy/mean Std                       0.779328
trainer/policy/mean Max                       0.999871
trainer/policy/mean Min                      -0.999931
trainer/policy/normal/std Mean                0.467466
trainer/policy/normal/std Std                 0.133051
trainer/policy/normal/std Max                 0.881842
trainer/policy/normal/std Min                 0.116493
trainer/policy/normal/log_std Mean           -0.805672
trainer/policy/normal/log_std Std             0.312919
trainer/policy/normal/log_std Max            -0.125742
trainer/policy/normal/log_std Min            -2.14992
trainer/Alpha                                 0.0697162
trainer/Alpha Loss                            0.303208
expl/num steps total                      91000
expl/num paths total                         91
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.10541
expl/Rewards Std                              1.0995
expl/Rewards Max                              6.32492
expl/Rewards Min                             -0.829069
expl/Returns Mean                          4105.41
expl/Returns Std                              0
expl/Returns Max                           4105.41
expl/Returns Min                           4105.41
expl/Actions Mean                             0.0132627
expl/Actions Std                              0.837025
expl/Actions Max                              0.999484
expl/Actions Min                             -0.999848
expl/Num Paths                                1
expl/Average Returns                       4105.41
expl/env_infos/final/reward_run Mean          4.06861
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.06861
expl/env_infos/final/reward_run Min           4.06861
expl/env_infos/initial/reward_run Mean       -0.189109
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.189109
expl/env_infos/initial/reward_run Min        -0.189109
expl/env_infos/reward_run Mean                4.52589
expl/env_infos/reward_run Std                 1.09415
expl/env_infos/reward_run Max                 6.7978
expl/env_infos/reward_run Min                -0.359807
expl/env_infos/final/reward_ctrl Mean        -0.327356
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.327356
expl/env_infos/final/reward_ctrl Min         -0.327356
expl/env_infos/initial/reward_ctrl Mean      -0.165975
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.165975
expl/env_infos/initial/reward_ctrl Min       -0.165975
expl/env_infos/reward_ctrl Mean              -0.420472
expl/env_infos/reward_ctrl Std                0.0768587
expl/env_infos/reward_ctrl Max               -0.165947
expl/env_infos/reward_ctrl Min               -0.583607
eval/num steps total                     450000
eval/num paths total                        450
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.25057
eval/Rewards Std                              1.13167
eval/Rewards Max                              6.43557
eval/Rewards Min                             -1.14817
eval/Returns Mean                          4250.57
eval/Returns Std                             80.3327
eval/Returns Max                           4337.3
eval/Returns Min                           4152.45
eval/Actions Mean                             0.0340819
eval/Actions Std                              0.850437
eval/Actions Max                              0.999848
eval/Actions Min                             -0.999868
eval/Num Paths                                5
eval/Average Returns                       4250.57
eval/env_infos/final/reward_run Mean          4.68233
eval/env_infos/final/reward_run Std           0.367301
eval/env_infos/final/reward_run Max           5.38845
eval/env_infos/final/reward_run Min           4.36767
eval/env_infos/initial/reward_run Mean       -0.0109949
eval/env_infos/initial/reward_run Std         0.275786
eval/env_infos/initial/reward_run Max         0.469523
eval/env_infos/initial/reward_run Min        -0.263663
eval/env_infos/reward_run Mean                4.68521
eval/env_infos/reward_run Std                 1.12924
eval/env_infos/reward_run Max                 6.9482
eval/env_infos/reward_run Min                -0.903593
eval/env_infos/final/reward_ctrl Mean        -0.435526
eval/env_infos/final/reward_ctrl Std          0.0911345
eval/env_infos/final/reward_ctrl Max         -0.271868
eval/env_infos/final/reward_ctrl Min         -0.524654
eval/env_infos/initial/reward_ctrl Mean      -0.182887
eval/env_infos/initial/reward_ctrl Std        0.0449682
eval/env_infos/initial/reward_ctrl Max       -0.105104
eval/env_infos/initial/reward_ctrl Min       -0.245795
eval/env_infos/reward_ctrl Mean              -0.434643
eval/env_infos/reward_ctrl Std                0.0752618
eval/env_infos/reward_ctrl Max               -0.105104
eval/env_infos/reward_ctrl Min               -0.587388
time/data storing (s)                         0.00456319
time/evaluation sampling (s)                  2.01685
time/exploration sampling (s)                 0.53498
time/logging (s)                              0.0147092
time/sac training (s)                         7.75826
time/saving (s)                               0.00427684
time/training (s)                             4.9158e-05
time/epoch (s)                               10.3337
time/total (s)                              960.486
Epoch                                        89
---------------------------------------  ---------------
2021-11-24 00:45:22.645466 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 90 finished
---------------------------------------  ---------------
epoch                                        90
replay_buffer/size                        92000
trainer/num train calls                   91000
trainer/QF1 Loss                             10.583
trainer/QF2 Loss                              8.95893
trainer/Policy Loss                        -194.244
trainer/Q1 Predictions Mean                 194.528
trainer/Q1 Predictions Std                   87.4583
trainer/Q1 Predictions Max                  285.038
trainer/Q1 Predictions Min                    7.81315
trainer/Q2 Predictions Mean                 194.269
trainer/Q2 Predictions Std                   87.1699
trainer/Q2 Predictions Max                  282.559
trainer/Q2 Predictions Min                    7.96856
trainer/Q Targets Mean                      194.47
trainer/Q Targets Std                        87.3869
trainer/Q Targets Max                       282.191
trainer/Q Targets Min                         6.99392
trainer/Log Pis Mean                          6.38367
trainer/Log Pis Std                           4.99772
trainer/Log Pis Max                          19.4261
trainer/Log Pis Min                          -4.47532
trainer/policy/mean Mean                      0.0171775
trainer/policy/mean Std                       0.777567
trainer/policy/mean Max                       0.999809
trainer/policy/mean Min                      -0.998452
trainer/policy/normal/std Mean                0.463453
trainer/policy/normal/std Std                 0.130388
trainer/policy/normal/std Max                 1.14691
trainer/policy/normal/std Min                 0.117645
trainer/policy/normal/log_std Mean           -0.81297
trainer/policy/normal/log_std Std             0.308253
trainer/policy/normal/log_std Max             0.13707
trainer/policy/normal/log_std Min            -2.14008
trainer/Alpha                                 0.0713145
trainer/Alpha Loss                            1.01315
expl/num steps total                      92000
expl/num paths total                         92
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.21761
expl/Rewards Std                              1.0761
expl/Rewards Max                              6.29386
expl/Rewards Min                             -1.14046
expl/Returns Mean                          4217.61
expl/Returns Std                              0
expl/Returns Max                           4217.61
expl/Returns Min                           4217.61
expl/Actions Mean                             0.0395912
expl/Actions Std                              0.836279
expl/Actions Max                              0.999679
expl/Actions Min                             -0.999599
expl/Num Paths                                1
expl/Average Returns                       4217.61
expl/env_infos/final/reward_run Mean          4.80036
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.80036
expl/env_infos/final/reward_run Min           4.80036
expl/env_infos/initial/reward_run Mean       -0.341024
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.341024
expl/env_infos/initial/reward_run Min        -0.341024
expl/env_infos/reward_run Mean                4.63817
expl/env_infos/reward_run Std                 1.0754
expl/env_infos/reward_run Max                 6.74054
expl/env_infos/reward_run Min                -0.610837
expl/env_infos/final/reward_ctrl Mean        -0.378887
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.378887
expl/env_infos/final/reward_ctrl Min         -0.378887
expl/env_infos/initial/reward_ctrl Mean      -0.201581
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.201581
expl/env_infos/initial/reward_ctrl Min       -0.201581
expl/env_infos/reward_ctrl Mean              -0.420558
expl/env_infos/reward_ctrl Std                0.0772491
expl/env_infos/reward_ctrl Max               -0.131175
expl/env_infos/reward_ctrl Min               -0.578665
eval/num steps total                     455000
eval/num paths total                        455
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.05814
eval/Rewards Std                              1.44047
eval/Rewards Max                              6.47764
eval/Rewards Min                             -1.58304
eval/Returns Mean                          4058.14
eval/Returns Std                            385.922
eval/Returns Max                           4350.74
eval/Returns Min                           3304.94
eval/Actions Mean                             0.0354363
eval/Actions Std                              0.838403
eval/Actions Max                              0.999973
eval/Actions Min                             -0.999756
eval/Num Paths                                5
eval/Average Returns                       4058.14
eval/env_infos/final/reward_run Mean          4.25024
eval/env_infos/final/reward_run Std           1.83837
eval/env_infos/final/reward_run Max           6.42638
eval/env_infos/final/reward_run Min           1.36779
eval/env_infos/initial/reward_run Mean       -0.124363
eval/env_infos/initial/reward_run Std         0.199991
eval/env_infos/initial/reward_run Max         0.201193
eval/env_infos/initial/reward_run Min        -0.356853
eval/env_infos/reward_run Mean                4.48065
eval/env_infos/reward_run Std                 1.46639
eval/env_infos/reward_run Max                 7.01117
eval/env_infos/reward_run Min                -1.25337
eval/env_infos/final/reward_ctrl Mean        -0.372685
eval/env_infos/final/reward_ctrl Std          0.103296
eval/env_infos/final/reward_ctrl Max         -0.256623
eval/env_infos/final/reward_ctrl Min         -0.525385
eval/env_infos/initial/reward_ctrl Mean      -0.191989
eval/env_infos/initial/reward_ctrl Std        0.0227401
eval/env_infos/initial/reward_ctrl Max       -0.169192
eval/env_infos/initial/reward_ctrl Min       -0.219669
eval/env_infos/reward_ctrl Mean              -0.422506
eval/env_infos/reward_ctrl Std                0.0834267
eval/env_infos/reward_ctrl Max               -0.0760759
eval/env_infos/reward_ctrl Min               -0.583424
time/data storing (s)                         0.00452533
time/evaluation sampling (s)                  2.00253
time/exploration sampling (s)                 0.524964
time/logging (s)                              0.0137631
time/sac training (s)                         7.80891
time/saving (s)                               0.00439825
time/training (s)                             4.9353e-05
time/epoch (s)                               10.3591
time/total (s)                              971.161
Epoch                                        90
---------------------------------------  ---------------
2021-11-24 00:45:33.347971 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 91 finished
---------------------------------------  ---------------
epoch                                        91
replay_buffer/size                        93000
trainer/num train calls                   92000
trainer/QF1 Loss                              9.92247
trainer/QF2 Loss                              7.09515
trainer/Policy Loss                        -191.332
trainer/Q1 Predictions Mean                 191.282
trainer/Q1 Predictions Std                   90.4792
trainer/Q1 Predictions Max                  286.703
trainer/Q1 Predictions Min                    7.12122
trainer/Q2 Predictions Mean                 191.381
trainer/Q2 Predictions Std                   90.5162
trainer/Q2 Predictions Max                  283.693
trainer/Q2 Predictions Min                    8.0298
trainer/Q Targets Mean                      191.204
trainer/Q Targets Std                        90.41
trainer/Q Targets Max                       282.317
trainer/Q Targets Min                         7.07068
trainer/Log Pis Mean                          6.37488
trainer/Log Pis Std                           5.2043
trainer/Log Pis Max                          23.311
trainer/Log Pis Min                          -5.10553
trainer/policy/mean Mean                      0.0219765
trainer/policy/mean Std                       0.781038
trainer/policy/mean Max                       0.999921
trainer/policy/mean Min                      -0.999912
trainer/policy/normal/std Mean                0.474785
trainer/policy/normal/std Std                 0.13808
trainer/policy/normal/std Max                 1.1419
trainer/policy/normal/std Min                 0.117116
trainer/policy/normal/log_std Mean           -0.790979
trainer/policy/normal/log_std Std             0.314487
trainer/policy/normal/log_std Max             0.132695
trainer/policy/normal/log_std Min            -2.14459
trainer/Alpha                                 0.0729385
trainer/Alpha Loss                            0.981487
expl/num steps total                      93000
expl/num paths total                         93
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.09184
expl/Rewards Std                              1.12193
expl/Rewards Max                              6.45141
expl/Rewards Min                             -0.693616
expl/Returns Mean                          4091.84
expl/Returns Std                              0
expl/Returns Max                           4091.84
expl/Returns Min                           4091.84
expl/Actions Mean                             0.0219323
expl/Actions Std                              0.84318
expl/Actions Max                              0.999923
expl/Actions Min                             -0.999935
expl/Num Paths                                1
expl/Average Returns                       4091.84
expl/env_infos/final/reward_run Mean          5.43221
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.43221
expl/env_infos/final/reward_run Min           5.43221
expl/env_infos/initial/reward_run Mean       -0.240985
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.240985
expl/env_infos/initial/reward_run Min        -0.240985
expl/env_infos/reward_run Mean                4.5187
expl/env_infos/reward_run Std                 1.12507
expl/env_infos/reward_run Max                 6.99798
expl/env_infos/reward_run Min                -0.240985
expl/env_infos/final/reward_ctrl Mean        -0.352356
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.352356
expl/env_infos/final/reward_ctrl Min         -0.352356
expl/env_infos/initial/reward_ctrl Mean      -0.348247
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.348247
expl/env_infos/initial/reward_ctrl Min       -0.348247
expl/env_infos/reward_ctrl Mean              -0.42686
expl/env_infos/reward_ctrl Std                0.0778132
expl/env_infos/reward_ctrl Max               -0.132666
expl/env_infos/reward_ctrl Min               -0.589481
eval/num steps total                     460000
eval/num paths total                        460
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.19403
eval/Rewards Std                              1.15809
eval/Rewards Max                              6.61269
eval/Rewards Min                             -0.826406
eval/Returns Mean                          4194.03
eval/Returns Std                             60.302
eval/Returns Max                           4257.28
eval/Returns Min                           4088.66
eval/Actions Mean                             0.0244974
eval/Actions Std                              0.854216
eval/Actions Max                              0.999306
eval/Actions Min                             -0.99982
eval/Num Paths                                5
eval/Average Returns                       4194.03
eval/env_infos/final/reward_run Mean          5.17715
eval/env_infos/final/reward_run Std           0.903382
eval/env_infos/final/reward_run Max           6.64512
eval/env_infos/final/reward_run Min           4.02243
eval/env_infos/initial/reward_run Mean        0.0633883
eval/env_infos/initial/reward_run Std         0.264273
eval/env_infos/initial/reward_run Max         0.569879
eval/env_infos/initial/reward_run Min        -0.154796
eval/env_infos/reward_run Mean                4.6322
eval/env_infos/reward_run Std                 1.16646
eval/env_infos/reward_run Max                 7.17418
eval/env_infos/reward_run Min                -0.365527
eval/env_infos/final/reward_ctrl Mean        -0.457281
eval/env_infos/final/reward_ctrl Std          0.0871363
eval/env_infos/final/reward_ctrl Max         -0.295149
eval/env_infos/final/reward_ctrl Min         -0.536741
eval/env_infos/initial/reward_ctrl Mean      -0.265619
eval/env_infos/initial/reward_ctrl Std        0.0267818
eval/env_infos/initial/reward_ctrl Max       -0.23655
eval/env_infos/initial/reward_ctrl Min       -0.303726
eval/env_infos/reward_ctrl Mean              -0.438171
eval/env_infos/reward_ctrl Std                0.0757392
eval/env_infos/reward_ctrl Max               -0.113216
eval/env_infos/reward_ctrl Min               -0.588988
time/data storing (s)                         0.00450207
time/evaluation sampling (s)                  2.08878
time/exploration sampling (s)                 0.53991
time/logging (s)                              0.0136161
time/sac training (s)                         7.7246
time/saving (s)                               0.00379401
time/training (s)                             3.3888e-05
time/epoch (s)                               10.3752
time/total (s)                              981.849
Epoch                                        91
---------------------------------------  ---------------
2021-11-24 00:45:44.210331 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 92 finished
---------------------------------------  ---------------
epoch                                        92
replay_buffer/size                        94000
trainer/num train calls                   93000
trainer/QF1 Loss                              8.49756
trainer/QF2 Loss                              7.13009
trainer/Policy Loss                        -186.656
trainer/Q1 Predictions Mean                 186.766
trainer/Q1 Predictions Std                   95.6701
trainer/Q1 Predictions Max                  295.224
trainer/Q1 Predictions Min                    9.43181
trainer/Q2 Predictions Mean                 186.356
trainer/Q2 Predictions Std                   95.3629
trainer/Q2 Predictions Max                  293.724
trainer/Q2 Predictions Min                    8.38153
trainer/Q Targets Mean                      186.604
trainer/Q Targets Std                        95.5552
trainer/Q Targets Max                       297.043
trainer/Q Targets Min                         7.80287
trainer/Log Pis Mean                          6.27608
trainer/Log Pis Std                           5.14798
trainer/Log Pis Max                          21.7852
trainer/Log Pis Min                          -6.65798
trainer/policy/mean Mean                      0.0187505
trainer/policy/mean Std                       0.77613
trainer/policy/mean Max                       0.999802
trainer/policy/mean Min                      -0.999835
trainer/policy/normal/std Mean                0.467751
trainer/policy/normal/std Std                 0.133464
trainer/policy/normal/std Max                 0.91454
trainer/policy/normal/std Min                 0.127352
trainer/policy/normal/log_std Mean           -0.805874
trainer/policy/normal/log_std Std             0.316677
trainer/policy/normal/log_std Max            -0.0893342
trainer/policy/normal/log_std Min            -2.0608
trainer/Alpha                                 0.0738848
trainer/Alpha Loss                            0.719262
expl/num steps total                      94000
expl/num paths total                         94
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.11058
expl/Rewards Std                              1.11006
expl/Rewards Max                              6.26773
expl/Rewards Min                             -0.832802
expl/Returns Mean                          4110.58
expl/Returns Std                              0
expl/Returns Max                           4110.58
expl/Returns Min                           4110.58
expl/Actions Mean                             0.0221803
expl/Actions Std                              0.836754
expl/Actions Max                              0.999916
expl/Actions Min                             -0.999644
expl/Num Paths                                1
expl/Average Returns                       4110.58
expl/env_infos/final/reward_run Mean          4.49369
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.49369
expl/env_infos/final/reward_run Min           4.49369
expl/env_infos/initial/reward_run Mean       -0.274
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.274
expl/env_infos/initial/reward_run Min        -0.274
expl/env_infos/reward_run Mean                4.53097
expl/env_infos/reward_run Std                 1.09946
expl/env_infos/reward_run Max                 6.74337
expl/env_infos/reward_run Min                -0.390488
expl/env_infos/final/reward_ctrl Mean        -0.257474
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.257474
expl/env_infos/final/reward_ctrl Min         -0.257474
expl/env_infos/initial/reward_ctrl Mean      -0.271009
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.271009
expl/env_infos/initial/reward_ctrl Min       -0.271009
expl/env_infos/reward_ctrl Mean              -0.42039
expl/env_infos/reward_ctrl Std                0.0809271
expl/env_infos/reward_ctrl Max               -0.147176
expl/env_infos/reward_ctrl Min               -0.588271
eval/num steps total                     465000
eval/num paths total                        465
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.15242
eval/Rewards Std                              1.16764
eval/Rewards Max                              6.47771
eval/Rewards Min                             -1.45434
eval/Returns Mean                          4152.42
eval/Returns Std                             72.959
eval/Returns Max                           4291.54
eval/Returns Min                           4086.25
eval/Actions Mean                             0.0180572
eval/Actions Std                              0.849134
eval/Actions Max                              0.999908
eval/Actions Min                             -0.999251
eval/Num Paths                                5
eval/Average Returns                       4152.42
eval/env_infos/final/reward_run Mean          4.63891
eval/env_infos/final/reward_run Std           1.18217
eval/env_infos/final/reward_run Max           6.18172
eval/env_infos/final/reward_run Min           2.73263
eval/env_infos/initial/reward_run Mean       -0.2154
eval/env_infos/initial/reward_run Std         0.074703
eval/env_infos/initial/reward_run Max        -0.10127
eval/env_infos/initial/reward_run Min        -0.313921
eval/env_infos/reward_run Mean                4.58523
eval/env_infos/reward_run Std                 1.16201
eval/env_infos/reward_run Max                 7.00765
eval/env_infos/reward_run Min                -0.882501
eval/env_infos/final/reward_ctrl Mean        -0.458755
eval/env_infos/final/reward_ctrl Std          0.047019
eval/env_infos/final/reward_ctrl Max         -0.379202
eval/env_infos/final/reward_ctrl Min         -0.501324
eval/env_infos/initial/reward_ctrl Mean      -0.204301
eval/env_infos/initial/reward_ctrl Std        0.0183318
eval/env_infos/initial/reward_ctrl Max       -0.168238
eval/env_infos/initial/reward_ctrl Min       -0.219404
eval/env_infos/reward_ctrl Mean              -0.432812
eval/env_infos/reward_ctrl Std                0.0780866
eval/env_infos/reward_ctrl Max               -0.126297
eval/env_infos/reward_ctrl Min               -0.588986
time/data storing (s)                         0.00450907
time/evaluation sampling (s)                  2.06869
time/exploration sampling (s)                 0.540914
time/logging (s)                              0.0144139
time/sac training (s)                         7.89671
time/saving (s)                               0.00394535
time/training (s)                             5.2559e-05
time/epoch (s)                               10.5292
time/total (s)                              992.697
Epoch                                        92
---------------------------------------  ---------------
2021-11-24 00:45:55.124956 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 93 finished
---------------------------------------  ---------------
epoch                                        93
replay_buffer/size                        95000
trainer/num train calls                   94000
trainer/QF1 Loss                              9.4442
trainer/QF2 Loss                              8.25469
trainer/Policy Loss                        -187.222
trainer/Q1 Predictions Mean                 187.262
trainer/Q1 Predictions Std                   94.998
trainer/Q1 Predictions Max                  284.866
trainer/Q1 Predictions Min                    7.10449
trainer/Q2 Predictions Mean                 187.08
trainer/Q2 Predictions Std                   94.9617
trainer/Q2 Predictions Max                  285.433
trainer/Q2 Predictions Min                    7.31677
trainer/Q Targets Mean                      187.685
trainer/Q Targets Std                        95.3015
trainer/Q Targets Max                       284.957
trainer/Q Targets Min                         7.44273
trainer/Log Pis Mean                          5.71617
trainer/Log Pis Std                           5.58205
trainer/Log Pis Max                          20.2044
trainer/Log Pis Min                          -7.75216
trainer/policy/mean Mean                      0.01465
trainer/policy/mean Std                       0.760352
trainer/policy/mean Max                       0.999724
trainer/policy/mean Min                      -0.999816
trainer/policy/normal/std Mean                0.463316
trainer/policy/normal/std Std                 0.134078
trainer/policy/normal/std Max                 1.10458
trainer/policy/normal/std Min                 0.105887
trainer/policy/normal/log_std Mean           -0.815145
trainer/policy/normal/log_std Std             0.313625
trainer/policy/normal/log_std Max             0.0994673
trainer/policy/normal/log_std Min            -2.24538
trainer/Alpha                                 0.0750152
trainer/Alpha Loss                           -0.735133
expl/num steps total                      95000
expl/num paths total                         95
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.08299
expl/Rewards Std                              1.08804
expl/Rewards Max                              6.24708
expl/Rewards Min                             -0.648751
expl/Returns Mean                          4082.99
expl/Returns Std                              0
expl/Returns Max                           4082.99
expl/Returns Min                           4082.99
expl/Actions Mean                             0.0422551
expl/Actions Std                              0.834198
expl/Actions Max                              0.999748
expl/Actions Min                             -0.999877
expl/Num Paths                                1
expl/Average Returns                       4082.99
expl/env_infos/final/reward_run Mean          6.17514
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.17514
expl/env_infos/final/reward_run Min           6.17514
expl/env_infos/initial/reward_run Mean       -0.0352477
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0352477
expl/env_infos/initial/reward_run Min        -0.0352477
expl/env_infos/reward_run Mean                4.5016
expl/env_infos/reward_run Std                 1.07795
expl/env_infos/reward_run Max                 6.61632
expl/env_infos/reward_run Min                -0.13153
expl/env_infos/final/reward_ctrl Mean        -0.431298
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.431298
expl/env_infos/final/reward_ctrl Min         -0.431298
expl/env_infos/initial/reward_ctrl Mean      -0.251854
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.251854
expl/env_infos/initial/reward_ctrl Min       -0.251854
expl/env_infos/reward_ctrl Mean              -0.418603
expl/env_infos/reward_ctrl Std                0.0770196
expl/env_infos/reward_ctrl Max               -0.184774
expl/env_infos/reward_ctrl Min               -0.577774
eval/num steps total                     470000
eval/num paths total                        470
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.17611
eval/Rewards Std                              1.143
eval/Rewards Max                              6.82252
eval/Rewards Min                             -1.07332
eval/Returns Mean                          4176.11
eval/Returns Std                             91.0386
eval/Returns Max                           4319.72
eval/Returns Min                           4064.31
eval/Actions Mean                             0.0395442
eval/Actions Std                              0.839854
eval/Actions Max                              0.999998
eval/Actions Min                             -0.999974
eval/Num Paths                                5
eval/Average Returns                       4176.11
eval/env_infos/final/reward_run Mean          3.77496
eval/env_infos/final/reward_run Std           0.997454
eval/env_infos/final/reward_run Max           5.22672
eval/env_infos/final/reward_run Min           2.31744
eval/env_infos/initial/reward_run Mean       -0.201637
eval/env_infos/initial/reward_run Std         0.169295
eval/env_infos/initial/reward_run Max         0.0802519
eval/env_infos/initial/reward_run Min        -0.438488
eval/env_infos/reward_run Mean                4.60026
eval/env_infos/reward_run Std                 1.14261
eval/env_infos/reward_run Max                 7.37998
eval/env_infos/reward_run Min                -0.561572
eval/env_infos/final/reward_ctrl Mean        -0.40957
eval/env_infos/final/reward_ctrl Std          0.0916578
eval/env_infos/final/reward_ctrl Max         -0.258371
eval/env_infos/final/reward_ctrl Min         -0.510647
eval/env_infos/initial/reward_ctrl Mean      -0.214792
eval/env_infos/initial/reward_ctrl Std        0.0427637
eval/env_infos/initial/reward_ctrl Max       -0.156963
eval/env_infos/initial/reward_ctrl Min       -0.2834
eval/env_infos/reward_ctrl Mean              -0.424151
eval/env_infos/reward_ctrl Std                0.0783772
eval/env_infos/reward_ctrl Max               -0.120549
eval/env_infos/reward_ctrl Min               -0.583878
time/data storing (s)                         0.00454628
time/evaluation sampling (s)                  2.08134
time/exploration sampling (s)                 0.562167
time/logging (s)                              0.0137111
time/sac training (s)                         7.91458
time/saving (s)                               0.0038123
time/training (s)                             3.5404e-05
time/epoch (s)                               10.5802
time/total (s)                             1003.6
Epoch                                        93
---------------------------------------  ---------------
2021-11-24 00:46:05.966148 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 94 finished
---------------------------------------  ---------------
epoch                                        94
replay_buffer/size                        96000
trainer/num train calls                   95000
trainer/QF1 Loss                              7.43718
trainer/QF2 Loss                              5.89891
trainer/Policy Loss                        -203.845
trainer/Q1 Predictions Mean                 203.842
trainer/Q1 Predictions Std                   88.4304
trainer/Q1 Predictions Max                  293.12
trainer/Q1 Predictions Min                    6.48871
trainer/Q2 Predictions Mean                 203.903
trainer/Q2 Predictions Std                   88.26
trainer/Q2 Predictions Max                  292.399
trainer/Q2 Predictions Min                    7.20615
trainer/Q Targets Mean                      204.149
trainer/Q Targets Std                        88.6248
trainer/Q Targets Max                       291.344
trainer/Q Targets Min                         5.64886
trainer/Log Pis Mean                          6.52868
trainer/Log Pis Std                           5.30665
trainer/Log Pis Max                          38.9023
trainer/Log Pis Min                          -5.49493
trainer/policy/mean Mean                     -0.0158024
trainer/policy/mean Std                       0.783304
trainer/policy/mean Max                       0.999895
trainer/policy/mean Min                      -0.999974
trainer/policy/normal/std Mean                0.452853
trainer/policy/normal/std Std                 0.133224
trainer/policy/normal/std Max                 1.02983
trainer/policy/normal/std Min                 0.116934
trainer/policy/normal/log_std Mean           -0.839676
trainer/policy/normal/log_std Std             0.319842
trainer/policy/normal/log_std Max             0.0293935
trainer/policy/normal/log_std Min            -2.14615
trainer/Alpha                                 0.0751385
trainer/Alpha Loss                            1.36844
expl/num steps total                      96000
expl/num paths total                         96
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.10584
expl/Rewards Std                              1.18584
expl/Rewards Max                              6.2965
expl/Rewards Min                             -0.365774
expl/Returns Mean                          4105.84
expl/Returns Std                              0
expl/Returns Max                           4105.84
expl/Returns Min                           4105.84
expl/Actions Mean                            -0.0043904
expl/Actions Std                              0.835097
expl/Actions Max                              0.999761
expl/Actions Min                             -0.999691
expl/Num Paths                                1
expl/Average Returns                       4105.84
expl/env_infos/final/reward_run Mean          3.85978
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.85978
expl/env_infos/final/reward_run Min           3.85978
expl/env_infos/initial/reward_run Mean        0.263973
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.263973
expl/env_infos/initial/reward_run Min         0.263973
expl/env_infos/reward_run Mean                4.52428
expl/env_infos/reward_run Std                 1.18415
expl/env_infos/reward_run Max                 6.84539
expl/env_infos/reward_run Min                -0.0823267
expl/env_infos/final/reward_ctrl Mean        -0.420785
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.420785
expl/env_infos/final/reward_ctrl Min         -0.420785
expl/env_infos/initial/reward_ctrl Mean      -0.178923
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.178923
expl/env_infos/initial/reward_ctrl Min       -0.178923
expl/env_infos/reward_ctrl Mean              -0.418444
expl/env_infos/reward_ctrl Std                0.0813852
expl/env_infos/reward_ctrl Max               -0.166782
expl/env_infos/reward_ctrl Min               -0.588378
eval/num steps total                     475000
eval/num paths total                        475
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.49561
eval/Rewards Std                              1.18008
eval/Rewards Max                              6.75252
eval/Rewards Min                             -1.3084
eval/Returns Mean                          4495.61
eval/Returns Std                            120.698
eval/Returns Max                           4643.69
eval/Returns Min                           4359.41
eval/Actions Mean                             0.00655102
eval/Actions Std                              0.851797
eval/Actions Max                              0.999865
eval/Actions Min                             -0.999882
eval/Num Paths                                5
eval/Average Returns                       4495.61
eval/env_infos/final/reward_run Mean          5.37973
eval/env_infos/final/reward_run Std           0.697455
eval/env_infos/final/reward_run Max           6.57441
eval/env_infos/final/reward_run Min           4.45122
eval/env_infos/initial/reward_run Mean       -0.159166
eval/env_infos/initial/reward_run Std         0.115989
eval/env_infos/initial/reward_run Max         0.0199448
eval/env_infos/initial/reward_run Min        -0.343835
eval/env_infos/reward_run Mean                4.93097
eval/env_infos/reward_run Std                 1.17779
eval/env_infos/reward_run Max                 7.26105
eval/env_infos/reward_run Min                -0.957091
eval/env_infos/final/reward_ctrl Mean        -0.435627
eval/env_infos/final/reward_ctrl Std          0.067174
eval/env_infos/final/reward_ctrl Max         -0.365635
eval/env_infos/final/reward_ctrl Min         -0.523244
eval/env_infos/initial/reward_ctrl Mean      -0.217912
eval/env_infos/initial/reward_ctrl Std        0.0245841
eval/env_infos/initial/reward_ctrl Max       -0.175875
eval/env_infos/initial/reward_ctrl Min       -0.243545
eval/env_infos/reward_ctrl Mean              -0.435361
eval/env_infos/reward_ctrl Std                0.0780917
eval/env_infos/reward_ctrl Max               -0.119636
eval/env_infos/reward_ctrl Min               -0.582377
time/data storing (s)                         0.00451277
time/evaluation sampling (s)                  2.04419
time/exploration sampling (s)                 0.541393
time/logging (s)                              0.0139295
time/sac training (s)                         7.90008
time/saving (s)                               0.00440558
time/training (s)                             4.3883e-05
time/epoch (s)                               10.5086
time/total (s)                             1014.42
Epoch                                        94
---------------------------------------  ---------------
2021-11-24 00:46:16.791499 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 95 finished
---------------------------------------  ---------------
epoch                                        95
replay_buffer/size                        97000
trainer/num train calls                   96000
trainer/QF1 Loss                              9.96663
trainer/QF2 Loss                              9.43393
trainer/Policy Loss                        -191.824
trainer/Q1 Predictions Mean                 191.974
trainer/Q1 Predictions Std                   97.8936
trainer/Q1 Predictions Max                  290.622
trainer/Q1 Predictions Min                    7.59762
trainer/Q2 Predictions Mean                 192.029
trainer/Q2 Predictions Std                   97.8522
trainer/Q2 Predictions Max                  291.838
trainer/Q2 Predictions Min                    8.18533
trainer/Q Targets Mean                      192.522
trainer/Q Targets Std                        98.1644
trainer/Q Targets Max                       297.113
trainer/Q Targets Min                         5.15816
trainer/Log Pis Mean                          5.70983
trainer/Log Pis Std                           5.07312
trainer/Log Pis Max                          23.6497
trainer/Log Pis Min                          -4.16136
trainer/policy/mean Mean                      0.0081577
trainer/policy/mean Std                       0.764718
trainer/policy/mean Max                       0.999871
trainer/policy/mean Min                      -0.999659
trainer/policy/normal/std Mean                0.459041
trainer/policy/normal/std Std                 0.133801
trainer/policy/normal/std Max                 1.07796
trainer/policy/normal/std Min                 0.102807
trainer/policy/normal/log_std Mean           -0.826238
trainer/policy/normal/log_std Std             0.32191
trainer/policy/normal/log_std Max             0.0750682
trainer/policy/normal/log_std Min            -2.27491
trainer/Alpha                                 0.0763515
trainer/Alpha Loss                           -0.746422
expl/num steps total                      97000
expl/num paths total                         97
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.15941
expl/Rewards Std                              1.1284
expl/Rewards Max                              6.29562
expl/Rewards Min                             -0.316218
expl/Returns Mean                          4159.41
expl/Returns Std                              0
expl/Returns Max                           4159.41
expl/Returns Min                           4159.41
expl/Actions Mean                             0.0493262
expl/Actions Std                              0.830241
expl/Actions Max                              0.999804
expl/Actions Min                             -0.99986
expl/Num Paths                                1
expl/Average Returns                       4159.41
expl/env_infos/final/reward_run Mean          5.51603
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.51603
expl/env_infos/final/reward_run Min           5.51603
expl/env_infos/initial/reward_run Mean        0.730216
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.730216
expl/env_infos/initial/reward_run Min         0.730216
expl/env_infos/reward_run Mean                4.57445
expl/env_infos/reward_run Std                 1.12565
expl/env_infos/reward_run Max                 6.79603
expl/env_infos/reward_run Min                 0.0766698
expl/env_infos/final/reward_ctrl Mean        -0.38477
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.38477
expl/env_infos/final/reward_ctrl Min         -0.38477
expl/env_infos/initial/reward_ctrl Mean      -0.283314
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.283314
expl/env_infos/initial/reward_ctrl Min       -0.283314
expl/env_infos/reward_ctrl Mean              -0.41504
expl/env_infos/reward_ctrl Std                0.0783417
expl/env_infos/reward_ctrl Max               -0.121051
expl/env_infos/reward_ctrl Min               -0.591707
eval/num steps total                     480000
eval/num paths total                        480
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.34431
eval/Rewards Std                              1.16047
eval/Rewards Max                              6.97775
eval/Rewards Min                             -0.488021
eval/Returns Mean                          4344.31
eval/Returns Std                             66.6947
eval/Returns Max                           4472.98
eval/Returns Min                           4281.38
eval/Actions Mean                             0.0477888
eval/Actions Std                              0.845484
eval/Actions Max                              0.999913
eval/Actions Min                             -0.999602
eval/Num Paths                                5
eval/Average Returns                       4344.31
eval/env_infos/final/reward_run Mean          4.93469
eval/env_infos/final/reward_run Std           1.08935
eval/env_infos/final/reward_run Max           6.58523
eval/env_infos/final/reward_run Min           3.65457
eval/env_infos/initial/reward_run Mean        0.24534
eval/env_infos/initial/reward_run Std         0.103738
eval/env_infos/initial/reward_run Max         0.392374
eval/env_infos/initial/reward_run Min         0.0701356
eval/env_infos/reward_run Mean                4.77459
eval/env_infos/reward_run Std                 1.15768
eval/env_infos/reward_run Max                 7.50188
eval/env_infos/reward_run Min                -0.129181
eval/env_infos/final/reward_ctrl Mean        -0.486056
eval/env_infos/final/reward_ctrl Std          0.0514657
eval/env_infos/final/reward_ctrl Max         -0.426771
eval/env_infos/final/reward_ctrl Min         -0.553327
eval/env_infos/initial/reward_ctrl Mean      -0.202481
eval/env_infos/initial/reward_ctrl Std        0.0277935
eval/env_infos/initial/reward_ctrl Max       -0.160123
eval/env_infos/initial/reward_ctrl Min       -0.247602
eval/env_infos/reward_ctrl Mean              -0.430276
eval/env_infos/reward_ctrl Std                0.0767462
eval/env_infos/reward_ctrl Max               -0.127566
eval/env_infos/reward_ctrl Min               -0.583868
time/data storing (s)                         0.00452405
time/evaluation sampling (s)                  2.06846
time/exploration sampling (s)                 0.541492
time/logging (s)                              0.0139746
time/sac training (s)                         7.86062
time/saving (s)                               0.00389438
time/training (s)                             4.847e-05
time/epoch (s)                               10.493
time/total (s)                             1025.23
Epoch                                        95
---------------------------------------  ---------------
2021-11-24 00:46:27.707704 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 96 finished
---------------------------------------  ---------------
epoch                                        96
replay_buffer/size                        98000
trainer/num train calls                   97000
trainer/QF1 Loss                              8.10002
trainer/QF2 Loss                              7.20921
trainer/Policy Loss                        -197.738
trainer/Q1 Predictions Mean                 197.888
trainer/Q1 Predictions Std                   95.882
trainer/Q1 Predictions Max                  289.559
trainer/Q1 Predictions Min                    9.43975
trainer/Q2 Predictions Mean                 197.802
trainer/Q2 Predictions Std                   95.7949
trainer/Q2 Predictions Max                  288.834
trainer/Q2 Predictions Min                    9.01689
trainer/Q Targets Mean                      198.104
trainer/Q Targets Std                        96.0962
trainer/Q Targets Max                       290.459
trainer/Q Targets Min                         7.97236
trainer/Log Pis Mean                          5.75371
trainer/Log Pis Std                           5.15005
trainer/Log Pis Max                          22.9249
trainer/Log Pis Min                          -4.89224
trainer/policy/mean Mean                      0.0566239
trainer/policy/mean Std                       0.759422
trainer/policy/mean Max                       0.999502
trainer/policy/mean Min                      -0.998285
trainer/policy/normal/std Mean                0.453919
trainer/policy/normal/std Std                 0.137079
trainer/policy/normal/std Max                 0.96631
trainer/policy/normal/std Min                 0.0940676
trainer/policy/normal/log_std Mean           -0.841765
trainer/policy/normal/log_std Std             0.33789
trainer/policy/normal/log_std Max            -0.0342709
trainer/policy/normal/log_std Min            -2.36374
trainer/Alpha                                 0.0775046
trainer/Alpha Loss                           -0.629877
expl/num steps total                      98000
expl/num paths total                         98
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.1292
expl/Rewards Std                              1.18918
expl/Rewards Max                              6.25595
expl/Rewards Min                             -0.790603
expl/Returns Mean                          4129.2
expl/Returns Std                              0
expl/Returns Max                           4129.2
expl/Returns Min                           4129.2
expl/Actions Mean                             0.0533185
expl/Actions Std                              0.829543
expl/Actions Max                              0.999929
expl/Actions Min                             -0.999503
expl/Num Paths                                1
expl/Average Returns                       4129.2
expl/env_infos/final/reward_run Mean          3.96863
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.96863
expl/env_infos/final/reward_run Min           3.96863
expl/env_infos/initial/reward_run Mean       -0.355708
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.355708
expl/env_infos/initial/reward_run Min        -0.355708
expl/env_infos/reward_run Mean                4.54379
expl/env_infos/reward_run Std                 1.18595
expl/env_infos/reward_run Max                 6.77319
expl/env_infos/reward_run Min                -0.355708
expl/env_infos/final/reward_ctrl Mean        -0.40873
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.40873
expl/env_infos/final/reward_ctrl Min         -0.40873
expl/env_infos/initial/reward_ctrl Mean      -0.220415
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.220415
expl/env_infos/initial/reward_ctrl Min       -0.220415
expl/env_infos/reward_ctrl Mean              -0.414591
expl/env_infos/reward_ctrl Std                0.0804111
expl/env_infos/reward_ctrl Max               -0.132127
expl/env_infos/reward_ctrl Min               -0.587274
eval/num steps total                     485000
eval/num paths total                        485
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.23041
eval/Rewards Std                              1.17759
eval/Rewards Max                              6.60885
eval/Rewards Min                             -0.882832
eval/Returns Mean                          4230.41
eval/Returns Std                             42.3069
eval/Returns Max                           4285.83
eval/Returns Min                           4169.29
eval/Actions Mean                             0.0665387
eval/Actions Std                              0.843234
eval/Actions Max                              0.999927
eval/Actions Min                             -0.999667
eval/Num Paths                                5
eval/Average Returns                       4230.41
eval/env_infos/final/reward_run Mean          4.23812
eval/env_infos/final/reward_run Std           0.983204
eval/env_infos/final/reward_run Max           6.04488
eval/env_infos/final/reward_run Min           3.08601
eval/env_infos/initial/reward_run Mean       -0.221227
eval/env_infos/initial/reward_run Std         0.182004
eval/env_infos/initial/reward_run Max         0.0914665
eval/env_infos/initial/reward_run Min        -0.420768
eval/env_infos/reward_run Mean                4.65969
eval/env_infos/reward_run Std                 1.17424
eval/env_infos/reward_run Max                 7.12252
eval/env_infos/reward_run Min                -0.425911
eval/env_infos/final/reward_ctrl Mean        -0.462084
eval/env_infos/final/reward_ctrl Std          0.0786191
eval/env_infos/final/reward_ctrl Max         -0.322995
eval/env_infos/final/reward_ctrl Min         -0.566078
eval/env_infos/initial/reward_ctrl Mean      -0.178847
eval/env_infos/initial/reward_ctrl Std        0.0239168
eval/env_infos/initial/reward_ctrl Max       -0.155055
eval/env_infos/initial/reward_ctrl Min       -0.21075
eval/env_infos/reward_ctrl Mean              -0.429282
eval/env_infos/reward_ctrl Std                0.0758064
eval/env_infos/reward_ctrl Max               -0.127481
eval/env_infos/reward_ctrl Min               -0.585281
time/data storing (s)                         0.00449759
time/evaluation sampling (s)                  2.05707
time/exploration sampling (s)                 0.528297
time/logging (s)                              0.013693
time/sac training (s)                         7.97056
time/saving (s)                               0.00379452
time/training (s)                             3.5534e-05
time/epoch (s)                               10.5779
time/total (s)                             1036.13
Epoch                                        96
---------------------------------------  ---------------
2021-11-24 00:46:38.626246 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 97 finished
---------------------------------------  ---------------
epoch                                        97
replay_buffer/size                        99000
trainer/num train calls                   98000
trainer/QF1 Loss                              6.42293
trainer/QF2 Loss                              5.25698
trainer/Policy Loss                        -196.804
trainer/Q1 Predictions Mean                 196.833
trainer/Q1 Predictions Std                   98.2682
trainer/Q1 Predictions Max                  298.101
trainer/Q1 Predictions Min                    8.65366
trainer/Q2 Predictions Mean                 196.768
trainer/Q2 Predictions Std                   98.1912
trainer/Q2 Predictions Max                  295.708
trainer/Q2 Predictions Min                    9.36208
trainer/Q Targets Mean                      196.449
trainer/Q Targets Std                        98.1494
trainer/Q Targets Max                       295.105
trainer/Q Targets Min                         8.41676
trainer/Log Pis Mean                          5.76963
trainer/Log Pis Std                           4.92685
trainer/Log Pis Max                          19.9608
trainer/Log Pis Min                          -4.32413
trainer/policy/mean Mean                     -0.00413347
trainer/policy/mean Std                       0.773104
trainer/policy/mean Max                       0.999329
trainer/policy/mean Min                      -0.999825
trainer/policy/normal/std Mean                0.460796
trainer/policy/normal/std Std                 0.133937
trainer/policy/normal/std Max                 1.18125
trainer/policy/normal/std Min                 0.100274
trainer/policy/normal/log_std Mean           -0.822138
trainer/policy/normal/log_std Std             0.321039
trainer/policy/normal/log_std Max             0.16657
trainer/policy/normal/log_std Min            -2.29985
trainer/Alpha                                 0.0770658
trainer/Alpha Loss                           -0.590453
expl/num steps total                      99000
expl/num paths total                         99
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.21658
expl/Rewards Std                              1.09121
expl/Rewards Max                              6.23203
expl/Rewards Min                             -0.443218
expl/Returns Mean                          4216.58
expl/Returns Std                              0
expl/Returns Max                           4216.58
expl/Returns Min                           4216.58
expl/Actions Mean                             0.00878823
expl/Actions Std                              0.838212
expl/Actions Max                              0.999732
expl/Actions Min                             -0.999523
expl/Num Paths                                1
expl/Average Returns                       4216.58
expl/env_infos/final/reward_run Mean          4.6051
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.6051
expl/env_infos/final/reward_run Min           4.6051
expl/env_infos/initial/reward_run Mean        0.0442078
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0442078
expl/env_infos/initial/reward_run Min         0.0442078
expl/env_infos/reward_run Mean                4.63819
expl/env_infos/reward_run Std                 1.08353
expl/env_infos/reward_run Max                 6.64226
expl/env_infos/reward_run Min                -0.0254345
expl/env_infos/final/reward_ctrl Mean        -0.531199
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.531199
expl/env_infos/final/reward_ctrl Min         -0.531199
expl/env_infos/initial/reward_ctrl Mean      -0.189013
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.189013
expl/env_infos/initial/reward_ctrl Min       -0.189013
expl/env_infos/reward_ctrl Mean              -0.421606
expl/env_infos/reward_ctrl Std                0.0780823
expl/env_infos/reward_ctrl Max               -0.189013
expl/env_infos/reward_ctrl Min               -0.584255
eval/num steps total                     490000
eval/num paths total                        490
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.29009
eval/Rewards Std                              1.13341
eval/Rewards Max                              6.76721
eval/Rewards Min                             -1.06055
eval/Returns Mean                          4290.09
eval/Returns Std                             76.1303
eval/Returns Max                           4387.56
eval/Returns Min                           4167.09
eval/Actions Mean                             0.00713983
eval/Actions Std                              0.848576
eval/Actions Max                              0.999188
eval/Actions Min                             -0.99947
eval/Num Paths                                5
eval/Average Returns                       4290.09
eval/env_infos/final/reward_run Mean          5.61951
eval/env_infos/final/reward_run Std           0.41561
eval/env_infos/final/reward_run Max           6.1486
eval/env_infos/final/reward_run Min           5.04612
eval/env_infos/initial/reward_run Mean        0.157059
eval/env_infos/initial/reward_run Std         0.372612
eval/env_infos/initial/reward_run Max         0.690282
eval/env_infos/initial/reward_run Min        -0.315881
eval/env_infos/reward_run Mean                4.72217
eval/env_infos/reward_run Std                 1.12839
eval/env_infos/reward_run Max                 7.29832
eval/env_infos/reward_run Min                -0.59584
eval/env_infos/final/reward_ctrl Mean        -0.413058
eval/env_infos/final/reward_ctrl Std          0.0756687
eval/env_infos/final/reward_ctrl Max         -0.290205
eval/env_infos/final/reward_ctrl Min         -0.502645
eval/env_infos/initial/reward_ctrl Mean      -0.182483
eval/env_infos/initial/reward_ctrl Std        0.030383
eval/env_infos/initial/reward_ctrl Max       -0.134304
eval/env_infos/initial/reward_ctrl Min       -0.229452
eval/env_infos/reward_ctrl Mean              -0.432079
eval/env_infos/reward_ctrl Std                0.0752336
eval/env_infos/reward_ctrl Max               -0.124352
eval/env_infos/reward_ctrl Min               -0.582867
time/data storing (s)                         0.00558424
time/evaluation sampling (s)                  2.03409
time/exploration sampling (s)                 0.537885
time/logging (s)                              0.0152676
time/sac training (s)                         7.98468
time/saving (s)                               0.00522466
time/training (s)                             7.6657e-05
time/epoch (s)                               10.5828
time/total (s)                             1047.04
Epoch                                        97
---------------------------------------  ---------------
2021-11-24 00:46:49.530829 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 98 finished
---------------------------------------  ---------------
epoch                                        98
replay_buffer/size                       100000
trainer/num train calls                   99000
trainer/QF1 Loss                             10.5054
trainer/QF2 Loss                              8.05238
trainer/Policy Loss                        -199.833
trainer/Q1 Predictions Mean                 200.22
trainer/Q1 Predictions Std                   97.4289
trainer/Q1 Predictions Max                  297.823
trainer/Q1 Predictions Min                    9.20232
trainer/Q2 Predictions Mean                 199.874
trainer/Q2 Predictions Std                   97.2589
trainer/Q2 Predictions Max                  297.906
trainer/Q2 Predictions Min                    9.81193
trainer/Q Targets Mean                      199.389
trainer/Q Targets Std                        97.2096
trainer/Q Targets Max                       295.928
trainer/Q Targets Min                         8.77697
trainer/Log Pis Mean                          6.0121
trainer/Log Pis Std                           5.24146
trainer/Log Pis Max                          18.6551
trainer/Log Pis Min                          -4.4674
trainer/policy/mean Mean                      0.0381655
trainer/policy/mean Std                       0.772724
trainer/policy/mean Max                       0.999915
trainer/policy/mean Min                      -0.999964
trainer/policy/normal/std Mean                0.470775
trainer/policy/normal/std Std                 0.139088
trainer/policy/normal/std Max                 0.97456
trainer/policy/normal/std Min                 0.135585
trainer/policy/normal/log_std Mean           -0.801886
trainer/policy/normal/log_std Std             0.32366
trainer/policy/normal/log_std Max            -0.0257697
trainer/policy/normal/log_std Min            -1.99816
trainer/Alpha                                 0.0796603
trainer/Alpha Loss                            0.0306004
expl/num steps total                     100000
expl/num paths total                        100
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.0284
expl/Rewards Std                              1.12177
expl/Rewards Max                              6.51808
expl/Rewards Min                             -0.344912
expl/Returns Mean                          4028.4
expl/Returns Std                              0
expl/Returns Max                           4028.4
expl/Returns Min                           4028.4
expl/Actions Mean                             0.0299675
expl/Actions Std                              0.840063
expl/Actions Max                              0.999975
expl/Actions Min                             -0.99983
expl/Num Paths                                1
expl/Average Returns                       4028.4
expl/env_infos/final/reward_run Mean          5.8221
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.8221
expl/env_infos/final/reward_run Min           5.8221
expl/env_infos/initial/reward_run Mean        0.417089
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.417089
expl/env_infos/initial/reward_run Min         0.417089
expl/env_infos/reward_run Mean                4.45237
expl/env_infos/reward_run Std                 1.11946
expl/env_infos/reward_run Max                 7.00234
expl/env_infos/reward_run Min                -0.0151621
expl/env_infos/final/reward_ctrl Mean        -0.45323
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.45323
expl/env_infos/final/reward_ctrl Min         -0.45323
expl/env_infos/initial/reward_ctrl Mean      -0.203671
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.203671
expl/env_infos/initial/reward_ctrl Min       -0.203671
expl/env_infos/reward_ctrl Mean              -0.423963
expl/env_infos/reward_ctrl Std                0.0829317
expl/env_infos/reward_ctrl Max               -0.0840258
expl/env_infos/reward_ctrl Min               -0.589057
eval/num steps total                     495000
eval/num paths total                        495
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.20074
eval/Rewards Std                              1.22937
eval/Rewards Max                              6.77213
eval/Rewards Min                             -0.995182
eval/Returns Mean                          4200.74
eval/Returns Std                             62.8981
eval/Returns Max                           4272.81
eval/Returns Min                           4083.74
eval/Actions Mean                             0.0216197
eval/Actions Std                              0.85912
eval/Actions Max                              0.999521
eval/Actions Min                             -0.999305
eval/Num Paths                                5
eval/Average Returns                       4200.74
eval/env_infos/final/reward_run Mean          4.94963
eval/env_infos/final/reward_run Std           1.23985
eval/env_infos/final/reward_run Max           6.81629
eval/env_infos/final/reward_run Min           3.05066
eval/env_infos/initial/reward_run Mean       -0.178759
eval/env_infos/initial/reward_run Std         0.136542
eval/env_infos/initial/reward_run Max        -0.00439394
eval/env_infos/initial/reward_run Min        -0.347629
eval/env_infos/reward_run Mean                4.64387
eval/env_infos/reward_run Std                 1.22635
eval/env_infos/reward_run Max                 7.32316
eval/env_infos/reward_run Min                -0.633832
eval/env_infos/final/reward_ctrl Mean        -0.476671
eval/env_infos/final/reward_ctrl Std          0.0764521
eval/env_infos/final/reward_ctrl Max         -0.364029
eval/env_infos/final/reward_ctrl Min         -0.573084
eval/env_infos/initial/reward_ctrl Mean      -0.217859
eval/env_infos/initial/reward_ctrl Std        0.0211229
eval/env_infos/initial/reward_ctrl Max       -0.185438
eval/env_infos/initial/reward_ctrl Min       -0.241341
eval/env_infos/reward_ctrl Mean              -0.443132
eval/env_infos/reward_ctrl Std                0.0754708
eval/env_infos/reward_ctrl Max               -0.111784
eval/env_infos/reward_ctrl Min               -0.586267
time/data storing (s)                         0.00450575
time/evaluation sampling (s)                  2.0712
time/exploration sampling (s)                 0.547309
time/logging (s)                              0.0136022
time/sac training (s)                         7.92804
time/saving (s)                               0.00379102
time/training (s)                             3.5306e-05
time/epoch (s)                               10.5685
time/total (s)                             1057.93
Epoch                                        98
---------------------------------------  ---------------
2021-11-24 00:47:00.382463 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 99 finished
---------------------------------------  ---------------
epoch                                        99
replay_buffer/size                       101000
trainer/num train calls                  100000
trainer/QF1 Loss                              9.64992
trainer/QF2 Loss                              7.63167
trainer/Policy Loss                        -205.815
trainer/Q1 Predictions Mean                 205.806
trainer/Q1 Predictions Std                   90.2985
trainer/Q1 Predictions Max                  298.148
trainer/Q1 Predictions Min                    9.45821
trainer/Q2 Predictions Mean                 205.651
trainer/Q2 Predictions Std                   90.1706
trainer/Q2 Predictions Max                  298.06
trainer/Q2 Predictions Min                    9.50333
trainer/Q Targets Mean                      205.558
trainer/Q Targets Std                        89.9259
trainer/Q Targets Max                       299.177
trainer/Q Targets Min                         9.40785
trainer/Log Pis Mean                          6.25588
trainer/Log Pis Std                           4.97353
trainer/Log Pis Max                          18.2995
trainer/Log Pis Min                          -7.7861
trainer/policy/mean Mean                     -0.00284861
trainer/policy/mean Std                       0.77843
trainer/policy/mean Max                       0.999027
trainer/policy/mean Min                      -0.999748
trainer/policy/normal/std Mean                0.461733
trainer/policy/normal/std Std                 0.136738
trainer/policy/normal/std Max                 1.13204
trainer/policy/normal/std Min                 0.128484
trainer/policy/normal/log_std Mean           -0.820977
trainer/policy/normal/log_std Std             0.322056
trainer/policy/normal/log_std Max             0.124023
trainer/policy/normal/log_std Min            -2.05195
trainer/Alpha                                 0.0815076
trainer/Alpha Loss                            0.641506
expl/num steps total                     101000
expl/num paths total                        101
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.06361
expl/Rewards Std                              1.18811
expl/Rewards Max                              6.36199
expl/Rewards Min                             -0.681212
expl/Returns Mean                          4063.61
expl/Returns Std                              0
expl/Returns Max                           4063.61
expl/Returns Min                           4063.61
expl/Actions Mean                             0.0147753
expl/Actions Std                              0.839359
expl/Actions Max                              0.999738
expl/Actions Min                             -0.999881
expl/Num Paths                                1
expl/Average Returns                       4063.61
expl/env_infos/final/reward_run Mean          5.87505
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.87505
expl/env_infos/final/reward_run Min           5.87505
expl/env_infos/initial/reward_run Mean       -0.124494
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.124494
expl/env_infos/initial/reward_run Min        -0.124494
expl/env_infos/reward_run Mean                4.48645
expl/env_infos/reward_run Std                 1.18344
expl/env_infos/reward_run Max                 6.80064
expl/env_infos/reward_run Min                -0.300015
expl/env_infos/final/reward_ctrl Mean        -0.486837
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.486837
expl/env_infos/final/reward_ctrl Min         -0.486837
expl/env_infos/initial/reward_ctrl Mean      -0.175383
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.175383
expl/env_infos/initial/reward_ctrl Min       -0.175383
expl/env_infos/reward_ctrl Mean              -0.422845
expl/env_infos/reward_ctrl Std                0.0795823
expl/env_infos/reward_ctrl Max               -0.150869
expl/env_infos/reward_ctrl Min               -0.585055
eval/num steps total                     500000
eval/num paths total                        500
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.27987
eval/Rewards Std                              1.14804
eval/Rewards Max                              6.52791
eval/Rewards Min                             -0.977334
eval/Returns Mean                          4279.87
eval/Returns Std                             34.1706
eval/Returns Max                           4326.97
eval/Returns Min                           4221.07
eval/Actions Mean                             0.0153508
eval/Actions Std                              0.856237
eval/Actions Max                              0.999433
eval/Actions Min                             -0.999123
eval/Num Paths                                5
eval/Average Returns                       4279.87
eval/env_infos/final/reward_run Mean          4.81618
eval/env_infos/final/reward_run Std           0.823544
eval/env_infos/final/reward_run Max           5.68015
eval/env_infos/final/reward_run Min           3.48795
eval/env_infos/initial/reward_run Mean        0.145585
eval/env_infos/initial/reward_run Std         0.154808
eval/env_infos/initial/reward_run Max         0.369443
eval/env_infos/initial/reward_run Min        -0.0526538
eval/env_infos/reward_run Mean                4.7199
eval/env_infos/reward_run Std                 1.13819
eval/env_infos/reward_run Max                 7.04674
eval/env_infos/reward_run Min                -0.467476
eval/env_infos/final/reward_ctrl Mean        -0.449206
eval/env_infos/final/reward_ctrl Std          0.0852476
eval/env_infos/final/reward_ctrl Max         -0.335916
eval/env_infos/final/reward_ctrl Min         -0.557178
eval/env_infos/initial/reward_ctrl Mean      -0.15838
eval/env_infos/initial/reward_ctrl Std        0.0212427
eval/env_infos/initial/reward_ctrl Max       -0.129041
eval/env_infos/initial/reward_ctrl Min       -0.181438
eval/env_infos/reward_ctrl Mean              -0.440027
eval/env_infos/reward_ctrl Std                0.0729167
eval/env_infos/reward_ctrl Max               -0.129041
eval/env_infos/reward_ctrl Min               -0.588189
time/data storing (s)                         0.00453541
time/evaluation sampling (s)                  2.04082
time/exploration sampling (s)                 0.537157
time/logging (s)                              0.0140764
time/sac training (s)                         7.91755
time/saving (s)                               0.00397336
time/training (s)                             4.0022e-05
time/epoch (s)                               10.5181
time/total (s)                             1068.76
Epoch                                        99
---------------------------------------  ---------------
2021-11-24 00:47:11.320628 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 100 finished
---------------------------------------  ---------------
epoch                                       100
replay_buffer/size                       102000
trainer/num train calls                  101000
trainer/QF1 Loss                              7.44736
trainer/QF2 Loss                              6.0208
trainer/Policy Loss                        -198.103
trainer/Q1 Predictions Mean                 198.13
trainer/Q1 Predictions Std                   99.3437
trainer/Q1 Predictions Max                  296.808
trainer/Q1 Predictions Min                    9.59855
trainer/Q2 Predictions Mean                 198.023
trainer/Q2 Predictions Std                   99.4757
trainer/Q2 Predictions Max                  297.025
trainer/Q2 Predictions Min                    9.49761
trainer/Q Targets Mean                      198.091
trainer/Q Targets Std                        99.453
trainer/Q Targets Max                       299.439
trainer/Q Targets Min                         8.99959
trainer/Log Pis Mean                          5.70017
trainer/Log Pis Std                           5.55579
trainer/Log Pis Max                          26.5831
trainer/Log Pis Min                          -6.94578
trainer/policy/mean Mean                      0.0440982
trainer/policy/mean Std                       0.768425
trainer/policy/mean Max                       0.999368
trainer/policy/mean Min                      -0.999801
trainer/policy/normal/std Mean                0.470146
trainer/policy/normal/std Std                 0.133958
trainer/policy/normal/std Max                 1.08606
trainer/policy/normal/std Min                 0.113823
trainer/policy/normal/log_std Mean           -0.800297
trainer/policy/normal/log_std Std             0.315346
trainer/policy/normal/log_std Max             0.0825521
trainer/policy/normal/log_std Min            -2.17311
trainer/Alpha                                 0.0815983
trainer/Alpha Loss                           -0.751364
expl/num steps total                     102000
expl/num paths total                        102
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.22212
expl/Rewards Std                              1.11227
expl/Rewards Max                              6.3716
expl/Rewards Min                             -0.605254
expl/Returns Mean                          4222.12
expl/Returns Std                              0
expl/Returns Max                           4222.12
expl/Returns Min                           4222.12
expl/Actions Mean                             0.0488272
expl/Actions Std                              0.841678
expl/Actions Max                              0.99986
expl/Actions Min                             -0.999747
expl/Num Paths                                1
expl/Average Returns                       4222.12
expl/env_infos/final/reward_run Mean          4.32944
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.32944
expl/env_infos/final/reward_run Min           4.32944
expl/env_infos/initial/reward_run Mean        0.0421605
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0421605
expl/env_infos/initial/reward_run Min         0.0421605
expl/env_infos/reward_run Mean                4.6486
expl/env_infos/reward_run Std                 1.11153
expl/env_infos/reward_run Max                 6.90155
expl/env_infos/reward_run Min                -0.222022
expl/env_infos/final/reward_ctrl Mean        -0.391909
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.391909
expl/env_infos/final/reward_ctrl Min         -0.391909
expl/env_infos/initial/reward_ctrl Mean      -0.206851
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.206851
expl/env_infos/initial/reward_ctrl Min       -0.206851
expl/env_infos/reward_ctrl Mean              -0.426484
expl/env_infos/reward_ctrl Std                0.073748
expl/env_infos/reward_ctrl Max               -0.171137
expl/env_infos/reward_ctrl Min               -0.580279
eval/num steps total                     505000
eval/num paths total                        505
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.32625
eval/Rewards Std                              1.14301
eval/Rewards Max                              6.56562
eval/Rewards Min                             -0.802638
eval/Returns Mean                          4326.25
eval/Returns Std                            136.84
eval/Returns Max                           4501.1
eval/Returns Min                           4124.9
eval/Actions Mean                             0.0453715
eval/Actions Std                              0.854016
eval/Actions Max                              0.999803
eval/Actions Min                             -0.999762
eval/Num Paths                                5
eval/Average Returns                       4326.25
eval/env_infos/final/reward_run Mean          5.38712
eval/env_infos/final/reward_run Std           1.20633
eval/env_infos/final/reward_run Max           6.52103
eval/env_infos/final/reward_run Min           3.0619
eval/env_infos/initial/reward_run Mean       -0.229457
eval/env_infos/initial/reward_run Std         0.160572
eval/env_infos/initial/reward_run Max         0.0264877
eval/env_infos/initial/reward_run Min        -0.441591
eval/env_infos/reward_run Mean                4.76509
eval/env_infos/reward_run Std                 1.14353
eval/env_infos/reward_run Max                 7.08932
eval/env_infos/reward_run Min                -0.441591
eval/env_infos/final/reward_ctrl Mean        -0.453571
eval/env_infos/final/reward_ctrl Std          0.0659548
eval/env_infos/final/reward_ctrl Max         -0.326118
eval/env_infos/final/reward_ctrl Min         -0.51567
eval/env_infos/initial/reward_ctrl Mean      -0.184874
eval/env_infos/initial/reward_ctrl Std        0.0264932
eval/env_infos/initial/reward_ctrl Max       -0.150118
eval/env_infos/initial/reward_ctrl Min       -0.227089
eval/env_infos/reward_ctrl Mean              -0.438841
eval/env_infos/reward_ctrl Std                0.0699223
eval/env_infos/reward_ctrl Max               -0.126436
eval/env_infos/reward_ctrl Min               -0.581327
time/data storing (s)                         0.00449731
time/evaluation sampling (s)                  2.09679
time/exploration sampling (s)                 0.546585
time/logging (s)                              0.0137443
time/sac training (s)                         7.93828
time/saving (s)                               0.00381472
time/training (s)                             3.6415e-05
time/epoch (s)                               10.6037
time/total (s)                             1079.68
Epoch                                       100
---------------------------------------  ---------------
2021-11-24 00:47:22.182309 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 101 finished
---------------------------------------  ---------------
epoch                                       101
replay_buffer/size                       103000
trainer/num train calls                  102000
trainer/QF1 Loss                              9.02182
trainer/QF2 Loss                              8.10891
trainer/Policy Loss                        -198.02
trainer/Q1 Predictions Mean                 198.151
trainer/Q1 Predictions Std                  101.939
trainer/Q1 Predictions Max                  305.318
trainer/Q1 Predictions Min                    9.94687
trainer/Q2 Predictions Mean                 198.254
trainer/Q2 Predictions Std                  101.894
trainer/Q2 Predictions Max                  303.724
trainer/Q2 Predictions Min                    9.98496
trainer/Q Targets Mean                      197.371
trainer/Q Targets Std                       101.355
trainer/Q Targets Max                       303.172
trainer/Q Targets Min                         8.89896
trainer/Log Pis Mean                          5.82245
trainer/Log Pis Std                           5.10639
trainer/Log Pis Max                          20.7671
trainer/Log Pis Min                          -6.25363
trainer/policy/mean Mean                      0.0262767
trainer/policy/mean Std                       0.765787
trainer/policy/mean Max                       0.99901
trainer/policy/mean Min                      -0.999569
trainer/policy/normal/std Mean                0.462229
trainer/policy/normal/std Std                 0.133397
trainer/policy/normal/std Max                 0.99789
trainer/policy/normal/std Min                 0.0896615
trainer/policy/normal/log_std Mean           -0.819151
trainer/policy/normal/log_std Std             0.322659
trainer/policy/normal/log_std Max            -0.00211259
trainer/policy/normal/log_std Min            -2.41171
trainer/Alpha                                 0.0813279
trainer/Alpha Loss                           -0.445513
expl/num steps total                     103000
expl/num paths total                        103
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.35167
expl/Rewards Std                              1.06628
expl/Rewards Max                              6.32552
expl/Rewards Min                             -0.683743
expl/Returns Mean                          4351.67
expl/Returns Std                              0
expl/Returns Max                           4351.67
expl/Returns Min                           4351.67
expl/Actions Mean                             0.0329867
expl/Actions Std                              0.837832
expl/Actions Max                              0.999856
expl/Actions Min                             -0.999704
expl/Num Paths                                1
expl/Average Returns                       4351.67
expl/env_infos/final/reward_run Mean          4.91902
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.91902
expl/env_infos/final/reward_run Min           4.91902
expl/env_infos/initial/reward_run Mean       -0.42661
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.42661
expl/env_infos/initial/reward_run Min        -0.42661
expl/env_infos/reward_run Mean                4.7735
expl/env_infos/reward_run Std                 1.07047
expl/env_infos/reward_run Max                 6.86552
expl/env_infos/reward_run Min                -0.42661
expl/env_infos/final/reward_ctrl Mean        -0.375599
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.375599
expl/env_infos/final/reward_ctrl Min         -0.375599
expl/env_infos/initial/reward_ctrl Mean      -0.256736
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.256736
expl/env_infos/initial/reward_ctrl Min       -0.256736
expl/env_infos/reward_ctrl Mean              -0.42183
expl/env_infos/reward_ctrl Std                0.0772526
expl/env_infos/reward_ctrl Max               -0.178348
expl/env_infos/reward_ctrl Min               -0.584221
eval/num steps total                     510000
eval/num paths total                        510
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.35495
eval/Rewards Std                              1.1304
eval/Rewards Max                              6.82126
eval/Rewards Min                             -0.957655
eval/Returns Mean                          4354.95
eval/Returns Std                             75.4825
eval/Returns Max                           4433.88
eval/Returns Min                           4214.25
eval/Actions Mean                             0.0320945
eval/Actions Std                              0.847316
eval/Actions Max                              0.999833
eval/Actions Min                             -0.999352
eval/Num Paths                                5
eval/Average Returns                       4354.95
eval/env_infos/final/reward_run Mean          5.52016
eval/env_infos/final/reward_run Std           0.275069
eval/env_infos/final/reward_run Max           5.93776
eval/env_infos/final/reward_run Min           5.13665
eval/env_infos/initial/reward_run Mean       -0.0747042
eval/env_infos/initial/reward_run Std         0.251995
eval/env_infos/initial/reward_run Max         0.185432
eval/env_infos/initial/reward_run Min        -0.476804
eval/env_infos/reward_run Mean                4.78634
eval/env_infos/reward_run Std                 1.1384
eval/env_infos/reward_run Max                 7.32591
eval/env_infos/reward_run Min                -0.498097
eval/env_infos/final/reward_ctrl Mean        -0.386156
eval/env_infos/final/reward_ctrl Std          0.05164
eval/env_infos/final/reward_ctrl Max         -0.316817
eval/env_infos/final/reward_ctrl Min         -0.462931
eval/env_infos/initial/reward_ctrl Mean      -0.195976
eval/env_infos/initial/reward_ctrl Std        0.0311089
eval/env_infos/initial/reward_ctrl Max       -0.16536
eval/env_infos/initial/reward_ctrl Min       -0.249095
eval/env_infos/reward_ctrl Mean              -0.431384
eval/env_infos/reward_ctrl Std                0.0772168
eval/env_infos/reward_ctrl Max               -0.101593
eval/env_infos/reward_ctrl Min               -0.585201
time/data storing (s)                         0.00497337
time/evaluation sampling (s)                  2.05436
time/exploration sampling (s)                 0.543361
time/logging (s)                              0.0139778
time/sac training (s)                         7.9096
time/saving (s)                               0.00407612
time/training (s)                             4.4381e-05
time/epoch (s)                               10.5304
time/total (s)                             1090.53
Epoch                                       101
---------------------------------------  ---------------
2021-11-24 00:47:33.079868 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 102 finished
---------------------------------------  ---------------
epoch                                       102
replay_buffer/size                       104000
trainer/num train calls                  103000
trainer/QF1 Loss                              7.20996
trainer/QF2 Loss                              6.19765
trainer/Policy Loss                        -202.04
trainer/Q1 Predictions Mean                 202.161
trainer/Q1 Predictions Std                  102.329
trainer/Q1 Predictions Max                  304.504
trainer/Q1 Predictions Min                    9.58
trainer/Q2 Predictions Mean                 202.535
trainer/Q2 Predictions Std                  102.602
trainer/Q2 Predictions Max                  306.439
trainer/Q2 Predictions Min                   10.2263
trainer/Q Targets Mean                      202.428
trainer/Q Targets Std                       102.637
trainer/Q Targets Max                       305.687
trainer/Q Targets Min                         9.08687
trainer/Log Pis Mean                          6.1134
trainer/Log Pis Std                           5.55361
trainer/Log Pis Max                          18.8279
trainer/Log Pis Min                          -8.47131
trainer/policy/mean Mean                      0.0200505
trainer/policy/mean Std                       0.768945
trainer/policy/mean Max                       0.998373
trainer/policy/mean Min                      -0.998719
trainer/policy/normal/std Mean                0.471552
trainer/policy/normal/std Std                 0.135352
trainer/policy/normal/std Max                 0.92243
trainer/policy/normal/std Min                 0.113848
trainer/policy/normal/log_std Mean           -0.799379
trainer/policy/normal/log_std Std             0.324157
trainer/policy/normal/log_std Max            -0.0807434
trainer/policy/normal/log_std Min            -2.17289
trainer/Alpha                                 0.0812809
trainer/Alpha Loss                            0.284615
expl/num steps total                     104000
expl/num paths total                        104
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.31562
expl/Rewards Std                              1.07276
expl/Rewards Max                              6.3342
expl/Rewards Min                             -0.193966
expl/Returns Mean                          4315.62
expl/Returns Std                              0
expl/Returns Max                           4315.62
expl/Returns Min                           4315.62
expl/Actions Mean                             0.052171
expl/Actions Std                              0.847413
expl/Actions Max                              0.999752
expl/Actions Min                             -0.999396
expl/Num Paths                                1
expl/Average Returns                       4315.62
expl/env_infos/final/reward_run Mean          4.98803
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.98803
expl/env_infos/final/reward_run Min           4.98803
expl/env_infos/initial/reward_run Mean        0.181072
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.181072
expl/env_infos/initial/reward_run Min         0.181072
expl/env_infos/reward_run Mean                4.74812
expl/env_infos/reward_run Std                 1.07561
expl/env_infos/reward_run Max                 6.78578
expl/env_infos/reward_run Min                 0.156007
expl/env_infos/final/reward_ctrl Mean        -0.53019
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.53019
expl/env_infos/final/reward_ctrl Min         -0.53019
expl/env_infos/initial/reward_ctrl Mean      -0.144033
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.144033
expl/env_infos/initial/reward_ctrl Min       -0.144033
expl/env_infos/reward_ctrl Mean              -0.432498
expl/env_infos/reward_ctrl Std                0.0772626
expl/env_infos/reward_ctrl Max               -0.12469
expl/env_infos/reward_ctrl Min               -0.585356
eval/num steps total                     515000
eval/num paths total                        515
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.34223
eval/Rewards Std                              1.17287
eval/Rewards Max                              6.64705
eval/Rewards Min                             -0.737499
eval/Returns Mean                          4342.23
eval/Returns Std                            123.493
eval/Returns Max                           4496.63
eval/Returns Min                           4236.83
eval/Actions Mean                             0.0447449
eval/Actions Std                              0.859076
eval/Actions Max                              0.99968
eval/Actions Min                             -0.998992
eval/Num Paths                                5
eval/Average Returns                       4342.23
eval/env_infos/final/reward_run Mean          4.96889
eval/env_infos/final/reward_run Std           0.62545
eval/env_infos/final/reward_run Max           5.8493
eval/env_infos/final/reward_run Min           4.12873
eval/env_infos/initial/reward_run Mean        0.130019
eval/env_infos/initial/reward_run Std         0.111043
eval/env_infos/initial/reward_run Max         0.33617
eval/env_infos/initial/reward_run Min        -0.00144522
eval/env_infos/reward_run Mean                4.78624
eval/env_infos/reward_run Std                 1.18069
eval/env_infos/reward_run Max                 7.21429
eval/env_infos/reward_run Min                -0.372311
eval/env_infos/final/reward_ctrl Mean        -0.419416
eval/env_infos/final/reward_ctrl Std          0.0806396
eval/env_infos/final/reward_ctrl Max         -0.303775
eval/env_infos/final/reward_ctrl Min         -0.527727
eval/env_infos/initial/reward_ctrl Mean      -0.168358
eval/env_infos/initial/reward_ctrl Std        0.0264686
eval/env_infos/initial/reward_ctrl Max       -0.11736
eval/env_infos/initial/reward_ctrl Min       -0.19002
eval/env_infos/reward_ctrl Mean              -0.444009
eval/env_infos/reward_ctrl Std                0.0761039
eval/env_infos/reward_ctrl Max               -0.11736
eval/env_infos/reward_ctrl Min               -0.583134
time/data storing (s)                         0.00456725
time/evaluation sampling (s)                  2.07346
time/exploration sampling (s)                 0.553577
time/logging (s)                              0.0136058
time/sac training (s)                         7.91341
time/saving (s)                               0.00382297
time/training (s)                             3.4812e-05
time/epoch (s)                               10.5625
time/total (s)                             1101.41
Epoch                                       102
---------------------------------------  ---------------
2021-11-24 00:47:44.041397 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 103 finished
---------------------------------------  ----------------
epoch                                       103
replay_buffer/size                       105000
trainer/num train calls                  104000
trainer/QF1 Loss                              9.31317
trainer/QF2 Loss                              7.03152
trainer/Policy Loss                        -209.759
trainer/Q1 Predictions Mean                 209.904
trainer/Q1 Predictions Std                   95.9757
trainer/Q1 Predictions Max                  310.037
trainer/Q1 Predictions Min                    9.45284
trainer/Q2 Predictions Mean                 209.522
trainer/Q2 Predictions Std                   95.696
trainer/Q2 Predictions Max                  308.759
trainer/Q2 Predictions Min                   10.1682
trainer/Q Targets Mean                      210.243
trainer/Q Targets Std                        95.9529
trainer/Q Targets Max                       309.621
trainer/Q Targets Min                         9.71828
trainer/Log Pis Mean                          6.61108
trainer/Log Pis Std                           5.16501
trainer/Log Pis Max                          22.0302
trainer/Log Pis Min                          -5.66262
trainer/policy/mean Mean                     -0.0013913
trainer/policy/mean Std                       0.794984
trainer/policy/mean Max                       0.999832
trainer/policy/mean Min                      -0.998965
trainer/policy/normal/std Mean                0.468083
trainer/policy/normal/std Std                 0.131453
trainer/policy/normal/std Max                 0.931079
trainer/policy/normal/std Min                 0.109319
trainer/policy/normal/log_std Mean           -0.804444
trainer/policy/normal/log_std Std             0.315841
trainer/policy/normal/log_std Max            -0.0714109
trainer/policy/normal/log_std Min            -2.21349
trainer/Alpha                                 0.0829771
trainer/Alpha Loss                            1.52109
expl/num steps total                     105000
expl/num paths total                        105
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.28253
expl/Rewards Std                              1.13703
expl/Rewards Max                              6.51891
expl/Rewards Min                             -0.602812
expl/Returns Mean                          4282.53
expl/Returns Std                              0
expl/Returns Max                           4282.53
expl/Returns Min                           4282.53
expl/Actions Mean                             0.0233406
expl/Actions Std                              0.841836
expl/Actions Max                              0.999749
expl/Actions Min                             -0.999876
expl/Num Paths                                1
expl/Average Returns                       4282.53
expl/env_infos/final/reward_run Mean          4.87409
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.87409
expl/env_infos/final/reward_run Min           4.87409
expl/env_infos/initial/reward_run Mean       -0.000428859
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.000428859
expl/env_infos/initial/reward_run Min        -0.000428859
expl/env_infos/reward_run Mean                4.70807
expl/env_infos/reward_run Std                 1.13292
expl/env_infos/reward_run Max                 7.08401
expl/env_infos/reward_run Min                -0.12424
expl/env_infos/final/reward_ctrl Mean        -0.340338
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.340338
expl/env_infos/final/reward_ctrl Min         -0.340338
expl/env_infos/initial/reward_ctrl Mean      -0.135302
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.135302
expl/env_infos/initial/reward_ctrl Min       -0.135302
expl/env_infos/reward_ctrl Mean              -0.425539
expl/env_infos/reward_ctrl Std                0.0794466
expl/env_infos/reward_ctrl Max               -0.135302
expl/env_infos/reward_ctrl Min               -0.59088
eval/num steps total                     520000
eval/num paths total                        520
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.34198
eval/Rewards Std                              1.15286
eval/Rewards Max                              6.58166
eval/Rewards Min                             -0.859242
eval/Returns Mean                          4341.98
eval/Returns Std                             82.9073
eval/Returns Max                           4471.46
eval/Returns Min                           4212.29
eval/Actions Mean                             0.0257341
eval/Actions Std                              0.855097
eval/Actions Max                              0.999313
eval/Actions Min                             -0.999716
eval/Num Paths                                5
eval/Average Returns                       4341.98
eval/env_infos/final/reward_run Mean          4.87468
eval/env_infos/final/reward_run Std           1.23858
eval/env_infos/final/reward_run Max           6.47753
eval/env_infos/final/reward_run Min           3.33722
eval/env_infos/initial/reward_run Mean        0.103846
eval/env_infos/initial/reward_run Std         0.268835
eval/env_infos/initial/reward_run Max         0.598683
eval/env_infos/initial/reward_run Min        -0.149747
eval/env_infos/reward_run Mean                4.78109
eval/env_infos/reward_run Std                 1.15092
eval/env_infos/reward_run Max                 7.14226
eval/env_infos/reward_run Min                -0.448407
eval/env_infos/final/reward_ctrl Mean        -0.461154
eval/env_infos/final/reward_ctrl Std          0.0614547
eval/env_infos/final/reward_ctrl Max         -0.351184
eval/env_infos/final/reward_ctrl Min         -0.540298
eval/env_infos/initial/reward_ctrl Mean      -0.156
eval/env_infos/initial/reward_ctrl Std        0.015801
eval/env_infos/initial/reward_ctrl Max       -0.138081
eval/env_infos/initial/reward_ctrl Min       -0.184889
eval/env_infos/reward_ctrl Mean              -0.439112
eval/env_infos/reward_ctrl Std                0.0786447
eval/env_infos/reward_ctrl Max               -0.0960584
eval/env_infos/reward_ctrl Min               -0.585771
time/data storing (s)                         0.00447141
time/evaluation sampling (s)                  2.04516
time/exploration sampling (s)                 0.542488
time/logging (s)                              0.0148918
time/sac training (s)                         8.01382
time/saving (s)                               0.00392964
time/training (s)                             5.2685e-05
time/epoch (s)                               10.6248
time/total (s)                             1112.36
Epoch                                       103
---------------------------------------  ----------------
2021-11-24 00:47:55.041860 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 104 finished
---------------------------------------  ---------------
epoch                                       104
replay_buffer/size                       106000
trainer/num train calls                  105000
trainer/QF1 Loss                              8.66754
trainer/QF2 Loss                              7.53243
trainer/Policy Loss                        -219.568
trainer/Q1 Predictions Mean                 220.154
trainer/Q1 Predictions Std                   94.0488
trainer/Q1 Predictions Max                  312.534
trainer/Q1 Predictions Min                    8.28114
trainer/Q2 Predictions Mean                 219.272
trainer/Q2 Predictions Std                   93.604
trainer/Q2 Predictions Max                  311.908
trainer/Q2 Predictions Min                    9.79626
trainer/Q Targets Mean                      219.472
trainer/Q Targets Std                        93.7847
trainer/Q Targets Max                       310.878
trainer/Q Targets Min                         8.81031
trainer/Log Pis Mean                          6.31193
trainer/Log Pis Std                           5.07246
trainer/Log Pis Max                          21.8016
trainer/Log Pis Min                          -5.11665
trainer/policy/mean Mean                      0.0399054
trainer/policy/mean Std                       0.779865
trainer/policy/mean Max                       0.999309
trainer/policy/mean Min                      -0.999067
trainer/policy/normal/std Mean                0.453533
trainer/policy/normal/std Std                 0.133023
trainer/policy/normal/std Max                 0.972252
trainer/policy/normal/std Min                 0.117585
trainer/policy/normal/log_std Mean           -0.839633
trainer/policy/normal/log_std Std             0.328039
trainer/policy/normal/log_std Max            -0.0281402
trainer/policy/normal/log_std Min            -2.14059
trainer/Alpha                                 0.0829769
trainer/Alpha Loss                            0.776456
expl/num steps total                     106000
expl/num paths total                        106
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.17457
expl/Rewards Std                              1.10542
expl/Rewards Max                              6.42565
expl/Rewards Min                             -0.250098
expl/Returns Mean                          4174.57
expl/Returns Std                              0
expl/Returns Max                           4174.57
expl/Returns Min                           4174.57
expl/Actions Mean                             0.0352037
expl/Actions Std                              0.834043
expl/Actions Max                              0.999571
expl/Actions Min                             -0.999737
expl/Num Paths                                1
expl/Average Returns                       4174.57
expl/env_infos/final/reward_run Mean          5.01736
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.01736
expl/env_infos/final/reward_run Min           5.01736
expl/env_infos/initial/reward_run Mean        0.490336
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.490336
expl/env_infos/initial/reward_run Min         0.490336
expl/env_infos/reward_run Mean                4.59269
expl/env_infos/reward_run Std                 1.10176
expl/env_infos/reward_run Max                 6.96246
expl/env_infos/reward_run Min                 0.0802775
expl/env_infos/final/reward_ctrl Mean        -0.415292
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.415292
expl/env_infos/final/reward_ctrl Min         -0.415292
expl/env_infos/initial/reward_ctrl Mean      -0.243538
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.243538
expl/env_infos/initial/reward_ctrl Min       -0.243538
expl/env_infos/reward_ctrl Mean              -0.418121
expl/env_infos/reward_ctrl Std                0.0822647
expl/env_infos/reward_ctrl Max               -0.159296
expl/env_infos/reward_ctrl Min               -0.58474
eval/num steps total                     525000
eval/num paths total                        525
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.40172
eval/Rewards Std                              1.11805
eval/Rewards Max                              6.5004
eval/Rewards Min                             -0.785835
eval/Returns Mean                          4401.72
eval/Returns Std                             87.5837
eval/Returns Max                           4487.85
eval/Returns Min                           4232.74
eval/Actions Mean                             0.0330893
eval/Actions Std                              0.846921
eval/Actions Max                              0.999178
eval/Actions Min                             -0.999121
eval/Num Paths                                5
eval/Average Returns                       4401.72
eval/env_infos/final/reward_run Mean          4.99773
eval/env_infos/final/reward_run Std           0.802932
eval/env_infos/final/reward_run Max           5.80509
eval/env_infos/final/reward_run Min           3.56818
eval/env_infos/initial/reward_run Mean       -0.206338
eval/env_infos/initial/reward_run Std         0.114514
eval/env_infos/initial/reward_run Max        -0.0129186
eval/env_infos/initial/reward_run Min        -0.32869
eval/env_infos/reward_run Mean                4.83274
eval/env_infos/reward_run Std                 1.11665
eval/env_infos/reward_run Max                 7.04693
eval/env_infos/reward_run Min                -0.32869
eval/env_infos/final/reward_ctrl Mean        -0.456495
eval/env_infos/final/reward_ctrl Std          0.0896921
eval/env_infos/final/reward_ctrl Max         -0.294918
eval/env_infos/final/reward_ctrl Min         -0.570532
eval/env_infos/initial/reward_ctrl Mean      -0.189937
eval/env_infos/initial/reward_ctrl Std        0.00972479
eval/env_infos/initial/reward_ctrl Max       -0.176976
eval/env_infos/initial/reward_ctrl Min       -0.20528
eval/env_infos/reward_ctrl Mean              -0.431022
eval/env_infos/reward_ctrl Std                0.0798029
eval/env_infos/reward_ctrl Max               -0.125042
eval/env_infos/reward_ctrl Min               -0.584515
time/data storing (s)                         0.00451967
time/evaluation sampling (s)                  2.06982
time/exploration sampling (s)                 0.557437
time/logging (s)                              0.0136319
time/sac training (s)                         8.01246
time/saving (s)                               0.00384016
time/training (s)                             3.5396e-05
time/epoch (s)                               10.6618
time/total (s)                             1123.34
Epoch                                       104
---------------------------------------  ---------------
2021-11-24 00:48:06.025828 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 105 finished
---------------------------------------  ---------------
epoch                                       105
replay_buffer/size                       107000
trainer/num train calls                  106000
trainer/QF1 Loss                             11.5507
trainer/QF2 Loss                              8.59337
trainer/Policy Loss                        -216.93
trainer/Q1 Predictions Mean                 216.785
trainer/Q1 Predictions Std                   94.3353
trainer/Q1 Predictions Max                  305.348
trainer/Q1 Predictions Min                    8.44949
trainer/Q2 Predictions Mean                 217.191
trainer/Q2 Predictions Std                   94.5729
trainer/Q2 Predictions Max                  305.045
trainer/Q2 Predictions Min                    9.35907
trainer/Q Targets Mean                      216.979
trainer/Q Targets Std                        94.6527
trainer/Q Targets Max                       307.507
trainer/Q Targets Min                         8.62456
trainer/Log Pis Mean                          6.09049
trainer/Log Pis Std                           5.27661
trainer/Log Pis Max                          22.1375
trainer/Log Pis Min                          -8.44128
trainer/policy/mean Mean                      0.00942138
trainer/policy/mean Std                       0.773396
trainer/policy/mean Max                       0.999904
trainer/policy/mean Min                      -0.999846
trainer/policy/normal/std Mean                0.455295
trainer/policy/normal/std Std                 0.137497
trainer/policy/normal/std Max                 1.2469
trainer/policy/normal/std Min                 0.119602
trainer/policy/normal/log_std Mean           -0.837591
trainer/policy/normal/log_std Std             0.332358
trainer/policy/normal/log_std Max             0.220663
trainer/policy/normal/log_std Min            -2.12358
trainer/Alpha                                 0.085034
trainer/Alpha Loss                            0.22304
expl/num steps total                     107000
expl/num paths total                        107
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.1663
expl/Rewards Std                              1.09634
expl/Rewards Max                              6.18559
expl/Rewards Min                             -0.412756
expl/Returns Mean                          4166.3
expl/Returns Std                              0
expl/Returns Max                           4166.3
expl/Returns Min                           4166.3
expl/Actions Mean                             0.0203645
expl/Actions Std                              0.836189
expl/Actions Max                              0.999782
expl/Actions Min                             -0.999459
expl/Num Paths                                1
expl/Average Returns                       4166.3
expl/env_infos/final/reward_run Mean          5.36022
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.36022
expl/env_infos/final/reward_run Min           5.36022
expl/env_infos/initial/reward_run Mean       -0.116544
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.116544
expl/env_infos/initial/reward_run Min        -0.116544
expl/env_infos/reward_run Mean                4.58608
expl/env_infos/reward_run Std                 1.09986
expl/env_infos/reward_run Max                 6.65051
expl/env_infos/reward_run Min                -0.116544
expl/env_infos/final/reward_ctrl Mean        -0.485022
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.485022
expl/env_infos/final/reward_ctrl Min         -0.485022
expl/env_infos/initial/reward_ctrl Mean      -0.217594
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.217594
expl/env_infos/initial/reward_ctrl Min       -0.217594
expl/env_infos/reward_ctrl Mean              -0.419776
expl/env_infos/reward_ctrl Std                0.0835423
expl/env_infos/reward_ctrl Max               -0.110284
expl/env_infos/reward_ctrl Min               -0.584452
eval/num steps total                     530000
eval/num paths total                        530
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.36642
eval/Rewards Std                              1.13614
eval/Rewards Max                              6.57837
eval/Rewards Min                             -0.924088
eval/Returns Mean                          4366.42
eval/Returns Std                             77.6671
eval/Returns Max                           4502.71
eval/Returns Min                           4280.07
eval/Actions Mean                             0.0251578
eval/Actions Std                              0.851961
eval/Actions Max                              0.99817
eval/Actions Min                             -0.998993
eval/Num Paths                                5
eval/Average Returns                       4366.42
eval/env_infos/final/reward_run Mean          4.39746
eval/env_infos/final/reward_run Std           1.45627
eval/env_infos/final/reward_run Max           6.85005
eval/env_infos/final/reward_run Min           3.16447
eval/env_infos/initial/reward_run Mean       -0.0198258
eval/env_infos/initial/reward_run Std         0.233173
eval/env_infos/initial/reward_run Max         0.293786
eval/env_infos/initial/reward_run Min        -0.31173
eval/env_infos/reward_run Mean                4.8023
eval/env_infos/reward_run Std                 1.13488
eval/env_infos/reward_run Max                 7.13923
eval/env_infos/reward_run Min                -0.39736
eval/env_infos/final/reward_ctrl Mean        -0.447403
eval/env_infos/final/reward_ctrl Std          0.07643
eval/env_infos/final/reward_ctrl Max         -0.300057
eval/env_infos/final/reward_ctrl Min         -0.520976
eval/env_infos/initial/reward_ctrl Mean      -0.1956
eval/env_infos/initial/reward_ctrl Std        0.0227604
eval/env_infos/initial/reward_ctrl Max       -0.16538
eval/env_infos/initial/reward_ctrl Min       -0.222907
eval/env_infos/reward_ctrl Mean              -0.435882
eval/env_infos/reward_ctrl Std                0.0778679
eval/env_infos/reward_ctrl Max               -0.125073
eval/env_infos/reward_ctrl Min               -0.585054
time/data storing (s)                         0.00449945
time/evaluation sampling (s)                  2.07105
time/exploration sampling (s)                 0.542905
time/logging (s)                              0.0141084
time/sac training (s)                         8.00467
time/saving (s)                               0.00443359
time/training (s)                             5.483e-05
time/epoch (s)                               10.6417
time/total (s)                             1134.31
Epoch                                       105
---------------------------------------  ---------------
2021-11-24 00:48:17.260524 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 106 finished
---------------------------------------  ----------------
epoch                                       106
replay_buffer/size                       108000
trainer/num train calls                  107000
trainer/QF1 Loss                              8.97344
trainer/QF2 Loss                              7.7602
trainer/Policy Loss                        -214.228
trainer/Q1 Predictions Mean                 214.192
trainer/Q1 Predictions Std                   96.0943
trainer/Q1 Predictions Max                  307.524
trainer/Q1 Predictions Min                   11.5195
trainer/Q2 Predictions Mean                 214.479
trainer/Q2 Predictions Std                   96.167
trainer/Q2 Predictions Max                  306.972
trainer/Q2 Predictions Min                   11.2068
trainer/Q Targets Mean                      214.158
trainer/Q Targets Std                        96.3212
trainer/Q Targets Max                       308.084
trainer/Q Targets Min                        10.4915
trainer/Log Pis Mean                          5.90563
trainer/Log Pis Std                           5.37346
trainer/Log Pis Max                          23.8671
trainer/Log Pis Min                          -6.38843
trainer/policy/mean Mean                      0.0025103
trainer/policy/mean Std                       0.766926
trainer/policy/mean Max                       0.998172
trainer/policy/mean Min                      -0.999903
trainer/policy/normal/std Mean                0.451895
trainer/policy/normal/std Std                 0.135764
trainer/policy/normal/std Max                 0.99945
trainer/policy/normal/std Min                 0.103584
trainer/policy/normal/log_std Mean           -0.846207
trainer/policy/normal/log_std Std             0.339036
trainer/policy/normal/log_std Max            -0.000550302
trainer/policy/normal/log_std Min            -2.26737
trainer/Alpha                                 0.084828
trainer/Alpha Loss                           -0.232821
expl/num steps total                     108000
expl/num paths total                        108
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.46371
expl/Rewards Std                              1.09316
expl/Rewards Max                              6.55458
expl/Rewards Min                             -0.305525
expl/Returns Mean                          4463.71
expl/Returns Std                              0
expl/Returns Max                           4463.71
expl/Returns Min                           4463.71
expl/Actions Mean                             0.0248888
expl/Actions Std                              0.843112
expl/Actions Max                              0.999601
expl/Actions Min                             -0.999753
expl/Num Paths                                1
expl/Average Returns                       4463.71
expl/env_infos/final/reward_run Mean          4.40984
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.40984
expl/env_infos/final/reward_run Min           4.40984
expl/env_infos/initial/reward_run Mean       -0.137777
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.137777
expl/env_infos/initial/reward_run Min        -0.137777
expl/env_infos/reward_run Mean                4.89058
expl/env_infos/reward_run Std                 1.08557
expl/env_infos/reward_run Max                 7.07769
expl/env_infos/reward_run Min                -0.137777
expl/env_infos/final/reward_ctrl Mean        -0.41315
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.41315
expl/env_infos/final/reward_ctrl Min         -0.41315
expl/env_infos/initial/reward_ctrl Mean      -0.167748
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.167748
expl/env_infos/initial/reward_ctrl Min       -0.167748
expl/env_infos/reward_ctrl Mean              -0.426874
expl/env_infos/reward_ctrl Std                0.0770617
expl/env_infos/reward_ctrl Max               -0.102668
expl/env_infos/reward_ctrl Min               -0.587091
eval/num steps total                     535000
eval/num paths total                        535
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.34527
eval/Rewards Std                              1.16247
eval/Rewards Max                              6.80869
eval/Rewards Min                             -0.900452
eval/Returns Mean                          4345.27
eval/Returns Std                             66.5528
eval/Returns Max                           4439.21
eval/Returns Min                           4232.91
eval/Actions Mean                             0.0267383
eval/Actions Std                              0.849458
eval/Actions Max                              0.998439
eval/Actions Min                             -0.99959
eval/Num Paths                                5
eval/Average Returns                       4345.27
eval/env_infos/final/reward_run Mean          5.56839
eval/env_infos/final/reward_run Std           1.03696
eval/env_infos/final/reward_run Max           6.68961
eval/env_infos/final/reward_run Min           3.79481
eval/env_infos/initial/reward_run Mean       -0.0722017
eval/env_infos/initial/reward_run Std         0.159987
eval/env_infos/initial/reward_run Max         0.123201
eval/env_infos/initial/reward_run Min        -0.314207
eval/env_infos/reward_run Mean                4.77865
eval/env_infos/reward_run Std                 1.15474
eval/env_infos/reward_run Max                 7.29872
eval/env_infos/reward_run Min                -0.444328
eval/env_infos/final/reward_ctrl Mean        -0.442872
eval/env_infos/final/reward_ctrl Std          0.0756626
eval/env_infos/final/reward_ctrl Max         -0.36975
eval/env_infos/final/reward_ctrl Min         -0.575326
eval/env_infos/initial/reward_ctrl Mean      -0.163686
eval/env_infos/initial/reward_ctrl Std        0.036408
eval/env_infos/initial/reward_ctrl Max       -0.127621
eval/env_infos/initial/reward_ctrl Min       -0.230379
eval/env_infos/reward_ctrl Mean              -0.433376
eval/env_infos/reward_ctrl Std                0.0767881
eval/env_infos/reward_ctrl Max               -0.118527
eval/env_infos/reward_ctrl Min               -0.594345
time/data storing (s)                         0.00499881
time/evaluation sampling (s)                  2.07445
time/exploration sampling (s)                 0.558181
time/logging (s)                              0.0135889
time/sac training (s)                         8.22786
time/saving (s)                               0.00388851
time/training (s)                             3.5793e-05
time/epoch (s)                               10.883
time/total (s)                             1145.53
Epoch                                       106
---------------------------------------  ----------------
2021-11-24 00:48:28.072200 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 107 finished
---------------------------------------  ---------------
epoch                                       107
replay_buffer/size                       109000
trainer/num train calls                  108000
trainer/QF1 Loss                             12.1504
trainer/QF2 Loss                              9.46986
trainer/Policy Loss                        -212.83
trainer/Q1 Predictions Mean                 213.074
trainer/Q1 Predictions Std                  100.728
trainer/Q1 Predictions Max                  310.707
trainer/Q1 Predictions Min                   11.4817
trainer/Q2 Predictions Mean                 213.239
trainer/Q2 Predictions Std                  101.004
trainer/Q2 Predictions Max                  310.053
trainer/Q2 Predictions Min                    8.76759
trainer/Q Targets Mean                      212.416
trainer/Q Targets Std                       100.452
trainer/Q Targets Max                       309.616
trainer/Q Targets Min                        10.8106
trainer/Log Pis Mean                          6.34661
trainer/Log Pis Std                           5.60919
trainer/Log Pis Max                          20.3836
trainer/Log Pis Min                          -7.01729
trainer/policy/mean Mean                      0.00427474
trainer/policy/mean Std                       0.783763
trainer/policy/mean Max                       0.999971
trainer/policy/mean Min                      -0.999604
trainer/policy/normal/std Mean                0.478004
trainer/policy/normal/std Std                 0.135758
trainer/policy/normal/std Max                 1.10311
trainer/policy/normal/std Min                 0.123819
trainer/policy/normal/log_std Mean           -0.783928
trainer/policy/normal/log_std Std             0.317001
trainer/policy/normal/log_std Max             0.0981294
trainer/policy/normal/log_std Min            -2.08893
trainer/Alpha                                 0.0848894
trainer/Alpha Loss                            0.854878
expl/num steps total                     109000
expl/num paths total                        109
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.12313
expl/Rewards Std                              1.18922
expl/Rewards Max                              6.2481
expl/Rewards Min                             -0.395961
expl/Returns Mean                          4123.13
expl/Returns Std                              0
expl/Returns Max                           4123.13
expl/Returns Min                           4123.13
expl/Actions Mean                             0.00879566
expl/Actions Std                              0.848564
expl/Actions Max                              0.999908
expl/Actions Min                             -0.999835
expl/Num Paths                                1
expl/Average Returns                       4123.13
expl/env_infos/final/reward_run Mean          2.97834
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.97834
expl/env_infos/final/reward_run Min           2.97834
expl/env_infos/initial/reward_run Mean        0.140618
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.140618
expl/env_infos/initial/reward_run Min         0.140618
expl/env_infos/reward_run Mean                4.55521
expl/env_infos/reward_run Std                 1.1841
expl/env_infos/reward_run Max                 6.7014
expl/env_infos/reward_run Min                -0.0317948
expl/env_infos/final/reward_ctrl Mean        -0.25632
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.25632
expl/env_infos/final/reward_ctrl Min         -0.25632
expl/env_infos/initial/reward_ctrl Mean      -0.183166
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.183166
expl/env_infos/initial/reward_ctrl Min       -0.183166
expl/env_infos/reward_ctrl Mean              -0.432083
expl/env_infos/reward_ctrl Std                0.0787836
expl/env_infos/reward_ctrl Max               -0.143888
expl/env_infos/reward_ctrl Min               -0.586247
eval/num steps total                     540000
eval/num paths total                        540
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.15784
eval/Rewards Std                              1.23207
eval/Rewards Max                              6.75668
eval/Rewards Min                             -0.922833
eval/Returns Mean                          4157.84
eval/Returns Std                            111.312
eval/Returns Max                           4285.46
eval/Returns Min                           4011.98
eval/Actions Mean                             0.0120874
eval/Actions Std                              0.862298
eval/Actions Max                              0.999893
eval/Actions Min                             -0.999689
eval/Num Paths                                5
eval/Average Returns                       4157.84
eval/env_infos/final/reward_run Mean          5.84261
eval/env_infos/final/reward_run Std           0.485623
eval/env_infos/final/reward_run Max           6.47982
eval/env_infos/final/reward_run Min           5.08955
eval/env_infos/initial/reward_run Mean        0.0444634
eval/env_infos/initial/reward_run Std         0.436858
eval/env_infos/initial/reward_run Max         0.728939
eval/env_infos/initial/reward_run Min        -0.634042
eval/env_infos/reward_run Mean                4.60406
eval/env_infos/reward_run Std                 1.22583
eval/env_infos/reward_run Max                 7.19255
eval/env_infos/reward_run Min                -0.634042
eval/env_infos/final/reward_ctrl Mean        -0.429676
eval/env_infos/final/reward_ctrl Std          0.0385952
eval/env_infos/final/reward_ctrl Max         -0.388172
eval/env_infos/final/reward_ctrl Min         -0.481017
eval/env_infos/initial/reward_ctrl Mean      -0.197655
eval/env_infos/initial/reward_ctrl Std        0.0494607
eval/env_infos/initial/reward_ctrl Max       -0.149471
eval/env_infos/initial/reward_ctrl Min       -0.288791
eval/env_infos/reward_ctrl Mean              -0.446222
eval/env_infos/reward_ctrl Std                0.0732432
eval/env_infos/reward_ctrl Max               -0.108034
eval/env_infos/reward_ctrl Min               -0.583616
time/data storing (s)                         0.00447746
time/evaluation sampling (s)                  2.02546
time/exploration sampling (s)                 0.517733
time/logging (s)                              0.0142993
time/sac training (s)                         7.91133
time/saving (s)                               0.00396794
time/training (s)                             4.7099e-05
time/epoch (s)                               10.4773
time/total (s)                             1156.33
Epoch                                       107
---------------------------------------  ---------------
2021-11-24 00:48:38.860193 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 108 finished
---------------------------------------  ---------------
epoch                                       108
replay_buffer/size                       110000
trainer/num train calls                  109000
trainer/QF1 Loss                              8.64062
trainer/QF2 Loss                              6.82553
trainer/Policy Loss                        -217.243
trainer/Q1 Predictions Mean                 217.303
trainer/Q1 Predictions Std                   98.0847
trainer/Q1 Predictions Max                  311.793
trainer/Q1 Predictions Min                   11.5679
trainer/Q2 Predictions Mean                 217.34
trainer/Q2 Predictions Std                   98.2191
trainer/Q2 Predictions Max                  313.011
trainer/Q2 Predictions Min                   11.3912
trainer/Q Targets Mean                      217.871
trainer/Q Targets Std                        98.4447
trainer/Q Targets Max                       312.471
trainer/Q Targets Min                         9.95166
trainer/Log Pis Mean                          6.38932
trainer/Log Pis Std                           4.82656
trainer/Log Pis Max                          16.6722
trainer/Log Pis Min                          -4.50921
trainer/policy/mean Mean                      0.0483137
trainer/policy/mean Std                       0.783712
trainer/policy/mean Max                       0.999557
trainer/policy/mean Min                      -0.998977
trainer/policy/normal/std Mean                0.470991
trainer/policy/normal/std Std                 0.128548
trainer/policy/normal/std Max                 0.960052
trainer/policy/normal/std Min                 0.106949
trainer/policy/normal/log_std Mean           -0.79574
trainer/policy/normal/log_std Std             0.307451
trainer/policy/normal/log_std Max            -0.0407676
trainer/policy/normal/log_std Min            -2.23541
trainer/Alpha                                 0.0860424
trainer/Alpha Loss                            0.954979
expl/num steps total                     110000
expl/num paths total                        110
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.18708
expl/Rewards Std                              1.19885
expl/Rewards Max                              6.44572
expl/Rewards Min                             -0.610105
expl/Returns Mean                          4187.08
expl/Returns Std                              0
expl/Returns Max                           4187.08
expl/Returns Min                           4187.08
expl/Actions Mean                             0.0259103
expl/Actions Std                              0.830994
expl/Actions Max                              0.999527
expl/Actions Min                             -0.999777
expl/Num Paths                                1
expl/Average Returns                       4187.08
expl/env_infos/final/reward_run Mean          5.5629
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.5629
expl/env_infos/final/reward_run Min           5.5629
expl/env_infos/initial/reward_run Mean        0.721011
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.721011
expl/env_infos/initial/reward_run Min         0.721011
expl/env_infos/reward_run Mean                4.60181
expl/env_infos/reward_run Std                 1.1956
expl/env_infos/reward_run Max                 6.96691
expl/env_infos/reward_run Min                -0.109168
expl/env_infos/final/reward_ctrl Mean        -0.284633
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.284633
expl/env_infos/final/reward_ctrl Min         -0.284633
expl/env_infos/initial/reward_ctrl Mean      -0.308828
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.308828
expl/env_infos/initial/reward_ctrl Min       -0.308828
expl/env_infos/reward_ctrl Mean              -0.414733
expl/env_infos/reward_ctrl Std                0.0807774
expl/env_infos/reward_ctrl Max               -0.0909755
expl/env_infos/reward_ctrl Min               -0.580194
eval/num steps total                     545000
eval/num paths total                        545
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.4055
eval/Rewards Std                              1.17659
eval/Rewards Max                              6.83004
eval/Rewards Min                             -1.27089
eval/Returns Mean                          4405.5
eval/Returns Std                             14.1318
eval/Returns Max                           4422.6
eval/Returns Min                           4380.45
eval/Actions Mean                             0.0330891
eval/Actions Std                              0.847715
eval/Actions Max                              0.998651
eval/Actions Min                             -0.998854
eval/Num Paths                                5
eval/Average Returns                       4405.5
eval/env_infos/final/reward_run Mean          5.31197
eval/env_infos/final/reward_run Std           1.00564
eval/env_infos/final/reward_run Max           6.49494
eval/env_infos/final/reward_run Min           3.56426
eval/env_infos/initial/reward_run Mean       -0.128377
eval/env_infos/initial/reward_run Std         0.0834861
eval/env_infos/initial/reward_run Max        -0.032938
eval/env_infos/initial/reward_run Min        -0.249256
eval/env_infos/reward_run Mean                4.83733
eval/env_infos/reward_run Std                 1.16887
eval/env_infos/reward_run Max                 7.30673
eval/env_infos/reward_run Min                -0.802506
eval/env_infos/final/reward_ctrl Mean        -0.44907
eval/env_infos/final/reward_ctrl Std          0.0669732
eval/env_infos/final/reward_ctrl Max         -0.354047
eval/env_infos/final/reward_ctrl Min         -0.559697
eval/env_infos/initial/reward_ctrl Mean      -0.174352
eval/env_infos/initial/reward_ctrl Std        0.0295189
eval/env_infos/initial/reward_ctrl Max       -0.145908
eval/env_infos/initial/reward_ctrl Min       -0.223417
eval/env_infos/reward_ctrl Mean              -0.431829
eval/env_infos/reward_ctrl Std                0.0738635
eval/env_infos/reward_ctrl Max               -0.124947
eval/env_infos/reward_ctrl Min               -0.580999
time/data storing (s)                         0.00449892
time/evaluation sampling (s)                  2.0119
time/exploration sampling (s)                 0.529902
time/logging (s)                              0.0137389
time/sac training (s)                         7.88951
time/saving (s)                               0.00382346
time/training (s)                             3.6646e-05
time/epoch (s)                               10.4534
time/total (s)                             1167.1
Epoch                                       108
---------------------------------------  ---------------
2021-11-24 00:48:49.697811 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 109 finished
---------------------------------------  ---------------
epoch                                       109
replay_buffer/size                       111000
trainer/num train calls                  110000
trainer/QF1 Loss                              6.94933
trainer/QF2 Loss                              7.38806
trainer/Policy Loss                        -211.202
trainer/Q1 Predictions Mean                 211.311
trainer/Q1 Predictions Std                  103.388
trainer/Q1 Predictions Max                  307.381
trainer/Q1 Predictions Min                    9.62971
trainer/Q2 Predictions Mean                 210.973
trainer/Q2 Predictions Std                  103.349
trainer/Q2 Predictions Max                  307.587
trainer/Q2 Predictions Min                    9.65297
trainer/Q Targets Mean                      211.285
trainer/Q Targets Std                       103.542
trainer/Q Targets Max                       308.046
trainer/Q Targets Min                         9.48221
trainer/Log Pis Mean                          5.8184
trainer/Log Pis Std                           5.48062
trainer/Log Pis Max                          18.7704
trainer/Log Pis Min                          -7.44439
trainer/policy/mean Mean                      0.0379965
trainer/policy/mean Std                       0.760188
trainer/policy/mean Max                       0.999607
trainer/policy/mean Min                      -0.999279
trainer/policy/normal/std Mean                0.469827
trainer/policy/normal/std Std                 0.134909
trainer/policy/normal/std Max                 0.911605
trainer/policy/normal/std Min                 0.0789033
trainer/policy/normal/log_std Mean           -0.80283
trainer/policy/normal/log_std Std             0.324357
trainer/policy/normal/log_std Max            -0.0925489
trainer/policy/normal/log_std Min            -2.53953
trainer/Alpha                                 0.0855385
trainer/Alpha Loss                           -0.446522
expl/num steps total                     111000
expl/num paths total                        111
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.38448
expl/Rewards Std                              1.15358
expl/Rewards Max                              6.43096
expl/Rewards Min                             -0.831735
expl/Returns Mean                          4384.48
expl/Returns Std                              0
expl/Returns Max                           4384.48
expl/Returns Min                           4384.48
expl/Actions Mean                             0.0579155
expl/Actions Std                              0.835313
expl/Actions Max                              0.999868
expl/Actions Min                             -0.999737
expl/Num Paths                                1
expl/Average Returns                       4384.48
expl/env_infos/final/reward_run Mean          3.91542
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.91542
expl/env_infos/final/reward_run Min           3.91542
expl/env_infos/initial/reward_run Mean        0.0596455
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0596455
expl/env_infos/initial/reward_run Min         0.0596455
expl/env_infos/reward_run Mean                4.80514
expl/env_infos/reward_run Std                 1.15395
expl/env_infos/reward_run Max                 6.98249
expl/env_infos/reward_run Min                -0.359775
expl/env_infos/final/reward_ctrl Mean        -0.490456
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.490456
expl/env_infos/final/reward_ctrl Min         -0.490456
expl/env_infos/initial/reward_ctrl Mean      -0.111237
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.111237
expl/env_infos/initial/reward_ctrl Min       -0.111237
expl/env_infos/reward_ctrl Mean              -0.420661
expl/env_infos/reward_ctrl Std                0.0778308
expl/env_infos/reward_ctrl Max               -0.111237
expl/env_infos/reward_ctrl Min               -0.583059
eval/num steps total                     550000
eval/num paths total                        550
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.30146
eval/Rewards Std                              1.19679
eval/Rewards Max                              6.66157
eval/Rewards Min                             -1.00106
eval/Returns Mean                          4301.46
eval/Returns Std                             72.703
eval/Returns Max                           4399.27
eval/Returns Min                           4236.79
eval/Actions Mean                             0.0649006
eval/Actions Std                              0.847066
eval/Actions Max                              0.999376
eval/Actions Min                             -0.999138
eval/Num Paths                                5
eval/Average Returns                       4301.46
eval/env_infos/final/reward_run Mean          4.51816
eval/env_infos/final/reward_run Std           0.491157
eval/env_infos/final/reward_run Max           5.35934
eval/env_infos/final/reward_run Min           3.96467
eval/env_infos/initial/reward_run Mean       -0.168403
eval/env_infos/initial/reward_run Std         0.311966
eval/env_infos/initial/reward_run Max         0.209734
eval/env_infos/initial/reward_run Min        -0.677653
eval/env_infos/reward_run Mean                4.7345
eval/env_infos/reward_run Std                 1.20086
eval/env_infos/reward_run Max                 7.18415
eval/env_infos/reward_run Min                -0.677653
eval/env_infos/final/reward_ctrl Mean        -0.409913
eval/env_infos/final/reward_ctrl Std          0.0923705
eval/env_infos/final/reward_ctrl Max         -0.230685
eval/env_infos/final/reward_ctrl Min         -0.477276
eval/env_infos/initial/reward_ctrl Mean      -0.195163
eval/env_infos/initial/reward_ctrl Std        0.0251243
eval/env_infos/initial/reward_ctrl Max       -0.159147
eval/env_infos/initial/reward_ctrl Min       -0.236634
eval/env_infos/reward_ctrl Mean              -0.43304
eval/env_infos/reward_ctrl Std                0.0734552
eval/env_infos/reward_ctrl Max               -0.111109
eval/env_infos/reward_ctrl Min               -0.57887
time/data storing (s)                         0.0045212
time/evaluation sampling (s)                  2.05695
time/exploration sampling (s)                 0.556944
time/logging (s)                              0.0136653
time/sac training (s)                         7.86258
time/saving (s)                               0.00379804
time/training (s)                             3.541e-05
time/epoch (s)                               10.4985
time/total (s)                             1177.92
Epoch                                       109
---------------------------------------  ---------------
2021-11-24 00:49:00.415469 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 110 finished
---------------------------------------  ---------------
epoch                                       110
replay_buffer/size                       112000
trainer/num train calls                  111000
trainer/QF1 Loss                             10.6665
trainer/QF2 Loss                              8.58718
trainer/Policy Loss                        -228.186
trainer/Q1 Predictions Mean                 228.158
trainer/Q1 Predictions Std                   91.6822
trainer/Q1 Predictions Max                  312.503
trainer/Q1 Predictions Min                   10.3205
trainer/Q2 Predictions Mean                 228.196
trainer/Q2 Predictions Std                   91.7648
trainer/Q2 Predictions Max                  312.71
trainer/Q2 Predictions Min                   10.4632
trainer/Q Targets Mean                      227.579
trainer/Q Targets Std                        91.7252
trainer/Q Targets Max                       313.724
trainer/Q Targets Min                        10.1292
trainer/Log Pis Mean                          6.38947
trainer/Log Pis Std                           4.77652
trainer/Log Pis Max                          21.7042
trainer/Log Pis Min                          -4.22474
trainer/policy/mean Mean                      0.0111525
trainer/policy/mean Std                       0.781037
trainer/policy/mean Max                       0.999347
trainer/policy/mean Min                      -0.999866
trainer/policy/normal/std Mean                0.453218
trainer/policy/normal/std Std                 0.128184
trainer/policy/normal/std Max                 1.12993
trainer/policy/normal/std Min                 0.1134
trainer/policy/normal/log_std Mean           -0.836676
trainer/policy/normal/log_std Std             0.31475
trainer/policy/normal/log_std Max             0.122155
trainer/policy/normal/log_std Min            -2.17683
trainer/Alpha                                 0.0864567
trainer/Alpha Loss                            0.953472
expl/num steps total                     112000
expl/num paths total                        112
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.18326
expl/Rewards Std                              1.23497
expl/Rewards Max                              6.46426
expl/Rewards Min                             -0.945577
expl/Returns Mean                          4183.26
expl/Returns Std                              0
expl/Returns Max                           4183.26
expl/Returns Min                           4183.26
expl/Actions Mean                             0.0430494
expl/Actions Std                              0.828873
expl/Actions Max                              0.999975
expl/Actions Min                             -0.999559
expl/Num Paths                                1
expl/Average Returns                       4183.26
expl/env_infos/final/reward_run Mean          5.40736
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.40736
expl/env_infos/final/reward_run Min           5.40736
expl/env_infos/initial/reward_run Mean        0.144256
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.144256
expl/env_infos/initial/reward_run Min         0.144256
expl/env_infos/reward_run Mean                4.59659
expl/env_infos/reward_run Std                 1.23801
expl/env_infos/reward_run Max                 6.96959
expl/env_infos/reward_run Min                -0.559034
expl/env_infos/final/reward_ctrl Mean        -0.506527
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.506527
expl/env_infos/final/reward_ctrl Min         -0.506527
expl/env_infos/initial/reward_ctrl Mean      -0.135402
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.135402
expl/env_infos/initial/reward_ctrl Min       -0.135402
expl/env_infos/reward_ctrl Mean              -0.41333
expl/env_infos/reward_ctrl Std                0.0812945
expl/env_infos/reward_ctrl Max               -0.113154
expl/env_infos/reward_ctrl Min               -0.585207
eval/num steps total                     555000
eval/num paths total                        555
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.39714
eval/Rewards Std                              1.15307
eval/Rewards Max                              6.71546
eval/Rewards Min                             -0.733741
eval/Returns Mean                          4397.14
eval/Returns Std                             79.937
eval/Returns Max                           4522.55
eval/Returns Min                           4279.68
eval/Actions Mean                             0.0498031
eval/Actions Std                              0.841845
eval/Actions Max                              0.999615
eval/Actions Min                             -0.999057
eval/Num Paths                                5
eval/Average Returns                       4397.14
eval/env_infos/final/reward_run Mean          5.02646
eval/env_infos/final/reward_run Std           1.22742
eval/env_infos/final/reward_run Max           6.62255
eval/env_infos/final/reward_run Min           3.5113
eval/env_infos/initial/reward_run Mean        0.00527504
eval/env_infos/initial/reward_run Std         0.145109
eval/env_infos/initial/reward_run Max         0.185023
eval/env_infos/initial/reward_run Min        -0.244282
eval/env_infos/reward_run Mean                4.82385
eval/env_infos/reward_run Std                 1.1519
eval/env_infos/reward_run Max                 7.20919
eval/env_infos/reward_run Min                -0.466093
eval/env_infos/final/reward_ctrl Mean        -0.378161
eval/env_infos/final/reward_ctrl Std          0.0869791
eval/env_infos/final/reward_ctrl Max         -0.250717
eval/env_infos/final/reward_ctrl Min         -0.505543
eval/env_infos/initial/reward_ctrl Mean      -0.153116
eval/env_infos/initial/reward_ctrl Std        0.0118543
eval/env_infos/initial/reward_ctrl Max       -0.131217
eval/env_infos/initial/reward_ctrl Min       -0.16522
eval/env_infos/reward_ctrl Mean              -0.42671
eval/env_infos/reward_ctrl Std                0.0728593
eval/env_infos/reward_ctrl Max               -0.0933787
eval/env_infos/reward_ctrl Min               -0.585758
time/data storing (s)                         0.00448444
time/evaluation sampling (s)                  2.03491
time/exploration sampling (s)                 0.531788
time/logging (s)                              0.0144632
time/sac training (s)                         7.79562
time/saving (s)                               0.00417184
time/training (s)                             5.0634e-05
time/epoch (s)                               10.3855
time/total (s)                             1188.63
Epoch                                       110
---------------------------------------  ---------------
2021-11-24 00:49:11.201792 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 111 finished
---------------------------------------  ---------------
epoch                                       111
replay_buffer/size                       113000
trainer/num train calls                  112000
trainer/QF1 Loss                              7.87343
trainer/QF2 Loss                              7.77306
trainer/Policy Loss                        -226.35
trainer/Q1 Predictions Mean                 226.744
trainer/Q1 Predictions Std                  100.173
trainer/Q1 Predictions Max                  315.542
trainer/Q1 Predictions Min                   11.7018
trainer/Q2 Predictions Mean                 226.523
trainer/Q2 Predictions Std                  100.115
trainer/Q2 Predictions Max                  317.976
trainer/Q2 Predictions Min                   11.5587
trainer/Q Targets Mean                      226.585
trainer/Q Targets Std                       100.117
trainer/Q Targets Max                       314.237
trainer/Q Targets Min                        10.8678
trainer/Log Pis Mean                          6.85015
trainer/Log Pis Std                           5.30708
trainer/Log Pis Max                          20.293
trainer/Log Pis Min                          -5.40652
trainer/policy/mean Mean                      0.0307716
trainer/policy/mean Std                       0.788484
trainer/policy/mean Max                       0.999994
trainer/policy/mean Min                      -0.999099
trainer/policy/normal/std Mean                0.455054
trainer/policy/normal/std Std                 0.129392
trainer/policy/normal/std Max                 0.879521
trainer/policy/normal/std Min                 0.123886
trainer/policy/normal/log_std Mean           -0.833832
trainer/policy/normal/log_std Std             0.320103
trainer/policy/normal/log_std Max            -0.128378
trainer/policy/normal/log_std Min            -2.08839
trainer/Alpha                                 0.0892281
trainer/Alpha Loss                            2.05443
expl/num steps total                     113000
expl/num paths total                        113
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.37029
expl/Rewards Std                              1.11155
expl/Rewards Max                              6.65035
expl/Rewards Min                             -0.401302
expl/Returns Mean                          4370.29
expl/Returns Std                              0
expl/Returns Max                           4370.29
expl/Returns Min                           4370.29
expl/Actions Mean                             0.0175307
expl/Actions Std                              0.847549
expl/Actions Max                              0.999854
expl/Actions Min                             -0.999703
expl/Num Paths                                1
expl/Average Returns                       4370.29
expl/env_infos/final/reward_run Mean          4.67554
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.67554
expl/env_infos/final/reward_run Min           4.67554
expl/env_infos/initial/reward_run Mean       -0.183169
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.183169
expl/env_infos/initial/reward_run Min        -0.183169
expl/env_infos/reward_run Mean                4.80147
expl/env_infos/reward_run Std                 1.09944
expl/env_infos/reward_run Max                 7.19312
expl/env_infos/reward_run Min                -0.183169
expl/env_infos/final/reward_ctrl Mean        -0.362196
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.362196
expl/env_infos/final/reward_ctrl Min         -0.362196
expl/env_infos/initial/reward_ctrl Mean      -0.218133
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.218133
expl/env_infos/initial/reward_ctrl Min       -0.218133
expl/env_infos/reward_ctrl Mean              -0.431188
expl/env_infos/reward_ctrl Std                0.0740697
expl/env_infos/reward_ctrl Max               -0.202051
expl/env_infos/reward_ctrl Min               -0.583161
eval/num steps total                     560000
eval/num paths total                        560
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.59775
eval/Rewards Std                              1.18037
eval/Rewards Max                              6.89325
eval/Rewards Min                             -0.617962
eval/Returns Mean                          4597.75
eval/Returns Std                             79.5394
eval/Returns Max                           4701.88
eval/Returns Min                           4486.64
eval/Actions Mean                             0.022759
eval/Actions Std                              0.860914
eval/Actions Max                              0.998925
eval/Actions Min                             -0.99856
eval/Num Paths                                5
eval/Average Returns                       4597.75
eval/env_infos/final/reward_run Mean          5.72482
eval/env_infos/final/reward_run Std           0.660135
eval/env_infos/final/reward_run Max           6.41508
eval/env_infos/final/reward_run Min           4.49283
eval/env_infos/initial/reward_run Mean       -0.0691655
eval/env_infos/initial/reward_run Std         0.131813
eval/env_infos/initial/reward_run Max         0.0670704
eval/env_infos/initial/reward_run Min        -0.254648
eval/env_infos/reward_run Mean                5.04276
eval/env_infos/reward_run Std                 1.16813
eval/env_infos/reward_run Max                 7.41347
eval/env_infos/reward_run Min                -0.264354
eval/env_infos/final/reward_ctrl Mean        -0.456383
eval/env_infos/final/reward_ctrl Std          0.0760439
eval/env_infos/final/reward_ctrl Max         -0.380799
eval/env_infos/final/reward_ctrl Min         -0.549845
eval/env_infos/initial/reward_ctrl Mean      -0.167365
eval/env_infos/initial/reward_ctrl Std        0.013265
eval/env_infos/initial/reward_ctrl Max       -0.155878
eval/env_infos/initial/reward_ctrl Min       -0.183764
eval/env_infos/reward_ctrl Mean              -0.445015
eval/env_infos/reward_ctrl Std                0.0715848
eval/env_infos/reward_ctrl Max               -0.118578
eval/env_infos/reward_ctrl Min               -0.586334
time/data storing (s)                         0.0045079
time/evaluation sampling (s)                  2.06751
time/exploration sampling (s)                 0.535929
time/logging (s)                              0.0137348
time/sac training (s)                         7.82925
time/saving (s)                               0.00382757
time/training (s)                             3.4311e-05
time/epoch (s)                               10.4548
time/total (s)                             1199.4
Epoch                                       111
---------------------------------------  ---------------
2021-11-24 00:49:22.015455 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 112 finished
---------------------------------------  ----------------
epoch                                       112
replay_buffer/size                       114000
trainer/num train calls                  113000
trainer/QF1 Loss                              9.82184
trainer/QF2 Loss                              6.82327
trainer/Policy Loss                        -218.647
trainer/Q1 Predictions Mean                 218.843
trainer/Q1 Predictions Std                  100.591
trainer/Q1 Predictions Max                  313.887
trainer/Q1 Predictions Min                   10.0271
trainer/Q2 Predictions Mean                 218.884
trainer/Q2 Predictions Std                  100.709
trainer/Q2 Predictions Max                  313.888
trainer/Q2 Predictions Min                    9.32699
trainer/Q Targets Mean                      219.106
trainer/Q Targets Std                       101.103
trainer/Q Targets Max                       315.709
trainer/Q Targets Min                        10.1997
trainer/Log Pis Mean                          5.80423
trainer/Log Pis Std                           5.09283
trainer/Log Pis Max                          16.9559
trainer/Log Pis Min                          -6.57632
trainer/policy/mean Mean                     -0.000327524
trainer/policy/mean Std                       0.774272
trainer/policy/mean Max                       0.997289
trainer/policy/mean Min                      -0.999809
trainer/policy/normal/std Mean                0.472897
trainer/policy/normal/std Std                 0.13424
trainer/policy/normal/std Max                 0.985266
trainer/policy/normal/std Min                 0.0893075
trainer/policy/normal/log_std Mean           -0.794884
trainer/policy/normal/log_std Std             0.318669
trainer/policy/normal/log_std Max            -0.0148435
trainer/policy/normal/log_std Min            -2.41567
trainer/Alpha                                 0.0884696
trainer/Alpha Loss                           -0.474768
expl/num steps total                     114000
expl/num paths total                        114
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.2753
expl/Rewards Std                              1.16485
expl/Rewards Max                              6.95217
expl/Rewards Min                             -0.145205
expl/Returns Mean                          4275.3
expl/Returns Std                              0
expl/Returns Max                           4275.3
expl/Returns Min                           4275.3
expl/Actions Mean                             0.0403038
expl/Actions Std                              0.827907
expl/Actions Max                              0.999904
expl/Actions Min                             -0.999752
expl/Num Paths                                1
expl/Average Returns                       4275.3
expl/env_infos/final/reward_run Mean          6.27829
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.27829
expl/env_infos/final/reward_run Min           6.27829
expl/env_infos/initial/reward_run Mean        0.551616
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.551616
expl/env_infos/initial/reward_run Min         0.551616
expl/env_infos/reward_run Mean                4.68753
expl/env_infos/reward_run Std                 1.16548
expl/env_infos/reward_run Max                 7.49203
expl/env_infos/reward_run Min                 0.216271
expl/env_infos/final/reward_ctrl Mean        -0.512835
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.512835
expl/env_infos/final/reward_ctrl Min         -0.512835
expl/env_infos/initial/reward_ctrl Mean      -0.252268
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.252268
expl/env_infos/initial/reward_ctrl Min       -0.252268
expl/env_infos/reward_ctrl Mean              -0.412232
expl/env_infos/reward_ctrl Std                0.084793
expl/env_infos/reward_ctrl Max               -0.0876737
expl/env_infos/reward_ctrl Min               -0.582793
eval/num steps total                     565000
eval/num paths total                        565
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.44098
eval/Rewards Std                              1.13598
eval/Rewards Max                              6.76349
eval/Rewards Min                             -0.467791
eval/Returns Mean                          4440.98
eval/Returns Std                             39.9366
eval/Returns Max                           4487.12
eval/Returns Min                           4385.11
eval/Actions Mean                             0.0456167
eval/Actions Std                              0.844057
eval/Actions Max                              0.999341
eval/Actions Min                             -0.998557
eval/Num Paths                                5
eval/Average Returns                       4440.98
eval/env_infos/final/reward_run Mean          4.89732
eval/env_infos/final/reward_run Std           1.0392
eval/env_infos/final/reward_run Max           6.20542
eval/env_infos/final/reward_run Min           3.27389
eval/env_infos/initial/reward_run Mean        0.0811312
eval/env_infos/initial/reward_run Std         0.241583
eval/env_infos/initial/reward_run Max         0.325463
eval/env_infos/initial/reward_run Min        -0.329225
eval/env_infos/reward_run Mean                4.86969
eval/env_infos/reward_run Std                 1.13858
eval/env_infos/reward_run Max                 7.31557
eval/env_infos/reward_run Min                -0.329225
eval/env_infos/final/reward_ctrl Mean        -0.416717
eval/env_infos/final/reward_ctrl Std          0.0479212
eval/env_infos/final/reward_ctrl Max         -0.357105
eval/env_infos/final/reward_ctrl Min         -0.468928
eval/env_infos/initial/reward_ctrl Mean      -0.138859
eval/env_infos/initial/reward_ctrl Std        0.00996166
eval/env_infos/initial/reward_ctrl Max       -0.127744
eval/env_infos/initial/reward_ctrl Min       -0.150664
eval/env_infos/reward_ctrl Mean              -0.428708
eval/env_infos/reward_ctrl Std                0.0801423
eval/env_infos/reward_ctrl Max               -0.0817109
eval/env_infos/reward_ctrl Min               -0.579215
time/data storing (s)                         0.00448199
time/evaluation sampling (s)                  2.04036
time/exploration sampling (s)                 0.530871
time/logging (s)                              0.0148103
time/sac training (s)                         7.88689
time/saving (s)                               0.0038585
time/training (s)                             4.1459e-05
time/epoch (s)                               10.4813
time/total (s)                             1210.2
Epoch                                       112
---------------------------------------  ----------------
2021-11-24 00:49:32.766798 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 113 finished
---------------------------------------  ----------------
epoch                                       113
replay_buffer/size                       115000
trainer/num train calls                  114000
trainer/QF1 Loss                              7.42051
trainer/QF2 Loss                              5.67587
trainer/Policy Loss                        -211.925
trainer/Q1 Predictions Mean                 211.953
trainer/Q1 Predictions Std                  107.447
trainer/Q1 Predictions Max                  311.387
trainer/Q1 Predictions Min                   10.1835
trainer/Q2 Predictions Mean                 211.955
trainer/Q2 Predictions Std                  107.45
trainer/Q2 Predictions Max                  311.61
trainer/Q2 Predictions Min                   10.7413
trainer/Q Targets Mean                      212.29
trainer/Q Targets Std                       107.664
trainer/Q Targets Max                       311.867
trainer/Q Targets Min                         9.9592
trainer/Log Pis Mean                          5.42848
trainer/Log Pis Std                           5.08246
trainer/Log Pis Max                          18.6898
trainer/Log Pis Min                          -6.71811
trainer/policy/mean Mean                      0.0217428
trainer/policy/mean Std                       0.756393
trainer/policy/mean Max                       0.999647
trainer/policy/mean Min                      -0.999336
trainer/policy/normal/std Mean                0.468663
trainer/policy/normal/std Std                 0.138731
trainer/policy/normal/std Max                 0.919381
trainer/policy/normal/std Min                 0.090439
trainer/policy/normal/log_std Mean           -0.808656
trainer/policy/normal/log_std Std             0.336132
trainer/policy/normal/log_std Max            -0.0840551
trainer/policy/normal/log_std Min            -2.40308
trainer/Alpha                                 0.0882973
trainer/Alpha Loss                           -1.3871
expl/num steps total                     115000
expl/num paths total                        115
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.26226
expl/Rewards Std                              1.14213
expl/Rewards Max                              6.57706
expl/Rewards Min                             -0.622223
expl/Returns Mean                          4262.26
expl/Returns Std                              0
expl/Returns Max                           4262.26
expl/Returns Min                           4262.26
expl/Actions Mean                             0.0296629
expl/Actions Std                              0.829269
expl/Actions Max                              0.999526
expl/Actions Min                             -0.999425
expl/Num Paths                                1
expl/Average Returns                       4262.26
expl/env_infos/final/reward_run Mean          5.30333
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.30333
expl/env_infos/final/reward_run Min           5.30333
expl/env_infos/initial/reward_run Mean        0.409448
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.409448
expl/env_infos/initial/reward_run Min         0.409448
expl/env_infos/reward_run Mean                4.6754
expl/env_infos/reward_run Std                 1.1337
expl/env_infos/reward_run Max                 7.04604
expl/env_infos/reward_run Min                -0.222419
expl/env_infos/final/reward_ctrl Mean        -0.319543
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.319543
expl/env_infos/final/reward_ctrl Min         -0.319543
expl/env_infos/initial/reward_ctrl Mean      -0.135455
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.135455
expl/env_infos/initial/reward_ctrl Min       -0.135455
expl/env_infos/reward_ctrl Mean              -0.41314
expl/env_infos/reward_ctrl Std                0.0826191
expl/env_infos/reward_ctrl Max               -0.135455
expl/env_infos/reward_ctrl Min               -0.585841
eval/num steps total                     570000
eval/num paths total                        570
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.5101
eval/Rewards Std                              1.15862
eval/Rewards Max                              6.80829
eval/Rewards Min                             -0.831959
eval/Returns Mean                          4510.1
eval/Returns Std                             55.9468
eval/Returns Max                           4557.32
eval/Returns Min                           4406.02
eval/Actions Mean                             0.0250355
eval/Actions Std                              0.846895
eval/Actions Max                              0.999623
eval/Actions Min                             -0.999149
eval/Num Paths                                5
eval/Average Returns                       4510.1
eval/env_infos/final/reward_run Mean          5.56991
eval/env_infos/final/reward_run Std           0.729079
eval/env_infos/final/reward_run Max           6.27906
eval/env_infos/final/reward_run Min           4.59958
eval/env_infos/initial/reward_run Mean       -0.138606
eval/env_infos/initial/reward_run Std         0.2398
eval/env_infos/initial/reward_run Max         0.184337
eval/env_infos/initial/reward_run Min        -0.520576
eval/env_infos/reward_run Mean                4.94081
eval/env_infos/reward_run Std                 1.15213
eval/env_infos/reward_run Max                 7.32839
eval/env_infos/reward_run Min                -0.520576
eval/env_infos/final/reward_ctrl Mean        -0.40742
eval/env_infos/final/reward_ctrl Std          0.051751
eval/env_infos/final/reward_ctrl Max         -0.307193
eval/env_infos/final/reward_ctrl Min         -0.453344
eval/env_infos/initial/reward_ctrl Mean      -0.213983
eval/env_infos/initial/reward_ctrl Std        0.0541399
eval/env_infos/initial/reward_ctrl Max       -0.158392
eval/env_infos/initial/reward_ctrl Min       -0.311383
eval/env_infos/reward_ctrl Mean              -0.430714
eval/env_infos/reward_ctrl Std                0.0780018
eval/env_infos/reward_ctrl Max               -0.130103
eval/env_infos/reward_ctrl Min               -0.581653
time/data storing (s)                         0.00473238
time/evaluation sampling (s)                  2.03671
time/exploration sampling (s)                 0.548826
time/logging (s)                              0.0136837
time/sac training (s)                         7.81432
time/saving (s)                               0.00399243
time/training (s)                             7.55709e-05
time/epoch (s)                               10.4223
time/total (s)                             1220.93
Epoch                                       113
---------------------------------------  ----------------
2021-11-24 00:49:43.428547 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 114 finished
---------------------------------------  ---------------
epoch                                       114
replay_buffer/size                       116000
trainer/num train calls                  115000
trainer/QF1 Loss                              7.06693
trainer/QF2 Loss                              7.11353
trainer/Policy Loss                        -225.658
trainer/Q1 Predictions Mean                 226.043
trainer/Q1 Predictions Std                   98.1065
trainer/Q1 Predictions Max                  318.998
trainer/Q1 Predictions Min                    9.72825
trainer/Q2 Predictions Mean                 225.893
trainer/Q2 Predictions Std                   98.0657
trainer/Q2 Predictions Max                  317.707
trainer/Q2 Predictions Min                    9.98754
trainer/Q Targets Mean                      226.31
trainer/Q Targets Std                        98.2304
trainer/Q Targets Max                       319.538
trainer/Q Targets Min                        10.4377
trainer/Log Pis Mean                          6.08674
trainer/Log Pis Std                           5.40447
trainer/Log Pis Max                          20.0531
trainer/Log Pis Min                          -8.32902
trainer/policy/mean Mean                      0.0231155
trainer/policy/mean Std                       0.779092
trainer/policy/mean Max                       0.999827
trainer/policy/mean Min                      -0.999733
trainer/policy/normal/std Mean                0.465026
trainer/policy/normal/std Std                 0.129713
trainer/policy/normal/std Max                 0.866522
trainer/policy/normal/std Min                 0.103739
trainer/policy/normal/log_std Mean           -0.810957
trainer/policy/normal/log_std Std             0.317161
trainer/policy/normal/log_std Max            -0.143267
trainer/policy/normal/log_std Min            -2.26588
trainer/Alpha                                 0.0883725
trainer/Alpha Loss                            0.210444
expl/num steps total                     116000
expl/num paths total                        116
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.23286
expl/Rewards Std                              1.17337
expl/Rewards Max                              6.36369
expl/Rewards Min                             -0.690642
expl/Returns Mean                          4232.86
expl/Returns Std                              0
expl/Returns Max                           4232.86
expl/Returns Min                           4232.86
expl/Actions Mean                             0.0514497
expl/Actions Std                              0.832075
expl/Actions Max                              0.999571
expl/Actions Min                             -0.999775
expl/Num Paths                                1
expl/Average Returns                       4232.86
expl/env_infos/final/reward_run Mean          2.4163
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           2.4163
expl/env_infos/final/reward_run Min           2.4163
expl/env_infos/initial/reward_run Mean        0.219996
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.219996
expl/env_infos/initial/reward_run Min         0.219996
expl/env_infos/reward_run Mean                4.64985
expl/env_infos/reward_run Std                 1.17036
expl/env_infos/reward_run Max                 6.90421
expl/env_infos/reward_run Min                -0.24292
expl/env_infos/final/reward_ctrl Mean        -0.540159
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.540159
expl/env_infos/final/reward_ctrl Min         -0.540159
expl/env_infos/initial/reward_ctrl Mean      -0.108284
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.108284
expl/env_infos/initial/reward_ctrl Min       -0.108284
expl/env_infos/reward_ctrl Mean              -0.416998
expl/env_infos/reward_ctrl Std                0.0880043
expl/env_infos/reward_ctrl Max               -0.0983442
expl/env_infos/reward_ctrl Min               -0.585763
eval/num steps total                     575000
eval/num paths total                        575
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             3.53664
eval/Rewards Std                              1.90366
eval/Rewards Max                              6.57295
eval/Rewards Min                             -1.61835
eval/Returns Mean                          3536.64
eval/Returns Std                           1421.19
eval/Returns Max                           4324.9
eval/Returns Min                            695.896
eval/Actions Mean                             0.040065
eval/Actions Std                              0.816593
eval/Actions Max                              0.999949
eval/Actions Min                             -0.999382
eval/Num Paths                                5
eval/Average Returns                       3536.64
eval/env_infos/final/reward_run Mean          3.73589
eval/env_infos/final/reward_run Std           2.34759
eval/env_infos/final/reward_run Max           5.70612
eval/env_infos/final/reward_run Min          -0.738188
eval/env_infos/initial/reward_run Mean        0.0174603
eval/env_infos/initial/reward_run Std         0.341497
eval/env_infos/initial/reward_run Max         0.353908
eval/env_infos/initial/reward_run Min        -0.610646
eval/env_infos/reward_run Mean                3.93769
eval/env_infos/reward_run Std                 1.95911
eval/env_infos/reward_run Max                 7.12001
eval/env_infos/reward_run Min                -1.32635
eval/env_infos/final/reward_ctrl Mean        -0.403938
eval/env_infos/final/reward_ctrl Std          0.151798
eval/env_infos/final/reward_ctrl Max         -0.133251
eval/env_infos/final/reward_ctrl Min         -0.559976
eval/env_infos/initial/reward_ctrl Mean      -0.15891
eval/env_infos/initial/reward_ctrl Std        0.057083
eval/env_infos/initial/reward_ctrl Max       -0.10669
eval/env_infos/initial/reward_ctrl Min       -0.268624
eval/env_infos/reward_ctrl Mean              -0.401058
eval/env_infos/reward_ctrl Std                0.107565
eval/env_infos/reward_ctrl Max               -0.0909619
eval/env_infos/reward_ctrl Min               -0.582546
time/data storing (s)                         0.00448053
time/evaluation sampling (s)                  2.00497
time/exploration sampling (s)                 0.517951
time/logging (s)                              0.0138005
time/sac training (s)                         7.78728
time/saving (s)                               0.00379406
time/training (s)                             3.6273e-05
time/epoch (s)                               10.3323
time/total (s)                             1231.58
Epoch                                       114
---------------------------------------  ---------------
2021-11-24 00:49:54.147686 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 115 finished
---------------------------------------  ---------------
epoch                                       115
replay_buffer/size                       117000
trainer/num train calls                  116000
trainer/QF1 Loss                              8.97286
trainer/QF2 Loss                              6.91691
trainer/Policy Loss                        -239.867
trainer/Q1 Predictions Mean                 239.853
trainer/Q1 Predictions Std                   85.8538
trainer/Q1 Predictions Max                  319.341
trainer/Q1 Predictions Min                   10.769
trainer/Q2 Predictions Mean                 240.661
trainer/Q2 Predictions Std                   86.0682
trainer/Q2 Predictions Max                  320.487
trainer/Q2 Predictions Min                   11.092
trainer/Q Targets Mean                      240.91
trainer/Q Targets Std                        86.1937
trainer/Q Targets Max                       319.059
trainer/Q Targets Min                        10.491
trainer/Log Pis Mean                          6.5435
trainer/Log Pis Std                           5.14937
trainer/Log Pis Max                          21.5512
trainer/Log Pis Min                          -5.48107
trainer/policy/mean Mean                      0.0314387
trainer/policy/mean Std                       0.783651
trainer/policy/mean Max                       0.999907
trainer/policy/mean Min                      -0.998072
trainer/policy/normal/std Mean                0.456759
trainer/policy/normal/std Std                 0.130572
trainer/policy/normal/std Max                 0.853699
trainer/policy/normal/std Min                 0.0862921
trainer/policy/normal/log_std Mean           -0.830513
trainer/policy/normal/log_std Std             0.322064
trainer/policy/normal/log_std Max            -0.158176
trainer/policy/normal/log_std Min            -2.45002
trainer/Alpha                                 0.0892918
trainer/Alpha Loss                            1.31301
expl/num steps total                     117000
expl/num paths total                        117
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.1368
expl/Rewards Std                              1.11959
expl/Rewards Max                              6.1648
expl/Rewards Min                             -0.491432
expl/Returns Mean                          4136.8
expl/Returns Std                              0
expl/Returns Max                           4136.8
expl/Returns Min                           4136.8
expl/Actions Mean                             0.0488066
expl/Actions Std                              0.839472
expl/Actions Max                              0.999691
expl/Actions Min                             -0.999627
expl/Num Paths                                1
expl/Average Returns                       4136.8
expl/env_infos/final/reward_run Mean          4.58922
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.58922
expl/env_infos/final/reward_run Min           4.58922
expl/env_infos/initial/reward_run Mean        0.308426
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.308426
expl/env_infos/initial/reward_run Min         0.308426
expl/env_infos/reward_run Mean                4.56106
expl/env_infos/reward_run Std                 1.11813
expl/env_infos/reward_run Max                 6.65977
expl/env_infos/reward_run Min                -0.0977852
expl/env_infos/final/reward_ctrl Mean        -0.462236
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.462236
expl/env_infos/final/reward_ctrl Min         -0.462236
expl/env_infos/initial/reward_ctrl Mean      -0.245974
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.245974
expl/env_infos/initial/reward_ctrl Min       -0.245974
expl/env_infos/reward_ctrl Mean              -0.424257
expl/env_infos/reward_ctrl Std                0.076753
expl/env_infos/reward_ctrl Max               -0.14603
expl/env_infos/reward_ctrl Min               -0.580347
eval/num steps total                     580000
eval/num paths total                        580
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.29381
eval/Rewards Std                              1.15828
eval/Rewards Max                              6.60855
eval/Rewards Min                             -0.724041
eval/Returns Mean                          4293.81
eval/Returns Std                             60.3769
eval/Returns Max                           4382.44
eval/Returns Min                           4204.22
eval/Actions Mean                             0.0552301
eval/Actions Std                              0.854635
eval/Actions Max                              0.999193
eval/Actions Min                             -0.998807
eval/Num Paths                                5
eval/Average Returns                       4293.81
eval/env_infos/final/reward_run Mean          5.03835
eval/env_infos/final/reward_run Std           1.08622
eval/env_infos/final/reward_run Max           6.48481
eval/env_infos/final/reward_run Min           3.68898
eval/env_infos/initial/reward_run Mean       -0.0111319
eval/env_infos/initial/reward_run Std         0.189196
eval/env_infos/initial/reward_run Max         0.174907
eval/env_infos/initial/reward_run Min        -0.332162
eval/env_infos/reward_run Mean                4.73388
eval/env_infos/reward_run Std                 1.16091
eval/env_infos/reward_run Max                 7.16002
eval/env_infos/reward_run Min                -0.332162
eval/env_infos/final/reward_ctrl Mean        -0.464598
eval/env_infos/final/reward_ctrl Std          0.0250189
eval/env_infos/final/reward_ctrl Max         -0.437769
eval/env_infos/final/reward_ctrl Min         -0.509651
eval/env_infos/initial/reward_ctrl Mean      -0.172278
eval/env_infos/initial/reward_ctrl Std        0.0392331
eval/env_infos/initial/reward_ctrl Max       -0.138924
eval/env_infos/initial/reward_ctrl Min       -0.248589
eval/env_infos/reward_ctrl Mean              -0.440071
eval/env_infos/reward_ctrl Std                0.0707829
eval/env_infos/reward_ctrl Max               -0.138924
eval/env_infos/reward_ctrl Min               -0.578882
time/data storing (s)                         0.00492833
time/evaluation sampling (s)                  2.04011
time/exploration sampling (s)                 0.549526
time/logging (s)                              0.0137354
time/sac training (s)                         7.77695
time/saving (s)                               0.00392743
time/training (s)                             6.0106e-05
time/epoch (s)                               10.3892
time/total (s)                             1242.28
Epoch                                       115
---------------------------------------  ---------------
2021-11-24 00:50:05.057079 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 116 finished
---------------------------------------  ---------------
epoch                                       116
replay_buffer/size                       118000
trainer/num train calls                  117000
trainer/QF1 Loss                              6.10183
trainer/QF2 Loss                              5.67713
trainer/Policy Loss                        -226.344
trainer/Q1 Predictions Mean                 226.743
trainer/Q1 Predictions Std                  102.684
trainer/Q1 Predictions Max                  321.483
trainer/Q1 Predictions Min                   10.6915
trainer/Q2 Predictions Mean                 226.74
trainer/Q2 Predictions Std                  102.634
trainer/Q2 Predictions Max                  319.567
trainer/Q2 Predictions Min                   10.9273
trainer/Q Targets Mean                      226.429
trainer/Q Targets Std                       102.62
trainer/Q Targets Max                       321.361
trainer/Q Targets Min                        11.4474
trainer/Log Pis Mean                          6.14564
trainer/Log Pis Std                           5.27858
trainer/Log Pis Max                          27.0621
trainer/Log Pis Min                          -7.51423
trainer/policy/mean Mean                      0.0293212
trainer/policy/mean Std                       0.774179
trainer/policy/mean Max                       0.999494
trainer/policy/mean Min                      -0.999944
trainer/policy/normal/std Mean                0.46164
trainer/policy/normal/std Std                 0.138108
trainer/policy/normal/std Max                 1.04371
trainer/policy/normal/std Min                 0.101222
trainer/policy/normal/log_std Mean           -0.824429
trainer/policy/normal/log_std Std             0.336511
trainer/policy/normal/log_std Max             0.0427827
trainer/policy/normal/log_std Min            -2.29044
trainer/Alpha                                 0.0885993
trainer/Alpha Loss                            0.352973
expl/num steps total                     118000
expl/num paths total                        118
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.26293
expl/Rewards Std                              1.17853
expl/Rewards Max                              6.38801
expl/Rewards Min                             -0.368875
expl/Returns Mean                          4262.93
expl/Returns Std                              0
expl/Returns Max                           4262.93
expl/Returns Min                           4262.93
expl/Actions Mean                             0.0317145
expl/Actions Std                              0.832931
expl/Actions Max                              0.999727
expl/Actions Min                             -0.999763
expl/Num Paths                                1
expl/Average Returns                       4262.93
expl/env_infos/final/reward_run Mean          3.75593
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.75593
expl/env_infos/final/reward_run Min           3.75593
expl/env_infos/initial/reward_run Mean       -0.158208
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.158208
expl/env_infos/initial/reward_run Min        -0.158208
expl/env_infos/reward_run Mean                4.6798
expl/env_infos/reward_run Std                 1.17821
expl/env_infos/reward_run Max                 6.85818
expl/env_infos/reward_run Min                -0.158208
expl/env_infos/final/reward_ctrl Mean        -0.400283
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.400283
expl/env_infos/final/reward_ctrl Min         -0.400283
expl/env_infos/initial/reward_ctrl Mean      -0.10686
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.10686
expl/env_infos/initial/reward_ctrl Min       -0.10686
expl/env_infos/reward_ctrl Mean              -0.416868
expl/env_infos/reward_ctrl Std                0.0828894
expl/env_infos/reward_ctrl Max               -0.10686
expl/env_infos/reward_ctrl Min               -0.581516
eval/num steps total                     585000
eval/num paths total                        585
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.39276
eval/Rewards Std                              1.18007
eval/Rewards Max                              6.81326
eval/Rewards Min                             -1.08313
eval/Returns Mean                          4392.76
eval/Returns Std                             87.3174
eval/Returns Max                           4502
eval/Returns Min                           4257.51
eval/Actions Mean                             0.0459032
eval/Actions Std                              0.848722
eval/Actions Max                              0.999138
eval/Actions Min                             -0.998904
eval/Num Paths                                5
eval/Average Returns                       4392.76
eval/env_infos/final/reward_run Mean          5.36063
eval/env_infos/final/reward_run Std           0.828802
eval/env_infos/final/reward_run Max           5.91784
eval/env_infos/final/reward_run Min           3.71844
eval/env_infos/initial/reward_run Mean       -0.213447
eval/env_infos/initial/reward_run Std         0.194558
eval/env_infos/initial/reward_run Max         0.0240311
eval/env_infos/initial/reward_run Min        -0.550797
eval/env_infos/reward_run Mean                4.82622
eval/env_infos/reward_run Std                 1.17161
eval/env_infos/reward_run Max                 7.35444
eval/env_infos/reward_run Min                -0.654495
eval/env_infos/final/reward_ctrl Mean        -0.412743
eval/env_infos/final/reward_ctrl Std          0.0868893
eval/env_infos/final/reward_ctrl Max         -0.288619
eval/env_infos/final/reward_ctrl Min         -0.552841
eval/env_infos/initial/reward_ctrl Mean      -0.164705
eval/env_infos/initial/reward_ctrl Std        0.0833082
eval/env_infos/initial/reward_ctrl Max       -0.0889738
eval/env_infos/initial/reward_ctrl Min       -0.319154
eval/env_infos/reward_ctrl Mean              -0.433461
eval/env_infos/reward_ctrl Std                0.0753592
eval/env_infos/reward_ctrl Max               -0.0889738
eval/env_infos/reward_ctrl Min               -0.576331
time/data storing (s)                         0.00467908
time/evaluation sampling (s)                  2.06501
time/exploration sampling (s)                 0.549232
time/logging (s)                              0.0135578
time/sac training (s)                         7.94277
time/saving (s)                               0.00379784
time/training (s)                             3.379e-05
time/epoch (s)                               10.5791
time/total (s)                             1253.18
Epoch                                       116
---------------------------------------  ---------------
2021-11-24 00:50:15.752673 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 117 finished
---------------------------------------  ---------------
epoch                                       117
replay_buffer/size                       119000
trainer/num train calls                  118000
trainer/QF1 Loss                              7.73396
trainer/QF2 Loss                              5.88222
trainer/Policy Loss                        -227.694
trainer/Q1 Predictions Mean                 227.583
trainer/Q1 Predictions Std                  101.17
trainer/Q1 Predictions Max                  319.589
trainer/Q1 Predictions Min                    8.32838
trainer/Q2 Predictions Mean                 228.167
trainer/Q2 Predictions Std                  101.437
trainer/Q2 Predictions Max                  320.194
trainer/Q2 Predictions Min                   10.8629
trainer/Q Targets Mean                      227.957
trainer/Q Targets Std                       101.198
trainer/Q Targets Max                       319.976
trainer/Q Targets Min                        10.1763
trainer/Log Pis Mean                          6.14315
trainer/Log Pis Std                           5.29532
trainer/Log Pis Max                          25.0966
trainer/Log Pis Min                          -4.43063
trainer/policy/mean Mean                     -0.0192384
trainer/policy/mean Std                       0.771837
trainer/policy/mean Max                       0.999881
trainer/policy/mean Min                      -0.999187
trainer/policy/normal/std Mean                0.457848
trainer/policy/normal/std Std                 0.138749
trainer/policy/normal/std Max                 0.974448
trainer/policy/normal/std Min                 0.107551
trainer/policy/normal/log_std Mean           -0.834155
trainer/policy/normal/log_std Std             0.342283
trainer/policy/normal/log_std Max            -0.0258844
trainer/policy/normal/log_std Min            -2.22979
trainer/Alpha                                 0.0898961
trainer/Alpha Loss                            0.344862
expl/num steps total                     119000
expl/num paths total                        119
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.37095
expl/Rewards Std                              1.22071
expl/Rewards Max                              6.66215
expl/Rewards Min                             -0.370425
expl/Returns Mean                          4370.95
expl/Returns Std                              0
expl/Returns Max                           4370.95
expl/Returns Min                           4370.95
expl/Actions Mean                             0.0090918
expl/Actions Std                              0.831814
expl/Actions Max                              0.999842
expl/Actions Min                             -0.99979
expl/Num Paths                                1
expl/Average Returns                       4370.95
expl/env_infos/final/reward_run Mean          5.91866
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.91866
expl/env_infos/final/reward_run Min           5.91866
expl/env_infos/initial/reward_run Mean        0.183451
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.183451
expl/env_infos/initial/reward_run Min         0.183451
expl/env_infos/reward_run Mean                4.78615
expl/env_infos/reward_run Std                 1.2057
expl/env_infos/reward_run Max                 7.17583
expl/env_infos/reward_run Min                -0.121767
expl/env_infos/final/reward_ctrl Mean        -0.394741
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.394741
expl/env_infos/final/reward_ctrl Min         -0.394741
expl/env_infos/initial/reward_ctrl Mean      -0.205574
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.205574
expl/env_infos/initial/reward_ctrl Min       -0.205574
expl/env_infos/reward_ctrl Mean              -0.415199
expl/env_infos/reward_ctrl Std                0.0855636
expl/env_infos/reward_ctrl Max               -0.150704
expl/env_infos/reward_ctrl Min               -0.586435
eval/num steps total                     590000
eval/num paths total                        590
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.43379
eval/Rewards Std                              1.20077
eval/Rewards Max                              6.91335
eval/Rewards Min                             -0.760171
eval/Returns Mean                          4433.79
eval/Returns Std                            117.594
eval/Returns Max                           4555.27
eval/Returns Min                           4266.52
eval/Actions Mean                             0.0200004
eval/Actions Std                              0.844872
eval/Actions Max                              0.999321
eval/Actions Min                             -0.999609
eval/Num Paths                                5
eval/Average Returns                       4433.79
eval/env_infos/final/reward_run Mean          4.90847
eval/env_infos/final/reward_run Std           1.00648
eval/env_infos/final/reward_run Max           6.4364
eval/env_infos/final/reward_run Min           3.65345
eval/env_infos/initial/reward_run Mean       -0.0692903
eval/env_infos/initial/reward_run Std         0.146753
eval/env_infos/initial/reward_run Max         0.0894693
eval/env_infos/initial/reward_run Min        -0.273058
eval/env_infos/reward_run Mean                4.86231
eval/env_infos/reward_run Std                 1.18067
eval/env_infos/reward_run Max                 7.39506
eval/env_infos/reward_run Min                -0.331286
eval/env_infos/final/reward_ctrl Mean        -0.419849
eval/env_infos/final/reward_ctrl Std          0.0913372
eval/env_infos/final/reward_ctrl Max         -0.311929
eval/env_infos/final/reward_ctrl Min         -0.5553
eval/env_infos/initial/reward_ctrl Mean      -0.200692
eval/env_infos/initial/reward_ctrl Std        0.0381673
eval/env_infos/initial/reward_ctrl Max       -0.15385
eval/env_infos/initial/reward_ctrl Min       -0.253308
eval/env_infos/reward_ctrl Mean              -0.428525
eval/env_infos/reward_ctrl Std                0.0816531
eval/env_infos/reward_ctrl Max               -0.15385
eval/env_infos/reward_ctrl Min               -0.585574
time/data storing (s)                         0.00452802
time/evaluation sampling (s)                  2.0176
time/exploration sampling (s)                 0.522315
time/logging (s)                              0.0137896
time/sac training (s)                         7.80262
time/saving (s)                               0.00384842
time/training (s)                             3.5004e-05
time/epoch (s)                               10.3647
time/total (s)                             1263.86
Epoch                                       117
---------------------------------------  ---------------
2021-11-24 00:50:26.481486 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 118 finished
---------------------------------------  ---------------
epoch                                       118
replay_buffer/size                       120000
trainer/num train calls                  119000
trainer/QF1 Loss                              7.02753
trainer/QF2 Loss                              6.7488
trainer/Policy Loss                        -218.866
trainer/Q1 Predictions Mean                 219.148
trainer/Q1 Predictions Std                  106.311
trainer/Q1 Predictions Max                  324.211
trainer/Q1 Predictions Min                   10.4512
trainer/Q2 Predictions Mean                 218.998
trainer/Q2 Predictions Std                  106.344
trainer/Q2 Predictions Max                  325.465
trainer/Q2 Predictions Min                    9.51109
trainer/Q Targets Mean                      219.346
trainer/Q Targets Std                       106.398
trainer/Q Targets Max                       322.58
trainer/Q Targets Min                         9.78465
trainer/Log Pis Mean                          5.90833
trainer/Log Pis Std                           5.12467
trainer/Log Pis Max                          20.6371
trainer/Log Pis Min                          -4.69663
trainer/policy/mean Mean                      0.00775469
trainer/policy/mean Std                       0.770641
trainer/policy/mean Max                       0.999716
trainer/policy/mean Min                      -0.999895
trainer/policy/normal/std Mean                0.47261
trainer/policy/normal/std Std                 0.136561
trainer/policy/normal/std Max                 0.918105
trainer/policy/normal/std Min                 0.0941478
trainer/policy/normal/log_std Mean           -0.797507
trainer/policy/normal/log_std Std             0.325578
trainer/policy/normal/log_std Max            -0.0854432
trainer/policy/normal/log_std Min            -2.36289
trainer/Alpha                                 0.091281
trainer/Alpha Loss                           -0.219435
expl/num steps total                     120000
expl/num paths total                        120
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.3403
expl/Rewards Std                              1.13133
expl/Rewards Max                              6.75224
expl/Rewards Min                             -0.342259
expl/Returns Mean                          4340.3
expl/Returns Std                              0
expl/Returns Max                           4340.3
expl/Returns Min                           4340.3
expl/Actions Mean                             0.0458542
expl/Actions Std                              0.835791
expl/Actions Max                              0.9997
expl/Actions Min                             -0.999396
expl/Num Paths                                1
expl/Average Returns                       4340.3
expl/env_infos/final/reward_run Mean          5.07637
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.07637
expl/env_infos/final/reward_run Min           5.07637
expl/env_infos/initial/reward_run Mean       -0.152683
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.152683
expl/env_infos/initial/reward_run Min        -0.152683
expl/env_infos/reward_run Mean                4.76069
expl/env_infos/reward_run Std                 1.12095
expl/env_infos/reward_run Max                 7.24605
expl/env_infos/reward_run Min                -0.152683
expl/env_infos/final/reward_ctrl Mean        -0.365916
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.365916
expl/env_infos/final/reward_ctrl Min         -0.365916
expl/env_infos/initial/reward_ctrl Mean      -0.189575
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.189575
expl/env_infos/initial/reward_ctrl Min       -0.189575
expl/env_infos/reward_ctrl Mean              -0.420389
expl/env_infos/reward_ctrl Std                0.0814412
expl/env_infos/reward_ctrl Max               -0.126361
expl/env_infos/reward_ctrl Min               -0.587542
eval/num steps total                     595000
eval/num paths total                        595
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.46269
eval/Rewards Std                              1.2218
eval/Rewards Max                              6.95425
eval/Rewards Min                             -0.843378
eval/Returns Mean                          4462.69
eval/Returns Std                             87.1937
eval/Returns Max                           4573.92
eval/Returns Min                           4310.11
eval/Actions Mean                             0.0447715
eval/Actions Std                              0.849612
eval/Actions Max                              0.998881
eval/Actions Min                             -0.998871
eval/Num Paths                                5
eval/Average Returns                       4462.69
eval/env_infos/final/reward_run Mean          5.33508
eval/env_infos/final/reward_run Std           0.620022
eval/env_infos/final/reward_run Max           6.17887
eval/env_infos/final/reward_run Min           4.5439
eval/env_infos/initial/reward_run Mean       -0.264493
eval/env_infos/initial/reward_run Std         0.130586
eval/env_infos/initial/reward_run Max        -0.0216586
eval/env_infos/initial/reward_run Min        -0.378079
eval/env_infos/reward_run Mean                4.897
eval/env_infos/reward_run Std                 1.21806
eval/env_infos/reward_run Max                 7.42562
eval/env_infos/reward_run Min                -0.378079
eval/env_infos/final/reward_ctrl Mean        -0.444337
eval/env_infos/final/reward_ctrl Std          0.0591198
eval/env_infos/final/reward_ctrl Max         -0.346649
eval/env_infos/final/reward_ctrl Min         -0.521215
eval/env_infos/initial/reward_ctrl Mean      -0.213966
eval/env_infos/initial/reward_ctrl Std        0.0401
eval/env_infos/initial/reward_ctrl Max       -0.166898
eval/env_infos/initial/reward_ctrl Min       -0.275632
eval/env_infos/reward_ctrl Mean              -0.434307
eval/env_infos/reward_ctrl Std                0.077235
eval/env_infos/reward_ctrl Max               -0.080922
eval/env_infos/reward_ctrl Min               -0.581703
time/data storing (s)                         0.00692079
time/evaluation sampling (s)                  2.02835
time/exploration sampling (s)                 0.564545
time/logging (s)                              0.014291
time/sac training (s)                         7.78019
time/saving (s)                               0.00386193
time/training (s)                             4.1397e-05
time/epoch (s)                               10.3982
time/total (s)                             1274.57
Epoch                                       118
---------------------------------------  ---------------
2021-11-24 00:50:37.205161 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 119 finished
---------------------------------------  ---------------
epoch                                       119
replay_buffer/size                       121000
trainer/num train calls                  120000
trainer/QF1 Loss                              9.02569
trainer/QF2 Loss                              7.9368
trainer/Policy Loss                        -226.008
trainer/Q1 Predictions Mean                 226.539
trainer/Q1 Predictions Std                  104.576
trainer/Q1 Predictions Max                  323.805
trainer/Q1 Predictions Min                   10.6416
trainer/Q2 Predictions Mean                 226.344
trainer/Q2 Predictions Std                  104.424
trainer/Q2 Predictions Max                  321.411
trainer/Q2 Predictions Min                   10.7943
trainer/Q Targets Mean                      226.118
trainer/Q Targets Std                       104.468
trainer/Q Targets Max                       323.619
trainer/Q Targets Min                        10.477
trainer/Log Pis Mean                          5.60328
trainer/Log Pis Std                           4.99698
trainer/Log Pis Max                          16.5406
trainer/Log Pis Min                          -6.36193
trainer/policy/mean Mean                      0.0319079
trainer/policy/mean Std                       0.764557
trainer/policy/mean Max                       0.998663
trainer/policy/mean Min                      -0.996604
trainer/policy/normal/std Mean                0.469776
trainer/policy/normal/std Std                 0.138848
trainer/policy/normal/std Max                 0.880306
trainer/policy/normal/std Min                 0.12466
trainer/policy/normal/log_std Mean           -0.805607
trainer/policy/normal/log_std Std             0.332257
trainer/policy/normal/log_std Max            -0.127486
trainer/policy/normal/log_std Min            -2.08216
trainer/Alpha                                 0.0932294
trainer/Alpha Loss                           -0.941306
expl/num steps total                     121000
expl/num paths total                        121
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.14893
expl/Rewards Std                              1.2004
expl/Rewards Max                              6.44581
expl/Rewards Min                             -1.3427
expl/Returns Mean                          4148.93
expl/Returns Std                              0
expl/Returns Max                           4148.93
expl/Returns Min                           4148.93
expl/Actions Mean                             0.0364595
expl/Actions Std                              0.822104
expl/Actions Max                              0.999646
expl/Actions Min                             -0.999713
expl/Num Paths                                1
expl/Average Returns                       4148.93
expl/env_infos/final/reward_run Mean          5.94848
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.94848
expl/env_infos/final/reward_run Min           5.94848
expl/env_infos/initial/reward_run Mean       -0.494667
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.494667
expl/env_infos/initial/reward_run Min        -0.494667
expl/env_infos/reward_run Mean                4.55524
expl/env_infos/reward_run Std                 1.19849
expl/env_infos/reward_run Max                 6.94127
expl/env_infos/reward_run Min                -0.920192
expl/env_infos/final/reward_ctrl Mean        -0.262211
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.262211
expl/env_infos/final/reward_ctrl Min         -0.262211
expl/env_infos/initial/reward_ctrl Mean      -0.263488
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.263488
expl/env_infos/initial/reward_ctrl Min       -0.263488
expl/env_infos/reward_ctrl Mean              -0.406311
expl/env_infos/reward_ctrl Std                0.0856745
expl/env_infos/reward_ctrl Max               -0.0934444
expl/env_infos/reward_ctrl Min               -0.58297
eval/num steps total                     600000
eval/num paths total                        600
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.45898
eval/Rewards Std                              1.20118
eval/Rewards Max                              7.00016
eval/Rewards Min                             -0.592295
eval/Returns Mean                          4458.98
eval/Returns Std                            160.402
eval/Returns Max                           4661.61
eval/Returns Min                           4211.66
eval/Actions Mean                             0.0522045
eval/Actions Std                              0.844748
eval/Actions Max                              0.999072
eval/Actions Min                             -0.998895
eval/Num Paths                                5
eval/Average Returns                       4458.98
eval/env_infos/final/reward_run Mean          5.3456
eval/env_infos/final/reward_run Std           0.990074
eval/env_infos/final/reward_run Max           6.20587
eval/env_infos/final/reward_run Min           3.61346
eval/env_infos/initial/reward_run Mean        0.00347179
eval/env_infos/initial/reward_run Std         0.189035
eval/env_infos/initial/reward_run Max         0.226197
eval/env_infos/initial/reward_run Min        -0.320616
eval/env_infos/reward_run Mean                4.88877
eval/env_infos/reward_run Std                 1.19697
eval/env_infos/reward_run Max                 7.50735
eval/env_infos/reward_run Min                -0.320616
eval/env_infos/final/reward_ctrl Mean        -0.480161
eval/env_infos/final/reward_ctrl Std          0.0302188
eval/env_infos/final/reward_ctrl Max         -0.43326
eval/env_infos/final/reward_ctrl Min         -0.527517
eval/env_infos/initial/reward_ctrl Mean      -0.167213
eval/env_infos/initial/reward_ctrl Std        0.0215191
eval/env_infos/initial/reward_ctrl Max       -0.141483
eval/env_infos/initial/reward_ctrl Min       -0.198959
eval/env_infos/reward_ctrl Mean              -0.429795
eval/env_infos/reward_ctrl Std                0.0753484
eval/env_infos/reward_ctrl Max               -0.102314
eval/env_infos/reward_ctrl Min               -0.573595
time/data storing (s)                         0.00445779
time/evaluation sampling (s)                  2.04206
time/exploration sampling (s)                 0.541309
time/logging (s)                              0.0135814
time/sac training (s)                         7.7874
time/saving (s)                               0.00394794
time/training (s)                             3.3986e-05
time/epoch (s)                               10.3928
time/total (s)                             1285.28
Epoch                                       119
---------------------------------------  ---------------
2021-11-24 00:50:48.061329 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 120 finished
---------------------------------------  ---------------
epoch                                       120
replay_buffer/size                       122000
trainer/num train calls                  121000
trainer/QF1 Loss                              8.46267
trainer/QF2 Loss                              8.03929
trainer/Policy Loss                        -239.91
trainer/Q1 Predictions Mean                 239.972
trainer/Q1 Predictions Std                   96.2982
trainer/Q1 Predictions Max                  323.988
trainer/Q1 Predictions Min                   11.5472
trainer/Q2 Predictions Mean                 240.621
trainer/Q2 Predictions Std                   96.4418
trainer/Q2 Predictions Max                  325.237
trainer/Q2 Predictions Min                   11.4038
trainer/Q Targets Mean                      240.197
trainer/Q Targets Std                        96.32
trainer/Q Targets Max                       322.991
trainer/Q Targets Min                        11.2915
trainer/Log Pis Mean                          6.58774
trainer/Log Pis Std                           4.79069
trainer/Log Pis Max                          17.997
trainer/Log Pis Min                          -3.9448
trainer/policy/mean Mean                     -0.00221343
trainer/policy/mean Std                       0.790764
trainer/policy/mean Max                       0.999529
trainer/policy/mean Min                      -0.996237
trainer/policy/normal/std Mean                0.464387
trainer/policy/normal/std Std                 0.136052
trainer/policy/normal/std Max                 0.902454
trainer/policy/normal/std Min                 0.116689
trainer/policy/normal/log_std Mean           -0.815976
trainer/policy/normal/log_std Std             0.32824
trainer/policy/normal/log_std Max            -0.102638
trainer/policy/normal/log_std Min            -2.14824
trainer/Alpha                                 0.0932497
trainer/Alpha Loss                            1.3944
expl/num steps total                     122000
expl/num paths total                        122
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.5884
expl/Rewards Std                              1.18484
expl/Rewards Max                              6.78148
expl/Rewards Min                             -0.395813
expl/Returns Mean                          4588.4
expl/Returns Std                              0
expl/Returns Max                           4588.4
expl/Returns Min                           4588.4
expl/Actions Mean                             0.0364918
expl/Actions Std                              0.840524
expl/Actions Max                              0.999783
expl/Actions Min                             -0.999692
expl/Num Paths                                1
expl/Average Returns                       4588.4
expl/env_infos/final/reward_run Mean          3.52125
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.52125
expl/env_infos/final/reward_run Min           3.52125
expl/env_infos/initial/reward_run Mean       -0.203989
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.203989
expl/env_infos/initial/reward_run Min        -0.203989
expl/env_infos/reward_run Mean                5.01309
expl/env_infos/reward_run Std                 1.18045
expl/env_infos/reward_run Max                 7.30314
expl/env_infos/reward_run Min                -0.203989
expl/env_infos/final/reward_ctrl Mean        -0.387072
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.387072
expl/env_infos/final/reward_ctrl Min         -0.387072
expl/env_infos/initial/reward_ctrl Mean      -0.169835
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.169835
expl/env_infos/initial/reward_ctrl Min       -0.169835
expl/env_infos/reward_ctrl Mean              -0.424687
expl/env_infos/reward_ctrl Std                0.0831234
expl/env_infos/reward_ctrl Max               -0.168864
expl/env_infos/reward_ctrl Min               -0.585899
eval/num steps total                     605000
eval/num paths total                        605
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.48574
eval/Rewards Std                              1.19867
eval/Rewards Max                              7.09224
eval/Rewards Min                             -0.525645
eval/Returns Mean                          4485.74
eval/Returns Std                            139.707
eval/Returns Max                           4684.16
eval/Returns Min                           4287.83
eval/Actions Mean                             0.0430316
eval/Actions Std                              0.854414
eval/Actions Max                              0.99945
eval/Actions Min                             -0.99895
eval/Num Paths                                5
eval/Average Returns                       4485.74
eval/env_infos/final/reward_run Mean          5.34768
eval/env_infos/final/reward_run Std           1.18441
eval/env_infos/final/reward_run Max           7.00388
eval/env_infos/final/reward_run Min           3.94371
eval/env_infos/initial/reward_run Mean       -0.11771
eval/env_infos/initial/reward_run Std         0.155471
eval/env_infos/initial/reward_run Max         0.138499
eval/env_infos/initial/reward_run Min        -0.304485
eval/env_infos/reward_run Mean                4.92486
eval/env_infos/reward_run Std                 1.19113
eval/env_infos/reward_run Max                 7.61281
eval/env_infos/reward_run Min                -0.304485
eval/env_infos/final/reward_ctrl Mean        -0.440833
eval/env_infos/final/reward_ctrl Std          0.0441877
eval/env_infos/final/reward_ctrl Max         -0.386828
eval/env_infos/final/reward_ctrl Min         -0.490944
eval/env_infos/initial/reward_ctrl Mean      -0.202186
eval/env_infos/initial/reward_ctrl Std        0.0403627
eval/env_infos/initial/reward_ctrl Max       -0.153111
eval/env_infos/initial/reward_ctrl Min       -0.247874
eval/env_infos/reward_ctrl Mean              -0.439125
eval/env_infos/reward_ctrl Std                0.0795217
eval/env_infos/reward_ctrl Max               -0.12083
eval/env_infos/reward_ctrl Min               -0.582939
time/data storing (s)                         0.00506524
time/evaluation sampling (s)                  2.07635
time/exploration sampling (s)                 0.536708
time/logging (s)                              0.0141924
time/sac training (s)                         7.88642
time/saving (s)                               0.00387116
time/training (s)                             4.4249e-05
time/epoch (s)                               10.5227
time/total (s)                             1296.12
Epoch                                       120
---------------------------------------  ---------------
2021-11-24 00:50:58.971567 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 121 finished
---------------------------------------  ---------------
epoch                                       121
replay_buffer/size                       123000
trainer/num train calls                  122000
trainer/QF1 Loss                              8.77629
trainer/QF2 Loss                              6.40295
trainer/Policy Loss                        -231.912
trainer/Q1 Predictions Mean                 232.192
trainer/Q1 Predictions Std                  100.218
trainer/Q1 Predictions Max                  332.846
trainer/Q1 Predictions Min                   10.8771
trainer/Q2 Predictions Mean                 232.264
trainer/Q2 Predictions Std                  100.366
trainer/Q2 Predictions Max                  333.478
trainer/Q2 Predictions Min                   10.288
trainer/Q Targets Mean                      232.412
trainer/Q Targets Std                       100.368
trainer/Q Targets Max                       333.565
trainer/Q Targets Min                        11.5558
trainer/Log Pis Mean                          6.34703
trainer/Log Pis Std                           5.35699
trainer/Log Pis Max                          20.4418
trainer/Log Pis Min                          -5.5641
trainer/policy/mean Mean                      0.0638272
trainer/policy/mean Std                       0.772575
trainer/policy/mean Max                       0.999602
trainer/policy/mean Min                      -0.998671
trainer/policy/normal/std Mean                0.459523
trainer/policy/normal/std Std                 0.137225
trainer/policy/normal/std Max                 0.965574
trainer/policy/normal/std Min                 0.103413
trainer/policy/normal/log_std Mean           -0.830034
trainer/policy/normal/log_std Std             0.342537
trainer/policy/normal/log_std Max            -0.0350322
trainer/policy/normal/log_std Min            -2.26902
trainer/Alpha                                 0.0929167
trainer/Alpha Loss                            0.82455
expl/num steps total                     123000
expl/num paths total                        123
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.43988
expl/Rewards Std                              1.17413
expl/Rewards Max                              6.68315
expl/Rewards Min                             -0.851513
expl/Returns Mean                          4439.88
expl/Returns Std                              0
expl/Returns Max                           4439.88
expl/Returns Min                           4439.88
expl/Actions Mean                             0.0736058
expl/Actions Std                              0.834476
expl/Actions Max                              0.999894
expl/Actions Min                             -0.999252
expl/Num Paths                                1
expl/Average Returns                       4439.88
expl/env_infos/final/reward_run Mean          5.862
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.862
expl/env_infos/final/reward_run Min           5.862
expl/env_infos/initial/reward_run Mean       -0.379936
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.379936
expl/env_infos/initial/reward_run Min        -0.379936
expl/env_infos/reward_run Mean                4.86094
expl/env_infos/reward_run Std                 1.16557
expl/env_infos/reward_run Max                 7.15792
expl/env_infos/reward_run Min                -0.447128
expl/env_infos/final/reward_ctrl Mean        -0.332107
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.332107
expl/env_infos/final/reward_ctrl Min         -0.332107
expl/env_infos/initial/reward_ctrl Mean      -0.237727
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.237727
expl/env_infos/initial/reward_ctrl Min       -0.237727
expl/env_infos/reward_ctrl Mean              -0.421061
expl/env_infos/reward_ctrl Std                0.077574
expl/env_infos/reward_ctrl Max               -0.165467
expl/env_infos/reward_ctrl Min               -0.579233
eval/num steps total                     610000
eval/num paths total                        610
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.45767
eval/Rewards Std                              1.17238
eval/Rewards Max                              6.79258
eval/Rewards Min                             -0.823785
eval/Returns Mean                          4457.67
eval/Returns Std                             94.0707
eval/Returns Max                           4571.7
eval/Returns Min                           4345.44
eval/Actions Mean                             0.0714997
eval/Actions Std                              0.845605
eval/Actions Max                              0.999401
eval/Actions Min                             -0.999385
eval/Num Paths                                5
eval/Average Returns                       4457.67
eval/env_infos/final/reward_run Mean          5.25558
eval/env_infos/final/reward_run Std           0.767274
eval/env_infos/final/reward_run Max           6.17793
eval/env_infos/final/reward_run Min           4.12395
eval/env_infos/initial/reward_run Mean       -0.329856
eval/env_infos/initial/reward_run Std         0.189887
eval/env_infos/initial/reward_run Max         0.0250641
eval/env_infos/initial/reward_run Min        -0.492465
eval/env_infos/reward_run Mean                4.88977
eval/env_infos/reward_run Std                 1.16981
eval/env_infos/reward_run Max                 7.32418
eval/env_infos/reward_run Min                -0.492465
eval/env_infos/final/reward_ctrl Mean        -0.462678
eval/env_infos/final/reward_ctrl Std          0.0786565
eval/env_infos/final/reward_ctrl Max         -0.315539
eval/env_infos/final/reward_ctrl Min         -0.534252
eval/env_infos/initial/reward_ctrl Mean      -0.186709
eval/env_infos/initial/reward_ctrl Std        0.0569212
eval/env_infos/initial/reward_ctrl Max       -0.0857369
eval/env_infos/initial/reward_ctrl Min       -0.251694
eval/env_infos/reward_ctrl Mean              -0.432096
eval/env_infos/reward_ctrl Std                0.0736629
eval/env_infos/reward_ctrl Max               -0.0857369
eval/env_infos/reward_ctrl Min               -0.584969
time/data storing (s)                         0.00451467
time/evaluation sampling (s)                  2.07146
time/exploration sampling (s)                 0.577478
time/logging (s)                              0.0137461
time/sac training (s)                         7.90544
time/saving (s)                               0.00380321
time/training (s)                             3.5006e-05
time/epoch (s)                               10.5765
time/total (s)                             1307.01
Epoch                                       121
---------------------------------------  ---------------
2021-11-24 00:51:09.864143 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 122 finished
---------------------------------------  ---------------
epoch                                       122
replay_buffer/size                       124000
trainer/num train calls                  123000
trainer/QF1 Loss                              7.07205
trainer/QF2 Loss                              5.3597
trainer/Policy Loss                        -234.89
trainer/Q1 Predictions Mean                 235.199
trainer/Q1 Predictions Std                  101.583
trainer/Q1 Predictions Max                  323.003
trainer/Q1 Predictions Min                   10.6102
trainer/Q2 Predictions Mean                 235.208
trainer/Q2 Predictions Std                  101.707
trainer/Q2 Predictions Max                  322.75
trainer/Q2 Predictions Min                    9.94449
trainer/Q Targets Mean                      234.834
trainer/Q Targets Std                       101.635
trainer/Q Targets Max                       320.585
trainer/Q Targets Min                         8.82683
trainer/Log Pis Mean                          5.46513
trainer/Log Pis Std                           4.76762
trainer/Log Pis Max                          20.9624
trainer/Log Pis Min                          -5.72214
trainer/policy/mean Mean                      0.0229909
trainer/policy/mean Std                       0.763902
trainer/policy/mean Max                       0.999804
trainer/policy/mean Min                      -0.999668
trainer/policy/normal/std Mean                0.470321
trainer/policy/normal/std Std                 0.143014
trainer/policy/normal/std Max                 1.19894
trainer/policy/normal/std Min                 0.106965
trainer/policy/normal/log_std Mean           -0.807761
trainer/policy/normal/log_std Std             0.34506
trainer/policy/normal/log_std Max             0.181442
trainer/policy/normal/log_std Min            -2.23525
trainer/Alpha                                 0.0939667
trainer/Alpha Loss                           -1.26487
expl/num steps total                     124000
expl/num paths total                        124
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.40248
expl/Rewards Std                              1.16711
expl/Rewards Max                              6.78993
expl/Rewards Min                             -1.24012
expl/Returns Mean                          4402.48
expl/Returns Std                              0
expl/Returns Max                           4402.48
expl/Returns Min                           4402.48
expl/Actions Mean                             0.0201809
expl/Actions Std                              0.837288
expl/Actions Max                              0.999906
expl/Actions Min                             -0.999729
expl/Num Paths                                1
expl/Average Returns                       4402.48
expl/env_infos/final/reward_run Mean          6.07841
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.07841
expl/env_infos/final/reward_run Min           6.07841
expl/env_infos/initial/reward_run Mean       -0.733842
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.733842
expl/env_infos/initial/reward_run Min        -0.733842
expl/env_infos/reward_run Mean                4.82335
expl/env_infos/reward_run Std                 1.17071
expl/env_infos/reward_run Max                 7.37024
expl/env_infos/reward_run Min                -0.935259
expl/env_infos/final/reward_ctrl Mean        -0.510264
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.510264
expl/env_infos/final/reward_ctrl Min         -0.510264
expl/env_infos/initial/reward_ctrl Mean      -0.236581
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.236581
expl/env_infos/initial/reward_ctrl Min       -0.236581
expl/env_infos/reward_ctrl Mean              -0.420875
expl/env_infos/reward_ctrl Std                0.0773213
expl/env_infos/reward_ctrl Max               -0.115408
expl/env_infos/reward_ctrl Min               -0.580312
eval/num steps total                     615000
eval/num paths total                        615
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.53269
eval/Rewards Std                              1.15311
eval/Rewards Max                              6.69568
eval/Rewards Min                             -0.796554
eval/Returns Mean                          4532.69
eval/Returns Std                             62.1161
eval/Returns Max                           4628.06
eval/Returns Min                           4450.49
eval/Actions Mean                             0.0305402
eval/Actions Std                              0.850463
eval/Actions Max                              0.999264
eval/Actions Min                             -0.99818
eval/Num Paths                                5
eval/Average Returns                       4532.69
eval/env_infos/final/reward_run Mean          5.66597
eval/env_infos/final/reward_run Std           0.784729
eval/env_infos/final/reward_run Max           6.65576
eval/env_infos/final/reward_run Min           4.36997
eval/env_infos/initial/reward_run Mean       -0.390347
eval/env_infos/initial/reward_run Std         0.0973242
eval/env_infos/initial/reward_run Max        -0.278623
eval/env_infos/initial/reward_run Min        -0.510568
eval/env_infos/reward_run Mean                4.96722
eval/env_infos/reward_run Std                 1.15685
eval/env_infos/reward_run Max                 7.21506
eval/env_infos/reward_run Min                -0.510568
eval/env_infos/final/reward_ctrl Mean        -0.479508
eval/env_infos/final/reward_ctrl Std          0.0373201
eval/env_infos/final/reward_ctrl Max         -0.425871
eval/env_infos/final/reward_ctrl Min         -0.525801
eval/env_infos/initial/reward_ctrl Mean      -0.233865
eval/env_infos/initial/reward_ctrl Std        0.0431956
eval/env_infos/initial/reward_ctrl Max       -0.179231
eval/env_infos/initial/reward_ctrl Min       -0.29243
eval/env_infos/reward_ctrl Mean              -0.434532
eval/env_infos/reward_ctrl Std                0.0734705
eval/env_infos/reward_ctrl Max               -0.128756
eval/env_infos/reward_ctrl Min               -0.573156
time/data storing (s)                         0.00449731
time/evaluation sampling (s)                  2.02618
time/exploration sampling (s)                 0.535017
time/logging (s)                              0.0176226
time/sac training (s)                         7.96646
time/saving (s)                               0.00579823
time/training (s)                             5.6159e-05
time/epoch (s)                               10.5556
time/total (s)                             1317.9
Epoch                                       122
---------------------------------------  ---------------
2021-11-24 00:51:20.870473 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 123 finished
---------------------------------------  ---------------
epoch                                       123
replay_buffer/size                       125000
trainer/num train calls                  124000
trainer/QF1 Loss                             12.234
trainer/QF2 Loss                              8.94163
trainer/Policy Loss                        -237.934
trainer/Q1 Predictions Mean                 238.425
trainer/Q1 Predictions Std                   99.4997
trainer/Q1 Predictions Max                  331.584
trainer/Q1 Predictions Min                   10.57
trainer/Q2 Predictions Mean                 238.264
trainer/Q2 Predictions Std                   99.3555
trainer/Q2 Predictions Max                  332.304
trainer/Q2 Predictions Min                   11.949
trainer/Q Targets Mean                      237.88
trainer/Q Targets Std                        99.1947
trainer/Q Targets Max                       329.618
trainer/Q Targets Min                        11.8302
trainer/Log Pis Mean                          5.96766
trainer/Log Pis Std                           4.9506
trainer/Log Pis Max                          18.2214
trainer/Log Pis Min                          -5.73002
trainer/policy/mean Mean                      0.0744312
trainer/policy/mean Std                       0.765084
trainer/policy/mean Max                       0.999234
trainer/policy/mean Min                      -0.998039
trainer/policy/normal/std Mean                0.468994
trainer/policy/normal/std Std                 0.138058
trainer/policy/normal/std Max                 0.945405
trainer/policy/normal/std Min                 0.119147
trainer/policy/normal/log_std Mean           -0.808531
trainer/policy/normal/log_std Std             0.339543
trainer/policy/normal/log_std Max            -0.0561418
trainer/policy/normal/log_std Min            -2.12739
trainer/Alpha                                 0.0929136
trainer/Alpha Loss                           -0.0768351
expl/num steps total                     125000
expl/num paths total                        125
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.47698
expl/Rewards Std                              1.1783
expl/Rewards Max                              6.77734
expl/Rewards Min                             -0.686615
expl/Returns Mean                          4476.98
expl/Returns Std                              0
expl/Returns Max                           4476.98
expl/Returns Min                           4476.98
expl/Actions Mean                             0.0429556
expl/Actions Std                              0.830964
expl/Actions Max                              0.999831
expl/Actions Min                             -0.999808
expl/Num Paths                                1
expl/Average Returns                       4476.98
expl/env_infos/final/reward_run Mean          5.93395
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.93395
expl/env_infos/final/reward_run Min           5.93395
expl/env_infos/initial/reward_run Mean       -0.338379
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.338379
expl/env_infos/initial/reward_run Min        -0.338379
expl/env_infos/reward_run Mean                4.89239
expl/env_infos/reward_run Std                 1.17333
expl/env_infos/reward_run Max                 7.27884
expl/env_infos/reward_run Min                -0.338379
expl/env_infos/final/reward_ctrl Mean        -0.417625
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.417625
expl/env_infos/final/reward_ctrl Min         -0.417625
expl/env_infos/initial/reward_ctrl Mean      -0.211807
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.211807
expl/env_infos/initial/reward_ctrl Min       -0.211807
expl/env_infos/reward_ctrl Mean              -0.415408
expl/env_infos/reward_ctrl Std                0.0838504
expl/env_infos/reward_ctrl Max               -0.156187
expl/env_infos/reward_ctrl Min               -0.587143
eval/num steps total                     620000
eval/num paths total                        620
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.62519
eval/Rewards Std                              1.19344
eval/Rewards Max                              6.91419
eval/Rewards Min                             -0.731771
eval/Returns Mean                          4625.19
eval/Returns Std                             82.6721
eval/Returns Max                           4740.95
eval/Returns Min                           4490.73
eval/Actions Mean                             0.0518191
eval/Actions Std                              0.846924
eval/Actions Max                              0.999081
eval/Actions Min                             -0.999814
eval/Num Paths                                5
eval/Average Returns                       4625.19
eval/env_infos/final/reward_run Mean          5.99375
eval/env_infos/final/reward_run Std           0.343995
eval/env_infos/final/reward_run Max           6.34625
eval/env_infos/final/reward_run Min           5.36624
eval/env_infos/initial/reward_run Mean       -0.191969
eval/env_infos/initial/reward_run Std         0.106557
eval/env_infos/initial/reward_run Max        -0.115861
eval/env_infos/initial/reward_run Min        -0.403118
eval/env_infos/reward_run Mean                5.05717
eval/env_infos/reward_run Std                 1.18462
eval/env_infos/reward_run Max                 7.43146
eval/env_infos/reward_run Min                -0.403118
eval/env_infos/final/reward_ctrl Mean        -0.361421
eval/env_infos/final/reward_ctrl Std          0.0648762
eval/env_infos/final/reward_ctrl Max         -0.249373
eval/env_infos/final/reward_ctrl Min         -0.417257
eval/env_infos/initial/reward_ctrl Mean      -0.178801
eval/env_infos/initial/reward_ctrl Std        0.0168177
eval/env_infos/initial/reward_ctrl Max       -0.160947
eval/env_infos/initial/reward_ctrl Min       -0.200977
eval/env_infos/reward_ctrl Mean              -0.43198
eval/env_infos/reward_ctrl Std                0.0757188
eval/env_infos/reward_ctrl Max               -0.10722
eval/env_infos/reward_ctrl Min               -0.578136
time/data storing (s)                         0.00454071
time/evaluation sampling (s)                  2.06166
time/exploration sampling (s)                 0.534612
time/logging (s)                              0.0138817
time/sac training (s)                         8.04487
time/saving (s)                               0.00384632
time/training (s)                             4.7108e-05
time/epoch (s)                               10.6635
time/total (s)                             1328.88
Epoch                                       123
---------------------------------------  ---------------
2021-11-24 00:51:31.776224 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 124 finished
---------------------------------------  ---------------
epoch                                       124
replay_buffer/size                       126000
trainer/num train calls                  125000
trainer/QF1 Loss                              8.25629
trainer/QF2 Loss                              6.94507
trainer/Policy Loss                        -235.927
trainer/Q1 Predictions Mean                 235.878
trainer/Q1 Predictions Std                   96.4608
trainer/Q1 Predictions Max                  328.37
trainer/Q1 Predictions Min                   11.1148
trainer/Q2 Predictions Mean                 236.378
trainer/Q2 Predictions Std                   96.6802
trainer/Q2 Predictions Max                  330.133
trainer/Q2 Predictions Min                   11.3445
trainer/Q Targets Mean                      236.068
trainer/Q Targets Std                        96.5803
trainer/Q Targets Max                       331.964
trainer/Q Targets Min                        11.2223
trainer/Log Pis Mean                          6.33263
trainer/Log Pis Std                           5.17014
trainer/Log Pis Max                          22.405
trainer/Log Pis Min                          -5.39801
trainer/policy/mean Mean                      0.0385272
trainer/policy/mean Std                       0.783233
trainer/policy/mean Max                       0.997792
trainer/policy/mean Min                      -0.999579
trainer/policy/normal/std Mean                0.463069
trainer/policy/normal/std Std                 0.13756
trainer/policy/normal/std Max                 0.847047
trainer/policy/normal/std Min                 0.0867948
trainer/policy/normal/log_std Mean           -0.821418
trainer/policy/normal/log_std Std             0.339363
trainer/policy/normal/log_std Max            -0.165999
trainer/policy/normal/log_std Min            -2.44421
trainer/Alpha                                 0.0939452
trainer/Alpha Loss                            0.786694
expl/num steps total                     126000
expl/num paths total                        126
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.53263
expl/Rewards Std                              1.23316
expl/Rewards Max                              6.82536
expl/Rewards Min                             -0.892033
expl/Returns Mean                          4532.63
expl/Returns Std                              0
expl/Returns Max                           4532.63
expl/Returns Min                           4532.63
expl/Actions Mean                             0.0714733
expl/Actions Std                              0.836414
expl/Actions Max                              0.999784
expl/Actions Min                             -0.999565
expl/Num Paths                                1
expl/Average Returns                       4532.63
expl/env_infos/final/reward_run Mean          5.91284
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.91284
expl/env_infos/final/reward_run Min           5.91284
expl/env_infos/initial/reward_run Mean        0.104888
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.104888
expl/env_infos/initial/reward_run Min         0.104888
expl/env_infos/reward_run Mean                4.95544
expl/env_infos/reward_run Std                 1.22162
expl/env_infos/reward_run Max                 7.29916
expl/env_infos/reward_run Min                -0.382983
expl/env_infos/final/reward_ctrl Mean        -0.364472
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.364472
expl/env_infos/final/reward_ctrl Min         -0.364472
expl/env_infos/initial/reward_ctrl Mean      -0.275324
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.275324
expl/env_infos/initial/reward_ctrl Min       -0.275324
expl/env_infos/reward_ctrl Mean              -0.422818
expl/env_infos/reward_ctrl Std                0.0788536
expl/env_infos/reward_ctrl Max               -0.140099
expl/env_infos/reward_ctrl Min               -0.592486
eval/num steps total                     625000
eval/num paths total                        625
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.45388
eval/Rewards Std                              1.20515
eval/Rewards Max                              7.10052
eval/Rewards Min                             -0.827683
eval/Returns Mean                          4453.88
eval/Returns Std                             78.2081
eval/Returns Max                           4536.25
eval/Returns Min                           4324.14
eval/Actions Mean                             0.0771114
eval/Actions Std                              0.846235
eval/Actions Max                              0.999744
eval/Actions Min                             -0.998905
eval/Num Paths                                5
eval/Average Returns                       4453.88
eval/env_infos/final/reward_run Mean          5.00007
eval/env_infos/final/reward_run Std           1.02719
eval/env_infos/final/reward_run Max           6.5835
eval/env_infos/final/reward_run Min           3.7524
eval/env_infos/initial/reward_run Mean       -0.266185
eval/env_infos/initial/reward_run Std         0.24425
eval/env_infos/initial/reward_run Max         0.0941725
eval/env_infos/initial/reward_run Min        -0.496998
eval/env_infos/reward_run Mean                4.88712
eval/env_infos/reward_run Std                 1.20014
eval/env_infos/reward_run Max                 7.61273
eval/env_infos/reward_run Min                -0.496998
eval/env_infos/final/reward_ctrl Mean        -0.454223
eval/env_infos/final/reward_ctrl Std          0.083024
eval/env_infos/final/reward_ctrl Max         -0.342332
eval/env_infos/final/reward_ctrl Min         -0.567967
eval/env_infos/initial/reward_ctrl Mean      -0.213294
eval/env_infos/initial/reward_ctrl Std        0.0630322
eval/env_infos/initial/reward_ctrl Max       -0.155635
eval/env_infos/initial/reward_ctrl Min       -0.330685
eval/env_infos/reward_ctrl Mean              -0.433235
eval/env_infos/reward_ctrl Std                0.0766835
eval/env_infos/reward_ctrl Max               -0.121304
eval/env_infos/reward_ctrl Min               -0.590162
time/data storing (s)                         0.00445565
time/evaluation sampling (s)                  2.07176
time/exploration sampling (s)                 0.542691
time/logging (s)                              0.0140543
time/sac training (s)                         7.93143
time/saving (s)                               0.00381604
time/training (s)                             3.5311e-05
time/epoch (s)                               10.5682
time/total (s)                             1339.77
Epoch                                       124
---------------------------------------  ---------------
2021-11-24 00:51:42.854595 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 125 finished
---------------------------------------  ---------------
epoch                                       125
replay_buffer/size                       127000
trainer/num train calls                  126000
trainer/QF1 Loss                              8.37765
trainer/QF2 Loss                              6.65084
trainer/Policy Loss                        -239.863
trainer/Q1 Predictions Mean                 240.425
trainer/Q1 Predictions Std                  103.954
trainer/Q1 Predictions Max                  330.858
trainer/Q1 Predictions Min                    9.73179
trainer/Q2 Predictions Mean                 240.137
trainer/Q2 Predictions Std                  103.887
trainer/Q2 Predictions Max                  331.798
trainer/Q2 Predictions Min                   10.1168
trainer/Q Targets Mean                      240.48
trainer/Q Targets Std                       104.105
trainer/Q Targets Max                       333.816
trainer/Q Targets Min                         9.5761
trainer/Log Pis Mean                          6.4541
trainer/Log Pis Std                           5.19633
trainer/Log Pis Max                          19.8789
trainer/Log Pis Min                          -4.83636
trainer/policy/mean Mean                      0.0357622
trainer/policy/mean Std                       0.785633
trainer/policy/mean Max                       0.999136
trainer/policy/mean Min                      -0.99958
trainer/policy/normal/std Mean                0.480318
trainer/policy/normal/std Std                 0.139851
trainer/policy/normal/std Max                 0.933202
trainer/policy/normal/std Min                 0.0975557
trainer/policy/normal/log_std Mean           -0.783292
trainer/policy/normal/log_std Std             0.33504
trainer/policy/normal/log_std Max            -0.0691339
trainer/policy/normal/log_std Min            -2.32733
trainer/Alpha                                 0.0929662
trainer/Alpha Loss                            1.07873
expl/num steps total                     127000
expl/num paths total                        127
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.54375
expl/Rewards Std                              1.11995
expl/Rewards Max                              6.89144
expl/Rewards Min                             -0.689755
expl/Returns Mean                          4543.75
expl/Returns Std                              0
expl/Returns Max                           4543.75
expl/Returns Min                           4543.75
expl/Actions Mean                             0.0352569
expl/Actions Std                              0.833966
expl/Actions Max                              0.999584
expl/Actions Min                             -0.999784
expl/Num Paths                                1
expl/Average Returns                       4543.75
expl/env_infos/final/reward_run Mean          4.60648
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.60648
expl/env_infos/final/reward_run Min           4.60648
expl/env_infos/initial/reward_run Mean       -0.344881
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.344881
expl/env_infos/initial/reward_run Min        -0.344881
expl/env_infos/reward_run Mean                4.9618
expl/env_infos/reward_run Std                 1.10855
expl/env_infos/reward_run Max                 7.32264
expl/env_infos/reward_run Min                -0.344881
expl/env_infos/final/reward_ctrl Mean        -0.353328
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.353328
expl/env_infos/final/reward_ctrl Min         -0.353328
expl/env_infos/initial/reward_ctrl Mean      -0.166242
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.166242
expl/env_infos/initial/reward_ctrl Min       -0.166242
expl/env_infos/reward_ctrl Mean              -0.418045
expl/env_infos/reward_ctrl Std                0.0826317
expl/env_infos/reward_ctrl Max               -0.157565
expl/env_infos/reward_ctrl Min               -0.582307
eval/num steps total                     630000
eval/num paths total                        630
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.65339
eval/Rewards Std                              1.20283
eval/Rewards Max                              7.17277
eval/Rewards Min                             -0.871538
eval/Returns Mean                          4653.39
eval/Returns Std                             66.8833
eval/Returns Max                           4772.93
eval/Returns Min                           4590.13
eval/Actions Mean                             0.0434512
eval/Actions Std                              0.846284
eval/Actions Max                              0.999552
eval/Actions Min                             -0.998699
eval/Num Paths                                5
eval/Average Returns                       4653.39
eval/env_infos/final/reward_run Mean          4.26022
eval/env_infos/final/reward_run Std           0.853014
eval/env_infos/final/reward_run Max           5.83007
eval/env_infos/final/reward_run Min           3.39378
eval/env_infos/initial/reward_run Mean       -0.259382
eval/env_infos/initial/reward_run Std         0.254202
eval/env_infos/initial/reward_run Max         0.0774026
eval/env_infos/initial/reward_run Min        -0.510949
eval/env_infos/reward_run Mean                5.08425
eval/env_infos/reward_run Std                 1.18979
eval/env_infos/reward_run Max                 7.67998
eval/env_infos/reward_run Min                -0.510949
eval/env_infos/final/reward_ctrl Mean        -0.486093
eval/env_infos/final/reward_ctrl Std          0.0601391
eval/env_infos/final/reward_ctrl Max         -0.387167
eval/env_infos/final/reward_ctrl Min         -0.557275
eval/env_infos/initial/reward_ctrl Mean      -0.224426
eval/env_infos/initial/reward_ctrl Std        0.0732205
eval/env_infos/initial/reward_ctrl Max       -0.147417
eval/env_infos/initial/reward_ctrl Min       -0.36059
eval/env_infos/reward_ctrl Mean              -0.43085
eval/env_infos/reward_ctrl Std                0.0788725
eval/env_infos/reward_ctrl Max               -0.139457
eval/env_infos/reward_ctrl Min               -0.58756
time/data storing (s)                         0.00450004
time/evaluation sampling (s)                  2.13719
time/exploration sampling (s)                 0.534997
time/logging (s)                              0.0138514
time/sac training (s)                         8.0419
time/saving (s)                               0.00384847
time/training (s)                             3.8666e-05
time/epoch (s)                               10.7363
time/total (s)                             1350.83
Epoch                                       125
---------------------------------------  ---------------
2021-11-24 00:51:53.807833 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 126 finished
---------------------------------------  ---------------
epoch                                       126
replay_buffer/size                       128000
trainer/num train calls                  127000
trainer/QF1 Loss                              9.49378
trainer/QF2 Loss                              8.69663
trainer/Policy Loss                        -246.64
trainer/Q1 Predictions Mean                 246.785
trainer/Q1 Predictions Std                   91.5734
trainer/Q1 Predictions Max                  325.83
trainer/Q1 Predictions Min                   12.2616
trainer/Q2 Predictions Mean                 247.204
trainer/Q2 Predictions Std                   91.825
trainer/Q2 Predictions Max                  326.946
trainer/Q2 Predictions Min                   12.1979
trainer/Q Targets Mean                      247.252
trainer/Q Targets Std                        91.7611
trainer/Q Targets Max                       327.438
trainer/Q Targets Min                        11.5671
trainer/Log Pis Mean                          6.36891
trainer/Log Pis Std                           4.64176
trainer/Log Pis Max                          20.1797
trainer/Log Pis Min                          -4.39509
trainer/policy/mean Mean                      0.0414675
trainer/policy/mean Std                       0.784976
trainer/policy/mean Max                       0.999866
trainer/policy/mean Min                      -0.996982
trainer/policy/normal/std Mean                0.452752
trainer/policy/normal/std Std                 0.130959
trainer/policy/normal/std Max                 0.88487
trainer/policy/normal/std Min                 0.079857
trainer/policy/normal/log_std Mean           -0.84108
trainer/policy/normal/log_std Std             0.329246
trainer/policy/normal/log_std Max            -0.122315
trainer/policy/normal/log_std Min            -2.52752
trainer/Alpha                                 0.0928942
trainer/Alpha Loss                            0.876639
expl/num steps total                     128000
expl/num paths total                        128
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.47302
expl/Rewards Std                              1.09598
expl/Rewards Max                              6.48907
expl/Rewards Min                             -0.864791
expl/Returns Mean                          4473.02
expl/Returns Std                              0
expl/Returns Max                           4473.02
expl/Returns Min                           4473.02
expl/Actions Mean                             0.05339
expl/Actions Std                              0.826276
expl/Actions Max                              0.999802
expl/Actions Min                             -0.999335
expl/Num Paths                                1
expl/Average Returns                       4473.02
expl/env_infos/final/reward_run Mean          4.45916
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.45916
expl/env_infos/final/reward_run Min           4.45916
expl/env_infos/initial/reward_run Mean       -0.589539
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.589539
expl/env_infos/initial/reward_run Min        -0.589539
expl/env_infos/reward_run Mean                4.88437
expl/env_infos/reward_run Std                 1.09632
expl/env_infos/reward_run Max                 7.03573
expl/env_infos/reward_run Min                -0.589539
expl/env_infos/final/reward_ctrl Mean        -0.281819
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.281819
expl/env_infos/final/reward_ctrl Min         -0.281819
expl/env_infos/initial/reward_ctrl Mean      -0.275252
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.275252
expl/env_infos/initial/reward_ctrl Min       -0.275252
expl/env_infos/reward_ctrl Mean              -0.411349
expl/env_infos/reward_ctrl Std                0.0862479
expl/env_infos/reward_ctrl Max               -0.131331
expl/env_infos/reward_ctrl Min               -0.576175
eval/num steps total                     635000
eval/num paths total                        635
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.43694
eval/Rewards Std                              1.14724
eval/Rewards Max                              6.80775
eval/Rewards Min                             -1.11961
eval/Returns Mean                          4436.94
eval/Returns Std                             99.8688
eval/Returns Max                           4522.69
eval/Returns Min                           4241.9
eval/Actions Mean                             0.0617367
eval/Actions Std                              0.837539
eval/Actions Max                              0.998563
eval/Actions Min                             -0.999199
eval/Num Paths                                5
eval/Average Returns                       4436.94
eval/env_infos/final/reward_run Mean          4.92215
eval/env_infos/final/reward_run Std           0.751892
eval/env_infos/final/reward_run Max           5.86526
eval/env_infos/final/reward_run Min           3.7663
eval/env_infos/initial/reward_run Mean       -0.440715
eval/env_infos/initial/reward_run Std         0.182478
eval/env_infos/initial/reward_run Max        -0.142513
eval/env_infos/initial/reward_run Min        -0.632458
eval/env_infos/reward_run Mean                4.86011
eval/env_infos/reward_run Std                 1.15003
eval/env_infos/reward_run Max                 7.21739
eval/env_infos/reward_run Min                -0.632458
eval/env_infos/final/reward_ctrl Mean        -0.343874
eval/env_infos/final/reward_ctrl Std          0.107051
eval/env_infos/final/reward_ctrl Max         -0.224911
eval/env_infos/final/reward_ctrl Min         -0.535698
eval/env_infos/initial/reward_ctrl Mean      -0.279205
eval/env_infos/initial/reward_ctrl Std        0.0551397
eval/env_infos/initial/reward_ctrl Max       -0.173972
eval/env_infos/initial/reward_ctrl Min       -0.3341
eval/env_infos/reward_ctrl Mean              -0.42317
eval/env_infos/reward_ctrl Std                0.0811472
eval/env_infos/reward_ctrl Max               -0.125531
eval/env_infos/reward_ctrl Min               -0.577772
time/data storing (s)                         0.00629863
time/evaluation sampling (s)                  2.02819
time/exploration sampling (s)                 0.594743
time/logging (s)                              0.0146753
time/sac training (s)                         7.96634
time/saving (s)                               0.00501809
time/training (s)                             3.7892e-05
time/epoch (s)                               10.6153
time/total (s)                             1361.77
Epoch                                       126
---------------------------------------  ---------------
2021-11-24 00:52:04.809327 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 127 finished
---------------------------------------  ---------------
epoch                                       127
replay_buffer/size                       129000
trainer/num train calls                  128000
trainer/QF1 Loss                              9.35942
trainer/QF2 Loss                              6.26919
trainer/Policy Loss                        -247.649
trainer/Q1 Predictions Mean                 248.269
trainer/Q1 Predictions Std                   94.4699
trainer/Q1 Predictions Max                  328.428
trainer/Q1 Predictions Min                   10.862
trainer/Q2 Predictions Mean                 248.052
trainer/Q2 Predictions Std                   94.5065
trainer/Q2 Predictions Max                  329.633
trainer/Q2 Predictions Min                   10.047
trainer/Q Targets Mean                      248.188
trainer/Q Targets Std                        94.553
trainer/Q Targets Max                       328.736
trainer/Q Targets Min                        10.1997
trainer/Log Pis Mean                          6.61661
trainer/Log Pis Std                           5.17106
trainer/Log Pis Max                          19.7298
trainer/Log Pis Min                          -5.33869
trainer/policy/mean Mean                      0.0103526
trainer/policy/mean Std                       0.782138
trainer/policy/mean Max                       0.998622
trainer/policy/mean Min                      -0.99986
trainer/policy/normal/std Mean                0.461935
trainer/policy/normal/std Std                 0.139059
trainer/policy/normal/std Max                 0.96498
trainer/policy/normal/std Min                 0.093589
trainer/policy/normal/log_std Mean           -0.825679
trainer/policy/normal/log_std Std             0.346275
trainer/policy/normal/log_std Max            -0.0356479
trainer/policy/normal/log_std Min            -2.36884
trainer/Alpha                                 0.0938661
trainer/Alpha Loss                            1.45882
expl/num steps total                     129000
expl/num paths total                        129
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.40773
expl/Rewards Std                              1.21759
expl/Rewards Max                              6.63154
expl/Rewards Min                             -0.504181
expl/Returns Mean                          4407.73
expl/Returns Std                              0
expl/Returns Max                           4407.73
expl/Returns Min                           4407.73
expl/Actions Mean                             0.0453673
expl/Actions Std                              0.832261
expl/Actions Max                              0.999965
expl/Actions Min                             -0.999839
expl/Num Paths                                1
expl/Average Returns                       4407.73
expl/env_infos/final/reward_run Mean          4.1257
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.1257
expl/env_infos/final/reward_run Min           4.1257
expl/env_infos/initial/reward_run Mean       -0.232276
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.232276
expl/env_infos/initial/reward_run Min        -0.232276
expl/env_infos/reward_run Mean                4.82456
expl/env_infos/reward_run Std                 1.21159
expl/env_infos/reward_run Max                 7.13141
expl/env_infos/reward_run Min                -0.232276
expl/env_infos/final/reward_ctrl Mean        -0.456317
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.456317
expl/env_infos/final/reward_ctrl Min         -0.456317
expl/env_infos/initial/reward_ctrl Mean      -0.271905
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.271905
expl/env_infos/initial/reward_ctrl Min       -0.271905
expl/env_infos/reward_ctrl Mean              -0.41683
expl/env_infos/reward_ctrl Std                0.0850858
expl/env_infos/reward_ctrl Max               -0.1513
expl/env_infos/reward_ctrl Min               -0.585472
eval/num steps total                     640000
eval/num paths total                        640
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.44661
eval/Rewards Std                              1.18215
eval/Rewards Max                              6.85418
eval/Rewards Min                             -0.795298
eval/Returns Mean                          4446.61
eval/Returns Std                             65.1647
eval/Returns Max                           4567.54
eval/Returns Min                           4380.79
eval/Actions Mean                             0.0514035
eval/Actions Std                              0.848041
eval/Actions Max                              0.999799
eval/Actions Min                             -0.998598
eval/Num Paths                                5
eval/Average Returns                       4446.61
eval/env_infos/final/reward_run Mean          5.1603
eval/env_infos/final/reward_run Std           1.06205
eval/env_infos/final/reward_run Max           6.72916
eval/env_infos/final/reward_run Min           3.9909
eval/env_infos/initial/reward_run Mean       -0.162465
eval/env_infos/initial/reward_run Std         0.455251
eval/env_infos/initial/reward_run Max         0.700706
eval/env_infos/initial/reward_run Min        -0.585276
eval/env_infos/reward_run Mean                4.8797
eval/env_infos/reward_run Std                 1.17289
eval/env_infos/reward_run Max                 7.37363
eval/env_infos/reward_run Min                -0.585276
eval/env_infos/final/reward_ctrl Mean        -0.437564
eval/env_infos/final/reward_ctrl Std          0.0710698
eval/env_infos/final/reward_ctrl Max         -0.309043
eval/env_infos/final/reward_ctrl Min         -0.505221
eval/env_infos/initial/reward_ctrl Mean      -0.200759
eval/env_infos/initial/reward_ctrl Std        0.042176
eval/env_infos/initial/reward_ctrl Max       -0.150347
eval/env_infos/initial/reward_ctrl Min       -0.278026
eval/env_infos/reward_ctrl Mean              -0.43309
eval/env_infos/reward_ctrl Std                0.0770814
eval/env_infos/reward_ctrl Max               -0.12617
eval/env_infos/reward_ctrl Min               -0.584035
time/data storing (s)                         0.00451924
time/evaluation sampling (s)                  2.08913
time/exploration sampling (s)                 0.555884
time/logging (s)                              0.0142677
time/sac training (s)                         7.98927
time/saving (s)                               0.00560446
time/training (s)                             6.0566e-05
time/epoch (s)                               10.6587
time/total (s)                             1372.76
Epoch                                       127
---------------------------------------  ---------------
2021-11-24 00:52:15.683229 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 128 finished
---------------------------------------  ---------------
epoch                                       128
replay_buffer/size                       130000
trainer/num train calls                  129000
trainer/QF1 Loss                              6.0093
trainer/QF2 Loss                              5.57436
trainer/Policy Loss                        -225.041
trainer/Q1 Predictions Mean                 225.231
trainer/Q1 Predictions Std                  112.903
trainer/Q1 Predictions Max                  336.856
trainer/Q1 Predictions Min                   10.4185
trainer/Q2 Predictions Mean                 225.07
trainer/Q2 Predictions Std                  112.865
trainer/Q2 Predictions Max                  339.695
trainer/Q2 Predictions Min                   11.368
trainer/Q Targets Mean                      225.03
trainer/Q Targets Std                       112.787
trainer/Q Targets Max                       337.991
trainer/Q Targets Min                         9.50256
trainer/Log Pis Mean                          5.59816
trainer/Log Pis Std                           4.84372
trainer/Log Pis Max                          25.4313
trainer/Log Pis Min                          -4.42455
trainer/policy/mean Mean                      0.0342744
trainer/policy/mean Std                       0.757182
trainer/policy/mean Max                       0.999857
trainer/policy/mean Min                      -0.997895
trainer/policy/normal/std Mean                0.466028
trainer/policy/normal/std Std                 0.141992
trainer/policy/normal/std Max                 1.17192
trainer/policy/normal/std Min                 0.0875067
trainer/policy/normal/log_std Mean           -0.818355
trainer/policy/normal/log_std Std             0.351056
trainer/policy/normal/log_std Max             0.158646
trainer/policy/normal/log_std Min            -2.43604
trainer/Alpha                                 0.0935828
trainer/Alpha Loss                           -0.951922
expl/num steps total                     130000
expl/num paths total                        130
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.56104
expl/Rewards Std                              1.13634
expl/Rewards Max                              6.92235
expl/Rewards Min                             -0.49158
expl/Returns Mean                          4561.04
expl/Returns Std                              0
expl/Returns Max                           4561.04
expl/Returns Min                           4561.04
expl/Actions Mean                             0.0300248
expl/Actions Std                              0.828816
expl/Actions Max                              0.999835
expl/Actions Min                             -0.9997
expl/Num Paths                                1
expl/Average Returns                       4561.04
expl/env_infos/final/reward_run Mean          3.87025
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.87025
expl/env_infos/final/reward_run Min           3.87025
expl/env_infos/initial/reward_run Mean       -0.0293735
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0293735
expl/env_infos/initial/reward_run Min        -0.0293735
expl/env_infos/reward_run Mean                4.97374
expl/env_infos/reward_run Std                 1.12334
expl/env_infos/reward_run Max                 7.45842
expl/env_infos/reward_run Min                -0.0452637
expl/env_infos/final/reward_ctrl Mean        -0.565931
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.565931
expl/env_infos/final/reward_ctrl Min         -0.565931
expl/env_infos/initial/reward_ctrl Mean      -0.262457
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.262457
expl/env_infos/initial/reward_ctrl Min       -0.262457
expl/env_infos/reward_ctrl Mean              -0.412703
expl/env_infos/reward_ctrl Std                0.0836189
expl/env_infos/reward_ctrl Max               -0.137563
expl/env_infos/reward_ctrl Min               -0.585629
eval/num steps total                     645000
eval/num paths total                        645
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.81745
eval/Rewards Std                              1.23699
eval/Rewards Max                              7.27403
eval/Rewards Min                             -1.1812
eval/Returns Mean                          4817.45
eval/Returns Std                             74.093
eval/Returns Max                           4907.75
eval/Returns Min                           4716.55
eval/Actions Mean                             0.0416607
eval/Actions Std                              0.845629
eval/Actions Max                              0.998555
eval/Actions Min                             -0.999455
eval/Num Paths                                5
eval/Average Returns                       4817.45
eval/env_infos/final/reward_run Mean          5.36937
eval/env_infos/final/reward_run Std           0.677923
eval/env_infos/final/reward_run Max           6.32923
eval/env_infos/final/reward_run Min           4.40603
eval/env_infos/initial/reward_run Mean       -0.290009
eval/env_infos/initial/reward_run Std         0.251676
eval/env_infos/initial/reward_run Max         0.11372
eval/env_infos/initial/reward_run Min        -0.553288
eval/env_infos/reward_run Mean                5.24754
eval/env_infos/reward_run Std                 1.22201
eval/env_infos/reward_run Max                 7.76376
eval/env_infos/reward_run Min                -0.715942
eval/env_infos/final/reward_ctrl Mean        -0.460448
eval/env_infos/final/reward_ctrl Std          0.0693739
eval/env_infos/final/reward_ctrl Max         -0.380825
eval/env_infos/final/reward_ctrl Min         -0.56796
eval/env_infos/initial/reward_ctrl Mean      -0.209768
eval/env_infos/initial/reward_ctrl Std        0.0432877
eval/env_infos/initial/reward_ctrl Max       -0.129733
eval/env_infos/initial/reward_ctrl Min       -0.25271
eval/env_infos/reward_ctrl Mean              -0.430094
eval/env_infos/reward_ctrl Std                0.0803077
eval/env_infos/reward_ctrl Max               -0.128001
eval/env_infos/reward_ctrl Min               -0.584237
time/data storing (s)                         0.00451076
time/evaluation sampling (s)                  2.08759
time/exploration sampling (s)                 0.538035
time/logging (s)                              0.0136294
time/sac training (s)                         7.89189
time/saving (s)                               0.00383493
time/training (s)                             3.4999e-05
time/epoch (s)                               10.5395
time/total (s)                             1383.62
Epoch                                       128
---------------------------------------  ---------------
2021-11-24 00:52:26.608120 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 129 finished
---------------------------------------  ---------------
epoch                                       129
replay_buffer/size                       131000
trainer/num train calls                  130000
trainer/QF1 Loss                              5.32073
trainer/QF2 Loss                              4.98115
trainer/Policy Loss                        -246.928
trainer/Q1 Predictions Mean                 247.198
trainer/Q1 Predictions Std                   94.4999
trainer/Q1 Predictions Max                  333.327
trainer/Q1 Predictions Min                    9.88439
trainer/Q2 Predictions Mean                 246.971
trainer/Q2 Predictions Std                   94.4405
trainer/Q2 Predictions Max                  334.834
trainer/Q2 Predictions Min                   10.7333
trainer/Q Targets Mean                      246.86
trainer/Q Targets Std                        94.491
trainer/Q Targets Max                       334.573
trainer/Q Targets Min                        11.4261
trainer/Log Pis Mean                          6.37504
trainer/Log Pis Std                           5.00366
trainer/Log Pis Max                          21.6596
trainer/Log Pis Min                          -4.67114
trainer/policy/mean Mean                      0.0376667
trainer/policy/mean Std                       0.775726
trainer/policy/mean Max                       0.998876
trainer/policy/mean Min                      -0.999258
trainer/policy/normal/std Mean                0.459845
trainer/policy/normal/std Std                 0.136941
trainer/policy/normal/std Max                 1.1014
trainer/policy/normal/std Min                 0.0879016
trainer/policy/normal/log_std Mean           -0.829054
trainer/policy/normal/log_std Std             0.342186
trainer/policy/normal/log_std Max             0.0965857
trainer/policy/normal/log_std Min            -2.43154
trainer/Alpha                                 0.0941377
trainer/Alpha Loss                            0.886224
expl/num steps total                     131000
expl/num paths total                        131
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.38038
expl/Rewards Std                              1.14431
expl/Rewards Max                              6.68867
expl/Rewards Min                             -0.296165
expl/Returns Mean                          4380.38
expl/Returns Std                              0
expl/Returns Max                           4380.38
expl/Returns Min                           4380.38
expl/Actions Mean                             0.0400671
expl/Actions Std                              0.828538
expl/Actions Max                              0.999649
expl/Actions Min                             -0.999701
expl/Num Paths                                1
expl/Average Returns                       4380.38
expl/env_infos/final/reward_run Mean          3.73371
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.73371
expl/env_infos/final/reward_run Min           3.73371
expl/env_infos/initial/reward_run Mean       -0.196372
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.196372
expl/env_infos/initial/reward_run Min        -0.196372
expl/env_infos/reward_run Mean                4.79322
expl/env_infos/reward_run Std                 1.13081
expl/env_infos/reward_run Max                 7.20749
expl/env_infos/reward_run Min                -0.196372
expl/env_infos/final/reward_ctrl Mean        -0.431141
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.431141
expl/env_infos/final/reward_ctrl Min         -0.431141
expl/env_infos/initial/reward_ctrl Mean      -0.0997932
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0997932
expl/env_infos/initial/reward_ctrl Min       -0.0997932
expl/env_infos/reward_ctrl Mean              -0.412849
expl/env_infos/reward_ctrl Std                0.0832388
expl/env_infos/reward_ctrl Max               -0.0997932
expl/env_infos/reward_ctrl Min               -0.582113
eval/num steps total                     650000
eval/num paths total                        650
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.7045
eval/Rewards Std                              1.23389
eval/Rewards Max                              7.00572
eval/Rewards Min                             -1.12688
eval/Returns Mean                          4704.5
eval/Returns Std                             69.4411
eval/Returns Max                           4771.04
eval/Returns Min                           4588.87
eval/Actions Mean                             0.0417368
eval/Actions Std                              0.84594
eval/Actions Max                              0.998228
eval/Actions Min                             -0.998016
eval/Num Paths                                5
eval/Average Returns                       4704.5
eval/env_infos/final/reward_run Mean          4.75515
eval/env_infos/final/reward_run Std           1.33855
eval/env_infos/final/reward_run Max           7.2844
eval/env_infos/final/reward_run Min           3.59573
eval/env_infos/initial/reward_run Mean       -0.539892
eval/env_infos/initial/reward_run Std         0.118441
eval/env_infos/initial/reward_run Max        -0.36947
eval/env_infos/initial/reward_run Min        -0.711097
eval/env_infos/reward_run Mean                5.13492
eval/env_infos/reward_run Std                 1.22044
eval/env_infos/reward_run Max                 7.52404
eval/env_infos/reward_run Min                -0.711097
eval/env_infos/final/reward_ctrl Mean        -0.502381
eval/env_infos/final/reward_ctrl Std          0.0231296
eval/env_infos/final/reward_ctrl Max         -0.465954
eval/env_infos/final/reward_ctrl Min         -0.531118
eval/env_infos/initial/reward_ctrl Mean      -0.334682
eval/env_infos/initial/reward_ctrl Std        0.0262265
eval/env_infos/initial/reward_ctrl Max       -0.293199
eval/env_infos/initial/reward_ctrl Min       -0.366344
eval/env_infos/reward_ctrl Mean              -0.430414
eval/env_infos/reward_ctrl Std                0.0761992
eval/env_infos/reward_ctrl Max               -0.0558949
eval/env_infos/reward_ctrl Min               -0.585901
time/data storing (s)                         0.00456678
time/evaluation sampling (s)                  2.06388
time/exploration sampling (s)                 0.54686
time/logging (s)                              0.0329257
time/sac training (s)                         7.94801
time/saving (s)                               0.00711317
time/training (s)                             6.2326e-05
time/epoch (s)                               10.6034
time/total (s)                             1394.55
Epoch                                       129
---------------------------------------  ---------------
2021-11-24 00:52:37.479505 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 130 finished
---------------------------------------  ---------------
epoch                                       130
replay_buffer/size                       132000
trainer/num train calls                  131000
trainer/QF1 Loss                              8.53879
trainer/QF2 Loss                              6.45378
trainer/Policy Loss                        -239.02
trainer/Q1 Predictions Mean                 239.309
trainer/Q1 Predictions Std                  105.433
trainer/Q1 Predictions Max                  336.79
trainer/Q1 Predictions Min                   10.8094
trainer/Q2 Predictions Mean                 239.058
trainer/Q2 Predictions Std                  105.351
trainer/Q2 Predictions Max                  336.323
trainer/Q2 Predictions Min                   10.7603
trainer/Q Targets Mean                      239.272
trainer/Q Targets Std                       105.405
trainer/Q Targets Max                       338.425
trainer/Q Targets Min                        10.8598
trainer/Log Pis Mean                          5.66186
trainer/Log Pis Std                           4.89238
trainer/Log Pis Max                          16.6631
trainer/Log Pis Min                          -6.58168
trainer/policy/mean Mean                      0.0422964
trainer/policy/mean Std                       0.778721
trainer/policy/mean Max                       0.998146
trainer/policy/mean Min                      -0.997679
trainer/policy/normal/std Mean                0.463505
trainer/policy/normal/std Std                 0.14124
trainer/policy/normal/std Max                 0.851783
trainer/policy/normal/std Min                 0.112204
trainer/policy/normal/log_std Mean           -0.823557
trainer/policy/normal/log_std Std             0.350125
trainer/policy/normal/log_std Max            -0.160423
trainer/policy/normal/log_std Min            -2.18744
trainer/Alpha                                 0.0963468
trainer/Alpha Loss                           -0.791175
expl/num steps total                     132000
expl/num paths total                        132
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.56823
expl/Rewards Std                              1.22541
expl/Rewards Max                              7.04377
expl/Rewards Min                             -0.684346
expl/Returns Mean                          4568.23
expl/Returns Std                              0
expl/Returns Max                           4568.23
expl/Returns Min                           4568.23
expl/Actions Mean                             0.0617765
expl/Actions Std                              0.842776
expl/Actions Max                              0.999534
expl/Actions Min                             -0.99923
expl/Num Paths                                1
expl/Average Returns                       4568.23
expl/env_infos/final/reward_run Mean          4.06049
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.06049
expl/env_infos/final/reward_run Min           4.06049
expl/env_infos/initial/reward_run Mean       -0.39142
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.39142
expl/env_infos/initial/reward_run Min        -0.39142
expl/env_infos/reward_run Mean                4.99668
expl/env_infos/reward_run Std                 1.21683
expl/env_infos/reward_run Max                 7.58444
expl/env_infos/reward_run Min                -0.39142
expl/env_infos/final/reward_ctrl Mean        -0.445531
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.445531
expl/env_infos/final/reward_ctrl Min         -0.445531
expl/env_infos/initial/reward_ctrl Mean      -0.292926
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.292926
expl/env_infos/initial/reward_ctrl Min       -0.292926
expl/env_infos/reward_ctrl Mean              -0.428453
expl/env_infos/reward_ctrl Std                0.0753021
expl/env_infos/reward_ctrl Max               -0.141985
expl/env_infos/reward_ctrl Min               -0.584544
eval/num steps total                     655000
eval/num paths total                        655
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.53958
eval/Rewards Std                              1.23539
eval/Rewards Max                              7.05481
eval/Rewards Min                             -1.08157
eval/Returns Mean                          4539.58
eval/Returns Std                             52.5318
eval/Returns Max                           4585.21
eval/Returns Min                           4443.36
eval/Actions Mean                             0.0681281
eval/Actions Std                              0.85227
eval/Actions Max                              0.998839
eval/Actions Min                             -0.997058
eval/Num Paths                                5
eval/Average Returns                       4539.58
eval/env_infos/final/reward_run Mean          5.29093
eval/env_infos/final/reward_run Std           1.34482
eval/env_infos/final/reward_run Max           6.9852
eval/env_infos/final/reward_run Min           3.51846
eval/env_infos/initial/reward_run Mean       -0.531109
eval/env_infos/initial/reward_run Std         0.127842
eval/env_infos/initial/reward_run Max        -0.348152
eval/env_infos/initial/reward_run Min        -0.675501
eval/env_infos/reward_run Mean                4.97818
eval/env_infos/reward_run Std                 1.22338
eval/env_infos/reward_run Max                 7.59132
eval/env_infos/reward_run Min                -0.675501
eval/env_infos/final/reward_ctrl Mean        -0.484657
eval/env_infos/final/reward_ctrl Std          0.0634251
eval/env_infos/final/reward_ctrl Max         -0.393157
eval/env_infos/final/reward_ctrl Min         -0.579142
eval/env_infos/initial/reward_ctrl Mean      -0.299492
eval/env_infos/initial/reward_ctrl Std        0.0467538
eval/env_infos/initial/reward_ctrl Max       -0.221603
eval/env_infos/initial/reward_ctrl Min       -0.348329
eval/env_infos/reward_ctrl Mean              -0.438603
eval/env_infos/reward_ctrl Std                0.0714498
eval/env_infos/reward_ctrl Max               -0.178084
eval/env_infos/reward_ctrl Min               -0.582641
time/data storing (s)                         0.00451689
time/evaluation sampling (s)                  2.05585
time/exploration sampling (s)                 0.53062
time/logging (s)                              0.013598
time/sac training (s)                         7.89837
time/saving (s)                               0.0038433
time/training (s)                             3.4413e-05
time/epoch (s)                               10.5068
time/total (s)                             1405.38
Epoch                                       130
---------------------------------------  ---------------
2021-11-24 00:52:48.435201 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 131 finished
---------------------------------------  ---------------
epoch                                       131
replay_buffer/size                       133000
trainer/num train calls                  132000
trainer/QF1 Loss                              5.05879
trainer/QF2 Loss                              5.28525
trainer/Policy Loss                        -251.392
trainer/Q1 Predictions Mean                 251.849
trainer/Q1 Predictions Std                   95.0744
trainer/Q1 Predictions Max                  334.199
trainer/Q1 Predictions Min                   11.1826
trainer/Q2 Predictions Mean                 251.669
trainer/Q2 Predictions Std                   95.1619
trainer/Q2 Predictions Max                  335.076
trainer/Q2 Predictions Min                    9.29533
trainer/Q Targets Mean                      251.983
trainer/Q Targets Std                        95.198
trainer/Q Targets Max                       337.143
trainer/Q Targets Min                        11.1647
trainer/Log Pis Mean                          6.2557
trainer/Log Pis Std                           5.3431
trainer/Log Pis Max                          43.8745
trainer/Log Pis Min                          -5.09584
trainer/policy/mean Mean                      0.049703
trainer/policy/mean Std                       0.783045
trainer/policy/mean Max                       0.999984
trainer/policy/mean Min                      -0.999948
trainer/policy/normal/std Mean                0.457009
trainer/policy/normal/std Std                 0.133004
trainer/policy/normal/std Max                 0.968019
trainer/policy/normal/std Min                 0.0969969
trainer/policy/normal/log_std Mean           -0.834188
trainer/policy/normal/log_std Std             0.34119
trainer/policy/normal/log_std Max            -0.0325039
trainer/policy/normal/log_std Min            -2.33308
trainer/Alpha                                 0.0965434
trainer/Alpha Loss                            0.597759
expl/num steps total                     133000
expl/num paths total                        133
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.50195
expl/Rewards Std                              1.14385
expl/Rewards Max                              6.90488
expl/Rewards Min                             -0.680703
expl/Returns Mean                          4501.95
expl/Returns Std                              0
expl/Returns Max                           4501.95
expl/Returns Min                           4501.95
expl/Actions Mean                             0.05758
expl/Actions Std                              0.834075
expl/Actions Max                              0.999569
expl/Actions Min                             -0.999874
expl/Num Paths                                1
expl/Average Returns                       4501.95
expl/env_infos/final/reward_run Mean          5.41886
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.41886
expl/env_infos/final/reward_run Min           5.41886
expl/env_infos/initial/reward_run Mean       -0.285534
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.285534
expl/env_infos/initial/reward_run Min        -0.285534
expl/env_infos/reward_run Mean                4.92135
expl/env_infos/reward_run Std                 1.14359
expl/env_infos/reward_run Max                 7.34786
expl/env_infos/reward_run Min                -0.363826
expl/env_infos/final/reward_ctrl Mean        -0.402512
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.402512
expl/env_infos/final/reward_ctrl Min         -0.402512
expl/env_infos/initial/reward_ctrl Mean      -0.283595
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.283595
expl/env_infos/initial/reward_ctrl Min       -0.283595
expl/env_infos/reward_ctrl Mean              -0.419398
expl/env_infos/reward_ctrl Std                0.0772212
expl/env_infos/reward_ctrl Max               -0.131342
expl/env_infos/reward_ctrl Min               -0.579469
eval/num steps total                     660000
eval/num paths total                        660
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.55155
eval/Rewards Std                              1.18931
eval/Rewards Max                              7.02534
eval/Rewards Min                             -0.979471
eval/Returns Mean                          4551.55
eval/Returns Std                             68.1999
eval/Returns Max                           4636.24
eval/Returns Min                           4487.02
eval/Actions Mean                             0.0688713
eval/Actions Std                              0.848048
eval/Actions Max                              0.998587
eval/Actions Min                             -0.99831
eval/Num Paths                                5
eval/Average Returns                       4551.55
eval/env_infos/final/reward_run Mean          4.9811
eval/env_infos/final/reward_run Std           0.805793
eval/env_infos/final/reward_run Max           5.78418
eval/env_infos/final/reward_run Min           3.88627
eval/env_infos/initial/reward_run Mean       -0.37669
eval/env_infos/initial/reward_run Std         0.246698
eval/env_infos/initial/reward_run Max        -0.00509687
eval/env_infos/initial/reward_run Min        -0.682228
eval/env_infos/reward_run Mean                4.98591
eval/env_infos/reward_run Std                 1.19223
eval/env_infos/reward_run Max                 7.51252
eval/env_infos/reward_run Min                -0.682228
eval/env_infos/final/reward_ctrl Mean        -0.425254
eval/env_infos/final/reward_ctrl Std          0.103332
eval/env_infos/final/reward_ctrl Max         -0.317032
eval/env_infos/final/reward_ctrl Min         -0.568963
eval/env_infos/initial/reward_ctrl Mean      -0.252581
eval/env_infos/initial/reward_ctrl Std        0.0752786
eval/env_infos/initial/reward_ctrl Max       -0.170225
eval/env_infos/initial/reward_ctrl Min       -0.369804
eval/env_infos/reward_ctrl Mean              -0.434357
eval/env_infos/reward_ctrl Std                0.0706071
eval/env_infos/reward_ctrl Max               -0.134318
eval/env_infos/reward_ctrl Min               -0.577852
time/data storing (s)                         0.00455527
time/evaluation sampling (s)                  2.05396
time/exploration sampling (s)                 0.543553
time/logging (s)                              0.0143524
time/sac training (s)                         7.99105
time/saving (s)                               0.00388858
time/training (s)                             4.3481e-05
time/epoch (s)                               10.6114
time/total (s)                             1416.32
Epoch                                       131
---------------------------------------  ---------------
2021-11-24 00:52:59.348555 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 132 finished
---------------------------------------  ---------------
epoch                                       132
replay_buffer/size                       134000
trainer/num train calls                  133000
trainer/QF1 Loss                              9.82226
trainer/QF2 Loss                              8.09419
trainer/Policy Loss                        -235.774
trainer/Q1 Predictions Mean                 236.202
trainer/Q1 Predictions Std                  109.426
trainer/Q1 Predictions Max                  335.707
trainer/Q1 Predictions Min                   11.0364
trainer/Q2 Predictions Mean                 236.18
trainer/Q2 Predictions Std                  109.518
trainer/Q2 Predictions Max                  337.107
trainer/Q2 Predictions Min                   10.6388
trainer/Q Targets Mean                      236.124
trainer/Q Targets Std                       109.397
trainer/Q Targets Max                       338.208
trainer/Q Targets Min                        11.1096
trainer/Log Pis Mean                          5.41403
trainer/Log Pis Std                           5.35916
trainer/Log Pis Max                          20.6202
trainer/Log Pis Min                          -5.76107
trainer/policy/mean Mean                      0.0107101
trainer/policy/mean Std                       0.764846
trainer/policy/mean Max                       0.999179
trainer/policy/mean Min                      -0.999288
trainer/policy/normal/std Mean                0.469626
trainer/policy/normal/std Std                 0.146121
trainer/policy/normal/std Max                 0.917064
trainer/policy/normal/std Min                 0.0957639
trainer/policy/normal/log_std Mean           -0.811312
trainer/policy/normal/log_std Std             0.350275
trainer/policy/normal/log_std Max            -0.0865782
trainer/policy/normal/log_std Min            -2.34587
trainer/Alpha                                 0.0957488
trainer/Alpha Loss                           -1.37469
expl/num steps total                     134000
expl/num paths total                        134
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.47591
expl/Rewards Std                              1.15193
expl/Rewards Max                              6.72144
expl/Rewards Min                             -0.69841
expl/Returns Mean                          4475.91
expl/Returns Std                              0
expl/Returns Max                           4475.91
expl/Returns Min                           4475.91
expl/Actions Mean                             0.050843
expl/Actions Std                              0.835291
expl/Actions Max                              0.999908
expl/Actions Min                             -0.999678
expl/Num Paths                                1
expl/Average Returns                       4475.91
expl/env_infos/final/reward_run Mean          4.80302
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.80302
expl/env_infos/final/reward_run Min           4.80302
expl/env_infos/initial/reward_run Mean       -0.459628
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.459628
expl/env_infos/initial/reward_run Min        -0.459628
expl/env_infos/reward_run Mean                4.89609
expl/env_infos/reward_run Std                 1.14368
expl/env_infos/reward_run Max                 7.24885
expl/env_infos/reward_run Min                -0.459628
expl/env_infos/final/reward_ctrl Mean        -0.484275
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.484275
expl/env_infos/final/reward_ctrl Min         -0.484275
expl/env_infos/initial/reward_ctrl Mean      -0.238782
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.238782
expl/env_infos/initial/reward_ctrl Min       -0.238782
expl/env_infos/reward_ctrl Mean              -0.420178
expl/env_infos/reward_ctrl Std                0.0828256
expl/env_infos/reward_ctrl Max               -0.149866
expl/env_infos/reward_ctrl Min               -0.583389
eval/num steps total                     665000
eval/num paths total                        665
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.71936
eval/Rewards Std                              1.1958
eval/Rewards Max                              7.23611
eval/Rewards Min                             -1.14975
eval/Returns Mean                          4719.36
eval/Returns Std                             82.9948
eval/Returns Max                           4812.06
eval/Returns Min                           4605.21
eval/Actions Mean                             0.0527141
eval/Actions Std                              0.844901
eval/Actions Max                              0.999831
eval/Actions Min                             -0.999429
eval/Num Paths                                5
eval/Average Returns                       4719.36
eval/env_infos/final/reward_run Mean          5.33253
eval/env_infos/final/reward_run Std           1.62928
eval/env_infos/final/reward_run Max           6.70748
eval/env_infos/final/reward_run Min           2.40969
eval/env_infos/initial/reward_run Mean       -0.552369
eval/env_infos/initial/reward_run Std         0.209156
eval/env_infos/initial/reward_run Max        -0.263757
eval/env_infos/initial/reward_run Min        -0.730691
eval/env_infos/reward_run Mean                5.14935
eval/env_infos/reward_run Std                 1.18782
eval/env_infos/reward_run Max                 7.77127
eval/env_infos/reward_run Min                -0.730691
eval/env_infos/final/reward_ctrl Mean        -0.350392
eval/env_infos/final/reward_ctrl Std          0.111738
eval/env_infos/final/reward_ctrl Max         -0.180426
eval/env_infos/final/reward_ctrl Min         -0.491563
eval/env_infos/initial/reward_ctrl Mean      -0.32032
eval/env_infos/initial/reward_ctrl Std        0.0641272
eval/env_infos/initial/reward_ctrl Max       -0.248676
eval/env_infos/initial/reward_ctrl Min       -0.420715
eval/env_infos/reward_ctrl Mean              -0.429982
eval/env_infos/reward_ctrl Std                0.0779403
eval/env_infos/reward_ctrl Max               -0.125442
eval/env_infos/reward_ctrl Min               -0.586373
time/data storing (s)                         0.00449969
time/evaluation sampling (s)                  2.04388
time/exploration sampling (s)                 0.582147
time/logging (s)                              0.0139464
time/sac training (s)                         7.92378
time/saving (s)                               0.00383296
time/training (s)                             3.4925e-05
time/epoch (s)                               10.5721
time/total (s)                             1427.22
Epoch                                       132
---------------------------------------  ---------------
2021-11-24 00:53:10.273665 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 133 finished
---------------------------------------  ---------------
epoch                                       133
replay_buffer/size                       135000
trainer/num train calls                  134000
trainer/QF1 Loss                              7.76348
trainer/QF2 Loss                              5.76303
trainer/Policy Loss                        -237.594
trainer/Q1 Predictions Mean                 237.612
trainer/Q1 Predictions Std                  106.403
trainer/Q1 Predictions Max                  335.296
trainer/Q1 Predictions Min                   11.3024
trainer/Q2 Predictions Mean                 238.221
trainer/Q2 Predictions Std                  106.652
trainer/Q2 Predictions Max                  337.067
trainer/Q2 Predictions Min                   11.4988
trainer/Q Targets Mean                      237.729
trainer/Q Targets Std                       106.547
trainer/Q Targets Max                       338.763
trainer/Q Targets Min                        10.8254
trainer/Log Pis Mean                          5.83016
trainer/Log Pis Std                           5.3732
trainer/Log Pis Max                          19.5874
trainer/Log Pis Min                          -6.00705
trainer/policy/mean Mean                      0.0225714
trainer/policy/mean Std                       0.769173
trainer/policy/mean Max                       0.998451
trainer/policy/mean Min                      -0.999849
trainer/policy/normal/std Mean                0.476318
trainer/policy/normal/std Std                 0.145636
trainer/policy/normal/std Max                 1.05806
trainer/policy/normal/std Min                 0.113197
trainer/policy/normal/log_std Mean           -0.79645
trainer/policy/normal/log_std Std             0.350245
trainer/policy/normal/log_std Max             0.05644
trainer/policy/normal/log_std Min            -2.17862
trainer/Alpha                                 0.0974033
trainer/Alpha Loss                           -0.395537
expl/num steps total                     135000
expl/num paths total                        135
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.49437
expl/Rewards Std                              1.25474
expl/Rewards Max                              6.83175
expl/Rewards Min                             -1.10921
expl/Returns Mean                          4494.37
expl/Returns Std                              0
expl/Returns Max                           4494.37
expl/Returns Min                           4494.37
expl/Actions Mean                             0.0337086
expl/Actions Std                              0.833039
expl/Actions Max                              0.999536
expl/Actions Min                             -0.999887
expl/Num Paths                                1
expl/Average Returns                       4494.37
expl/env_infos/final/reward_run Mean          6.16027
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.16027
expl/env_infos/final/reward_run Min           6.16027
expl/env_infos/initial/reward_run Mean       -0.784531
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.784531
expl/env_infos/initial/reward_run Min        -0.784531
expl/env_infos/reward_run Mean                4.91143
expl/env_infos/reward_run Std                 1.25391
expl/env_infos/reward_run Max                 7.29816
expl/env_infos/reward_run Min                -0.784531
expl/env_infos/final/reward_ctrl Mean        -0.408972
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.408972
expl/env_infos/final/reward_ctrl Min         -0.408972
expl/env_infos/initial/reward_ctrl Mean      -0.324683
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.324683
expl/env_infos/initial/reward_ctrl Min       -0.324683
expl/env_infos/reward_ctrl Mean              -0.417055
expl/env_infos/reward_ctrl Std                0.0791547
expl/env_infos/reward_ctrl Max               -0.110098
expl/env_infos/reward_ctrl Min               -0.572475
eval/num steps total                     670000
eval/num paths total                        670
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.92279
eval/Rewards Std                              1.3137
eval/Rewards Max                              7.69706
eval/Rewards Min                             -1.09754
eval/Returns Mean                          4922.79
eval/Returns Std                            139.249
eval/Returns Max                           5081.43
eval/Returns Min                           4708.84
eval/Actions Mean                             0.0306978
eval/Actions Std                              0.849423
eval/Actions Max                              0.998656
eval/Actions Min                             -0.998969
eval/Num Paths                                5
eval/Average Returns                       4922.79
eval/env_infos/final/reward_run Mean          5.18839
eval/env_infos/final/reward_run Std           0.669322
eval/env_infos/final/reward_run Max           6.21157
eval/env_infos/final/reward_run Min           4.53995
eval/env_infos/initial/reward_run Mean       -0.567809
eval/env_infos/initial/reward_run Std         0.0991649
eval/env_infos/initial/reward_run Max        -0.40422
eval/env_infos/initial/reward_run Min        -0.712957
eval/env_infos/reward_run Mean                5.35627
eval/env_infos/reward_run Std                 1.30934
eval/env_infos/reward_run Max                 8.21517
eval/env_infos/reward_run Min                -0.712957
eval/env_infos/final/reward_ctrl Mean        -0.463047
eval/env_infos/final/reward_ctrl Std          0.107743
eval/env_infos/final/reward_ctrl Max         -0.306127
eval/env_infos/final/reward_ctrl Min         -0.558677
eval/env_infos/initial/reward_ctrl Mean      -0.354026
eval/env_infos/initial/reward_ctrl Std        0.031737
eval/env_infos/initial/reward_ctrl Max       -0.308025
eval/env_infos/initial/reward_ctrl Min       -0.38704
eval/env_infos/reward_ctrl Mean              -0.433477
eval/env_infos/reward_ctrl Std                0.0716599
eval/env_infos/reward_ctrl Max               -0.0825809
eval/env_infos/reward_ctrl Min               -0.575213
time/data storing (s)                         0.00461515
time/evaluation sampling (s)                  2.04662
time/exploration sampling (s)                 0.527563
time/logging (s)                              0.0143159
time/sac training (s)                         7.984
time/saving (s)                               0.00394567
time/training (s)                             4.9824e-05
time/epoch (s)                               10.5811
time/total (s)                             1438.13
Epoch                                       133
---------------------------------------  ---------------
2021-11-24 00:53:21.235545 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 134 finished
---------------------------------------  ---------------
epoch                                       134
replay_buffer/size                       136000
trainer/num train calls                  135000
trainer/QF1 Loss                              8.01655
trainer/QF2 Loss                              6.219
trainer/Policy Loss                        -236.281
trainer/Q1 Predictions Mean                 236.939
trainer/Q1 Predictions Std                  110.63
trainer/Q1 Predictions Max                  337.625
trainer/Q1 Predictions Min                   10.8453
trainer/Q2 Predictions Mean                 236.666
trainer/Q2 Predictions Std                  110.497
trainer/Q2 Predictions Max                  337.583
trainer/Q2 Predictions Min                   11.194
trainer/Q Targets Mean                      236.729
trainer/Q Targets Std                       110.466
trainer/Q Targets Max                       338.294
trainer/Q Targets Min                        11.2013
trainer/Log Pis Mean                          5.32466
trainer/Log Pis Std                           4.95828
trainer/Log Pis Max                          17.5977
trainer/Log Pis Min                          -4.00263
trainer/policy/mean Mean                      0.0387431
trainer/policy/mean Std                       0.757229
trainer/policy/mean Max                       0.997876
trainer/policy/mean Min                      -0.999581
trainer/policy/normal/std Mean                0.467293
trainer/policy/normal/std Std                 0.146221
trainer/policy/normal/std Max                 0.949852
trainer/policy/normal/std Min                 0.118087
trainer/policy/normal/log_std Mean           -0.818222
trainer/policy/normal/log_std Std             0.358598
trainer/policy/normal/log_std Max            -0.0514495
trainer/policy/normal/log_std Min            -2.13633
trainer/Alpha                                 0.0964708
trainer/Alpha Loss                           -1.5793
expl/num steps total                     136000
expl/num paths total                        136
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.63144
expl/Rewards Std                              1.14746
expl/Rewards Max                              6.75394
expl/Rewards Min                             -0.805644
expl/Returns Mean                          4631.44
expl/Returns Std                              0
expl/Returns Max                           4631.44
expl/Returns Min                           4631.44
expl/Actions Mean                             0.0545744
expl/Actions Std                              0.827989
expl/Actions Max                              0.999614
expl/Actions Min                             -0.999725
expl/Num Paths                                1
expl/Average Returns                       4631.44
expl/env_infos/final/reward_run Mean          4.80232
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.80232
expl/env_infos/final/reward_run Min           4.80232
expl/env_infos/initial/reward_run Mean       -0.619698
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.619698
expl/env_infos/initial/reward_run Min        -0.619698
expl/env_infos/reward_run Mean                5.04456
expl/env_infos/reward_run Std                 1.14035
expl/env_infos/reward_run Max                 7.24072
expl/env_infos/reward_run Min                -0.619698
expl/env_infos/final/reward_ctrl Mean        -0.464455
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.464455
expl/env_infos/final/reward_ctrl Min         -0.464455
expl/env_infos/initial/reward_ctrl Mean      -0.185946
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.185946
expl/env_infos/initial/reward_ctrl Min       -0.185946
expl/env_infos/reward_ctrl Mean              -0.413126
expl/env_infos/reward_ctrl Std                0.0776203
expl/env_infos/reward_ctrl Max               -0.163233
expl/env_infos/reward_ctrl Min               -0.578852
eval/num steps total                     675000
eval/num paths total                        675
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.84303
eval/Rewards Std                              1.24527
eval/Rewards Max                              7.42231
eval/Rewards Min                             -1.18145
eval/Returns Mean                          4843.03
eval/Returns Std                             81.1196
eval/Returns Max                           4959.96
eval/Returns Min                           4715.3
eval/Actions Mean                             0.0536363
eval/Actions Std                              0.847138
eval/Actions Max                              0.999805
eval/Actions Min                             -0.998539
eval/Num Paths                                5
eval/Average Returns                       4843.03
eval/env_infos/final/reward_run Mean          6.01197
eval/env_infos/final/reward_run Std           0.649133
eval/env_infos/final/reward_run Max           6.60283
eval/env_infos/final/reward_run Min           4.76459
eval/env_infos/initial/reward_run Mean       -0.371724
eval/env_infos/initial/reward_run Std         0.280039
eval/env_infos/initial/reward_run Max        -0.0192654
eval/env_infos/initial/reward_run Min        -0.775443
eval/env_infos/reward_run Mean                5.27535
eval/env_infos/reward_run Std                 1.23541
eval/env_infos/reward_run Max                 7.93893
eval/env_infos/reward_run Min                -0.775443
eval/env_infos/final/reward_ctrl Mean        -0.423105
eval/env_infos/final/reward_ctrl Std          0.0522008
eval/env_infos/final/reward_ctrl Max         -0.367942
eval/env_infos/final/reward_ctrl Min         -0.507992
eval/env_infos/initial/reward_ctrl Mean      -0.279518
eval/env_infos/initial/reward_ctrl Std        0.087519
eval/env_infos/initial/reward_ctrl Max       -0.170226
eval/env_infos/initial/reward_ctrl Min       -0.40601
eval/env_infos/reward_ctrl Mean              -0.432311
eval/env_infos/reward_ctrl Std                0.0714238
eval/env_infos/reward_ctrl Max               -0.140141
eval/env_infos/reward_ctrl Min               -0.579805
time/data storing (s)                         0.00453726
time/evaluation sampling (s)                  2.08708
time/exploration sampling (s)                 0.546297
time/logging (s)                              0.0135664
time/sac training (s)                         7.96245
time/saving (s)                               0.00379708
time/training (s)                             3.439e-05
time/epoch (s)                               10.6178
time/total (s)                             1449.07
Epoch                                       134
---------------------------------------  ---------------
2021-11-24 00:53:31.882297 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 135 finished
---------------------------------------  ---------------
epoch                                       135
replay_buffer/size                       137000
trainer/num train calls                  136000
trainer/QF1 Loss                              7.93529
trainer/QF2 Loss                              7.79917
trainer/Policy Loss                        -244.257
trainer/Q1 Predictions Mean                 244.512
trainer/Q1 Predictions Std                  105.319
trainer/Q1 Predictions Max                  338.229
trainer/Q1 Predictions Min                   11.6966
trainer/Q2 Predictions Mean                 244.684
trainer/Q2 Predictions Std                  105.184
trainer/Q2 Predictions Max                  336.74
trainer/Q2 Predictions Min                   11.1997
trainer/Q Targets Mean                      244.168
trainer/Q Targets Std                       105.194
trainer/Q Targets Max                       337.896
trainer/Q Targets Min                        10.2705
trainer/Log Pis Mean                          6.09409
trainer/Log Pis Std                           5.29867
trainer/Log Pis Max                          18.021
trainer/Log Pis Min                          -6.03586
trainer/policy/mean Mean                      0.0473141
trainer/policy/mean Std                       0.774382
trainer/policy/mean Max                       0.998876
trainer/policy/mean Min                      -0.997121
trainer/policy/normal/std Mean                0.462023
trainer/policy/normal/std Std                 0.139779
trainer/policy/normal/std Max                 1.00512
trainer/policy/normal/std Min                 0.109354
trainer/policy/normal/log_std Mean           -0.825568
trainer/policy/normal/log_std Std             0.345443
trainer/policy/normal/log_std Max             0.00510318
trainer/policy/normal/log_std Min            -2.21316
trainer/Alpha                                 0.0970339
trainer/Alpha Loss                            0.219494
expl/num steps total                     137000
expl/num paths total                        137
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.73222
expl/Rewards Std                              1.14825
expl/Rewards Max                              6.85329
expl/Rewards Min                             -0.793549
expl/Returns Mean                          4732.22
expl/Returns Std                              0
expl/Returns Max                           4732.22
expl/Returns Min                           4732.22
expl/Actions Mean                             0.0424449
expl/Actions Std                              0.829775
expl/Actions Max                              0.99949
expl/Actions Min                             -0.999299
expl/Num Paths                                1
expl/Average Returns                       4732.22
expl/env_infos/final/reward_run Mean          5.16486
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.16486
expl/env_infos/final/reward_run Min           5.16486
expl/env_infos/initial/reward_run Mean       -0.519002
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.519002
expl/env_infos/initial/reward_run Min        -0.519002
expl/env_infos/reward_run Mean                5.14641
expl/env_infos/reward_run Std                 1.13589
expl/env_infos/reward_run Max                 7.24558
expl/env_infos/reward_run Min                -0.519002
expl/env_infos/final/reward_ctrl Mean        -0.434569
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.434569
expl/env_infos/final/reward_ctrl Min         -0.434569
expl/env_infos/initial/reward_ctrl Mean      -0.274546
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.274546
expl/env_infos/initial/reward_ctrl Min       -0.274546
expl/env_infos/reward_ctrl Mean              -0.414197
expl/env_infos/reward_ctrl Std                0.0831476
expl/env_infos/reward_ctrl Max               -0.0658658
expl/env_infos/reward_ctrl Min               -0.590475
eval/num steps total                     680000
eval/num paths total                        680
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.80952
eval/Rewards Std                              1.22115
eval/Rewards Max                              7.26137
eval/Rewards Min                             -0.970945
eval/Returns Mean                          4809.52
eval/Returns Std                             13.6892
eval/Returns Max                           4833.89
eval/Returns Min                           4795.91
eval/Actions Mean                             0.0492258
eval/Actions Std                              0.840209
eval/Actions Max                              0.999845
eval/Actions Min                             -0.998242
eval/Num Paths                                5
eval/Average Returns                       4809.52
eval/env_infos/final/reward_run Mean          5.45093
eval/env_infos/final/reward_run Std           0.749688
eval/env_infos/final/reward_run Max           6.3932
eval/env_infos/final/reward_run Min           4.48988
eval/env_infos/initial/reward_run Mean       -0.516298
eval/env_infos/initial/reward_run Std         0.0801854
eval/env_infos/initial/reward_run Max        -0.434297
eval/env_infos/initial/reward_run Min        -0.635415
eval/env_infos/reward_run Mean                5.23454
eval/env_infos/reward_run Std                 1.21051
eval/env_infos/reward_run Max                 7.78147
eval/env_infos/reward_run Min                -0.635415
eval/env_infos/final/reward_ctrl Mean        -0.448012
eval/env_infos/final/reward_ctrl Std          0.0727894
eval/env_infos/final/reward_ctrl Max         -0.359002
eval/env_infos/final/reward_ctrl Min         -0.580463
eval/env_infos/initial/reward_ctrl Mean      -0.32421
eval/env_infos/initial/reward_ctrl Std        0.0514689
eval/env_infos/initial/reward_ctrl Max       -0.253217
eval/env_infos/initial/reward_ctrl Min       -0.411589
eval/env_infos/reward_ctrl Mean              -0.425024
eval/env_infos/reward_ctrl Std                0.0789643
eval/env_infos/reward_ctrl Max               -0.134159
eval/env_infos/reward_ctrl Min               -0.58273
time/data storing (s)                         0.00449258
time/evaluation sampling (s)                  2.018
time/exploration sampling (s)                 0.535103
time/logging (s)                              0.0140605
time/sac training (s)                         7.73791
time/saving (s)                               0.00392787
time/training (s)                             4.0325e-05
time/epoch (s)                               10.3135
time/total (s)                             1459.7
Epoch                                       135
---------------------------------------  ---------------
2021-11-24 00:53:42.631594 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 136 finished
---------------------------------------  ---------------
epoch                                       136
replay_buffer/size                       138000
trainer/num train calls                  137000
trainer/QF1 Loss                              8.21359
trainer/QF2 Loss                              7.48058
trainer/Policy Loss                        -247.424
trainer/Q1 Predictions Mean                 247.87
trainer/Q1 Predictions Std                  104.321
trainer/Q1 Predictions Max                  343.093
trainer/Q1 Predictions Min                   10.5594
trainer/Q2 Predictions Mean                 247.822
trainer/Q2 Predictions Std                  104.231
trainer/Q2 Predictions Max                  344.007
trainer/Q2 Predictions Min                   10.1561
trainer/Q Targets Mean                      248.378
trainer/Q Targets Std                       104.516
trainer/Q Targets Max                       347.398
trainer/Q Targets Min                         9.82391
trainer/Log Pis Mean                          5.86528
trainer/Log Pis Std                           4.72308
trainer/Log Pis Max                          19.7107
trainer/Log Pis Min                          -6.24751
trainer/policy/mean Mean                      0.0296467
trainer/policy/mean Std                       0.770804
trainer/policy/mean Max                       0.999489
trainer/policy/mean Min                      -0.99917
trainer/policy/normal/std Mean                0.463778
trainer/policy/normal/std Std                 0.145798
trainer/policy/normal/std Max                 1.34548
trainer/policy/normal/std Min                 0.117175
trainer/policy/normal/log_std Mean           -0.82542
trainer/policy/normal/log_std Std             0.356463
trainer/policy/normal/log_std Max             0.296752
trainer/policy/normal/log_std Min            -2.14409
trainer/Alpha                                 0.0972353
trainer/Alpha Loss                           -0.313985
expl/num steps total                     138000
expl/num paths total                        138
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.6463
expl/Rewards Std                              1.20349
expl/Rewards Max                              7.14347
expl/Rewards Min                             -0.573038
expl/Returns Mean                          4646.3
expl/Returns Std                              0
expl/Returns Max                           4646.3
expl/Returns Min                           4646.3
expl/Actions Mean                             0.0549774
expl/Actions Std                              0.826081
expl/Actions Max                              0.999832
expl/Actions Min                             -0.999637
expl/Num Paths                                1
expl/Average Returns                       4646.3
expl/env_infos/final/reward_run Mean          3.80283
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.80283
expl/env_infos/final/reward_run Min           3.80283
expl/env_infos/initial/reward_run Mean       -0.220866
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.220866
expl/env_infos/initial/reward_run Min        -0.220866
expl/env_infos/reward_run Mean                5.05756
expl/env_infos/reward_run Std                 1.19816
expl/env_infos/reward_run Max                 7.62026
expl/env_infos/reward_run Min                -0.220866
expl/env_infos/final/reward_ctrl Mean        -0.394599
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.394599
expl/env_infos/final/reward_ctrl Min         -0.394599
expl/env_infos/initial/reward_ctrl Mean      -0.352172
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.352172
expl/env_infos/initial/reward_ctrl Min       -0.352172
expl/env_infos/reward_ctrl Mean              -0.41126
expl/env_infos/reward_ctrl Std                0.0823382
expl/env_infos/reward_ctrl Max               -0.101828
expl/env_infos/reward_ctrl Min               -0.58784
eval/num steps total                     685000
eval/num paths total                        685
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.7737
eval/Rewards Std                              1.18996
eval/Rewards Max                              7.34039
eval/Rewards Min                             -0.952375
eval/Returns Mean                          4773.7
eval/Returns Std                             58.7133
eval/Returns Max                           4869.86
eval/Returns Min                           4705.63
eval/Actions Mean                             0.0586681
eval/Actions Std                              0.840713
eval/Actions Max                              0.99871
eval/Actions Min                             -0.998079
eval/Num Paths                                5
eval/Average Returns                       4773.7
eval/env_infos/final/reward_run Mean          5.1495
eval/env_infos/final/reward_run Std           1.13626
eval/env_infos/final/reward_run Max           6.65498
eval/env_infos/final/reward_run Min           3.33783
eval/env_infos/initial/reward_run Mean       -0.39588
eval/env_infos/initial/reward_run Std         0.13339
eval/env_infos/initial/reward_run Max        -0.213903
eval/env_infos/initial/reward_run Min        -0.583837
eval/env_infos/reward_run Mean                5.19984
eval/env_infos/reward_run Std                 1.18417
eval/env_infos/reward_run Max                 7.88373
eval/env_infos/reward_run Min                -0.583837
eval/env_infos/final/reward_ctrl Mean        -0.457591
eval/env_infos/final/reward_ctrl Std          0.0794812
eval/env_infos/final/reward_ctrl Max         -0.343824
eval/env_infos/final/reward_ctrl Min         -0.55309
eval/env_infos/initial/reward_ctrl Mean      -0.301072
eval/env_infos/initial/reward_ctrl Std        0.0528499
eval/env_infos/initial/reward_ctrl Max       -0.245224
eval/env_infos/initial/reward_ctrl Min       -0.368539
eval/env_infos/reward_ctrl Mean              -0.426145
eval/env_infos/reward_ctrl Std                0.0765855
eval/env_infos/reward_ctrl Max               -0.120661
eval/env_infos/reward_ctrl Min               -0.581292
time/data storing (s)                         0.00448815
time/evaluation sampling (s)                  2.04755
time/exploration sampling (s)                 0.536757
time/logging (s)                              0.0143754
time/sac training (s)                         7.80569
time/saving (s)                               0.00385551
time/training (s)                             4.5052e-05
time/epoch (s)                               10.4128
time/total (s)                             1470.44
Epoch                                       136
---------------------------------------  ---------------
2021-11-24 00:53:53.255031 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 137 finished
---------------------------------------  ---------------
epoch                                       137
replay_buffer/size                       139000
trainer/num train calls                  138000
trainer/QF1 Loss                              9.7354
trainer/QF2 Loss                              9.62231
trainer/Policy Loss                        -252.134
trainer/Q1 Predictions Mean                 252.634
trainer/Q1 Predictions Std                   98.449
trainer/Q1 Predictions Max                  330.396
trainer/Q1 Predictions Min                   11.2789
trainer/Q2 Predictions Mean                 252.802
trainer/Q2 Predictions Std                   98.4882
trainer/Q2 Predictions Max                  332.267
trainer/Q2 Predictions Min                   11.281
trainer/Q Targets Mean                      253.663
trainer/Q Targets Std                        99.0681
trainer/Q Targets Max                       334.667
trainer/Q Targets Min                        10.1761
trainer/Log Pis Mean                          6.1329
trainer/Log Pis Std                           4.95727
trainer/Log Pis Max                          18.0281
trainer/Log Pis Min                          -5.70038
trainer/policy/mean Mean                      0.0365365
trainer/policy/mean Std                       0.780864
trainer/policy/mean Max                       0.998394
trainer/policy/mean Min                      -0.996532
trainer/policy/normal/std Mean                0.457296
trainer/policy/normal/std Std                 0.137865
trainer/policy/normal/std Max                 1.01224
trainer/policy/normal/std Min                 0.0970166
trainer/policy/normal/log_std Mean           -0.835394
trainer/policy/normal/log_std Std             0.344398
trainer/policy/normal/log_std Max             0.0121655
trainer/policy/normal/log_std Min            -2.33287
trainer/Alpha                                 0.0992089
trainer/Alpha Loss                            0.307069
expl/num steps total                     139000
expl/num paths total                        139
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.51522
expl/Rewards Std                              1.15315
expl/Rewards Max                              6.67577
expl/Rewards Min                             -0.645781
expl/Returns Mean                          4515.22
expl/Returns Std                              0
expl/Returns Max                           4515.22
expl/Returns Min                           4515.22
expl/Actions Mean                             0.052429
expl/Actions Std                              0.828357
expl/Actions Max                              0.999634
expl/Actions Min                             -0.999635
expl/Num Paths                                1
expl/Average Returns                       4515.22
expl/env_infos/final/reward_run Mean          3.84394
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.84394
expl/env_infos/final/reward_run Min           3.84394
expl/env_infos/initial/reward_run Mean       -0.333989
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.333989
expl/env_infos/initial/reward_run Min        -0.333989
expl/env_infos/reward_run Mean                4.92857
expl/env_infos/reward_run Std                 1.14915
expl/env_infos/reward_run Max                 7.16633
expl/env_infos/reward_run Min                -0.333989
expl/env_infos/final/reward_ctrl Mean        -0.235867
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.235867
expl/env_infos/final/reward_ctrl Min         -0.235867
expl/env_infos/initial/reward_ctrl Mean      -0.311792
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.311792
expl/env_infos/initial/reward_ctrl Min       -0.311792
expl/env_infos/reward_ctrl Mean              -0.413355
expl/env_infos/reward_ctrl Std                0.0760155
expl/env_infos/reward_ctrl Max               -0.130367
expl/env_infos/reward_ctrl Min               -0.582771
eval/num steps total                     690000
eval/num paths total                        690
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.84357
eval/Rewards Std                              1.19813
eval/Rewards Max                              7.57253
eval/Rewards Min                             -0.881021
eval/Returns Mean                          4843.57
eval/Returns Std                            102.257
eval/Returns Max                           4936.8
eval/Returns Min                           4693.03
eval/Actions Mean                             0.0586023
eval/Actions Std                              0.837674
eval/Actions Max                              0.999594
eval/Actions Min                             -0.999385
eval/Num Paths                                5
eval/Average Returns                       4843.57
eval/env_infos/final/reward_run Mean          5.0323
eval/env_infos/final/reward_run Std           1.12581
eval/env_infos/final/reward_run Max           6.24259
eval/env_infos/final/reward_run Min           3.47412
eval/env_infos/initial/reward_run Mean       -0.370175
eval/env_infos/initial/reward_run Std         0.164919
eval/env_infos/initial/reward_run Max        -0.124135
eval/env_infos/initial/reward_run Min        -0.546357
eval/env_infos/reward_run Mean                5.26665
eval/env_infos/reward_run Std                 1.19674
eval/env_infos/reward_run Max                 8.08316
eval/env_infos/reward_run Min                -0.546357
eval/env_infos/final/reward_ctrl Mean        -0.377534
eval/env_infos/final/reward_ctrl Std          0.0974814
eval/env_infos/final/reward_ctrl Max         -0.258776
eval/env_infos/final/reward_ctrl Min         -0.529485
eval/env_infos/initial/reward_ctrl Mean      -0.258856
eval/env_infos/initial/reward_ctrl Std        0.0580104
eval/env_infos/initial/reward_ctrl Max       -0.189858
eval/env_infos/initial/reward_ctrl Min       -0.334663
eval/env_infos/reward_ctrl Mean              -0.423079
eval/env_infos/reward_ctrl Std                0.0732261
eval/env_infos/reward_ctrl Max               -0.113362
eval/env_infos/reward_ctrl Min               -0.590565
time/data storing (s)                         0.00450625
time/evaluation sampling (s)                  1.9992
time/exploration sampling (s)                 0.534597
time/logging (s)                              0.0141172
time/sac training (s)                         7.73302
time/saving (s)                               0.00380395
time/training (s)                             3.4868e-05
time/epoch (s)                               10.2893
time/total (s)                             1481.05
Epoch                                       137
---------------------------------------  ---------------
2021-11-24 00:54:04.000646 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 138 finished
---------------------------------------  ---------------
epoch                                       138
replay_buffer/size                       140000
trainer/num train calls                  139000
trainer/QF1 Loss                              6.33711
trainer/QF2 Loss                              6.9464
trainer/Policy Loss                        -250.375
trainer/Q1 Predictions Mean                 250.55
trainer/Q1 Predictions Std                  105.879
trainer/Q1 Predictions Max                  342.297
trainer/Q1 Predictions Min                   10.5078
trainer/Q2 Predictions Mean                 250.656
trainer/Q2 Predictions Std                  105.942
trainer/Q2 Predictions Max                  343.396
trainer/Q2 Predictions Min                   11.4966
trainer/Q Targets Mean                      250.108
trainer/Q Targets Std                       105.718
trainer/Q Targets Max                       341.066
trainer/Q Targets Min                         9.25387
trainer/Log Pis Mean                          6.14277
trainer/Log Pis Std                           5.32871
trainer/Log Pis Max                          21.3034
trainer/Log Pis Min                          -5.50892
trainer/policy/mean Mean                      0.0403605
trainer/policy/mean Std                       0.771892
trainer/policy/mean Max                       0.999157
trainer/policy/mean Min                      -0.997834
trainer/policy/normal/std Mean                0.462456
trainer/policy/normal/std Std                 0.140898
trainer/policy/normal/std Max                 0.886277
trainer/policy/normal/std Min                 0.10224
trainer/policy/normal/log_std Mean           -0.825831
trainer/policy/normal/log_std Std             0.350042
trainer/policy/normal/log_std Max            -0.120726
trainer/policy/normal/log_std Min            -2.28043
trainer/Alpha                                 0.0983056
trainer/Alpha Loss                            0.33118
expl/num steps total                     140000
expl/num paths total                        140
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.67017
expl/Rewards Std                              1.14919
expl/Rewards Max                              6.83242
expl/Rewards Min                             -0.727015
expl/Returns Mean                          4670.17
expl/Returns Std                              0
expl/Returns Max                           4670.17
expl/Returns Min                           4670.17
expl/Actions Mean                             0.0200992
expl/Actions Std                              0.825517
expl/Actions Max                              0.999974
expl/Actions Min                             -0.999675
expl/Num Paths                                1
expl/Average Returns                       4670.17
expl/env_infos/final/reward_run Mean          5.33404
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.33404
expl/env_infos/final/reward_run Min           5.33404
expl/env_infos/initial/reward_run Mean       -0.39103
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.39103
expl/env_infos/initial/reward_run Min        -0.39103
expl/env_infos/reward_run Mean                5.0793
expl/env_infos/reward_run Std                 1.13801
expl/env_infos/reward_run Max                 7.3496
expl/env_infos/reward_run Min                -0.39103
expl/env_infos/final/reward_ctrl Mean        -0.273644
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.273644
expl/env_infos/final/reward_ctrl Min         -0.273644
expl/env_infos/initial/reward_ctrl Mean      -0.335985
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.335985
expl/env_infos/initial/reward_ctrl Min       -0.335985
expl/env_infos/reward_ctrl Mean              -0.409129
expl/env_infos/reward_ctrl Std                0.0845226
expl/env_infos/reward_ctrl Max               -0.161517
expl/env_infos/reward_ctrl Min               -0.58297
eval/num steps total                     695000
eval/num paths total                        695
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.89913
eval/Rewards Std                              1.18902
eval/Rewards Max                              7.26452
eval/Rewards Min                             -1.0725
eval/Returns Mean                          4899.13
eval/Returns Std                             87.3218
eval/Returns Max                           5016.6
eval/Returns Min                           4746.2
eval/Actions Mean                             0.0315573
eval/Actions Std                              0.842048
eval/Actions Max                              0.999934
eval/Actions Min                             -0.998861
eval/Num Paths                                5
eval/Average Returns                       4899.13
eval/env_infos/final/reward_run Mean          5.10155
eval/env_infos/final/reward_run Std           1.0258
eval/env_infos/final/reward_run Max           6.51756
eval/env_infos/final/reward_run Min           3.92505
eval/env_infos/initial/reward_run Mean       -0.272874
eval/env_infos/initial/reward_run Std         0.287635
eval/env_infos/initial/reward_run Max         0.094015
eval/env_infos/initial/reward_run Min        -0.700096
eval/env_infos/reward_run Mean                5.32515
eval/env_infos/reward_run Std                 1.17824
eval/env_infos/reward_run Max                 7.78321
eval/env_infos/reward_run Min                -0.700096
eval/env_infos/final/reward_ctrl Mean        -0.420241
eval/env_infos/final/reward_ctrl Std          0.0679365
eval/env_infos/final/reward_ctrl Max         -0.353071
eval/env_infos/final/reward_ctrl Min         -0.506838
eval/env_infos/initial/reward_ctrl Mean      -0.260547
eval/env_infos/initial/reward_ctrl Std        0.0878775
eval/env_infos/initial/reward_ctrl Max       -0.182502
eval/env_infos/initial/reward_ctrl Min       -0.372402
eval/env_infos/reward_ctrl Mean              -0.426024
eval/env_infos/reward_ctrl Std                0.0782343
eval/env_infos/reward_ctrl Max               -0.0702929
eval/env_infos/reward_ctrl Min               -0.578852
time/data storing (s)                         0.00498411
time/evaluation sampling (s)                  2.0095
time/exploration sampling (s)                 0.534457
time/logging (s)                              0.0147185
time/sac training (s)                         7.83986
time/saving (s)                               0.00398577
time/training (s)                             4.257e-05
time/epoch (s)                               10.4076
time/total (s)                             1491.78
Epoch                                       138
---------------------------------------  ---------------
2021-11-24 00:54:14.746836 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 139 finished
---------------------------------------  ---------------
epoch                                       139
replay_buffer/size                       141000
trainer/num train calls                  140000
trainer/QF1 Loss                              8.07072
trainer/QF2 Loss                              6.27848
trainer/Policy Loss                        -247.675
trainer/Q1 Predictions Mean                 248.202
trainer/Q1 Predictions Std                  106.902
trainer/Q1 Predictions Max                  342.197
trainer/Q1 Predictions Min                   12.0993
trainer/Q2 Predictions Mean                 248.435
trainer/Q2 Predictions Std                  106.98
trainer/Q2 Predictions Max                  341.877
trainer/Q2 Predictions Min                   12.1557
trainer/Q Targets Mean                      247.929
trainer/Q Targets Std                       106.985
trainer/Q Targets Max                       341.387
trainer/Q Targets Min                        11.4357
trainer/Log Pis Mean                          5.86824
trainer/Log Pis Std                           5.36234
trainer/Log Pis Max                          19.3576
trainer/Log Pis Min                          -6.88634
trainer/policy/mean Mean                      0.0397865
trainer/policy/mean Std                       0.774707
trainer/policy/mean Max                       0.99927
trainer/policy/mean Min                      -0.998133
trainer/policy/normal/std Mean                0.468391
trainer/policy/normal/std Std                 0.141866
trainer/policy/normal/std Max                 0.939778
trainer/policy/normal/std Min                 0.115644
trainer/policy/normal/log_std Mean           -0.812392
trainer/policy/normal/log_std Std             0.34741
trainer/policy/normal/log_std Max            -0.0621114
trainer/policy/normal/log_std Min            -2.15724
trainer/Alpha                                 0.0991914
trainer/Alpha Loss                           -0.304448
expl/num steps total                     141000
expl/num paths total                        141
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.8462
expl/Rewards Std                              1.19617
expl/Rewards Max                              7.09866
expl/Rewards Min                             -0.79509
expl/Returns Mean                          4846.2
expl/Returns Std                              0
expl/Returns Max                           4846.2
expl/Returns Min                           4846.2
expl/Actions Mean                             0.0482376
expl/Actions Std                              0.826493
expl/Actions Max                              0.999811
expl/Actions Min                             -0.99964
expl/Num Paths                                1
expl/Average Returns                       4846.2
expl/env_infos/final/reward_run Mean          6.38166
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.38166
expl/env_infos/final/reward_run Min           6.38166
expl/env_infos/initial/reward_run Mean       -0.487184
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.487184
expl/env_infos/initial/reward_run Min        -0.487184
expl/env_infos/reward_run Mean                5.25745
expl/env_infos/reward_run Std                 1.18161
expl/env_infos/reward_run Max                 7.63326
expl/env_infos/reward_run Min                -0.487184
expl/env_infos/final/reward_ctrl Mean        -0.361254
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.361254
expl/env_infos/final/reward_ctrl Min         -0.361254
expl/env_infos/initial/reward_ctrl Mean      -0.307906
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.307906
expl/env_infos/initial/reward_ctrl Min       -0.307906
expl/env_infos/reward_ctrl Mean              -0.411251
expl/env_infos/reward_ctrl Std                0.0804102
expl/env_infos/reward_ctrl Max               -0.143104
expl/env_infos/reward_ctrl Min               -0.578603
eval/num steps total                     700000
eval/num paths total                        700
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.90094
eval/Rewards Std                              1.21791
eval/Rewards Max                              7.4322
eval/Rewards Min                             -1.22609
eval/Returns Mean                          4900.94
eval/Returns Std                            109.603
eval/Returns Max                           5006.94
eval/Returns Min                           4718.48
eval/Actions Mean                             0.0452718
eval/Actions Std                              0.838336
eval/Actions Max                              0.999552
eval/Actions Min                             -0.997643
eval/Num Paths                                5
eval/Average Returns                       4900.94
eval/env_infos/final/reward_run Mean          6.15594
eval/env_infos/final/reward_run Std           1.10482
eval/env_infos/final/reward_run Max           6.85925
eval/env_infos/final/reward_run Min           3.95786
eval/env_infos/initial/reward_run Mean       -0.425029
eval/env_infos/initial/reward_run Std         0.180785
eval/env_infos/initial/reward_run Max        -0.0995274
eval/env_infos/initial/reward_run Min        -0.594393
eval/env_infos/reward_run Mean                5.32386
eval/env_infos/reward_run Std                 1.20845
eval/env_infos/reward_run Max                 7.93241
eval/env_infos/reward_run Min                -0.826893
eval/env_infos/final/reward_ctrl Mean        -0.464398
eval/env_infos/final/reward_ctrl Std          0.0478626
eval/env_infos/final/reward_ctrl Max         -0.409323
eval/env_infos/final/reward_ctrl Min         -0.544932
eval/env_infos/initial/reward_ctrl Mean      -0.278015
eval/env_infos/initial/reward_ctrl Std        0.0348043
eval/env_infos/initial/reward_ctrl Max       -0.233809
eval/env_infos/initial/reward_ctrl Min       -0.322088
eval/env_infos/reward_ctrl Mean              -0.422914
eval/env_infos/reward_ctrl Std                0.0754913
eval/env_infos/reward_ctrl Max               -0.169221
eval/env_infos/reward_ctrl Min               -0.579396
time/data storing (s)                         0.0045012
time/evaluation sampling (s)                  2.03299
time/exploration sampling (s)                 0.530006
time/logging (s)                              0.0136779
time/sac training (s)                         7.82674
time/saving (s)                               0.0039446
time/training (s)                             5.1873e-05
time/epoch (s)                               10.4119
time/total (s)                             1502.51
Epoch                                       139
---------------------------------------  ---------------
2021-11-24 00:54:25.619289 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 140 finished
---------------------------------------  ---------------
epoch                                       140
replay_buffer/size                       142000
trainer/num train calls                  141000
trainer/QF1 Loss                              7.97788
trainer/QF2 Loss                              6.35433
trainer/Policy Loss                        -248.545
trainer/Q1 Predictions Mean                 248.868
trainer/Q1 Predictions Std                  105.469
trainer/Q1 Predictions Max                  343.634
trainer/Q1 Predictions Min                   10.72
trainer/Q2 Predictions Mean                 248.932
trainer/Q2 Predictions Std                  105.531
trainer/Q2 Predictions Max                  343.626
trainer/Q2 Predictions Min                   10.8737
trainer/Q Targets Mean                      248.961
trainer/Q Targets Std                       105.661
trainer/Q Targets Max                       343.048
trainer/Q Targets Min                        10.9695
trainer/Log Pis Mean                          6.02084
trainer/Log Pis Std                           5.20526
trainer/Log Pis Max                          18.4811
trainer/Log Pis Min                          -5.76282
trainer/policy/mean Mean                      0.0270692
trainer/policy/mean Std                       0.769483
trainer/policy/mean Max                       0.999936
trainer/policy/mean Min                      -0.998448
trainer/policy/normal/std Mean                0.468547
trainer/policy/normal/std Std                 0.142939
trainer/policy/normal/std Max                 0.918078
trainer/policy/normal/std Min                 0.103837
trainer/policy/normal/log_std Mean           -0.815023
trainer/policy/normal/log_std Std             0.361621
trainer/policy/normal/log_std Max            -0.0854726
trainer/policy/normal/log_std Min            -2.26494
trainer/Alpha                                 0.0992785
trainer/Alpha Loss                            0.0481429
expl/num steps total                     142000
expl/num paths total                        142
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.92959
expl/Rewards Std                              1.17865
expl/Rewards Max                              7.11518
expl/Rewards Min                             -0.808158
expl/Returns Mean                          4929.59
expl/Returns Std                              0
expl/Returns Max                           4929.59
expl/Returns Min                           4929.59
expl/Actions Mean                             0.0414498
expl/Actions Std                              0.831978
expl/Actions Max                              0.999604
expl/Actions Min                             -0.999733
expl/Num Paths                                1
expl/Average Returns                       4929.59
expl/env_infos/final/reward_run Mean          3.89432
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.89432
expl/env_infos/final/reward_run Min           3.89432
expl/env_infos/initial/reward_run Mean       -0.543784
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.543784
expl/env_infos/initial/reward_run Min        -0.543784
expl/env_infos/reward_run Mean                5.34594
expl/env_infos/reward_run Std                 1.16271
expl/env_infos/reward_run Max                 7.60379
expl/env_infos/reward_run Min                -0.543784
expl/env_infos/final/reward_ctrl Mean        -0.575702
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.575702
expl/env_infos/final/reward_ctrl Min         -0.575702
expl/env_infos/initial/reward_ctrl Mean      -0.264374
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.264374
expl/env_infos/initial/reward_ctrl Min       -0.264374
expl/env_infos/reward_ctrl Mean              -0.416344
expl/env_infos/reward_ctrl Std                0.0883747
expl/env_infos/reward_ctrl Max               -0.104915
expl/env_infos/reward_ctrl Min               -0.590213
eval/num steps total                     705000
eval/num paths total                        705
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.98461
eval/Rewards Std                              1.24743
eval/Rewards Max                              7.58703
eval/Rewards Min                             -1.19498
eval/Returns Mean                          4984.61
eval/Returns Std                             62.491
eval/Returns Max                           5075.22
eval/Returns Min                           4905.13
eval/Actions Mean                             0.0449406
eval/Actions Std                              0.843693
eval/Actions Max                              0.999652
eval/Actions Min                             -0.999553
eval/Num Paths                                5
eval/Average Returns                       4984.61
eval/env_infos/final/reward_run Mean          5.35667
eval/env_infos/final/reward_run Std           0.89987
eval/env_infos/final/reward_run Max           6.63872
eval/env_infos/final/reward_run Min           3.96492
eval/env_infos/initial/reward_run Mean       -0.531279
eval/env_infos/initial/reward_run Std         0.173265
eval/env_infos/initial/reward_run Max        -0.286219
eval/env_infos/initial/reward_run Min        -0.814972
eval/env_infos/reward_run Mean                5.41291
eval/env_infos/reward_run Std                 1.234
eval/env_infos/reward_run Max                 8.10004
eval/env_infos/reward_run Min                -0.814972
eval/env_infos/final/reward_ctrl Mean        -0.42414
eval/env_infos/final/reward_ctrl Std          0.0706131
eval/env_infos/final/reward_ctrl Max         -0.301878
eval/env_infos/final/reward_ctrl Min         -0.490817
eval/env_infos/initial/reward_ctrl Mean      -0.287589
eval/env_infos/initial/reward_ctrl Std        0.0734671
eval/env_infos/initial/reward_ctrl Max       -0.176625
eval/env_infos/initial/reward_ctrl Min       -0.380013
eval/env_infos/reward_ctrl Mean              -0.428302
eval/env_infos/reward_ctrl Std                0.0853678
eval/env_infos/reward_ctrl Max               -0.131686
eval/env_infos/reward_ctrl Min               -0.585047
time/data storing (s)                         0.00449616
time/evaluation sampling (s)                  2.04869
time/exploration sampling (s)                 0.527974
time/logging (s)                              0.013569
time/sac training (s)                         7.9396
time/saving (s)                               0.0037859
time/training (s)                             3.4511e-05
time/epoch (s)                               10.5381
time/total (s)                             1513.37
Epoch                                       140
---------------------------------------  ---------------
2021-11-24 00:54:36.343059 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 141 finished
---------------------------------------  ---------------
epoch                                       141
replay_buffer/size                       143000
trainer/num train calls                  142000
trainer/QF1 Loss                              8.00312
trainer/QF2 Loss                              6.68636
trainer/Policy Loss                        -254.814
trainer/Q1 Predictions Mean                 255.212
trainer/Q1 Predictions Std                  100.447
trainer/Q1 Predictions Max                  345.142
trainer/Q1 Predictions Min                   11.5653
trainer/Q2 Predictions Mean                 255.118
trainer/Q2 Predictions Std                  100.365
trainer/Q2 Predictions Max                  346.587
trainer/Q2 Predictions Min                   12.3648
trainer/Q Targets Mean                      255.14
trainer/Q Targets Std                       100.488
trainer/Q Targets Max                       345.933
trainer/Q Targets Min                        11.1879
trainer/Log Pis Mean                          6.14098
trainer/Log Pis Std                           4.77799
trainer/Log Pis Max                          16.8039
trainer/Log Pis Min                          -4.68675
trainer/policy/mean Mean                      0.0469222
trainer/policy/mean Std                       0.779753
trainer/policy/mean Max                       0.997433
trainer/policy/mean Min                      -0.995809
trainer/policy/normal/std Mean                0.458206
trainer/policy/normal/std Std                 0.1384
trainer/policy/normal/std Max                 0.886283
trainer/policy/normal/std Min                 0.0821602
trainer/policy/normal/log_std Mean           -0.835093
trainer/policy/normal/log_std Std             0.352524
trainer/policy/normal/log_std Max            -0.120719
trainer/policy/normal/log_std Min            -2.49908
trainer/Alpha                                 0.0992752
trainer/Alpha Loss                            0.325645
expl/num steps total                     143000
expl/num paths total                        143
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.53708
expl/Rewards Std                              1.13303
expl/Rewards Max                              6.65059
expl/Rewards Min                             -0.570273
expl/Returns Mean                          4537.08
expl/Returns Std                              0
expl/Returns Max                           4537.08
expl/Returns Min                           4537.08
expl/Actions Mean                             0.0345855
expl/Actions Std                              0.832263
expl/Actions Max                              0.999802
expl/Actions Min                             -0.999636
expl/Num Paths                                1
expl/Average Returns                       4537.08
expl/env_infos/final/reward_run Mean          3.81633
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.81633
expl/env_infos/final/reward_run Min           3.81633
expl/env_infos/initial/reward_run Mean       -0.212857
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.212857
expl/env_infos/initial/reward_run Min        -0.212857
expl/env_infos/reward_run Mean                4.95339
expl/env_infos/reward_run Std                 1.12743
expl/env_infos/reward_run Max                 7.15792
expl/env_infos/reward_run Min                -0.212857
expl/env_infos/final/reward_ctrl Mean        -0.527636
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.527636
expl/env_infos/final/reward_ctrl Min         -0.527636
expl/env_infos/initial/reward_ctrl Mean      -0.357416
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.357416
expl/env_infos/initial/reward_ctrl Min       -0.357416
expl/env_infos/reward_ctrl Mean              -0.416315
expl/env_infos/reward_ctrl Std                0.083703
expl/env_infos/reward_ctrl Max               -0.137116
expl/env_infos/reward_ctrl Min               -0.574575
eval/num steps total                     710000
eval/num paths total                        710
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.89225
eval/Rewards Std                              1.21394
eval/Rewards Max                              7.19065
eval/Rewards Min                             -0.817764
eval/Returns Mean                          4892.25
eval/Returns Std                             39.8345
eval/Returns Max                           4944.68
eval/Returns Min                           4838.38
eval/Actions Mean                             0.0328801
eval/Actions Std                              0.85068
eval/Actions Max                              0.999108
eval/Actions Min                             -0.999519
eval/Num Paths                                5
eval/Average Returns                       4892.25
eval/env_infos/final/reward_run Mean          5.19308
eval/env_infos/final/reward_run Std           1.30164
eval/env_infos/final/reward_run Max           7.14461
eval/env_infos/final/reward_run Min           3.90004
eval/env_infos/initial/reward_run Mean       -0.259505
eval/env_infos/initial/reward_run Std         0.278979
eval/env_infos/initial/reward_run Max         0.252947
eval/env_infos/initial/reward_run Min        -0.575091
eval/env_infos/reward_run Mean                5.32709
eval/env_infos/reward_run Std                 1.20583
eval/env_infos/reward_run Max                 7.72635
eval/env_infos/reward_run Min                -0.575091
eval/env_infos/final/reward_ctrl Mean        -0.449383
eval/env_infos/final/reward_ctrl Std          0.0661224
eval/env_infos/final/reward_ctrl Max         -0.374403
eval/env_infos/final/reward_ctrl Min         -0.535436
eval/env_infos/initial/reward_ctrl Mean      -0.227821
eval/env_infos/initial/reward_ctrl Std        0.0672242
eval/env_infos/initial/reward_ctrl Max       -0.118188
eval/env_infos/initial/reward_ctrl Min       -0.299998
eval/env_infos/reward_ctrl Mean              -0.434843
eval/env_infos/reward_ctrl Std                0.0772781
eval/env_infos/reward_ctrl Max               -0.118188
eval/env_infos/reward_ctrl Min               -0.57297
time/data storing (s)                         0.00448901
time/evaluation sampling (s)                  2.02789
time/exploration sampling (s)                 0.527835
time/logging (s)                              0.0140487
time/sac training (s)                         7.80549
time/saving (s)                               0.004249
time/training (s)                             4.5325e-05
time/epoch (s)                               10.384
time/total (s)                             1524.07
Epoch                                       141
---------------------------------------  ---------------
2021-11-24 00:54:47.035518 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 142 finished
---------------------------------------  ---------------
epoch                                       142
replay_buffer/size                       144000
trainer/num train calls                  143000
trainer/QF1 Loss                              8.59631
trainer/QF2 Loss                              7.28148
trainer/Policy Loss                        -248.323
trainer/Q1 Predictions Mean                 249.004
trainer/Q1 Predictions Std                  106.031
trainer/Q1 Predictions Max                  344.665
trainer/Q1 Predictions Min                   11.5467
trainer/Q2 Predictions Mean                 248.417
trainer/Q2 Predictions Std                  105.844
trainer/Q2 Predictions Max                  344.651
trainer/Q2 Predictions Min                   12.0423
trainer/Q Targets Mean                      248.873
trainer/Q Targets Std                       106.197
trainer/Q Targets Max                       344.575
trainer/Q Targets Min                        11.6804
trainer/Log Pis Mean                          5.53431
trainer/Log Pis Std                           5.07051
trainer/Log Pis Max                          18.4844
trainer/Log Pis Min                          -5.78723
trainer/policy/mean Mean                      0.0424398
trainer/policy/mean Std                       0.766756
trainer/policy/mean Max                       0.999016
trainer/policy/mean Min                      -0.998961
trainer/policy/normal/std Mean                0.468023
trainer/policy/normal/std Std                 0.144238
trainer/policy/normal/std Max                 0.888266
trainer/policy/normal/std Min                 0.101157
trainer/policy/normal/log_std Mean           -0.815537
trainer/policy/normal/log_std Std             0.356916
trainer/policy/normal/log_std Max            -0.118484
trainer/policy/normal/log_std Min            -2.29108
trainer/Alpha                                 0.099201
trainer/Alpha Loss                           -1.07603
expl/num steps total                     144000
expl/num paths total                        144
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.64933
expl/Rewards Std                              1.19573
expl/Rewards Max                              6.7437
expl/Rewards Min                             -0.829989
expl/Returns Mean                          4649.33
expl/Returns Std                              0
expl/Returns Max                           4649.33
expl/Returns Min                           4649.33
expl/Actions Mean                             0.0342742
expl/Actions Std                              0.828128
expl/Actions Max                              0.999551
expl/Actions Min                             -0.999926
expl/Num Paths                                1
expl/Average Returns                       4649.33
expl/env_infos/final/reward_run Mean          6.28624
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.28624
expl/env_infos/final/reward_run Min           6.28624
expl/env_infos/initial/reward_run Mean       -0.554504
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.554504
expl/env_infos/initial/reward_run Min        -0.554504
expl/env_infos/reward_run Mean                5.06151
expl/env_infos/reward_run Std                 1.18797
expl/env_infos/reward_run Max                 7.23761
expl/env_infos/reward_run Min                -0.554504
expl/env_infos/final/reward_ctrl Mean        -0.342713
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.342713
expl/env_infos/final/reward_ctrl Min         -0.342713
expl/env_infos/initial/reward_ctrl Mean      -0.234179
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.234179
expl/env_infos/initial/reward_ctrl Min       -0.234179
expl/env_infos/reward_ctrl Mean              -0.412183
expl/env_infos/reward_ctrl Std                0.0839375
expl/env_infos/reward_ctrl Max               -0.11067
expl/env_infos/reward_ctrl Min               -0.578513
eval/num steps total                     715000
eval/num paths total                        715
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.93091
eval/Rewards Std                              1.22817
eval/Rewards Max                              7.56071
eval/Rewards Min                             -1.14245
eval/Returns Mean                          4930.91
eval/Returns Std                            116.961
eval/Returns Max                           5132.27
eval/Returns Min                           4776.95
eval/Actions Mean                             0.0327346
eval/Actions Std                              0.845327
eval/Actions Max                              0.997964
eval/Actions Min                             -0.998915
eval/Num Paths                                5
eval/Average Returns                       4930.91
eval/env_infos/final/reward_run Mean          4.37361
eval/env_infos/final/reward_run Std           1.18186
eval/env_infos/final/reward_run Max           5.85919
eval/env_infos/final/reward_run Min           3.04265
eval/env_infos/initial/reward_run Mean       -0.480798
eval/env_infos/initial/reward_run Std         0.244346
eval/env_infos/initial/reward_run Max        -0.136672
eval/env_infos/initial/reward_run Min        -0.757277
eval/env_infos/reward_run Mean                5.3603
eval/env_infos/reward_run Std                 1.21909
eval/env_infos/reward_run Max                 8.08759
eval/env_infos/reward_run Min                -0.757277
eval/env_infos/final/reward_ctrl Mean        -0.430968
eval/env_infos/final/reward_ctrl Std          0.0946054
eval/env_infos/final/reward_ctrl Max         -0.298801
eval/env_infos/final/reward_ctrl Min         -0.562543
eval/env_infos/initial/reward_ctrl Mean      -0.275495
eval/env_infos/initial/reward_ctrl Std        0.0596458
eval/env_infos/initial/reward_ctrl Max       -0.19786
eval/env_infos/initial/reward_ctrl Min       -0.351226
eval/env_infos/reward_ctrl Mean              -0.429389
eval/env_infos/reward_ctrl Std                0.0816024
eval/env_infos/reward_ctrl Max               -0.128125
eval/env_infos/reward_ctrl Min               -0.575807
time/data storing (s)                         0.00446281
time/evaluation sampling (s)                  2.03485
time/exploration sampling (s)                 0.531158
time/logging (s)                              0.0137494
time/sac training (s)                         7.76785
time/saving (s)                               0.00379657
time/training (s)                             3.525e-05
time/epoch (s)                               10.3559
time/total (s)                             1534.75
Epoch                                       142
---------------------------------------  ---------------
2021-11-24 00:54:57.766026 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 143 finished
---------------------------------------  ---------------
epoch                                       143
replay_buffer/size                       145000
trainer/num train calls                  144000
trainer/QF1 Loss                              6.93492
trainer/QF2 Loss                              5.73106
trainer/Policy Loss                        -252.436
trainer/Q1 Predictions Mean                 252.599
trainer/Q1 Predictions Std                  104.519
trainer/Q1 Predictions Max                  347.5
trainer/Q1 Predictions Min                   12.5085
trainer/Q2 Predictions Mean                 252.857
trainer/Q2 Predictions Std                  104.622
trainer/Q2 Predictions Max                  348.269
trainer/Q2 Predictions Min                   12.541
trainer/Q Targets Mean                      252.795
trainer/Q Targets Std                       104.517
trainer/Q Targets Max                       347.591
trainer/Q Targets Min                         9.79087
trainer/Log Pis Mean                          6.46962
trainer/Log Pis Std                           5.4642
trainer/Log Pis Max                          22.2086
trainer/Log Pis Min                          -7.42319
trainer/policy/mean Mean                      0.00496714
trainer/policy/mean Std                       0.790198
trainer/policy/mean Max                       0.999725
trainer/policy/mean Min                      -0.99956
trainer/policy/normal/std Mean                0.464866
trainer/policy/normal/std Std                 0.149343
trainer/policy/normal/std Max                 1.12512
trainer/policy/normal/std Min                 0.113185
trainer/policy/normal/log_std Mean           -0.825979
trainer/policy/normal/log_std Std             0.365949
trainer/policy/normal/log_std Max             0.117894
trainer/policy/normal/log_std Min            -2.17873
trainer/Alpha                                 0.0993528
trainer/Alpha Loss                            1.0844
expl/num steps total                     145000
expl/num paths total                        145
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.79977
expl/Rewards Std                              1.17552
expl/Rewards Max                              7.00006
expl/Rewards Min                             -0.461115
expl/Returns Mean                          4799.77
expl/Returns Std                              0
expl/Returns Max                           4799.77
expl/Returns Min                           4799.77
expl/Actions Mean                             0.0287794
expl/Actions Std                              0.837835
expl/Actions Max                              0.999549
expl/Actions Min                             -0.999723
expl/Num Paths                                1
expl/Average Returns                       4799.77
expl/env_infos/final/reward_run Mean          5.49718
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.49718
expl/env_infos/final/reward_run Min           5.49718
expl/env_infos/initial/reward_run Mean       -0.230041
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.230041
expl/env_infos/initial/reward_run Min        -0.230041
expl/env_infos/reward_run Mean                5.22145
expl/env_infos/reward_run Std                 1.1676
expl/env_infos/reward_run Max                 7.46886
expl/env_infos/reward_run Min                -0.230041
expl/env_infos/final/reward_ctrl Mean        -0.506459
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.506459
expl/env_infos/final/reward_ctrl Min         -0.506459
expl/env_infos/initial/reward_ctrl Mean      -0.231073
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.231073
expl/env_infos/initial/reward_ctrl Min       -0.231073
expl/env_infos/reward_ctrl Mean              -0.421677
expl/env_infos/reward_ctrl Std                0.082735
expl/env_infos/reward_ctrl Max               -0.0833735
expl/env_infos/reward_ctrl Min               -0.587703
eval/num steps total                     720000
eval/num paths total                        720
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.88539
eval/Rewards Std                              1.28183
eval/Rewards Max                              7.4773
eval/Rewards Min                             -1.13578
eval/Returns Mean                          4885.39
eval/Returns Std                             59.5688
eval/Returns Max                           4960.83
eval/Returns Min                           4779.59
eval/Actions Mean                             0.0314029
eval/Actions Std                              0.850279
eval/Actions Max                              0.999959
eval/Actions Min                             -0.999561
eval/Num Paths                                5
eval/Average Returns                       4885.39
eval/env_infos/final/reward_run Mean          4.97553
eval/env_infos/final/reward_run Std           0.740782
eval/env_infos/final/reward_run Max           5.77964
eval/env_infos/final/reward_run Min           3.71777
eval/env_infos/initial/reward_run Mean       -0.445357
eval/env_infos/initial/reward_run Std         0.17637
eval/env_infos/initial/reward_run Max        -0.264505
eval/env_infos/initial/reward_run Min        -0.685583
eval/env_infos/reward_run Mean                5.31977
eval/env_infos/reward_run Std                 1.27297
eval/env_infos/reward_run Max                 7.99323
eval/env_infos/reward_run Min                -0.685583
eval/env_infos/final/reward_ctrl Mean        -0.454443
eval/env_infos/final/reward_ctrl Std          0.0616264
eval/env_infos/final/reward_ctrl Max         -0.377874
eval/env_infos/final/reward_ctrl Min         -0.542167
eval/env_infos/initial/reward_ctrl Mean      -0.280319
eval/env_infos/initial/reward_ctrl Std        0.0885783
eval/env_infos/initial/reward_ctrl Max       -0.189463
eval/env_infos/initial/reward_ctrl Min       -0.450196
eval/env_infos/reward_ctrl Mean              -0.434376
eval/env_infos/reward_ctrl Std                0.0785649
eval/env_infos/reward_ctrl Max               -0.020041
eval/env_infos/reward_ctrl Min               -0.583687
time/data storing (s)                         0.00446893
time/evaluation sampling (s)                  2.01642
time/exploration sampling (s)                 0.520086
time/logging (s)                              0.0136284
time/sac training (s)                         7.8356
time/saving (s)                               0.00379745
time/training (s)                             3.8916e-05
time/epoch (s)                               10.394
time/total (s)                             1545.47
Epoch                                       143
---------------------------------------  ---------------
2021-11-24 00:55:08.480053 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 144 finished
---------------------------------------  ---------------
epoch                                       144
replay_buffer/size                       146000
trainer/num train calls                  145000
trainer/QF1 Loss                             11.8513
trainer/QF2 Loss                              8.92214
trainer/Policy Loss                        -262.128
trainer/Q1 Predictions Mean                 262.308
trainer/Q1 Predictions Std                   97.6183
trainer/Q1 Predictions Max                  351.507
trainer/Q1 Predictions Min                   11.9836
trainer/Q2 Predictions Mean                 262.464
trainer/Q2 Predictions Std                   97.5829
trainer/Q2 Predictions Max                  351.16
trainer/Q2 Predictions Min                   10.2657
trainer/Q Targets Mean                      262.465
trainer/Q Targets Std                        97.3701
trainer/Q Targets Max                       350.287
trainer/Q Targets Min                        11.711
trainer/Log Pis Mean                          6.28552
trainer/Log Pis Std                           4.66287
trainer/Log Pis Max                          16.3414
trainer/Log Pis Min                          -6.33111
trainer/policy/mean Mean                      0.022984
trainer/policy/mean Std                       0.778916
trainer/policy/mean Max                       0.998123
trainer/policy/mean Min                      -0.997718
trainer/policy/normal/std Mean                0.452022
trainer/policy/normal/std Std                 0.143731
trainer/policy/normal/std Max                 0.984609
trainer/policy/normal/std Min                 0.108514
trainer/policy/normal/log_std Mean           -0.852926
trainer/policy/normal/log_std Std             0.363265
trainer/policy/normal/log_std Max            -0.0155103
trainer/policy/normal/log_std Min            -2.22088
trainer/Alpha                                 0.101058
trainer/Alpha Loss                            0.65442
expl/num steps total                     146000
expl/num paths total                        146
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.68991
expl/Rewards Std                              1.17556
expl/Rewards Max                              7.69427
expl/Rewards Min                             -0.395394
expl/Returns Mean                          4689.91
expl/Returns Std                              0
expl/Returns Max                           4689.91
expl/Returns Min                           4689.91
expl/Actions Mean                             0.0485106
expl/Actions Std                              0.829655
expl/Actions Max                              0.99955
expl/Actions Min                             -0.999409
expl/Num Paths                                1
expl/Average Returns                       4689.91
expl/env_infos/final/reward_run Mean          7.0834
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.0834
expl/env_infos/final/reward_run Min           7.0834
expl/env_infos/initial/reward_run Mean       -0.185076
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.185076
expl/env_infos/initial/reward_run Min        -0.185076
expl/env_infos/reward_run Mean                5.10432
expl/env_infos/reward_run Std                 1.16838
expl/env_infos/reward_run Max                 8.12829
expl/env_infos/reward_run Min                -0.185076
expl/env_infos/final/reward_ctrl Mean        -0.421324
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.421324
expl/env_infos/final/reward_ctrl Min         -0.421324
expl/env_infos/initial/reward_ctrl Mean      -0.210319
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.210319
expl/env_infos/initial/reward_ctrl Min       -0.210319
expl/env_infos/reward_ctrl Mean              -0.414408
expl/env_infos/reward_ctrl Std                0.0785865
expl/env_infos/reward_ctrl Max               -0.113189
expl/env_infos/reward_ctrl Min               -0.577595
eval/num steps total                     725000
eval/num paths total                        725
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.78932
eval/Rewards Std                              1.24465
eval/Rewards Max                              7.25486
eval/Rewards Min                             -1.36433
eval/Returns Mean                          4789.32
eval/Returns Std                            112.089
eval/Returns Max                           4970.38
eval/Returns Min                           4652.77
eval/Actions Mean                             0.0659102
eval/Actions Std                              0.839951
eval/Actions Max                              0.998725
eval/Actions Min                             -0.999219
eval/Num Paths                                5
eval/Average Returns                       4789.32
eval/env_infos/final/reward_run Mean          5.15001
eval/env_infos/final/reward_run Std           0.983467
eval/env_infos/final/reward_run Max           6.48794
eval/env_infos/final/reward_run Min           3.71082
eval/env_infos/initial/reward_run Mean       -0.740032
eval/env_infos/initial/reward_run Std         0.098786
eval/env_infos/initial/reward_run Max        -0.654643
eval/env_infos/initial/reward_run Min        -0.915606
eval/env_infos/reward_run Mean                5.21524
eval/env_infos/reward_run Std                 1.23631
eval/env_infos/reward_run Max                 7.75559
eval/env_infos/reward_run Min                -1.00326
eval/env_infos/final/reward_ctrl Mean        -0.364367
eval/env_infos/final/reward_ctrl Std          0.0314007
eval/env_infos/final/reward_ctrl Max         -0.32891
eval/env_infos/final/reward_ctrl Min         -0.414334
eval/env_infos/initial/reward_ctrl Mean      -0.390688
eval/env_infos/initial/reward_ctrl Std        0.0741747
eval/env_infos/initial/reward_ctrl Max       -0.297987
eval/env_infos/initial/reward_ctrl Min       -0.493607
eval/env_infos/reward_ctrl Mean              -0.425917
eval/env_infos/reward_ctrl Std                0.0718554
eval/env_infos/reward_ctrl Max               -0.128281
eval/env_infos/reward_ctrl Min               -0.581403
time/data storing (s)                         0.00451095
time/evaluation sampling (s)                  2.04449
time/exploration sampling (s)                 0.559552
time/logging (s)                              0.0151583
time/sac training (s)                         7.7512
time/saving (s)                               0.0038501
time/training (s)                             4.5706e-05
time/epoch (s)                               10.3788
time/total (s)                             1556.17
Epoch                                       144
---------------------------------------  ---------------
2021-11-24 00:55:19.289120 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 145 finished
---------------------------------------  ---------------
epoch                                       145
replay_buffer/size                       147000
trainer/num train calls                  146000
trainer/QF1 Loss                              5.89944
trainer/QF2 Loss                              4.27898
trainer/Policy Loss                        -256.313
trainer/Q1 Predictions Mean                 256.999
trainer/Q1 Predictions Std                  107.277
trainer/Q1 Predictions Max                  347.657
trainer/Q1 Predictions Min                   11.1749
trainer/Q2 Predictions Mean                 256.764
trainer/Q2 Predictions Std                  107.202
trainer/Q2 Predictions Max                  348.687
trainer/Q2 Predictions Min                   10.8128
trainer/Q Targets Mean                      257.191
trainer/Q Targets Std                       107.476
trainer/Q Targets Max                       351.043
trainer/Q Targets Min                         9.74254
trainer/Log Pis Mean                          6.06205
trainer/Log Pis Std                           5.24018
trainer/Log Pis Max                          20.0702
trainer/Log Pis Min                          -5.19063
trainer/policy/mean Mean                      0.0218707
trainer/policy/mean Std                       0.76883
trainer/policy/mean Max                       0.999344
trainer/policy/mean Min                      -0.997823
trainer/policy/normal/std Mean                0.454904
trainer/policy/normal/std Std                 0.158371
trainer/policy/normal/std Max                 0.95078
trainer/policy/normal/std Min                 0.0941417
trainer/policy/normal/log_std Mean           -0.85567
trainer/policy/normal/log_std Std             0.386455
trainer/policy/normal/log_std Max            -0.0504722
trainer/policy/normal/log_std Min            -2.36295
trainer/Alpha                                 0.101032
trainer/Alpha Loss                            0.142232
expl/num steps total                     147000
expl/num paths total                        147
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.68439
expl/Rewards Std                              1.17003
expl/Rewards Max                              6.86891
expl/Rewards Min                             -0.449006
expl/Returns Mean                          4684.39
expl/Returns Std                              0
expl/Returns Max                           4684.39
expl/Returns Min                           4684.39
expl/Actions Mean                             0.0390623
expl/Actions Std                              0.829631
expl/Actions Max                              0.999743
expl/Actions Min                             -0.999797
expl/Num Paths                                1
expl/Average Returns                       4684.39
expl/env_infos/final/reward_run Mean          6.70026
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.70026
expl/env_infos/final/reward_run Min           6.70026
expl/env_infos/initial/reward_run Mean       -0.204995
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.204995
expl/env_infos/initial/reward_run Min        -0.204995
expl/env_infos/reward_run Mean                5.09828
expl/env_infos/reward_run Std                 1.15713
expl/env_infos/reward_run Max                 7.33173
expl/env_infos/reward_run Min                -0.204995
expl/env_infos/final/reward_ctrl Mean        -0.368549
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.368549
expl/env_infos/final/reward_ctrl Min         -0.368549
expl/env_infos/initial/reward_ctrl Mean      -0.244012
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.244012
expl/env_infos/initial/reward_ctrl Min       -0.244012
expl/env_infos/reward_ctrl Mean              -0.413888
expl/env_infos/reward_ctrl Std                0.0870946
expl/env_infos/reward_ctrl Max               -0.14296
expl/env_infos/reward_ctrl Min               -0.580358
eval/num steps total                     730000
eval/num paths total                        730
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.02661
eval/Rewards Std                              1.22405
eval/Rewards Max                              7.56656
eval/Rewards Min                             -1.33945
eval/Returns Mean                          5026.61
eval/Returns Std                            115.838
eval/Returns Max                           5190.32
eval/Returns Min                           4838.7
eval/Actions Mean                             0.0293439
eval/Actions Std                              0.843535
eval/Actions Max                              0.998102
eval/Actions Min                             -0.998454
eval/Num Paths                                5
eval/Average Returns                       5026.61
eval/env_infos/final/reward_run Mean          6.03726
eval/env_infos/final/reward_run Std           0.977447
eval/env_infos/final/reward_run Max           7.10742
eval/env_infos/final/reward_run Min           4.264
eval/env_infos/initial/reward_run Mean       -0.552858
eval/env_infos/initial/reward_run Std         0.209857
eval/env_infos/initial/reward_run Max        -0.306918
eval/env_infos/initial/reward_run Min        -0.939774
eval/env_infos/reward_run Mean                5.45406
eval/env_infos/reward_run Std                 1.21159
eval/env_infos/reward_run Max                 8.03645
eval/env_infos/reward_run Min                -0.939774
eval/env_infos/final/reward_ctrl Mean        -0.465668
eval/env_infos/final/reward_ctrl Std          0.0610223
eval/env_infos/final/reward_ctrl Max         -0.376906
eval/env_infos/final/reward_ctrl Min         -0.539115
eval/env_infos/initial/reward_ctrl Mean      -0.316624
eval/env_infos/initial/reward_ctrl Std        0.0733297
eval/env_infos/initial/reward_ctrl Max       -0.181651
eval/env_infos/initial/reward_ctrl Min       -0.399674
eval/env_infos/reward_ctrl Mean              -0.427447
eval/env_infos/reward_ctrl Std                0.0846954
eval/env_infos/reward_ctrl Max               -0.092629
eval/env_infos/reward_ctrl Min               -0.583586
time/data storing (s)                         0.00445697
time/evaluation sampling (s)                  2.03115
time/exploration sampling (s)                 0.522337
time/logging (s)                              0.0140671
time/sac training (s)                         7.89717
time/saving (s)                               0.00383034
time/training (s)                             3.5345e-05
time/epoch (s)                               10.473
time/total (s)                             1566.96
Epoch                                       145
---------------------------------------  ---------------
2021-11-24 00:55:30.004220 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 146 finished
---------------------------------------  ---------------
epoch                                       146
replay_buffer/size                       148000
trainer/num train calls                  147000
trainer/QF1 Loss                              5.70105
trainer/QF2 Loss                              5.05513
trainer/Policy Loss                        -257.244
trainer/Q1 Predictions Mean                 257.66
trainer/Q1 Predictions Std                  106.944
trainer/Q1 Predictions Max                  348.534
trainer/Q1 Predictions Min                   11.7737
trainer/Q2 Predictions Mean                 257.798
trainer/Q2 Predictions Std                  107
trainer/Q2 Predictions Max                  347.238
trainer/Q2 Predictions Min                   11.4076
trainer/Q Targets Mean                      257.723
trainer/Q Targets Std                       106.973
trainer/Q Targets Max                       345.503
trainer/Q Targets Min                        10.5132
trainer/Log Pis Mean                          5.74535
trainer/Log Pis Std                           5.31538
trainer/Log Pis Max                          16.708
trainer/Log Pis Min                          -5.55597
trainer/policy/mean Mean                      0.0286022
trainer/policy/mean Std                       0.764899
trainer/policy/mean Max                       0.998505
trainer/policy/mean Min                      -0.995153
trainer/policy/normal/std Mean                0.45824
trainer/policy/normal/std Std                 0.145328
trainer/policy/normal/std Max                 0.875361
trainer/policy/normal/std Min                 0.106373
trainer/policy/normal/log_std Mean           -0.839962
trainer/policy/normal/log_std Std             0.366316
trainer/policy/normal/log_std Max            -0.133119
trainer/policy/normal/log_std Min            -2.2408
trainer/Alpha                                 0.101617
trainer/Alpha Loss                           -0.582278
expl/num steps total                     148000
expl/num paths total                        148
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.68222
expl/Rewards Std                              1.1641
expl/Rewards Max                              6.96053
expl/Rewards Min                             -1.28877
expl/Returns Mean                          4682.22
expl/Returns Std                              0
expl/Returns Max                           4682.22
expl/Returns Min                           4682.22
expl/Actions Mean                             0.0568844
expl/Actions Std                              0.833834
expl/Actions Max                              0.999881
expl/Actions Min                             -0.999827
expl/Num Paths                                1
expl/Average Returns                       4682.22
expl/env_infos/final/reward_run Mean          4.9381
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.9381
expl/env_infos/final/reward_run Min           4.9381
expl/env_infos/initial/reward_run Mean       -0.68807
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.68807
expl/env_infos/initial/reward_run Min        -0.68807
expl/env_infos/reward_run Mean                5.10133
expl/env_infos/reward_run Std                 1.14892
expl/env_infos/reward_run Max                 7.42953
expl/env_infos/reward_run Min                -0.877125
expl/env_infos/final/reward_ctrl Mean        -0.503358
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.503358
expl/env_infos/final/reward_ctrl Min         -0.503358
expl/env_infos/initial/reward_ctrl Mean      -0.316017
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.316017
expl/env_infos/initial/reward_ctrl Min       -0.316017
expl/env_infos/reward_ctrl Mean              -0.419109
expl/env_infos/reward_ctrl Std                0.0806324
expl/env_infos/reward_ctrl Max               -0.128904
expl/env_infos/reward_ctrl Min               -0.584799
eval/num steps total                     735000
eval/num paths total                        735
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.0548
eval/Rewards Std                              1.21404
eval/Rewards Max                              7.65141
eval/Rewards Min                             -0.726875
eval/Returns Mean                          5054.8
eval/Returns Std                             84.746
eval/Returns Max                           5187.28
eval/Returns Min                           4966.94
eval/Actions Mean                             0.0496929
eval/Actions Std                              0.844785
eval/Actions Max                              0.999664
eval/Actions Min                             -0.9985
eval/Num Paths                                5
eval/Average Returns                       5054.8
eval/env_infos/final/reward_run Mean          5.40415
eval/env_infos/final/reward_run Std           0.702932
eval/env_infos/final/reward_run Max           6.39758
eval/env_infos/final/reward_run Min           4.71248
eval/env_infos/initial/reward_run Mean       -0.293007
eval/env_infos/initial/reward_run Std         0.151413
eval/env_infos/initial/reward_run Max        -0.010416
eval/env_infos/initial/reward_run Min        -0.425917
eval/env_infos/reward_run Mean                5.48447
eval/env_infos/reward_run Std                 1.19907
eval/env_infos/reward_run Max                 8.17237
eval/env_infos/reward_run Min                -0.425917
eval/env_infos/final/reward_ctrl Mean        -0.411127
eval/env_infos/final/reward_ctrl Std          0.0537947
eval/env_infos/final/reward_ctrl Max         -0.344568
eval/env_infos/final/reward_ctrl Min         -0.483
eval/env_infos/initial/reward_ctrl Mean      -0.249389
eval/env_infos/initial/reward_ctrl Std        0.0442356
eval/env_infos/initial/reward_ctrl Max       -0.186217
eval/env_infos/initial/reward_ctrl Min       -0.312515
eval/env_infos/reward_ctrl Mean              -0.429678
eval/env_infos/reward_ctrl Std                0.0770623
eval/env_infos/reward_ctrl Max               -0.15684
eval/env_infos/reward_ctrl Min               -0.584472
time/data storing (s)                         0.00455186
time/evaluation sampling (s)                  2.06999
time/exploration sampling (s)                 0.530871
time/logging (s)                              0.014547
time/sac training (s)                         7.75639
time/saving (s)                               0.0047497
time/training (s)                             3.8731e-05
time/epoch (s)                               10.3811
time/total (s)                             1577.66
Epoch                                       146
---------------------------------------  ---------------
2021-11-24 00:55:40.734929 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 147 finished
---------------------------------------  ---------------
epoch                                       147
replay_buffer/size                       149000
trainer/num train calls                  148000
trainer/QF1 Loss                             12.6173
trainer/QF2 Loss                              8.17497
trainer/Policy Loss                        -262.054
trainer/Q1 Predictions Mean                 262.647
trainer/Q1 Predictions Std                   99.8676
trainer/Q1 Predictions Max                  351.067
trainer/Q1 Predictions Min                   10.7799
trainer/Q2 Predictions Mean                 262.176
trainer/Q2 Predictions Std                   99.8416
trainer/Q2 Predictions Max                  353.562
trainer/Q2 Predictions Min                   11.646
trainer/Q Targets Mean                      262.71
trainer/Q Targets Std                       100.174
trainer/Q Targets Max                       354.832
trainer/Q Targets Min                        11.7019
trainer/Log Pis Mean                          6.24625
trainer/Log Pis Std                           5.01607
trainer/Log Pis Max                          17.8501
trainer/Log Pis Min                          -7.11885
trainer/policy/mean Mean                      0.0802971
trainer/policy/mean Std                       0.775325
trainer/policy/mean Max                       0.999477
trainer/policy/mean Min                      -0.997628
trainer/policy/normal/std Mean                0.465147
trainer/policy/normal/std Std                 0.141816
trainer/policy/normal/std Max                 0.885457
trainer/policy/normal/std Min                 0.0941275
trainer/policy/normal/log_std Mean           -0.822455
trainer/policy/normal/log_std Std             0.361767
trainer/policy/normal/log_std Max            -0.121652
trainer/policy/normal/log_std Min            -2.36311
trainer/Alpha                                 0.103544
trainer/Alpha Loss                            0.558424
expl/num steps total                     149000
expl/num paths total                        149
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.77335
expl/Rewards Std                              1.18501
expl/Rewards Max                              7.21377
expl/Rewards Min                             -1.02178
expl/Returns Mean                          4773.35
expl/Returns Std                              0
expl/Returns Max                           4773.35
expl/Returns Min                           4773.35
expl/Actions Mean                             0.0635912
expl/Actions Std                              0.832503
expl/Actions Max                              0.999522
expl/Actions Min                             -0.999319
expl/Num Paths                                1
expl/Average Returns                       4773.35
expl/env_infos/final/reward_run Mean          5.76089
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.76089
expl/env_infos/final/reward_run Min           5.76089
expl/env_infos/initial/reward_run Mean       -0.779621
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.779621
expl/env_infos/initial/reward_run Min        -0.779621
expl/env_infos/reward_run Mean                5.19161
expl/env_infos/reward_run Std                 1.17442
expl/env_infos/reward_run Max                 7.6972
expl/env_infos/reward_run Min                -0.779621
expl/env_infos/final/reward_ctrl Mean        -0.333682
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.333682
expl/env_infos/final/reward_ctrl Min         -0.333682
expl/env_infos/initial/reward_ctrl Mean      -0.242163
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.242163
expl/env_infos/initial/reward_ctrl Min       -0.242163
expl/env_infos/reward_ctrl Mean              -0.418263
expl/env_infos/reward_ctrl Std                0.0832806
expl/env_infos/reward_ctrl Max               -0.157917
expl/env_infos/reward_ctrl Min               -0.577417
eval/num steps total                     740000
eval/num paths total                        740
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.85955
eval/Rewards Std                              1.26547
eval/Rewards Max                              7.7242
eval/Rewards Min                             -1.2542
eval/Returns Mean                          4859.55
eval/Returns Std                             46.1467
eval/Returns Max                           4914.8
eval/Returns Min                           4774.81
eval/Actions Mean                             0.0675647
eval/Actions Std                              0.842668
eval/Actions Max                              0.999403
eval/Actions Min                             -0.998844
eval/Num Paths                                5
eval/Average Returns                       4859.55
eval/env_infos/final/reward_run Mean          5.30006
eval/env_infos/final/reward_run Std           0.622615
eval/env_infos/final/reward_run Max           6.32896
eval/env_infos/final/reward_run Min           4.42469
eval/env_infos/initial/reward_run Mean       -0.271888
eval/env_infos/initial/reward_run Std         0.452931
eval/env_infos/initial/reward_run Max         0.254922
eval/env_infos/initial/reward_run Min        -0.807691
eval/env_infos/reward_run Mean                5.28834
eval/env_infos/reward_run Std                 1.25813
eval/env_infos/reward_run Max                 8.27628
eval/env_infos/reward_run Min                -0.807691
eval/env_infos/final/reward_ctrl Mean        -0.456709
eval/env_infos/final/reward_ctrl Std          0.0785611
eval/env_infos/final/reward_ctrl Max         -0.33424
eval/env_infos/final/reward_ctrl Min         -0.540289
eval/env_infos/initial/reward_ctrl Mean      -0.249703
eval/env_infos/initial/reward_ctrl Std        0.114136
eval/env_infos/initial/reward_ctrl Max       -0.115453
eval/env_infos/initial/reward_ctrl Min       -0.446505
eval/env_infos/reward_ctrl Mean              -0.428792
eval/env_infos/reward_ctrl Std                0.078412
eval/env_infos/reward_ctrl Max               -0.115453
eval/env_infos/reward_ctrl Min               -0.570274
time/data storing (s)                         0.00449034
time/evaluation sampling (s)                  2.03079
time/exploration sampling (s)                 0.532338
time/logging (s)                              0.0142894
time/sac training (s)                         7.80619
time/saving (s)                               0.00388395
time/training (s)                             4.7956e-05
time/epoch (s)                               10.392
time/total (s)                             1588.37
Epoch                                       147
---------------------------------------  ---------------
2021-11-24 00:55:51.924647 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 148 finished
---------------------------------------  ---------------
epoch                                       148
replay_buffer/size                       150000
trainer/num train calls                  149000
trainer/QF1 Loss                              9.45373
trainer/QF2 Loss                              7.97161
trainer/Policy Loss                        -260.036
trainer/Q1 Predictions Mean                 260.263
trainer/Q1 Predictions Std                  101.023
trainer/Q1 Predictions Max                  359.997
trainer/Q1 Predictions Min                   12.3454
trainer/Q2 Predictions Mean                 260.597
trainer/Q2 Predictions Std                  101.244
trainer/Q2 Predictions Max                  359.821
trainer/Q2 Predictions Min                   12.0227
trainer/Q Targets Mean                      260.599
trainer/Q Targets Std                       101.219
trainer/Q Targets Max                       363.213
trainer/Q Targets Min                        12.0352
trainer/Log Pis Mean                          6.226
trainer/Log Pis Std                           5.08875
trainer/Log Pis Max                          18.8757
trainer/Log Pis Min                          -4.96908
trainer/policy/mean Mean                      0.051681
trainer/policy/mean Std                       0.781314
trainer/policy/mean Max                       0.999283
trainer/policy/mean Min                      -0.998018
trainer/policy/normal/std Mean                0.454634
trainer/policy/normal/std Std                 0.144872
trainer/policy/normal/std Max                 1.0365
trainer/policy/normal/std Min                 0.103039
trainer/policy/normal/log_std Mean           -0.849374
trainer/policy/normal/log_std Std             0.373472
trainer/policy/normal/log_std Max             0.0358481
trainer/policy/normal/log_std Min            -2.27265
trainer/Alpha                                 0.103915
trainer/Alpha Loss                            0.51171
expl/num steps total                     150000
expl/num paths total                        150
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.70539
expl/Rewards Std                              1.19835
expl/Rewards Max                              7.11745
expl/Rewards Min                             -0.988242
expl/Returns Mean                          4705.39
expl/Returns Std                              0
expl/Returns Max                           4705.39
expl/Returns Min                           4705.39
expl/Actions Mean                             0.0573245
expl/Actions Std                              0.826487
expl/Actions Max                              0.999756
expl/Actions Min                             -0.999529
expl/Num Paths                                1
expl/Average Returns                       4705.39
expl/env_infos/final/reward_run Mean          5.69448
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.69448
expl/env_infos/final/reward_run Min           5.69448
expl/env_infos/initial/reward_run Mean       -0.676838
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.676838
expl/env_infos/initial/reward_run Min        -0.676838
expl/env_infos/reward_run Mean                5.11721
expl/env_infos/reward_run Std                 1.18858
expl/env_infos/reward_run Max                 7.59204
expl/env_infos/reward_run Min                -0.676838
expl/env_infos/final/reward_ctrl Mean        -0.352254
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.352254
expl/env_infos/final/reward_ctrl Min         -0.352254
expl/env_infos/initial/reward_ctrl Mean      -0.299036
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.299036
expl/env_infos/initial/reward_ctrl Min       -0.299036
expl/env_infos/reward_ctrl Mean              -0.41182
expl/env_infos/reward_ctrl Std                0.082377
expl/env_infos/reward_ctrl Max               -0.12569
expl/env_infos/reward_ctrl Min               -0.57364
eval/num steps total                     745000
eval/num paths total                        745
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.92194
eval/Rewards Std                              1.2467
eval/Rewards Max                              7.41226
eval/Rewards Min                             -1.1135
eval/Returns Mean                          4921.94
eval/Returns Std                            123.125
eval/Returns Max                           5093.5
eval/Returns Min                           4733.35
eval/Actions Mean                             0.0582889
eval/Actions Std                              0.837643
eval/Actions Max                              0.999433
eval/Actions Min                             -0.999234
eval/Num Paths                                5
eval/Average Returns                       4921.94
eval/env_infos/final/reward_run Mean          5.97081
eval/env_infos/final/reward_run Std           0.905292
eval/env_infos/final/reward_run Max           7.08315
eval/env_infos/final/reward_run Min           4.99852
eval/env_infos/initial/reward_run Mean       -0.445942
eval/env_infos/initial/reward_run Std         0.232045
eval/env_infos/initial/reward_run Max        -0.0821642
eval/env_infos/initial/reward_run Min        -0.746154
eval/env_infos/reward_run Mean                5.34496
eval/env_infos/reward_run Std                 1.23484
eval/env_infos/reward_run Max                 7.92239
eval/env_infos/reward_run Min                -0.746154
eval/env_infos/final/reward_ctrl Mean        -0.485047
eval/env_infos/final/reward_ctrl Std          0.0483936
eval/env_infos/final/reward_ctrl Max         -0.434248
eval/env_infos/final/reward_ctrl Min         -0.563405
eval/env_infos/initial/reward_ctrl Mean      -0.302989
eval/env_infos/initial/reward_ctrl Std        0.0848632
eval/env_infos/initial/reward_ctrl Max       -0.216837
eval/env_infos/initial/reward_ctrl Min       -0.437172
eval/env_infos/reward_ctrl Mean              -0.423026
eval/env_infos/reward_ctrl Std                0.0784947
eval/env_infos/reward_ctrl Max               -0.126692
eval/env_infos/reward_ctrl Min               -0.578212
time/data storing (s)                         0.00455165
time/evaluation sampling (s)                  2.32568
time/exploration sampling (s)                 0.545521
time/logging (s)                              0.0140001
time/sac training (s)                         7.94919
time/saving (s)                               0.00438994
time/training (s)                             4.1678e-05
time/epoch (s)                               10.8434
time/total (s)                             1599.55
Epoch                                       148
---------------------------------------  ---------------
2021-11-24 00:56:02.888567 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 149 finished
---------------------------------------  ---------------
epoch                                       149
replay_buffer/size                       151000
trainer/num train calls                  150000
trainer/QF1 Loss                              7.56309
trainer/QF2 Loss                              7.04297
trainer/Policy Loss                        -263.111
trainer/Q1 Predictions Mean                 263.317
trainer/Q1 Predictions Std                  102.059
trainer/Q1 Predictions Max                  360.361
trainer/Q1 Predictions Min                   10.7919
trainer/Q2 Predictions Mean                 263.61
trainer/Q2 Predictions Std                  102.151
trainer/Q2 Predictions Max                  363.607
trainer/Q2 Predictions Min                   11.4622
trainer/Q Targets Mean                      262.89
trainer/Q Targets Std                       101.938
trainer/Q Targets Max                       362.113
trainer/Q Targets Min                        10.6736
trainer/Log Pis Mean                          6.35281
trainer/Log Pis Std                           4.9326
trainer/Log Pis Max                          19.7318
trainer/Log Pis Min                          -6.2553
trainer/policy/mean Mean                      0.0301854
trainer/policy/mean Std                       0.785095
trainer/policy/mean Max                       0.998928
trainer/policy/mean Min                      -0.998852
trainer/policy/normal/std Mean                0.455794
trainer/policy/normal/std Std                 0.149482
trainer/policy/normal/std Max                 0.891872
trainer/policy/normal/std Min                 0.0885334
trainer/policy/normal/log_std Mean           -0.850179
trainer/policy/normal/log_std Std             0.383605
trainer/policy/normal/log_std Max            -0.114433
trainer/policy/normal/log_std Min            -2.42437
trainer/Alpha                                 0.104111
trainer/Alpha Loss                            0.798151
expl/num steps total                     151000
expl/num paths total                        151
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.77699
expl/Rewards Std                              1.15646
expl/Rewards Max                              6.98456
expl/Rewards Min                             -0.486342
expl/Returns Mean                          4776.99
expl/Returns Std                              0
expl/Returns Max                           4776.99
expl/Returns Min                           4776.99
expl/Actions Mean                             0.0321657
expl/Actions Std                              0.830598
expl/Actions Max                              0.999541
expl/Actions Min                             -0.999893
expl/Num Paths                                1
expl/Average Returns                       4776.99
expl/env_infos/final/reward_run Mean          6.0227
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.0227
expl/env_infos/final/reward_run Min           6.0227
expl/env_infos/initial/reward_run Mean       -0.290239
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.290239
expl/env_infos/initial/reward_run Min        -0.290239
expl/env_infos/reward_run Mean                5.19155
expl/env_infos/reward_run Std                 1.14941
expl/env_infos/reward_run Max                 7.43785
expl/env_infos/reward_run Min                -0.290239
expl/env_infos/final/reward_ctrl Mean        -0.301275
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.301275
expl/env_infos/final/reward_ctrl Min         -0.301275
expl/env_infos/initial/reward_ctrl Mean      -0.154207
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.154207
expl/env_infos/initial/reward_ctrl Min       -0.154207
expl/env_infos/reward_ctrl Mean              -0.414557
expl/env_infos/reward_ctrl Std                0.0827122
expl/env_infos/reward_ctrl Max               -0.149115
expl/env_infos/reward_ctrl Min               -0.584143
eval/num steps total                     750000
eval/num paths total                        750
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.06964
eval/Rewards Std                              1.22539
eval/Rewards Max                              7.48693
eval/Rewards Min                             -1.20513
eval/Returns Mean                          5069.64
eval/Returns Std                             85.7834
eval/Returns Max                           5185.22
eval/Returns Min                           4961.8
eval/Actions Mean                             0.0274959
eval/Actions Std                              0.84754
eval/Actions Max                              0.999869
eval/Actions Min                             -0.999227
eval/Num Paths                                5
eval/Average Returns                       5069.64
eval/env_infos/final/reward_run Mean          5.2742
eval/env_infos/final/reward_run Std           0.464006
eval/env_infos/final/reward_run Max           5.87132
eval/env_infos/final/reward_run Min           4.79496
eval/env_infos/initial/reward_run Mean       -0.362832
eval/env_infos/initial/reward_run Std         0.25733
eval/env_infos/initial/reward_run Max        -0.111157
eval/env_infos/initial/reward_run Min        -0.800415
eval/env_infos/reward_run Mean                5.50108
eval/env_infos/reward_run Std                 1.21714
eval/env_infos/reward_run Max                 8.00548
eval/env_infos/reward_run Min                -0.800415
eval/env_infos/final/reward_ctrl Mean        -0.478253
eval/env_infos/final/reward_ctrl Std          0.0362704
eval/env_infos/final/reward_ctrl Max         -0.428146
eval/env_infos/final/reward_ctrl Min         -0.520432
eval/env_infos/initial/reward_ctrl Mean      -0.2664
eval/env_infos/initial/reward_ctrl Std        0.0930798
eval/env_infos/initial/reward_ctrl Max       -0.149437
eval/env_infos/initial/reward_ctrl Min       -0.404716
eval/env_infos/reward_ctrl Mean              -0.431448
eval/env_infos/reward_ctrl Std                0.0760352
eval/env_infos/reward_ctrl Max               -0.143212
eval/env_infos/reward_ctrl Min               -0.581576
time/data storing (s)                         0.00533198
time/evaluation sampling (s)                  2.0791
time/exploration sampling (s)                 0.5559
time/logging (s)                              0.0138034
time/sac training (s)                         7.96128
time/saving (s)                               0.00384598
time/training (s)                             3.5371e-05
time/epoch (s)                               10.6193
time/total (s)                             1610.5
Epoch                                       149
---------------------------------------  ---------------
2021-11-24 00:56:13.946353 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 150 finished
---------------------------------------  ---------------
epoch                                       150
replay_buffer/size                       152000
trainer/num train calls                  151000
trainer/QF1 Loss                              7.55653
trainer/QF2 Loss                              6.61089
trainer/Policy Loss                        -267.602
trainer/Q1 Predictions Mean                 268.254
trainer/Q1 Predictions Std                  100.479
trainer/Q1 Predictions Max                  357.98
trainer/Q1 Predictions Min                   12.0689
trainer/Q2 Predictions Mean                 268.046
trainer/Q2 Predictions Std                  100.385
trainer/Q2 Predictions Max                  359.859
trainer/Q2 Predictions Min                   11.8807
trainer/Q Targets Mean                      267.484
trainer/Q Targets Std                       100.184
trainer/Q Targets Max                       357.6
trainer/Q Targets Min                        13.0496
trainer/Log Pis Mean                          6.35571
trainer/Log Pis Std                           4.97621
trainer/Log Pis Max                          19.0282
trainer/Log Pis Min                          -7.00299
trainer/policy/mean Mean                      0.0582703
trainer/policy/mean Std                       0.777129
trainer/policy/mean Max                       0.998816
trainer/policy/mean Min                      -0.999231
trainer/policy/normal/std Mean                0.458346
trainer/policy/normal/std Std                 0.150071
trainer/policy/normal/std Max                 1.11707
trainer/policy/normal/std Min                 0.104263
trainer/policy/normal/log_std Mean           -0.843341
trainer/policy/normal/log_std Std             0.37765
trainer/policy/normal/log_std Max             0.110713
trainer/policy/normal/log_std Min            -2.26084
trainer/Alpha                                 0.105386
trainer/Alpha Loss                            0.800386
expl/num steps total                     152000
expl/num paths total                        152
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.89228
expl/Rewards Std                              1.24455
expl/Rewards Max                              7.1912
expl/Rewards Min                             -0.734111
expl/Returns Mean                          4892.28
expl/Returns Std                              0
expl/Returns Max                           4892.28
expl/Returns Min                           4892.28
expl/Actions Mean                             0.0517257
expl/Actions Std                              0.831081
expl/Actions Max                              0.999332
expl/Actions Min                             -0.999825
expl/Num Paths                                1
expl/Average Returns                       4892.28
expl/env_infos/final/reward_run Mean          4.8223
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.8223
expl/env_infos/final/reward_run Min           4.8223
expl/env_infos/initial/reward_run Mean       -0.43966
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.43966
expl/env_infos/initial/reward_run Min        -0.43966
expl/env_infos/reward_run Mean                5.3083
expl/env_infos/reward_run Std                 1.23733
expl/env_infos/reward_run Max                 7.6257
expl/env_infos/reward_run Min                -0.43966
expl/env_infos/final/reward_ctrl Mean        -0.330775
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.330775
expl/env_infos/final/reward_ctrl Min         -0.330775
expl/env_infos/initial/reward_ctrl Mean      -0.159824
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.159824
expl/env_infos/initial/reward_ctrl Min       -0.159824
expl/env_infos/reward_ctrl Mean              -0.416023
expl/env_infos/reward_ctrl Std                0.082314
expl/env_infos/reward_ctrl Max               -0.113281
expl/env_infos/reward_ctrl Min               -0.57825
eval/num steps total                     755000
eval/num paths total                        755
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.0138
eval/Rewards Std                              1.22316
eval/Rewards Max                              7.46533
eval/Rewards Min                             -1.05561
eval/Returns Mean                          5013.8
eval/Returns Std                             14.9595
eval/Returns Max                           5033.01
eval/Returns Min                           4988.14
eval/Actions Mean                             0.0542627
eval/Actions Std                              0.844279
eval/Actions Max                              0.999498
eval/Actions Min                             -0.998027
eval/Num Paths                                5
eval/Average Returns                       5013.8
eval/env_infos/final/reward_run Mean          5.22488
eval/env_infos/final/reward_run Std           1.52469
eval/env_infos/final/reward_run Max           7.1572
eval/env_infos/final/reward_run Min           3.56532
eval/env_infos/initial/reward_run Mean       -0.30802
eval/env_infos/initial/reward_run Std         0.191985
eval/env_infos/initial/reward_run Max        -0.059006
eval/env_infos/initial/reward_run Min        -0.651806
eval/env_infos/reward_run Mean                5.44326
eval/env_infos/reward_run Std                 1.20468
eval/env_infos/reward_run Max                 7.95503
eval/env_infos/reward_run Min                -0.651806
eval/env_infos/final/reward_ctrl Mean        -0.514264
eval/env_infos/final/reward_ctrl Std          0.0615487
eval/env_infos/final/reward_ctrl Max         -0.398596
eval/env_infos/final/reward_ctrl Min         -0.568687
eval/env_infos/initial/reward_ctrl Mean      -0.256049
eval/env_infos/initial/reward_ctrl Std        0.0809781
eval/env_infos/initial/reward_ctrl Max       -0.18875
eval/env_infos/initial/reward_ctrl Min       -0.403807
eval/env_infos/reward_ctrl Mean              -0.429451
eval/env_infos/reward_ctrl Std                0.0747167
eval/env_infos/reward_ctrl Max               -0.136799
eval/env_infos/reward_ctrl Min               -0.584182
time/data storing (s)                         0.00448394
time/evaluation sampling (s)                  2.12179
time/exploration sampling (s)                 0.553321
time/logging (s)                              0.0138865
time/sac training (s)                         8.011
time/saving (s)                               0.00438709
time/training (s)                             5.0392e-05
time/epoch (s)                               10.7089
time/total (s)                             1621.54
Epoch                                       150
---------------------------------------  ---------------
2021-11-24 00:56:25.056036 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 151 finished
---------------------------------------  ---------------
epoch                                       151
replay_buffer/size                       153000
trainer/num train calls                  152000
trainer/QF1 Loss                              8.79505
trainer/QF2 Loss                              6.40981
trainer/Policy Loss                        -261.113
trainer/Q1 Predictions Mean                 261.147
trainer/Q1 Predictions Std                   97.7307
trainer/Q1 Predictions Max                  345.89
trainer/Q1 Predictions Min                   11.9233
trainer/Q2 Predictions Mean                 261.348
trainer/Q2 Predictions Std                   97.8385
trainer/Q2 Predictions Max                  346.649
trainer/Q2 Predictions Min                   11.8194
trainer/Q Targets Mean                      261.088
trainer/Q Targets Std                        97.7678
trainer/Q Targets Max                       347
trainer/Q Targets Min                        11.459
trainer/Log Pis Mean                          6.07546
trainer/Log Pis Std                           5.09244
trainer/Log Pis Max                          19.3561
trainer/Log Pis Min                          -5.91314
trainer/policy/mean Mean                      0.0418099
trainer/policy/mean Std                       0.764698
trainer/policy/mean Max                       0.99984
trainer/policy/mean Min                      -0.99841
trainer/policy/normal/std Mean                0.463747
trainer/policy/normal/std Std                 0.152414
trainer/policy/normal/std Max                 1.04044
trainer/policy/normal/std Min                 0.106198
trainer/policy/normal/log_std Mean           -0.832047
trainer/policy/normal/log_std Std             0.379327
trainer/policy/normal/log_std Max             0.0396478
trainer/policy/normal/log_std Min            -2.24245
trainer/Alpha                                 0.104889
trainer/Alpha Loss                            0.170145
expl/num steps total                     153000
expl/num paths total                        153
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.66349
expl/Rewards Std                              1.23384
expl/Rewards Max                              6.93335
expl/Rewards Min                             -0.7856
expl/Returns Mean                          4663.49
expl/Returns Std                              0
expl/Returns Max                           4663.49
expl/Returns Min                           4663.49
expl/Actions Mean                             0.0294504
expl/Actions Std                              0.825246
expl/Actions Max                              0.999762
expl/Actions Min                             -0.999702
expl/Num Paths                                1
expl/Average Returns                       4663.49
expl/env_infos/final/reward_run Mean          4.9908
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.9908
expl/env_infos/final/reward_run Min           4.9908
expl/env_infos/initial/reward_run Mean       -0.462466
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.462466
expl/env_infos/initial/reward_run Min        -0.462466
expl/env_infos/reward_run Mean                5.07263
expl/env_infos/reward_run Std                 1.22535
expl/env_infos/reward_run Max                 7.41769
expl/env_infos/reward_run Min                -0.462466
expl/env_infos/final/reward_ctrl Mean        -0.383718
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.383718
expl/env_infos/final/reward_ctrl Min         -0.383718
expl/env_infos/initial/reward_ctrl Mean      -0.323134
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.323134
expl/env_infos/initial/reward_ctrl Min       -0.323134
expl/env_infos/reward_ctrl Mean              -0.409139
expl/env_infos/reward_ctrl Std                0.0883588
expl/env_infos/reward_ctrl Max               -0.042242
expl/env_infos/reward_ctrl Min               -0.575898
eval/num steps total                     760000
eval/num paths total                        760
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.97639
eval/Rewards Std                              1.25274
eval/Rewards Max                              7.41536
eval/Rewards Min                             -1.26782
eval/Returns Mean                          4976.39
eval/Returns Std                            147.755
eval/Returns Max                           5143.59
eval/Returns Min                           4729.07
eval/Actions Mean                             0.030842
eval/Actions Std                              0.84418
eval/Actions Max                              0.998765
eval/Actions Min                             -0.999422
eval/Num Paths                                5
eval/Average Returns                       4976.39
eval/env_infos/final/reward_run Mean          6.13759
eval/env_infos/final/reward_run Std           0.657495
eval/env_infos/final/reward_run Max           6.6872
eval/env_infos/final/reward_run Min           4.88786
eval/env_infos/initial/reward_run Mean       -0.369249
eval/env_infos/initial/reward_run Std         0.3705
eval/env_infos/initial/reward_run Max         0.196095
eval/env_infos/initial/reward_run Min        -0.886077
eval/env_infos/reward_run Mean                5.40454
eval/env_infos/reward_run Std                 1.23795
eval/env_infos/reward_run Max                 7.9005
eval/env_infos/reward_run Min                -0.886077
eval/env_infos/final/reward_ctrl Mean        -0.405126
eval/env_infos/final/reward_ctrl Std          0.0923186
eval/env_infos/final/reward_ctrl Max         -0.287539
eval/env_infos/final/reward_ctrl Min         -0.513398
eval/env_infos/initial/reward_ctrl Mean      -0.272029
eval/env_infos/initial/reward_ctrl Std        0.0903692
eval/env_infos/initial/reward_ctrl Max       -0.162787
eval/env_infos/initial/reward_ctrl Min       -0.381744
eval/env_infos/reward_ctrl Mean              -0.428154
eval/env_infos/reward_ctrl Std                0.079224
eval/env_infos/reward_ctrl Max               -0.140036
eval/env_infos/reward_ctrl Min               -0.584544
time/data storing (s)                         0.00638252
time/evaluation sampling (s)                  2.08818
time/exploration sampling (s)                 0.645968
time/logging (s)                              0.013609
time/sac training (s)                         8.00019
time/saving (s)                               0.00384293
time/training (s)                             3.4475e-05
time/epoch (s)                               10.7582
time/total (s)                             1632.63
Epoch                                       151
---------------------------------------  ---------------
2021-11-24 00:56:36.010152 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 152 finished
---------------------------------------  ---------------
epoch                                       152
replay_buffer/size                       154000
trainer/num train calls                  153000
trainer/QF1 Loss                              7.14961
trainer/QF2 Loss                              6.46331
trainer/Policy Loss                        -252.206
trainer/Q1 Predictions Mean                 252.569
trainer/Q1 Predictions Std                  110.34
trainer/Q1 Predictions Max                  358.129
trainer/Q1 Predictions Min                   12.1593
trainer/Q2 Predictions Mean                 252.438
trainer/Q2 Predictions Std                  110.202
trainer/Q2 Predictions Max                  358.953
trainer/Q2 Predictions Min                   12.3119
trainer/Q Targets Mean                      252.096
trainer/Q Targets Std                       110.182
trainer/Q Targets Max                       361.633
trainer/Q Targets Min                        12.0222
trainer/Log Pis Mean                          5.84185
trainer/Log Pis Std                           4.87429
trainer/Log Pis Max                          22.6398
trainer/Log Pis Min                          -5.34504
trainer/policy/mean Mean                      0.0344067
trainer/policy/mean Std                       0.764476
trainer/policy/mean Max                       0.999827
trainer/policy/mean Min                      -0.999521
trainer/policy/normal/std Mean                0.46932
trainer/policy/normal/std Std                 0.153732
trainer/policy/normal/std Max                 0.983946
trainer/policy/normal/std Min                 0.102066
trainer/policy/normal/log_std Mean           -0.819273
trainer/policy/normal/log_std Std             0.374736
trainer/policy/normal/log_std Max            -0.0161845
trainer/policy/normal/log_std Min            -2.28214
trainer/Alpha                                 0.104503
trainer/Alpha Loss                           -0.35718
expl/num steps total                     154000
expl/num paths total                        154
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.79325
expl/Rewards Std                              1.16062
expl/Rewards Max                              7.07709
expl/Rewards Min                             -0.303595
expl/Returns Mean                          4793.25
expl/Returns Std                              0
expl/Returns Max                           4793.25
expl/Returns Min                           4793.25
expl/Actions Mean                             0.0217498
expl/Actions Std                              0.822573
expl/Actions Max                              0.999581
expl/Actions Min                             -0.999217
expl/Num Paths                                1
expl/Average Returns                       4793.25
expl/env_infos/final/reward_run Mean          6.51771
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.51771
expl/env_infos/final/reward_run Min           6.51771
expl/env_infos/initial/reward_run Mean       -0.0230584
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0230584
expl/env_infos/initial/reward_run Min        -0.0230584
expl/env_infos/reward_run Mean                5.19951
expl/env_infos/reward_run Std                 1.14862
expl/env_infos/reward_run Max                 7.5908
expl/env_infos/reward_run Min                -0.0230584
expl/env_infos/final/reward_ctrl Mean        -0.423126
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.423126
expl/env_infos/final/reward_ctrl Min         -0.423126
expl/env_infos/initial/reward_ctrl Mean      -0.180237
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.180237
expl/env_infos/initial/reward_ctrl Min       -0.180237
expl/env_infos/reward_ctrl Mean              -0.40626
expl/env_infos/reward_ctrl Std                0.0831157
expl/env_infos/reward_ctrl Max               -0.13189
expl/env_infos/reward_ctrl Min               -0.574216
eval/num steps total                     765000
eval/num paths total                        765
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.90227
eval/Rewards Std                              1.20395
eval/Rewards Max                              7.56353
eval/Rewards Min                             -0.969488
eval/Returns Mean                          4902.27
eval/Returns Std                            110.972
eval/Returns Max                           5085.01
eval/Returns Min                           4792.98
eval/Actions Mean                             0.030574
eval/Actions Std                              0.839694
eval/Actions Max                              0.99865
eval/Actions Min                             -0.998974
eval/Num Paths                                5
eval/Average Returns                       4902.27
eval/env_infos/final/reward_run Mean          4.7413
eval/env_infos/final/reward_run Std           0.472962
eval/env_infos/final/reward_run Max           5.38768
eval/env_infos/final/reward_run Min           4.19229
eval/env_infos/initial/reward_run Mean       -0.393822
eval/env_infos/initial/reward_run Std         0.192368
eval/env_infos/initial/reward_run Max        -0.0252814
eval/env_infos/initial/reward_run Min        -0.551814
eval/env_infos/reward_run Mean                5.32588
eval/env_infos/reward_run Std                 1.18684
eval/env_infos/reward_run Max                 8.08356
eval/env_infos/reward_run Min                -0.551814
eval/env_infos/final/reward_ctrl Mean        -0.49051
eval/env_infos/final/reward_ctrl Std          0.0444265
eval/env_infos/final/reward_ctrl Max         -0.442972
eval/env_infos/final/reward_ctrl Min         -0.565745
eval/env_infos/initial/reward_ctrl Mean      -0.344927
eval/env_infos/initial/reward_ctrl Std        0.0855521
eval/env_infos/initial/reward_ctrl Max       -0.180612
eval/env_infos/initial/reward_ctrl Min       -0.426054
eval/env_infos/reward_ctrl Mean              -0.423613
eval/env_infos/reward_ctrl Std                0.0772523
eval/env_infos/reward_ctrl Max               -0.113086
eval/env_infos/reward_ctrl Min               -0.580736
time/data storing (s)                         0.00450183
time/evaluation sampling (s)                  2.0588
time/exploration sampling (s)                 0.531936
time/logging (s)                              0.0156189
time/sac training (s)                         7.99921
time/saving (s)                               0.00397169
time/training (s)                             6.4457e-05
time/epoch (s)                               10.6141
time/total (s)                             1643.57
Epoch                                       152
---------------------------------------  ---------------
2021-11-24 00:56:46.961536 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 153 finished
---------------------------------------  ---------------
epoch                                       153
replay_buffer/size                       155000
trainer/num train calls                  154000
trainer/QF1 Loss                             10.2657
trainer/QF2 Loss                              7.73187
trainer/Policy Loss                        -282.153
trainer/Q1 Predictions Mean                 282.995
trainer/Q1 Predictions Std                   84.0105
trainer/Q1 Predictions Max                  358.859
trainer/Q1 Predictions Min                   12.6608
trainer/Q2 Predictions Mean                 282.595
trainer/Q2 Predictions Std                   83.8941
trainer/Q2 Predictions Max                  359.676
trainer/Q2 Predictions Min                   12.3857
trainer/Q Targets Mean                      282.984
trainer/Q Targets Std                        84.0014
trainer/Q Targets Max                       356.719
trainer/Q Targets Min                        12.5254
trainer/Log Pis Mean                          6.4022
trainer/Log Pis Std                           4.80082
trainer/Log Pis Max                          19.9281
trainer/Log Pis Min                          -5.04615
trainer/policy/mean Mean                      0.0380789
trainer/policy/mean Std                       0.785777
trainer/policy/mean Max                       0.999312
trainer/policy/mean Min                      -0.998564
trainer/policy/normal/std Mean                0.442076
trainer/policy/normal/std Std                 0.140242
trainer/policy/normal/std Max                 1.31387
trainer/policy/normal/std Min                 0.102484
trainer/policy/normal/log_std Mean           -0.874626
trainer/policy/normal/log_std Std             0.361863
trainer/policy/normal/log_std Max             0.272977
trainer/policy/normal/log_std Min            -2.27805
trainer/Alpha                                 0.104063
trainer/Alpha Loss                            0.910093
expl/num steps total                     155000
expl/num paths total                        155
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.51265
expl/Rewards Std                              1.15976
expl/Rewards Max                              6.78927
expl/Rewards Min                             -0.845365
expl/Returns Mean                          4512.65
expl/Returns Std                              0
expl/Returns Max                           4512.65
expl/Returns Min                           4512.65
expl/Actions Mean                             0.0223721
expl/Actions Std                              0.817413
expl/Actions Max                              0.999809
expl/Actions Min                             -0.999626
expl/Num Paths                                1
expl/Average Returns                       4512.65
expl/env_infos/final/reward_run Mean          4.70942
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.70942
expl/env_infos/final/reward_run Min           4.70942
expl/env_infos/initial/reward_run Mean       -0.53248
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.53248
expl/env_infos/initial/reward_run Min        -0.53248
expl/env_infos/reward_run Mean                4.91385
expl/env_infos/reward_run Std                 1.14492
expl/env_infos/reward_run Max                 7.25429
expl/env_infos/reward_run Min                -0.53248
expl/env_infos/final/reward_ctrl Mean        -0.317207
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.317207
expl/env_infos/final/reward_ctrl Min         -0.317207
expl/env_infos/initial/reward_ctrl Mean      -0.252249
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.252249
expl/env_infos/initial/reward_ctrl Min       -0.252249
expl/env_infos/reward_ctrl Mean              -0.401199
expl/env_infos/reward_ctrl Std                0.0902301
expl/env_infos/reward_ctrl Max               -0.0986965
expl/env_infos/reward_ctrl Min               -0.58621
eval/num steps total                     770000
eval/num paths total                        770
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.97449
eval/Rewards Std                              1.18014
eval/Rewards Max                              7.34113
eval/Rewards Min                             -0.961941
eval/Returns Mean                          4974.49
eval/Returns Std                             87.8868
eval/Returns Max                           5076.89
eval/Returns Min                           4818.53
eval/Actions Mean                             0.0155435
eval/Actions Std                              0.837476
eval/Actions Max                              0.997975
eval/Actions Min                             -0.998647
eval/Num Paths                                5
eval/Average Returns                       4974.49
eval/env_infos/final/reward_run Mean          5.12612
eval/env_infos/final/reward_run Std           0.975377
eval/env_infos/final/reward_run Max           6.99951
eval/env_infos/final/reward_run Min           4.17003
eval/env_infos/initial/reward_run Mean       -0.280504
eval/env_infos/initial/reward_run Std         0.294389
eval/env_infos/initial/reward_run Max         0.168669
eval/env_infos/initial/reward_run Min        -0.649422
eval/env_infos/reward_run Mean                5.39545
eval/env_infos/reward_run Std                 1.16417
eval/env_infos/reward_run Max                 7.84573
eval/env_infos/reward_run Min                -0.649422
eval/env_infos/final/reward_ctrl Mean        -0.471671
eval/env_infos/final/reward_ctrl Std          0.0577843
eval/env_infos/final/reward_ctrl Max         -0.36071
eval/env_infos/final/reward_ctrl Min         -0.518976
eval/env_infos/initial/reward_ctrl Mean      -0.246814
eval/env_infos/initial/reward_ctrl Std        0.0429862
eval/env_infos/initial/reward_ctrl Max       -0.185232
eval/env_infos/initial/reward_ctrl Min       -0.312519
eval/env_infos/reward_ctrl Mean              -0.420965
eval/env_infos/reward_ctrl Std                0.086719
eval/env_infos/reward_ctrl Max               -0.153207
eval/env_infos/reward_ctrl Min               -0.584968
time/data storing (s)                         0.00453279
time/evaluation sampling (s)                  2.08051
time/exploration sampling (s)                 0.557131
time/logging (s)                              0.0137307
time/sac training (s)                         7.94421
time/saving (s)                               0.00383733
time/training (s)                             3.5368e-05
time/epoch (s)                               10.604
time/total (s)                             1654.51
Epoch                                       153
---------------------------------------  ---------------
2021-11-24 00:56:57.736420 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 154 finished
---------------------------------------  ---------------
epoch                                       154
replay_buffer/size                       156000
trainer/num train calls                  155000
trainer/QF1 Loss                              7.46817
trainer/QF2 Loss                              5.83358
trainer/Policy Loss                        -273.255
trainer/Q1 Predictions Mean                 274.207
trainer/Q1 Predictions Std                   96.8812
trainer/Q1 Predictions Max                  356.117
trainer/Q1 Predictions Min                   11.1524
trainer/Q2 Predictions Mean                 273.694
trainer/Q2 Predictions Std                   96.7722
trainer/Q2 Predictions Max                  357.106
trainer/Q2 Predictions Min                   11.5615
trainer/Q Targets Mean                      274.053
trainer/Q Targets Std                        96.8616
trainer/Q Targets Max                       358.413
trainer/Q Targets Min                        10.6901
trainer/Log Pis Mean                          5.99215
trainer/Log Pis Std                           4.99539
trainer/Log Pis Max                          17.8008
trainer/Log Pis Min                          -6.75235
trainer/policy/mean Mean                      0.0395312
trainer/policy/mean Std                       0.773218
trainer/policy/mean Max                       0.999562
trainer/policy/mean Min                      -0.997796
trainer/policy/normal/std Mean                0.458
trainer/policy/normal/std Std                 0.146559
trainer/policy/normal/std Max                 1.17432
trainer/policy/normal/std Min                 0.0907104
trainer/policy/normal/log_std Mean           -0.842044
trainer/policy/normal/log_std Std             0.373688
trainer/policy/normal/log_std Max             0.160692
trainer/policy/normal/log_std Min            -2.40008
trainer/Alpha                                 0.104168
trainer/Alpha Loss                           -0.0177482
expl/num steps total                     156000
expl/num paths total                        156
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.02592
expl/Rewards Std                              1.21205
expl/Rewards Max                              7.19802
expl/Rewards Min                             -0.784869
expl/Returns Mean                          5025.92
expl/Returns Std                              0
expl/Returns Max                           5025.92
expl/Returns Min                           5025.92
expl/Actions Mean                             0.0697455
expl/Actions Std                              0.825515
expl/Actions Max                              0.999632
expl/Actions Min                             -0.999811
expl/Num Paths                                1
expl/Average Returns                       5025.92
expl/env_infos/final/reward_run Mean          5.83473
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.83473
expl/env_infos/final/reward_run Min           5.83473
expl/env_infos/initial/reward_run Mean       -0.471964
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.471964
expl/env_infos/initial/reward_run Min        -0.471964
expl/env_infos/reward_run Mean                5.43772
expl/env_infos/reward_run Std                 1.20288
expl/env_infos/reward_run Max                 7.62086
expl/env_infos/reward_run Min                -0.471964
expl/env_infos/final/reward_ctrl Mean        -0.393207
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.393207
expl/env_infos/final/reward_ctrl Min         -0.393207
expl/env_infos/initial/reward_ctrl Mean      -0.312905
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.312905
expl/env_infos/initial/reward_ctrl Min       -0.312905
expl/env_infos/reward_ctrl Mean              -0.411804
expl/env_infos/reward_ctrl Std                0.0819779
expl/env_infos/reward_ctrl Max               -0.144043
expl/env_infos/reward_ctrl Min               -0.583664
eval/num steps total                     775000
eval/num paths total                        775
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.97632
eval/Rewards Std                              1.25861
eval/Rewards Max                              7.72373
eval/Rewards Min                             -1.13351
eval/Returns Mean                          4976.32
eval/Returns Std                            102.065
eval/Returns Max                           5124.25
eval/Returns Min                           4863.67
eval/Actions Mean                             0.0748538
eval/Actions Std                              0.836348
eval/Actions Max                              0.999383
eval/Actions Min                             -0.998644
eval/Num Paths                                5
eval/Average Returns                       4976.32
eval/env_infos/final/reward_run Mean          5.98308
eval/env_infos/final/reward_run Std           0.91981
eval/env_infos/final/reward_run Max           7.02143
eval/env_infos/final/reward_run Min           4.42044
eval/env_infos/initial/reward_run Mean       -0.503543
eval/env_infos/initial/reward_run Std         0.200366
eval/env_infos/initial/reward_run Max        -0.209133
eval/env_infos/initial/reward_run Min        -0.73668
eval/env_infos/reward_run Mean                5.39937
eval/env_infos/reward_run Std                 1.2486
eval/env_infos/reward_run Max                 8.24546
eval/env_infos/reward_run Min                -0.73668
eval/env_infos/final/reward_ctrl Mean        -0.454512
eval/env_infos/final/reward_ctrl Std          0.0425304
eval/env_infos/final/reward_ctrl Max         -0.403231
eval/env_infos/final/reward_ctrl Min         -0.504465
eval/env_infos/initial/reward_ctrl Mean      -0.317116
eval/env_infos/initial/reward_ctrl Std        0.0860928
eval/env_infos/initial/reward_ctrl Max       -0.206277
eval/env_infos/initial/reward_ctrl Min       -0.436433
eval/env_infos/reward_ctrl Mean              -0.423049
eval/env_infos/reward_ctrl Std                0.0751787
eval/env_infos/reward_ctrl Max               -0.080542
eval/env_infos/reward_ctrl Min               -0.579754
time/data storing (s)                         0.0044452
time/evaluation sampling (s)                  2.0299
time/exploration sampling (s)                 0.528441
time/logging (s)                              0.0135938
time/sac training (s)                         7.85709
time/saving (s)                               0.00380802
time/training (s)                             3.4269e-05
time/epoch (s)                               10.4373
time/total (s)                             1665.27
Epoch                                       154
---------------------------------------  ---------------
2021-11-24 00:57:08.842857 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 155 finished
---------------------------------------  ---------------
epoch                                       155
replay_buffer/size                       157000
trainer/num train calls                  156000
trainer/QF1 Loss                              7.80957
trainer/QF2 Loss                              5.98495
trainer/Policy Loss                        -260.905
trainer/Q1 Predictions Mean                 261.377
trainer/Q1 Predictions Std                  107.937
trainer/Q1 Predictions Max                  359.748
trainer/Q1 Predictions Min                   10.6227
trainer/Q2 Predictions Mean                 261.079
trainer/Q2 Predictions Std                  107.86
trainer/Q2 Predictions Max                  360.42
trainer/Q2 Predictions Min                   10.8677
trainer/Q Targets Mean                      260.435
trainer/Q Targets Std                       107.577
trainer/Q Targets Max                       361.586
trainer/Q Targets Min                        11.4866
trainer/Log Pis Mean                          5.85516
trainer/Log Pis Std                           5.02505
trainer/Log Pis Max                          18.2061
trainer/Log Pis Min                          -5.95247
trainer/policy/mean Mean                      0.0588609
trainer/policy/mean Std                       0.770291
trainer/policy/mean Max                       0.997793
trainer/policy/mean Min                      -0.997915
trainer/policy/normal/std Mean                0.469533
trainer/policy/normal/std Std                 0.156034
trainer/policy/normal/std Max                 1.15411
trainer/policy/normal/std Min                 0.101259
trainer/policy/normal/log_std Mean           -0.81882
trainer/policy/normal/log_std Std             0.373327
trainer/policy/normal/log_std Max             0.143327
trainer/policy/normal/log_std Min            -2.29008
trainer/Alpha                                 0.105297
trainer/Alpha Loss                           -0.32603
expl/num steps total                     157000
expl/num paths total                        157
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.71744
expl/Rewards Std                              1.2282
expl/Rewards Max                              7.18754
expl/Rewards Min                             -0.381034
expl/Returns Mean                          4717.44
expl/Returns Std                              0
expl/Returns Max                           4717.44
expl/Returns Min                           4717.44
expl/Actions Mean                             0.0425309
expl/Actions Std                              0.829353
expl/Actions Max                              0.999609
expl/Actions Min                             -0.99987
expl/Num Paths                                1
expl/Average Returns                       4717.44
expl/env_infos/final/reward_run Mean          6.08399
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.08399
expl/env_infos/final/reward_run Min           6.08399
expl/env_infos/initial/reward_run Mean        0.314192
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.314192
expl/env_infos/initial/reward_run Min         0.314192
expl/env_infos/reward_run Mean                5.13122
expl/env_infos/reward_run Std                 1.22024
expl/env_infos/reward_run Max                 7.67576
expl/env_infos/reward_run Min                -0.21846
expl/env_infos/final/reward_ctrl Mean        -0.338183
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.338183
expl/env_infos/final/reward_ctrl Min         -0.338183
expl/env_infos/initial/reward_ctrl Mean      -0.172087
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.172087
expl/env_infos/initial/reward_ctrl Min       -0.172087
expl/env_infos/reward_ctrl Mean              -0.413781
expl/env_infos/reward_ctrl Std                0.0853684
expl/env_infos/reward_ctrl Max               -0.0945993
expl/env_infos/reward_ctrl Min               -0.584051
eval/num steps total                     780000
eval/num paths total                        780
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.01643
eval/Rewards Std                              1.22877
eval/Rewards Max                              7.67752
eval/Rewards Min                             -0.976334
eval/Returns Mean                          5016.43
eval/Returns Std                             39.1807
eval/Returns Max                           5065.11
eval/Returns Min                           4960.26
eval/Actions Mean                             0.0493912
eval/Actions Std                              0.844599
eval/Actions Max                              0.99976
eval/Actions Min                             -0.999516
eval/Num Paths                                5
eval/Average Returns                       5016.43
eval/env_infos/final/reward_run Mean          4.28368
eval/env_infos/final/reward_run Std           0.494281
eval/env_infos/final/reward_run Max           5.18606
eval/env_infos/final/reward_run Min           3.74551
eval/env_infos/initial/reward_run Mean       -0.15868
eval/env_infos/initial/reward_run Std         0.289135
eval/env_infos/initial/reward_run Max         0.209771
eval/env_infos/initial/reward_run Min        -0.576035
eval/env_infos/reward_run Mean                5.4459
eval/env_infos/reward_run Std                 1.21278
eval/env_infos/reward_run Max                 8.16614
eval/env_infos/reward_run Min                -0.576035
eval/env_infos/final/reward_ctrl Mean        -0.436098
eval/env_infos/final/reward_ctrl Std          0.0501943
eval/env_infos/final/reward_ctrl Max         -0.367897
eval/env_infos/final/reward_ctrl Min         -0.494539
eval/env_infos/initial/reward_ctrl Mean      -0.256714
eval/env_infos/initial/reward_ctrl Std        0.0938824
eval/env_infos/initial/reward_ctrl Max       -0.160624
eval/env_infos/initial/reward_ctrl Min       -0.400299
eval/env_infos/reward_ctrl Mean              -0.429472
eval/env_infos/reward_ctrl Std                0.0795973
eval/env_infos/reward_ctrl Max               -0.135136
eval/env_infos/reward_ctrl Min               -0.579261
time/data storing (s)                         0.00503266
time/evaluation sampling (s)                  2.11683
time/exploration sampling (s)                 0.545663
time/logging (s)                              0.0137062
time/sac training (s)                         8.06473
time/saving (s)                               0.00407876
time/training (s)                             3.9009e-05
time/epoch (s)                               10.7501
time/total (s)                             1676.36
Epoch                                       155
---------------------------------------  ---------------
2021-11-24 00:57:19.687208 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 156 finished
---------------------------------------  ---------------
epoch                                       156
replay_buffer/size                       158000
trainer/num train calls                  157000
trainer/QF1 Loss                              7.02569
trainer/QF2 Loss                              6.85624
trainer/Policy Loss                        -269.995
trainer/Q1 Predictions Mean                 270.271
trainer/Q1 Predictions Std                   96.1754
trainer/Q1 Predictions Max                  359.263
trainer/Q1 Predictions Min                   12.4271
trainer/Q2 Predictions Mean                 269.973
trainer/Q2 Predictions Std                   96.1209
trainer/Q2 Predictions Max                  359.323
trainer/Q2 Predictions Min                   12.0188
trainer/Q Targets Mean                      269.963
trainer/Q Targets Std                        96.2537
trainer/Q Targets Max                       360.065
trainer/Q Targets Min                        11.9921
trainer/Log Pis Mean                          6.58674
trainer/Log Pis Std                           4.76351
trainer/Log Pis Max                          22.1014
trainer/Log Pis Min                          -4.86221
trainer/policy/mean Mean                      0.0411942
trainer/policy/mean Std                       0.787752
trainer/policy/mean Max                       0.999573
trainer/policy/mean Min                      -0.999548
trainer/policy/normal/std Mean                0.464687
trainer/policy/normal/std Std                 0.153788
trainer/policy/normal/std Max                 1.21696
trainer/policy/normal/std Min                 0.0911094
trainer/policy/normal/log_std Mean           -0.830882
trainer/policy/normal/log_std Std             0.382498
trainer/policy/normal/log_std Max             0.196359
trainer/policy/normal/log_std Min            -2.39569
trainer/Alpha                                 0.104
trainer/Alpha Loss                            1.32801
expl/num steps total                     158000
expl/num paths total                        158
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.76342
expl/Rewards Std                              1.13616
expl/Rewards Max                              6.95152
expl/Rewards Min                             -0.802423
expl/Returns Mean                          4763.42
expl/Returns Std                              0
expl/Returns Max                           4763.42
expl/Returns Min                           4763.42
expl/Actions Mean                             0.040295
expl/Actions Std                              0.821684
expl/Actions Max                              0.999278
expl/Actions Min                             -0.999784
expl/Num Paths                                1
expl/Average Returns                       4763.42
expl/env_infos/final/reward_run Mean          5.50173
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.50173
expl/env_infos/final/reward_run Min           5.50173
expl/env_infos/initial/reward_run Mean       -0.504754
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.504754
expl/env_infos/initial/reward_run Min        -0.504754
expl/env_infos/reward_run Mean                5.16949
expl/env_infos/reward_run Std                 1.12276
expl/env_infos/reward_run Max                 7.46407
expl/env_infos/reward_run Min                -0.504754
expl/env_infos/final/reward_ctrl Mean        -0.31709
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.31709
expl/env_infos/final/reward_ctrl Min         -0.31709
expl/env_infos/initial/reward_ctrl Mean      -0.193973
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.193973
expl/env_infos/initial/reward_ctrl Min       -0.193973
expl/env_infos/reward_ctrl Mean              -0.406073
expl/env_infos/reward_ctrl Std                0.0821189
expl/env_infos/reward_ctrl Max               -0.144774
expl/env_infos/reward_ctrl Min               -0.578316
eval/num steps total                     785000
eval/num paths total                        785
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.04494
eval/Rewards Std                              1.21081
eval/Rewards Max                              7.77328
eval/Rewards Min                             -1.04048
eval/Returns Mean                          5044.94
eval/Returns Std                            109.372
eval/Returns Max                           5206.12
eval/Returns Min                           4891.52
eval/Actions Mean                             0.0314012
eval/Actions Std                              0.838752
eval/Actions Max                              0.999239
eval/Actions Min                             -0.999457
eval/Num Paths                                5
eval/Average Returns                       5044.94
eval/env_infos/final/reward_run Mean          5.16536
eval/env_infos/final/reward_run Std           0.739148
eval/env_infos/final/reward_run Max           6.31896
eval/env_infos/final/reward_run Min           4.26748
eval/env_infos/initial/reward_run Mean       -0.503321
eval/env_infos/initial/reward_run Std         0.10489
eval/env_infos/initial/reward_run Max        -0.371275
eval/env_infos/initial/reward_run Min        -0.684273
eval/env_infos/reward_run Mean                5.46764
eval/env_infos/reward_run Std                 1.1928
eval/env_infos/reward_run Max                 8.26508
eval/env_infos/reward_run Min                -0.684273
eval/env_infos/final/reward_ctrl Mean        -0.488991
eval/env_infos/final/reward_ctrl Std          0.0482253
eval/env_infos/final/reward_ctrl Max         -0.415535
eval/env_infos/final/reward_ctrl Min         -0.548227
eval/env_infos/initial/reward_ctrl Mean      -0.326204
eval/env_infos/initial/reward_ctrl Std        0.0541941
eval/env_infos/initial/reward_ctrl Max       -0.237706
eval/env_infos/initial/reward_ctrl Min       -0.40169
eval/env_infos/reward_ctrl Mean              -0.422694
eval/env_infos/reward_ctrl Std                0.0759959
eval/env_infos/reward_ctrl Max               -0.148406
eval/env_infos/reward_ctrl Min               -0.578834
time/data storing (s)                         0.00455029
time/evaluation sampling (s)                  2.04474
time/exploration sampling (s)                 0.545517
time/logging (s)                              0.0136294
time/sac training (s)                         7.89183
time/saving (s)                               0.00378973
time/training (s)                             3.454e-05
time/epoch (s)                               10.5041
time/total (s)                             1687.18
Epoch                                       156
---------------------------------------  ---------------
2021-11-24 00:57:30.660932 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 157 finished
---------------------------------------  ---------------
epoch                                       157
replay_buffer/size                       159000
trainer/num train calls                  158000
trainer/QF1 Loss                              8.57341
trainer/QF2 Loss                              6.6491
trainer/Policy Loss                        -267.41
trainer/Q1 Predictions Mean                 267.563
trainer/Q1 Predictions Std                  105.611
trainer/Q1 Predictions Max                  363.421
trainer/Q1 Predictions Min                   12.0929
trainer/Q2 Predictions Mean                 268.437
trainer/Q2 Predictions Std                  106.044
trainer/Q2 Predictions Max                  363.386
trainer/Q2 Predictions Min                   12.7133
trainer/Q Targets Mean                      267.745
trainer/Q Targets Std                       105.723
trainer/Q Targets Max                       362.157
trainer/Q Targets Min                        12.8539
trainer/Log Pis Mean                          6.08532
trainer/Log Pis Std                           4.82437
trainer/Log Pis Max                          19.5753
trainer/Log Pis Min                          -6.18375
trainer/policy/mean Mean                      0.0291861
trainer/policy/mean Std                       0.775128
trainer/policy/mean Max                       0.999296
trainer/policy/mean Min                      -0.997648
trainer/policy/normal/std Mean                0.461917
trainer/policy/normal/std Std                 0.156139
trainer/policy/normal/std Max                 1.07543
trainer/policy/normal/std Min                 0.0893387
trainer/policy/normal/log_std Mean           -0.84024
trainer/policy/normal/log_std Std             0.393225
trainer/policy/normal/log_std Max             0.072717
trainer/policy/normal/log_std Min            -2.41532
trainer/Alpha                                 0.106654
trainer/Alpha Loss                            0.190952
expl/num steps total                     159000
expl/num paths total                        159
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.64404
expl/Rewards Std                              1.12294
expl/Rewards Max                              6.81833
expl/Rewards Min                             -0.747168
expl/Returns Mean                          4644.04
expl/Returns Std                              0
expl/Returns Max                           4644.04
expl/Returns Min                           4644.04
expl/Actions Mean                             0.0402329
expl/Actions Std                              0.823813
expl/Actions Max                              0.999316
expl/Actions Min                             -0.999748
expl/Num Paths                                1
expl/Average Returns                       4644.04
expl/env_infos/final/reward_run Mean          4.82416
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.82416
expl/env_infos/final/reward_run Min           4.82416
expl/env_infos/initial/reward_run Mean       -0.425145
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.425145
expl/env_infos/initial/reward_run Min        -0.425145
expl/env_infos/reward_run Mean                5.05222
expl/env_infos/reward_run Std                 1.11202
expl/env_infos/reward_run Max                 7.25151
expl/env_infos/reward_run Min                -0.425145
expl/env_infos/final/reward_ctrl Mean        -0.475383
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.475383
expl/env_infos/final/reward_ctrl Min         -0.475383
expl/env_infos/initial/reward_ctrl Mean      -0.322024
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.322024
expl/env_infos/initial/reward_ctrl Min       -0.322024
expl/env_infos/reward_ctrl Mean              -0.408172
expl/env_infos/reward_ctrl Std                0.0830357
expl/env_infos/reward_ctrl Max               -0.127591
expl/env_infos/reward_ctrl Min               -0.573476
eval/num steps total                     790000
eval/num paths total                        790
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.88831
eval/Rewards Std                              1.1983
eval/Rewards Max                              7.29009
eval/Rewards Min                             -1.06564
eval/Returns Mean                          4888.31
eval/Returns Std                            107.11
eval/Returns Max                           5067.36
eval/Returns Min                           4780.21
eval/Actions Mean                             0.0345799
eval/Actions Std                              0.842191
eval/Actions Max                              0.999292
eval/Actions Min                             -0.999467
eval/Num Paths                                5
eval/Average Returns                       4888.31
eval/env_infos/final/reward_run Mean          5.82615
eval/env_infos/final/reward_run Std           0.990623
eval/env_infos/final/reward_run Max           6.63118
eval/env_infos/final/reward_run Min           4.09257
eval/env_infos/initial/reward_run Mean       -0.429916
eval/env_infos/initial/reward_run Std         0.13771
eval/env_infos/initial/reward_run Max        -0.280501
eval/env_infos/initial/reward_run Min        -0.669722
eval/env_infos/reward_run Mean                5.3146
eval/env_infos/reward_run Std                 1.18698
eval/env_infos/reward_run Max                 7.79572
eval/env_infos/reward_run Min                -0.669722
eval/env_infos/final/reward_ctrl Mean        -0.433176
eval/env_infos/final/reward_ctrl Std          0.0767279
eval/env_infos/final/reward_ctrl Max         -0.319762
eval/env_infos/final/reward_ctrl Min         -0.522631
eval/env_infos/initial/reward_ctrl Mean      -0.357766
eval/env_infos/initial/reward_ctrl Std        0.0448003
eval/env_infos/initial/reward_ctrl Max       -0.300105
eval/env_infos/initial/reward_ctrl Min       -0.412604
eval/env_infos/reward_ctrl Mean              -0.426289
eval/env_infos/reward_ctrl Std                0.0776117
eval/env_infos/reward_ctrl Max               -0.0735569
eval/env_infos/reward_ctrl Min               -0.572106
time/data storing (s)                         0.00449284
time/evaluation sampling (s)                  2.08696
time/exploration sampling (s)                 0.557983
time/logging (s)                              0.0139961
time/sac training (s)                         7.96256
time/saving (s)                               0.00384829
time/training (s)                             4.5727e-05
time/epoch (s)                               10.6299
time/total (s)                             1698.14
Epoch                                       157
---------------------------------------  ---------------
2021-11-24 00:57:41.493126 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 158 finished
---------------------------------------  ---------------
epoch                                       158
replay_buffer/size                       160000
trainer/num train calls                  159000
trainer/QF1 Loss                              7.09286
trainer/QF2 Loss                              5.54282
trainer/Policy Loss                        -272.2
trainer/Q1 Predictions Mean                 272.607
trainer/Q1 Predictions Std                   96.3654
trainer/Q1 Predictions Max                  356.685
trainer/Q1 Predictions Min                   10.3663
trainer/Q2 Predictions Mean                 272.565
trainer/Q2 Predictions Std                   96.4228
trainer/Q2 Predictions Max                  358.15
trainer/Q2 Predictions Min                   11.2734
trainer/Q Targets Mean                      273.033
trainer/Q Targets Std                        96.5248
trainer/Q Targets Max                       362.072
trainer/Q Targets Min                         9.73073
trainer/Log Pis Mean                          6.2008
trainer/Log Pis Std                           4.81455
trainer/Log Pis Max                          18.191
trainer/Log Pis Min                          -7.53693
trainer/policy/mean Mean                      0.0300406
trainer/policy/mean Std                       0.777456
trainer/policy/mean Max                       0.998467
trainer/policy/mean Min                      -0.99754
trainer/policy/normal/std Mean                0.451006
trainer/policy/normal/std Std                 0.150474
trainer/policy/normal/std Max                 1.25252
trainer/policy/normal/std Min                 0.0959507
trainer/policy/normal/log_std Mean           -0.86101
trainer/policy/normal/log_std Std             0.381596
trainer/policy/normal/log_std Max             0.225154
trainer/policy/normal/log_std Min            -2.34392
trainer/Alpha                                 0.103528
trainer/Alpha Loss                            0.455408
expl/num steps total                     160000
expl/num paths total                        160
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.63864
expl/Rewards Std                              1.11961
expl/Rewards Max                              6.71742
expl/Rewards Min                             -0.819509
expl/Returns Mean                          4638.64
expl/Returns Std                              0
expl/Returns Max                           4638.64
expl/Returns Min                           4638.64
expl/Actions Mean                             0.042067
expl/Actions Std                              0.821031
expl/Actions Max                              0.999583
expl/Actions Min                             -0.999534
expl/Num Paths                                1
expl/Average Returns                       4638.64
expl/env_infos/final/reward_run Mean          5.59261
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.59261
expl/env_infos/final/reward_run Min           5.59261
expl/env_infos/initial/reward_run Mean       -0.414941
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.414941
expl/env_infos/initial/reward_run Min        -0.414941
expl/env_infos/reward_run Mean                5.04416
expl/env_infos/reward_run Std                 1.11233
expl/env_infos/reward_run Max                 7.19849
expl/env_infos/reward_run Min                -0.414941
expl/env_infos/final/reward_ctrl Mean        -0.235541
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.235541
expl/env_infos/final/reward_ctrl Min         -0.235541
expl/env_infos/initial/reward_ctrl Mean      -0.377563
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.377563
expl/env_infos/initial/reward_ctrl Min       -0.377563
expl/env_infos/reward_ctrl Mean              -0.405517
expl/env_infos/reward_ctrl Std                0.0859324
expl/env_infos/reward_ctrl Max               -0.137382
expl/env_infos/reward_ctrl Min               -0.579371
eval/num steps total                     795000
eval/num paths total                        795
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.03623
eval/Rewards Std                              1.1938
eval/Rewards Max                              7.45055
eval/Rewards Min                             -1.03872
eval/Returns Mean                          5036.23
eval/Returns Std                             76.919
eval/Returns Max                           5129.09
eval/Returns Min                           4943.79
eval/Actions Mean                             0.0491274
eval/Actions Std                              0.840714
eval/Actions Max                              0.999008
eval/Actions Min                             -0.998854
eval/Num Paths                                5
eval/Average Returns                       5036.23
eval/env_infos/final/reward_run Mean          5.56418
eval/env_infos/final/reward_run Std           0.866649
eval/env_infos/final/reward_run Max           6.45844
eval/env_infos/final/reward_run Min           4.17669
eval/env_infos/initial/reward_run Mean       -0.418375
eval/env_infos/initial/reward_run Std         0.195901
eval/env_infos/initial/reward_run Max        -0.123038
eval/env_infos/initial/reward_run Min        -0.646889
eval/env_infos/reward_run Mean                5.46176
eval/env_infos/reward_run Std                 1.18279
eval/env_infos/reward_run Max                 7.93711
eval/env_infos/reward_run Min                -0.646889
eval/env_infos/final/reward_ctrl Mean        -0.417232
eval/env_infos/final/reward_ctrl Std          0.0381291
eval/env_infos/final/reward_ctrl Max         -0.368222
eval/env_infos/final/reward_ctrl Min         -0.463473
eval/env_infos/initial/reward_ctrl Mean      -0.348392
eval/env_infos/initial/reward_ctrl Std        0.0660097
eval/env_infos/initial/reward_ctrl Max       -0.24691
eval/env_infos/initial/reward_ctrl Min       -0.423407
eval/env_infos/reward_ctrl Mean              -0.425528
eval/env_infos/reward_ctrl Std                0.0780219
eval/env_infos/reward_ctrl Max               -0.144624
eval/env_infos/reward_ctrl Min               -0.578259
time/data storing (s)                         0.00448437
time/evaluation sampling (s)                  2.04548
time/exploration sampling (s)                 0.526037
time/logging (s)                              0.013895
time/sac training (s)                         7.89846
time/saving (s)                               0.00379194
time/training (s)                             3.4644e-05
time/epoch (s)                               10.4922
time/total (s)                             1708.96
Epoch                                       158
---------------------------------------  ---------------
2021-11-24 00:57:52.288350 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 159 finished
---------------------------------------  ---------------
epoch                                       159
replay_buffer/size                       161000
trainer/num train calls                  160000
trainer/QF1 Loss                              8.22399
trainer/QF2 Loss                              7.79091
trainer/Policy Loss                        -270.195
trainer/Q1 Predictions Mean                 270.465
trainer/Q1 Predictions Std                   99.7728
trainer/Q1 Predictions Max                  356.544
trainer/Q1 Predictions Min                   13.6877
trainer/Q2 Predictions Mean                 270.469
trainer/Q2 Predictions Std                   99.7967
trainer/Q2 Predictions Max                  356.339
trainer/Q2 Predictions Min                   12.7233
trainer/Q Targets Mean                      270.135
trainer/Q Targets Std                        99.6351
trainer/Q Targets Max                       357.744
trainer/Q Targets Min                        10.207
trainer/Log Pis Mean                          6.33421
trainer/Log Pis Std                           4.76918
trainer/Log Pis Max                          19.6078
trainer/Log Pis Min                          -6.60041
trainer/policy/mean Mean                      0.0188049
trainer/policy/mean Std                       0.774258
trainer/policy/mean Max                       0.998911
trainer/policy/mean Min                      -0.999846
trainer/policy/normal/std Mean                0.452248
trainer/policy/normal/std Std                 0.152989
trainer/policy/normal/std Max                 1.17131
trainer/policy/normal/std Min                 0.096667
trainer/policy/normal/log_std Mean           -0.860398
trainer/policy/normal/log_std Std             0.387763
trainer/policy/normal/log_std Max             0.158126
trainer/policy/normal/log_std Min            -2.33648
trainer/Alpha                                 0.107058
trainer/Alpha Loss                            0.746755
expl/num steps total                     161000
expl/num paths total                        161
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.85057
expl/Rewards Std                              1.14478
expl/Rewards Max                              7.09448
expl/Rewards Min                             -0.703154
expl/Returns Mean                          4850.57
expl/Returns Std                              0
expl/Returns Max                           4850.57
expl/Returns Min                           4850.57
expl/Actions Mean                             0.0396538
expl/Actions Std                              0.822505
expl/Actions Max                              0.999822
expl/Actions Min                             -0.999559
expl/Num Paths                                1
expl/Average Returns                       4850.57
expl/env_infos/final/reward_run Mean          5.60963
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.60963
expl/env_infos/final/reward_run Min           5.60963
expl/env_infos/initial/reward_run Mean       -0.336365
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.336365
expl/env_infos/initial/reward_run Min        -0.336365
expl/env_infos/reward_run Mean                5.25742
expl/env_infos/reward_run Std                 1.12967
expl/env_infos/reward_run Max                 7.58861
expl/env_infos/reward_run Min                -0.336365
expl/env_infos/final/reward_ctrl Mean        -0.324837
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.324837
expl/env_infos/final/reward_ctrl Min         -0.324837
expl/env_infos/initial/reward_ctrl Mean      -0.366789
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.366789
expl/env_infos/initial/reward_ctrl Min       -0.366789
expl/env_infos/reward_ctrl Mean              -0.406852
expl/env_infos/reward_ctrl Std                0.0813071
expl/env_infos/reward_ctrl Max               -0.16752
expl/env_infos/reward_ctrl Min               -0.583594
eval/num steps total                     800000
eval/num paths total                        800
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.97323
eval/Rewards Std                              1.2147
eval/Rewards Max                              7.42406
eval/Rewards Min                             -0.948243
eval/Returns Mean                          4973.23
eval/Returns Std                             17.9465
eval/Returns Max                           4993.83
eval/Returns Min                           4948.26
eval/Actions Mean                             0.0547366
eval/Actions Std                              0.836479
eval/Actions Max                              0.999622
eval/Actions Min                             -0.99787
eval/Num Paths                                5
eval/Average Returns                       4973.23
eval/env_infos/final/reward_run Mean          5.35493
eval/env_infos/final/reward_run Std           1.19903
eval/env_infos/final/reward_run Max           7.1118
eval/env_infos/final/reward_run Min           4.09806
eval/env_infos/initial/reward_run Mean       -0.325268
eval/env_infos/initial/reward_run Std         0.207548
eval/env_infos/initial/reward_run Max        -0.0460739
eval/env_infos/initial/reward_run Min        -0.581599
eval/env_infos/reward_run Mean                5.39485
eval/env_infos/reward_run Std                 1.19482
eval/env_infos/reward_run Max                 7.87252
eval/env_infos/reward_run Min                -0.581599
eval/env_infos/final/reward_ctrl Mean        -0.428755
eval/env_infos/final/reward_ctrl Std          0.0506605
eval/env_infos/final/reward_ctrl Max         -0.364923
eval/env_infos/final/reward_ctrl Min         -0.514998
eval/env_infos/initial/reward_ctrl Mean      -0.298997
eval/env_infos/initial/reward_ctrl Std        0.0566178
eval/env_infos/initial/reward_ctrl Max       -0.212934
eval/env_infos/initial/reward_ctrl Min       -0.366644
eval/env_infos/reward_ctrl Mean              -0.421616
eval/env_infos/reward_ctrl Std                0.0772268
eval/env_infos/reward_ctrl Max               -0.0702169
eval/env_infos/reward_ctrl Min               -0.575494
time/data storing (s)                         0.00450523
time/evaluation sampling (s)                  2.09703
time/exploration sampling (s)                 0.54451
time/logging (s)                              0.0140542
time/sac training (s)                         7.79293
time/saving (s)                               0.0039557
time/training (s)                             5.7122e-05
time/epoch (s)                               10.457
time/total (s)                             1719.74
Epoch                                       159
---------------------------------------  ---------------
2021-11-24 00:58:03.019273 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 160 finished
---------------------------------------  ---------------
epoch                                       160
replay_buffer/size                       162000
trainer/num train calls                  161000
trainer/QF1 Loss                              7.13017
trainer/QF2 Loss                              4.82299
trainer/Policy Loss                        -286.332
trainer/Q1 Predictions Mean                 287.034
trainer/Q1 Predictions Std                   86.273
trainer/Q1 Predictions Max                  366.184
trainer/Q1 Predictions Min                   12.4678
trainer/Q2 Predictions Mean                 286.726
trainer/Q2 Predictions Std                   86.3632
trainer/Q2 Predictions Max                  365.463
trainer/Q2 Predictions Min                   11.7784
trainer/Q Targets Mean                      287.043
trainer/Q Targets Std                        86.2808
trainer/Q Targets Max                       368.678
trainer/Q Targets Min                        12.3997
trainer/Log Pis Mean                          5.99415
trainer/Log Pis Std                           4.78005
trainer/Log Pis Max                          18.3779
trainer/Log Pis Min                          -5.91733
trainer/policy/mean Mean                      0.0559525
trainer/policy/mean Std                       0.784751
trainer/policy/mean Max                       0.999505
trainer/policy/mean Min                      -0.996654
trainer/policy/normal/std Mean                0.450111
trainer/policy/normal/std Std                 0.142469
trainer/policy/normal/std Max                 1.03041
trainer/policy/normal/std Min                 0.101169
trainer/policy/normal/log_std Mean           -0.859034
trainer/policy/normal/log_std Std             0.373319
trainer/policy/normal/log_std Max             0.0299608
trainer/policy/normal/log_std Min            -2.29096
trainer/Alpha                                 0.105981
trainer/Alpha Loss                           -0.0131206
expl/num steps total                     162000
expl/num paths total                        162
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.74079
expl/Rewards Std                              1.16051
expl/Rewards Max                              6.90916
expl/Rewards Min                             -0.648626
expl/Returns Mean                          4740.79
expl/Returns Std                              0
expl/Returns Max                           4740.79
expl/Returns Min                           4740.79
expl/Actions Mean                             0.0742106
expl/Actions Std                              0.815347
expl/Actions Max                              0.999475
expl/Actions Min                             -0.999692
expl/Num Paths                                1
expl/Average Returns                       4740.79
expl/env_infos/final/reward_run Mean          4.77761
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.77761
expl/env_infos/final/reward_run Min           4.77761
expl/env_infos/initial/reward_run Mean       -0.380775
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.380775
expl/env_infos/initial/reward_run Min        -0.380775
expl/env_infos/reward_run Mean                5.14297
expl/env_infos/reward_run Std                 1.1519
expl/env_infos/reward_run Max                 7.35973
expl/env_infos/reward_run Min                -0.380775
expl/env_infos/final/reward_ctrl Mean        -0.438012
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.438012
expl/env_infos/final/reward_ctrl Min         -0.438012
expl/env_infos/initial/reward_ctrl Mean      -0.267851
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.267851
expl/env_infos/initial/reward_ctrl Min       -0.267851
expl/env_infos/reward_ctrl Mean              -0.402179
expl/env_infos/reward_ctrl Std                0.0798157
expl/env_infos/reward_ctrl Max               -0.151117
expl/env_infos/reward_ctrl Min               -0.587067
eval/num steps total                     805000
eval/num paths total                        805
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.00501
eval/Rewards Std                              1.20243
eval/Rewards Max                              7.48887
eval/Rewards Min                             -0.857615
eval/Returns Mean                          5005.01
eval/Returns Std                             81.8671
eval/Returns Max                           5081.94
eval/Returns Min                           4847.62
eval/Actions Mean                             0.0631076
eval/Actions Std                              0.829827
eval/Actions Max                              0.999724
eval/Actions Min                             -0.998035
eval/Num Paths                                5
eval/Average Returns                       5005.01
eval/env_infos/final/reward_run Mean          5.43004
eval/env_infos/final/reward_run Std           0.629531
eval/env_infos/final/reward_run Max           6.52988
eval/env_infos/final/reward_run Min           4.69952
eval/env_infos/initial/reward_run Mean       -0.282827
eval/env_infos/initial/reward_run Std         0.105186
eval/env_infos/initial/reward_run Max        -0.151204
eval/env_infos/initial/reward_run Min        -0.44923
eval/env_infos/reward_run Mean                5.42057
eval/env_infos/reward_run Std                 1.19491
eval/env_infos/reward_run Max                 7.97296
eval/env_infos/reward_run Min                -0.44923
eval/env_infos/final/reward_ctrl Mean        -0.419475
eval/env_infos/final/reward_ctrl Std          0.0497694
eval/env_infos/final/reward_ctrl Max         -0.371149
eval/env_infos/final/reward_ctrl Min         -0.513296
eval/env_infos/initial/reward_ctrl Mean      -0.307717
eval/env_infos/initial/reward_ctrl Std        0.0685803
eval/env_infos/initial/reward_ctrl Max       -0.227697
eval/env_infos/initial/reward_ctrl Min       -0.408385
eval/env_infos/reward_ctrl Mean              -0.415557
eval/env_infos/reward_ctrl Std                0.077251
eval/env_infos/reward_ctrl Max               -0.107675
eval/env_infos/reward_ctrl Min               -0.577497
time/data storing (s)                         0.00460879
time/evaluation sampling (s)                  2.0303
time/exploration sampling (s)                 0.541796
time/logging (s)                              0.0135099
time/sac training (s)                         7.79835
time/saving (s)                               0.00382179
time/training (s)                             3.566e-05
time/epoch (s)                               10.3924
time/total (s)                             1730.45
Epoch                                       160
---------------------------------------  ---------------
2021-11-24 00:58:13.642873 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 161 finished
---------------------------------------  ---------------
epoch                                       161
replay_buffer/size                       163000
trainer/num train calls                  162000
trainer/QF1 Loss                              7.72575
trainer/QF2 Loss                              6.79653
trainer/Policy Loss                        -280.366
trainer/Q1 Predictions Mean                 280.436
trainer/Q1 Predictions Std                   96.1679
trainer/Q1 Predictions Max                  362.706
trainer/Q1 Predictions Min                   13.9427
trainer/Q2 Predictions Mean                 280.931
trainer/Q2 Predictions Std                   96.401
trainer/Q2 Predictions Max                  364.405
trainer/Q2 Predictions Min                   13.2458
trainer/Q Targets Mean                      280.63
trainer/Q Targets Std                        96.3611
trainer/Q Targets Max                       364.634
trainer/Q Targets Min                        13.4767
trainer/Log Pis Mean                          6.35606
trainer/Log Pis Std                           4.94266
trainer/Log Pis Max                          18.761
trainer/Log Pis Min                          -5.05699
trainer/policy/mean Mean                      0.0513702
trainer/policy/mean Std                       0.766466
trainer/policy/mean Max                       0.998992
trainer/policy/mean Min                      -0.997459
trainer/policy/normal/std Mean                0.450895
trainer/policy/normal/std Std                 0.146747
trainer/policy/normal/std Max                 1.31071
trainer/policy/normal/std Min                 0.093107
trainer/policy/normal/log_std Mean           -0.858076
trainer/policy/normal/log_std Std             0.371239
trainer/policy/normal/log_std Max             0.270572
trainer/policy/normal/log_std Min            -2.37401
trainer/Alpha                                 0.10628
trainer/Alpha Loss                            0.798176
expl/num steps total                     163000
expl/num paths total                        163
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.8202
expl/Rewards Std                              1.22925
expl/Rewards Max                              7.22936
expl/Rewards Min                             -0.875773
expl/Returns Mean                          4820.2
expl/Returns Std                              0
expl/Returns Max                           4820.2
expl/Returns Min                           4820.2
expl/Actions Mean                             0.0736944
expl/Actions Std                              0.819798
expl/Actions Max                              0.999414
expl/Actions Min                             -0.999906
expl/Num Paths                                1
expl/Average Returns                       4820.2
expl/env_infos/final/reward_run Mean          6.05088
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.05088
expl/env_infos/final/reward_run Min           6.05088
expl/env_infos/initial/reward_run Mean       -0.648183
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.648183
expl/env_infos/initial/reward_run Min        -0.648183
expl/env_infos/reward_run Mean                5.2267
expl/env_infos/reward_run Std                 1.20545
expl/env_infos/reward_run Max                 7.70151
expl/env_infos/reward_run Min                -0.648183
expl/env_infos/final/reward_ctrl Mean        -0.430889
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.430889
expl/env_infos/final/reward_ctrl Min         -0.430889
expl/env_infos/initial/reward_ctrl Mean      -0.22759
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.22759
expl/env_infos/initial/reward_ctrl Min       -0.22759
expl/env_infos/reward_ctrl Mean              -0.4065
expl/env_infos/reward_ctrl Std                0.0855963
expl/env_infos/reward_ctrl Max               -0.163804
expl/env_infos/reward_ctrl Min               -0.587546
eval/num steps total                     810000
eval/num paths total                        810
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.98592
eval/Rewards Std                              1.25942
eval/Rewards Max                              7.62372
eval/Rewards Min                             -1.12722
eval/Returns Mean                          4985.92
eval/Returns Std                            103.622
eval/Returns Max                           5121.64
eval/Returns Min                           4842.35
eval/Actions Mean                             0.0799282
eval/Actions Std                              0.832824
eval/Actions Max                              0.998704
eval/Actions Min                             -0.998595
eval/Num Paths                                5
eval/Average Returns                       4985.92
eval/env_infos/final/reward_run Mean          5.96518
eval/env_infos/final/reward_run Std           0.923969
eval/env_infos/final/reward_run Max           7.20491
eval/env_infos/final/reward_run Min           4.43084
eval/env_infos/initial/reward_run Mean       -0.44208
eval/env_infos/initial/reward_run Std         0.241802
eval/env_infos/initial/reward_run Max        -0.152028
eval/env_infos/initial/reward_run Min        -0.709887
eval/env_infos/reward_run Mean                5.40592
eval/env_infos/reward_run Std                 1.23324
eval/env_infos/reward_run Max                 8.12392
eval/env_infos/reward_run Min                -0.709887
eval/env_infos/final/reward_ctrl Mean        -0.433461
eval/env_infos/final/reward_ctrl Std          0.0352238
eval/env_infos/final/reward_ctrl Max         -0.388613
eval/env_infos/final/reward_ctrl Min         -0.486698
eval/env_infos/initial/reward_ctrl Mean      -0.340978
eval/env_infos/initial/reward_ctrl Std        0.0789677
eval/env_infos/initial/reward_ctrl Max       -0.240308
eval/env_infos/initial/reward_ctrl Min       -0.417337
eval/env_infos/reward_ctrl Mean              -0.419991
eval/env_infos/reward_ctrl Std                0.0820701
eval/env_infos/reward_ctrl Max               -0.134678
eval/env_infos/reward_ctrl Min               -0.58491
time/data storing (s)                         0.00457274
time/evaluation sampling (s)                  2.02181
time/exploration sampling (s)                 0.52656
time/logging (s)                              0.0135804
time/sac training (s)                         7.72045
time/saving (s)                               0.00377271
time/training (s)                             3.4164e-05
time/epoch (s)                               10.2908
time/total (s)                             1741.06
Epoch                                       161
---------------------------------------  ---------------
2021-11-24 00:58:24.353799 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 162 finished
---------------------------------------  ---------------
epoch                                       162
replay_buffer/size                       164000
trainer/num train calls                  163000
trainer/QF1 Loss                              7.43538
trainer/QF2 Loss                              7.13883
trainer/Policy Loss                        -281.863
trainer/Q1 Predictions Mean                 282.317
trainer/Q1 Predictions Std                   99.2216
trainer/Q1 Predictions Max                  362.926
trainer/Q1 Predictions Min                   12.7889
trainer/Q2 Predictions Mean                 281.976
trainer/Q2 Predictions Std                   99.3052
trainer/Q2 Predictions Max                  362.349
trainer/Q2 Predictions Min                   12.9155
trainer/Q Targets Mean                      281.758
trainer/Q Targets Std                        99.1879
trainer/Q Targets Max                       365.25
trainer/Q Targets Min                        12.9886
trainer/Log Pis Mean                          6.32644
trainer/Log Pis Std                           4.8626
trainer/Log Pis Max                          21.2245
trainer/Log Pis Min                          -4.4015
trainer/policy/mean Mean                      0.06708
trainer/policy/mean Std                       0.778094
trainer/policy/mean Max                       0.998388
trainer/policy/mean Min                      -0.999629
trainer/policy/normal/std Mean                0.455257
trainer/policy/normal/std Std                 0.151746
trainer/policy/normal/std Max                 0.899464
trainer/policy/normal/std Min                 0.101441
trainer/policy/normal/log_std Mean           -0.85466
trainer/policy/normal/log_std Std             0.394389
trainer/policy/normal/log_std Max            -0.105956
trainer/policy/normal/log_std Min            -2.28828
trainer/Alpha                                 0.107817
trainer/Alpha Loss                            0.727084
expl/num steps total                     164000
expl/num paths total                        164
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.76133
expl/Rewards Std                              1.1421
expl/Rewards Max                              7.03317
expl/Rewards Min                             -0.659242
expl/Returns Mean                          4761.33
expl/Returns Std                              0
expl/Returns Max                           4761.33
expl/Returns Min                           4761.33
expl/Actions Mean                             0.0556333
expl/Actions Std                              0.819441
expl/Actions Max                              0.999549
expl/Actions Min                             -0.999773
expl/Num Paths                                1
expl/Average Returns                       4761.33
expl/env_infos/final/reward_run Mean          3.01413
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.01413
expl/env_infos/final/reward_run Min           3.01413
expl/env_infos/initial/reward_run Mean       -0.223176
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.223176
expl/env_infos/initial/reward_run Min        -0.223176
expl/env_infos/reward_run Mean                5.16608
expl/env_infos/reward_run Std                 1.12349
expl/env_infos/reward_run Max                 7.47972
expl/env_infos/reward_run Min                -0.223176
expl/env_infos/final/reward_ctrl Mean        -0.528106
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.528106
expl/env_infos/final/reward_ctrl Min         -0.528106
expl/env_infos/initial/reward_ctrl Mean      -0.436067
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.436067
expl/env_infos/initial/reward_ctrl Min       -0.436067
expl/env_infos/reward_ctrl Mean              -0.404747
expl/env_infos/reward_ctrl Std                0.0868548
expl/env_infos/reward_ctrl Max               -0.1571
expl/env_infos/reward_ctrl Min               -0.584965
eval/num steps total                     815000
eval/num paths total                        815
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.04647
eval/Rewards Std                              1.21772
eval/Rewards Max                              7.43308
eval/Rewards Min                             -0.825138
eval/Returns Mean                          5046.47
eval/Returns Std                             44.5067
eval/Returns Max                           5121.32
eval/Returns Min                           4994.8
eval/Actions Mean                             0.0654282
eval/Actions Std                              0.831673
eval/Actions Max                              0.999474
eval/Actions Min                             -0.999028
eval/Num Paths                                5
eval/Average Returns                       5046.47
eval/env_infos/final/reward_run Mean          5.37331
eval/env_infos/final/reward_run Std           1.10004
eval/env_infos/final/reward_run Max           7.05446
eval/env_infos/final/reward_run Min           3.62251
eval/env_infos/initial/reward_run Mean       -0.322703
eval/env_infos/initial/reward_run Std         0.126692
eval/env_infos/initial/reward_run Max        -0.0809425
eval/env_infos/initial/reward_run Min        -0.441563
eval/env_infos/reward_run Mean                5.46404
eval/env_infos/reward_run Std                 1.19775
eval/env_infos/reward_run Max                 7.94443
eval/env_infos/reward_run Min                -0.441563
eval/env_infos/final/reward_ctrl Mean        -0.390055
eval/env_infos/final/reward_ctrl Std          0.0778293
eval/env_infos/final/reward_ctrl Max         -0.321532
eval/env_infos/final/reward_ctrl Min         -0.537266
eval/env_infos/initial/reward_ctrl Mean      -0.343299
eval/env_infos/initial/reward_ctrl Std        0.0609172
eval/env_infos/initial/reward_ctrl Max       -0.239134
eval/env_infos/initial/reward_ctrl Min       -0.419441
eval/env_infos/reward_ctrl Mean              -0.417577
eval/env_infos/reward_ctrl Std                0.0826242
eval/env_infos/reward_ctrl Max               -0.114148
eval/env_infos/reward_ctrl Min               -0.582476
time/data storing (s)                         0.00450388
time/evaluation sampling (s)                  1.99661
time/exploration sampling (s)                 0.524509
time/logging (s)                              0.0142803
time/sac training (s)                         7.83259
time/saving (s)                               0.00396179
time/training (s)                             4.7688e-05
time/epoch (s)                               10.3765
time/total (s)                             1751.76
Epoch                                       162
---------------------------------------  ---------------
2021-11-24 00:58:35.540316 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 163 finished
---------------------------------------  ---------------
epoch                                       163
replay_buffer/size                       165000
trainer/num train calls                  164000
trainer/QF1 Loss                              8.74043
trainer/QF2 Loss                              7.86211
trainer/Policy Loss                        -278.695
trainer/Q1 Predictions Mean                 279.314
trainer/Q1 Predictions Std                   96.7243
trainer/Q1 Predictions Max                  364.532
trainer/Q1 Predictions Min                   13.3501
trainer/Q2 Predictions Mean                 278.902
trainer/Q2 Predictions Std                   96.5748
trainer/Q2 Predictions Max                  363.978
trainer/Q2 Predictions Min                   13.5876
trainer/Q Targets Mean                      278.937
trainer/Q Targets Std                        96.8047
trainer/Q Targets Max                       365.569
trainer/Q Targets Min                        12.0201
trainer/Log Pis Mean                          6.2987
trainer/Log Pis Std                           4.79526
trainer/Log Pis Max                          20.0915
trainer/Log Pis Min                          -6.6696
trainer/policy/mean Mean                      0.0519782
trainer/policy/mean Std                       0.781913
trainer/policy/mean Max                       0.999887
trainer/policy/mean Min                      -0.998356
trainer/policy/normal/std Mean                0.456285
trainer/policy/normal/std Std                 0.151831
trainer/policy/normal/std Max                 1.20136
trainer/policy/normal/std Min                 0.093681
trainer/policy/normal/log_std Mean           -0.848676
trainer/policy/normal/log_std Std             0.378864
trainer/policy/normal/log_std Max             0.183457
trainer/policy/normal/log_std Min            -2.36786
trainer/Alpha                                 0.10825
trainer/Alpha Loss                            0.664111
expl/num steps total                     165000
expl/num paths total                        165
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.68806
expl/Rewards Std                              1.19294
expl/Rewards Max                              7.09886
expl/Rewards Min                             -0.742218
expl/Returns Mean                          4688.06
expl/Returns Std                              0
expl/Returns Max                           4688.06
expl/Returns Min                           4688.06
expl/Actions Mean                             0.0524007
expl/Actions Std                              0.825833
expl/Actions Max                              0.999618
expl/Actions Min                             -0.999718
expl/Num Paths                                1
expl/Average Returns                       4688.06
expl/env_infos/final/reward_run Mean          5.05139
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.05139
expl/env_infos/final/reward_run Min           5.05139
expl/env_infos/initial/reward_run Mean       -0.505924
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.505924
expl/env_infos/initial/reward_run Min        -0.505924
expl/env_infos/reward_run Mean                5.09891
expl/env_infos/reward_run Std                 1.17421
expl/env_infos/reward_run Max                 7.50793
expl/env_infos/reward_run Min                -0.505924
expl/env_infos/final/reward_ctrl Mean        -0.266933
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.266933
expl/env_infos/final/reward_ctrl Min         -0.266933
expl/env_infos/initial/reward_ctrl Mean      -0.236294
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.236294
expl/env_infos/initial/reward_ctrl Min       -0.236294
expl/env_infos/reward_ctrl Mean              -0.410848
expl/env_infos/reward_ctrl Std                0.0886268
expl/env_infos/reward_ctrl Max               -0.129709
expl/env_infos/reward_ctrl Min               -0.583576
eval/num steps total                     820000
eval/num paths total                        820
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             4.82639
eval/Rewards Std                              1.21258
eval/Rewards Max                              7.31947
eval/Rewards Min                             -0.975262
eval/Returns Mean                          4826.39
eval/Returns Std                             83.4094
eval/Returns Max                           4903.01
eval/Returns Min                           4713.97
eval/Actions Mean                             0.0476665
eval/Actions Std                              0.837741
eval/Actions Max                              0.998743
eval/Actions Min                             -0.999899
eval/Num Paths                                5
eval/Average Returns                       4826.39
eval/env_infos/final/reward_run Mean          5.64887
eval/env_infos/final/reward_run Std           1.00032
eval/env_infos/final/reward_run Max           7.62046
eval/env_infos/final/reward_run Min           4.92915
eval/env_infos/initial/reward_run Mean       -0.263635
eval/env_infos/initial/reward_run Std         0.277884
eval/env_infos/initial/reward_run Max         0.197382
eval/env_infos/initial/reward_run Min        -0.564513
eval/env_infos/reward_run Mean                5.24884
eval/env_infos/reward_run Std                 1.18921
eval/env_infos/reward_run Max                 7.82159
eval/env_infos/reward_run Min                -0.564513
eval/env_infos/final/reward_ctrl Mean        -0.457281
eval/env_infos/final/reward_ctrl Std          0.0464841
eval/env_infos/final/reward_ctrl Max         -0.37217
eval/env_infos/final/reward_ctrl Min         -0.512658
eval/env_infos/initial/reward_ctrl Mean      -0.320524
eval/env_infos/initial/reward_ctrl Std        0.0823994
eval/env_infos/initial/reward_ctrl Max       -0.242932
eval/env_infos/initial/reward_ctrl Min       -0.431012
eval/env_infos/reward_ctrl Mean              -0.42245
eval/env_infos/reward_ctrl Std                0.082875
eval/env_infos/reward_ctrl Max               -0.148156
eval/env_infos/reward_ctrl Min               -0.574615
time/data storing (s)                         0.00628077
time/evaluation sampling (s)                  2.09537
time/exploration sampling (s)                 0.681437
time/logging (s)                              0.0137053
time/sac training (s)                         8.04028
time/saving (s)                               0.0038209
time/training (s)                             3.415e-05
time/epoch (s)                               10.8409
time/total (s)                             1762.93
Epoch                                       163
---------------------------------------  ---------------
2021-11-24 00:58:46.726367 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 164 finished
---------------------------------------  ---------------
epoch                                       164
replay_buffer/size                       166000
trainer/num train calls                  165000
trainer/QF1 Loss                              7.21134
trainer/QF2 Loss                              8.16228
trainer/Policy Loss                        -275.923
trainer/Q1 Predictions Mean                 276.186
trainer/Q1 Predictions Std                   98.9785
trainer/Q1 Predictions Max                  368.728
trainer/Q1 Predictions Min                   14.2897
trainer/Q2 Predictions Mean                 276.776
trainer/Q2 Predictions Std                   99.1614
trainer/Q2 Predictions Max                  368.004
trainer/Q2 Predictions Min                   14.1346
trainer/Q Targets Mean                      276.562
trainer/Q Targets Std                        99.2997
trainer/Q Targets Max                       370.163
trainer/Q Targets Min                        13.657
trainer/Log Pis Mean                          6.42399
trainer/Log Pis Std                           4.71801
trainer/Log Pis Max                          18.5042
trainer/Log Pis Min                          -5.29086
trainer/policy/mean Mean                      0.0321201
trainer/policy/mean Std                       0.781922
trainer/policy/mean Max                       0.997904
trainer/policy/mean Min                      -0.998386
trainer/policy/normal/std Mean                0.456261
trainer/policy/normal/std Std                 0.148971
trainer/policy/normal/std Max                 1.0421
trainer/policy/normal/std Min                 0.101965
trainer/policy/normal/log_std Mean           -0.846965
trainer/policy/normal/log_std Std             0.374958
trainer/policy/normal/log_std Max             0.0412379
trainer/policy/normal/log_std Min            -2.28313
trainer/Alpha                                 0.108386
trainer/Alpha Loss                            0.942125
expl/num steps total                     166000
expl/num paths total                        166
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.8186
expl/Rewards Std                              1.15579
expl/Rewards Max                              7.18447
expl/Rewards Min                             -0.51602
expl/Returns Mean                          4818.6
expl/Returns Std                              0
expl/Returns Max                           4818.6
expl/Returns Min                           4818.6
expl/Actions Mean                             0.0357817
expl/Actions Std                              0.830296
expl/Actions Max                              0.999666
expl/Actions Min                             -0.999551
expl/Num Paths                                1
expl/Average Returns                       4818.6
expl/env_infos/final/reward_run Mean          4.00931
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.00931
expl/env_infos/final/reward_run Min           4.00931
expl/env_infos/initial/reward_run Mean       -0.0483999
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0483999
expl/env_infos/initial/reward_run Min        -0.0483999
expl/env_infos/reward_run Mean                5.233
expl/env_infos/reward_run Std                 1.14241
expl/env_infos/reward_run Max                 7.61028
expl/env_infos/reward_run Min                -0.132273
expl/env_infos/final/reward_ctrl Mean        -0.55381
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.55381
expl/env_infos/final/reward_ctrl Min         -0.55381
expl/env_infos/initial/reward_ctrl Mean      -0.183632
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.183632
expl/env_infos/initial/reward_ctrl Min       -0.183632
expl/env_infos/reward_ctrl Mean              -0.414403
expl/env_infos/reward_ctrl Std                0.0826344
expl/env_infos/reward_ctrl Max               -0.16155
expl/env_infos/reward_ctrl Min               -0.582867
eval/num steps total                     825000
eval/num paths total                        825
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.09307
eval/Rewards Std                              1.19131
eval/Rewards Max                              7.46168
eval/Rewards Min                             -0.986643
eval/Returns Mean                          5093.07
eval/Returns Std                             15.9407
eval/Returns Max                           5117.07
eval/Returns Min                           5067.92
eval/Actions Mean                             0.0286531
eval/Actions Std                              0.843624
eval/Actions Max                              0.999716
eval/Actions Min                             -0.997622
eval/Num Paths                                5
eval/Average Returns                       5093.07
eval/env_infos/final/reward_run Mean          6.07488
eval/env_infos/final/reward_run Std           0.514905
eval/env_infos/final/reward_run Max           7.00858
eval/env_infos/final/reward_run Min           5.6282
eval/env_infos/initial/reward_run Mean       -0.462604
eval/env_infos/initial/reward_run Std         0.16688
eval/env_infos/initial/reward_run Max        -0.144579
eval/env_infos/initial/reward_run Min        -0.6133
eval/env_infos/reward_run Mean                5.52059
eval/env_infos/reward_run Std                 1.17737
eval/env_infos/reward_run Max                 7.92938
eval/env_infos/reward_run Min                -0.6133
eval/env_infos/final/reward_ctrl Mean        -0.421327
eval/env_infos/final/reward_ctrl Std          0.0529024
eval/env_infos/final/reward_ctrl Max         -0.361884
eval/env_infos/final/reward_ctrl Min         -0.504802
eval/env_infos/initial/reward_ctrl Mean      -0.341297
eval/env_infos/initial/reward_ctrl Std        0.0667121
eval/env_infos/initial/reward_ctrl Max       -0.219102
eval/env_infos/initial/reward_ctrl Min       -0.40673
eval/env_infos/reward_ctrl Mean              -0.427514
eval/env_infos/reward_ctrl Std                0.0800315
eval/env_infos/reward_ctrl Max               -0.0662469
eval/env_infos/reward_ctrl Min               -0.577088
time/data storing (s)                         0.00447454
time/evaluation sampling (s)                  2.12964
time/exploration sampling (s)                 0.563106
time/logging (s)                              0.013745
time/sac training (s)                         8.11437
time/saving (s)                               0.00432167
time/training (s)                             4.9513e-05
time/epoch (s)                               10.8297
time/total (s)                             1774.1
Epoch                                       164
---------------------------------------  ---------------
2021-11-24 00:58:57.640510 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 165 finished
---------------------------------------  ---------------
epoch                                       165
replay_buffer/size                       167000
trainer/num train calls                  166000
trainer/QF1 Loss                              6.98609
trainer/QF2 Loss                              7.40756
trainer/Policy Loss                        -276.064
trainer/Q1 Predictions Mean                 276.653
trainer/Q1 Predictions Std                  101.652
trainer/Q1 Predictions Max                  361.673
trainer/Q1 Predictions Min                   12.2301
trainer/Q2 Predictions Mean                 276.467
trainer/Q2 Predictions Std                  101.495
trainer/Q2 Predictions Max                  362.622
trainer/Q2 Predictions Min                   12.238
trainer/Q Targets Mean                      277.102
trainer/Q Targets Std                       101.75
trainer/Q Targets Max                       362.577
trainer/Q Targets Min                        12.3424
trainer/Log Pis Mean                          6.07178
trainer/Log Pis Std                           4.91472
trainer/Log Pis Max                          17.6159
trainer/Log Pis Min                          -7.57209
trainer/policy/mean Mean                      0.0377199
trainer/policy/mean Std                       0.773275
trainer/policy/mean Max                       0.998034
trainer/policy/mean Min                      -0.995272
trainer/policy/normal/std Mean                0.452267
trainer/policy/normal/std Std                 0.155363
trainer/policy/normal/std Max                 0.949405
trainer/policy/normal/std Min                 0.0907991
trainer/policy/normal/log_std Mean           -0.865194
trainer/policy/normal/log_std Std             0.406098
trainer/policy/normal/log_std Max            -0.0519196
trainer/policy/normal/log_std Min            -2.39911
trainer/Alpha                                 0.106764
trainer/Alpha Loss                            0.160579
expl/num steps total                     167000
expl/num paths total                        167
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.86123
expl/Rewards Std                              1.16821
expl/Rewards Max                              7.42165
expl/Rewards Min                             -0.828664
expl/Returns Mean                          4861.23
expl/Returns Std                              0
expl/Returns Max                           4861.23
expl/Returns Min                           4861.23
expl/Actions Mean                             0.0573348
expl/Actions Std                              0.827479
expl/Actions Max                              0.999707
expl/Actions Min                             -0.999586
expl/Num Paths                                1
expl/Average Returns                       4861.23
expl/env_infos/final/reward_run Mean          6.15784
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.15784
expl/env_infos/final/reward_run Min           6.15784
expl/env_infos/initial/reward_run Mean       -0.419029
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.419029
expl/env_infos/initial/reward_run Min        -0.419029
expl/env_infos/reward_run Mean                5.27403
expl/env_infos/reward_run Std                 1.15258
expl/env_infos/reward_run Max                 7.84593
expl/env_infos/reward_run Min                -0.419029
expl/env_infos/final/reward_ctrl Mean        -0.293253
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.293253
expl/env_infos/final/reward_ctrl Min         -0.293253
expl/env_infos/initial/reward_ctrl Mean      -0.409636
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.409636
expl/env_infos/initial/reward_ctrl Min       -0.409636
expl/env_infos/reward_ctrl Mean              -0.412805
expl/env_infos/reward_ctrl Std                0.0812315
expl/env_infos/reward_ctrl Max               -0.160475
expl/env_infos/reward_ctrl Min               -0.581412
eval/num steps total                     830000
eval/num paths total                        830
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.15528
eval/Rewards Std                              1.22153
eval/Rewards Max                              7.51283
eval/Rewards Min                             -0.929062
eval/Returns Mean                          5155.28
eval/Returns Std                             40.8809
eval/Returns Max                           5192.87
eval/Returns Min                           5085.68
eval/Actions Mean                             0.0478639
eval/Actions Std                              0.841674
eval/Actions Max                              0.999335
eval/Actions Min                             -0.996712
eval/Num Paths                                5
eval/Average Returns                       5155.28
eval/env_infos/final/reward_run Mean          4.58759
eval/env_infos/final/reward_run Std           0.572187
eval/env_infos/final/reward_run Max           5.15647
eval/env_infos/final/reward_run Min           3.59403
eval/env_infos/initial/reward_run Mean       -0.418992
eval/env_infos/initial/reward_run Std         0.182225
eval/env_infos/initial/reward_run Max        -0.12641
eval/env_infos/initial/reward_run Min        -0.62874
eval/env_infos/reward_run Mean                5.5817
eval/env_infos/reward_run Std                 1.2068
eval/env_infos/reward_run Max                 7.98934
eval/env_infos/reward_run Min                -0.62874
eval/env_infos/final/reward_ctrl Mean        -0.498367
eval/env_infos/final/reward_ctrl Std          0.0356962
eval/env_infos/final/reward_ctrl Max         -0.445994
eval/env_infos/final/reward_ctrl Min         -0.553944
eval/env_infos/initial/reward_ctrl Mean      -0.290892
eval/env_infos/initial/reward_ctrl Std        0.0450186
eval/env_infos/initial/reward_ctrl Max       -0.228393
eval/env_infos/initial/reward_ctrl Min       -0.361948
eval/env_infos/reward_ctrl Mean              -0.426424
eval/env_infos/reward_ctrl Std                0.079835
eval/env_infos/reward_ctrl Max               -0.0992878
eval/env_infos/reward_ctrl Min               -0.583194
time/data storing (s)                         0.00448815
time/evaluation sampling (s)                  2.04406
time/exploration sampling (s)                 0.543187
time/logging (s)                              0.0135915
time/sac training (s)                         7.95754
time/saving (s)                               0.00377061
time/training (s)                             3.3984e-05
time/epoch (s)                               10.5667
time/total (s)                             1785
Epoch                                       165
---------------------------------------  ---------------
2021-11-24 00:59:08.476902 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 166 finished
---------------------------------------  ---------------
epoch                                       166
replay_buffer/size                       168000
trainer/num train calls                  167000
trainer/QF1 Loss                             12.6337
trainer/QF2 Loss                             10.7834
trainer/Policy Loss                        -275.646
trainer/Q1 Predictions Mean                 276.26
trainer/Q1 Predictions Std                  105.008
trainer/Q1 Predictions Max                  363.181
trainer/Q1 Predictions Min                   12.0948
trainer/Q2 Predictions Mean                 275.899
trainer/Q2 Predictions Std                  104.83
trainer/Q2 Predictions Max                  363.503
trainer/Q2 Predictions Min                   12.6992
trainer/Q Targets Mean                      276.795
trainer/Q Targets Std                       105.078
trainer/Q Targets Max                       365.148
trainer/Q Targets Min                        13.4863
trainer/Log Pis Mean                          6.30208
trainer/Log Pis Std                           5.18952
trainer/Log Pis Max                          24.811
trainer/Log Pis Min                          -5.26431
trainer/policy/mean Mean                      0.0291672
trainer/policy/mean Std                       0.783356
trainer/policy/mean Max                       0.999978
trainer/policy/mean Min                      -0.999883
trainer/policy/normal/std Mean                0.457035
trainer/policy/normal/std Std                 0.151226
trainer/policy/normal/std Max                 1.15472
trainer/policy/normal/std Min                 0.0925543
trainer/policy/normal/log_std Mean           -0.848034
trainer/policy/normal/log_std Std             0.384537
trainer/policy/normal/log_std Max             0.143861
trainer/policy/normal/log_std Min            -2.37996
trainer/Alpha                                 0.10819
trainer/Alpha Loss                            0.671795
expl/num steps total                     168000
expl/num paths total                        168
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.00044
expl/Rewards Std                              1.18685
expl/Rewards Max                              7.29446
expl/Rewards Min                             -0.770679
expl/Returns Mean                          5000.44
expl/Returns Std                              0
expl/Returns Max                           5000.44
expl/Returns Min                           5000.44
expl/Actions Mean                             0.0372426
expl/Actions Std                              0.817062
expl/Actions Max                              0.999748
expl/Actions Min                             -0.999841
expl/Num Paths                                1
expl/Average Returns                       5000.44
expl/env_infos/final/reward_run Mean          5.33354
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.33354
expl/env_infos/final/reward_run Min           5.33354
expl/env_infos/initial/reward_run Mean       -0.406557
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.406557
expl/env_infos/initial/reward_run Min        -0.406557
expl/env_infos/reward_run Mean                5.40182
expl/env_infos/reward_run Std                 1.16342
expl/env_infos/reward_run Max                 7.76527
expl/env_infos/reward_run Min                -0.406557
expl/env_infos/final/reward_ctrl Mean        -0.29097
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.29097
expl/env_infos/final/reward_ctrl Min         -0.29097
expl/env_infos/initial/reward_ctrl Mean      -0.364122
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.364122
expl/env_infos/initial/reward_ctrl Min       -0.364122
expl/env_infos/reward_ctrl Mean              -0.401387
expl/env_infos/reward_ctrl Std                0.0885681
expl/env_infos/reward_ctrl Max               -0.147023
expl/env_infos/reward_ctrl Min               -0.588707
eval/num steps total                     835000
eval/num paths total                        835
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.1311
eval/Rewards Std                              1.21637
eval/Rewards Max                              7.6934
eval/Rewards Min                             -1.13717
eval/Returns Mean                          5131.1
eval/Returns Std                             89.7385
eval/Returns Max                           5240.44
eval/Returns Min                           5017.89
eval/Actions Mean                             0.0423291
eval/Actions Std                              0.833857
eval/Actions Max                              0.997917
eval/Actions Min                             -0.998651
eval/Num Paths                                5
eval/Average Returns                       5131.1
eval/env_infos/final/reward_run Mean          6.6255
eval/env_infos/final/reward_run Std           0.334624
eval/env_infos/final/reward_run Max           6.93224
eval/env_infos/final/reward_run Min           6.04181
eval/env_infos/initial/reward_run Mean       -0.631787
eval/env_infos/initial/reward_run Std         0.0481038
eval/env_infos/initial/reward_run Max        -0.584257
eval/env_infos/initial/reward_run Min        -0.711967
eval/env_infos/reward_run Mean                5.54936
eval/env_infos/reward_run Std                 1.18994
eval/env_infos/reward_run Max                 8.14691
eval/env_infos/reward_run Min                -0.711967
eval/env_infos/final/reward_ctrl Mean        -0.367885
eval/env_infos/final/reward_ctrl Std          0.0545772
eval/env_infos/final/reward_ctrl Max         -0.312718
eval/env_infos/final/reward_ctrl Min         -0.444235
eval/env_infos/initial/reward_ctrl Mean      -0.401358
eval/env_infos/initial/reward_ctrl Std        0.0446479
eval/env_infos/initial/reward_ctrl Max       -0.318048
eval/env_infos/initial/reward_ctrl Min       -0.443551
eval/env_infos/reward_ctrl Mean              -0.418266
eval/env_infos/reward_ctrl Std                0.0828704
eval/env_infos/reward_ctrl Max               -0.146796
eval/env_infos/reward_ctrl Min               -0.585619
time/data storing (s)                         0.00448823
time/evaluation sampling (s)                  2.05333
time/exploration sampling (s)                 0.530608
time/logging (s)                              0.0158519
time/sac training (s)                         7.89238
time/saving (s)                               0.00384636
time/training (s)                             4.035e-05
time/epoch (s)                               10.5005
time/total (s)                             1795.82
Epoch                                       166
---------------------------------------  ---------------
2021-11-24 00:59:19.287083 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 167 finished
---------------------------------------  ---------------
epoch                                       167
replay_buffer/size                       169000
trainer/num train calls                  168000
trainer/QF1 Loss                              7.54254
trainer/QF2 Loss                              7.39874
trainer/Policy Loss                        -288.562
trainer/Q1 Predictions Mean                 288.899
trainer/Q1 Predictions Std                   93.0466
trainer/Q1 Predictions Max                  362.68
trainer/Q1 Predictions Min                   13.2137
trainer/Q2 Predictions Mean                 289.25
trainer/Q2 Predictions Std                   93.0901
trainer/Q2 Predictions Max                  363.136
trainer/Q2 Predictions Min                   13.37
trainer/Q Targets Mean                      288.405
trainer/Q Targets Std                        92.8396
trainer/Q Targets Max                       364.249
trainer/Q Targets Min                        12.1365
trainer/Log Pis Mean                          6.57336
trainer/Log Pis Std                           5.04925
trainer/Log Pis Max                          19.5654
trainer/Log Pis Min                          -8.78326
trainer/policy/mean Mean                      0.060475
trainer/policy/mean Std                       0.777779
trainer/policy/mean Max                       0.998768
trainer/policy/mean Min                      -0.999254
trainer/policy/normal/std Mean                0.441266
trainer/policy/normal/std Std                 0.150962
trainer/policy/normal/std Max                 1.03286
trainer/policy/normal/std Min                 0.101732
trainer/policy/normal/log_std Mean           -0.884911
trainer/policy/normal/log_std Std             0.385626
trainer/policy/normal/log_std Max             0.0323293
trainer/policy/normal/log_std Min            -2.28541
trainer/Alpha                                 0.107516
trainer/Alpha Loss                            1.27866
expl/num steps total                     169000
expl/num paths total                        169
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.82668
expl/Rewards Std                              1.22012
expl/Rewards Max                              7.005
expl/Rewards Min                             -1.15273
expl/Returns Mean                          4826.68
expl/Returns Std                              0
expl/Returns Max                           4826.68
expl/Returns Min                           4826.68
expl/Actions Mean                             0.0525164
expl/Actions Std                              0.818623
expl/Actions Max                              0.999803
expl/Actions Min                             -0.999945
expl/Num Paths                                1
expl/Average Returns                       4826.68
expl/env_infos/final/reward_run Mean          5.8017
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.8017
expl/env_infos/final/reward_run Min           5.8017
expl/env_infos/initial/reward_run Mean       -0.764842
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.764842
expl/env_infos/initial/reward_run Min        -0.764842
expl/env_infos/reward_run Mean                5.23043
expl/env_infos/reward_run Std                 1.20338
expl/env_infos/reward_run Max                 7.44371
expl/env_infos/reward_run Min                -0.764842
expl/env_infos/final/reward_ctrl Mean        -0.451801
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.451801
expl/env_infos/final/reward_ctrl Min         -0.451801
expl/env_infos/initial/reward_ctrl Mean      -0.387891
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.387891
expl/env_infos/initial/reward_ctrl Min       -0.387891
expl/env_infos/reward_ctrl Mean              -0.403741
expl/env_infos/reward_ctrl Std                0.0899383
expl/env_infos/reward_ctrl Max               -0.0965836
expl/env_infos/reward_ctrl Min               -0.583035
eval/num steps total                     840000
eval/num paths total                        840
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.00772
eval/Rewards Std                              1.19928
eval/Rewards Max                              7.36742
eval/Rewards Min                             -1.20087
eval/Returns Mean                          5007.72
eval/Returns Std                            101.878
eval/Returns Max                           5180.6
eval/Returns Min                           4860.34
eval/Actions Mean                             0.0607751
eval/Actions Std                              0.832017
eval/Actions Max                              0.998302
eval/Actions Min                             -0.999132
eval/Num Paths                                5
eval/Average Returns                       5007.72
eval/env_infos/final/reward_run Mean          5.98269
eval/env_infos/final/reward_run Std           0.995527
eval/env_infos/final/reward_run Max           7.18137
eval/env_infos/final/reward_run Min           4.26645
eval/env_infos/initial/reward_run Mean       -0.652162
eval/env_infos/initial/reward_run Std         0.123217
eval/env_infos/initial/reward_run Max        -0.496843
eval/env_infos/initial/reward_run Min        -0.759873
eval/env_infos/reward_run Mean                5.42529
eval/env_infos/reward_run Std                 1.17573
eval/env_infos/reward_run Max                 7.76188
eval/env_infos/reward_run Min                -0.759873
eval/env_infos/final/reward_ctrl Mean        -0.469323
eval/env_infos/final/reward_ctrl Std          0.0535806
eval/env_infos/final/reward_ctrl Max         -0.411731
eval/env_infos/final/reward_ctrl Min         -0.569219
eval/env_infos/initial/reward_ctrl Mean      -0.388384
eval/env_infos/initial/reward_ctrl Std        0.0546435
eval/env_infos/initial/reward_ctrl Max       -0.326179
eval/env_infos/initial/reward_ctrl Min       -0.452766
eval/env_infos/reward_ctrl Mean              -0.417568
eval/env_infos/reward_ctrl Std                0.0866283
eval/env_infos/reward_ctrl Max               -0.110206
eval/env_infos/reward_ctrl Min               -0.582182
time/data storing (s)                         0.00445388
time/evaluation sampling (s)                  2.07844
time/exploration sampling (s)                 0.541908
time/logging (s)                              0.0137988
time/sac training (s)                         7.82823
time/saving (s)                               0.00385669
time/training (s)                             3.5683e-05
time/epoch (s)                               10.4707
time/total (s)                             1806.61
Epoch                                       167
---------------------------------------  ---------------
2021-11-24 00:59:30.194276 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 168 finished
---------------------------------------  ---------------
epoch                                       168
replay_buffer/size                       170000
trainer/num train calls                  169000
trainer/QF1 Loss                              8.08145
trainer/QF2 Loss                              7.4614
trainer/Policy Loss                        -276.517
trainer/Q1 Predictions Mean                 276.858
trainer/Q1 Predictions Std                  101.319
trainer/Q1 Predictions Max                  366.897
trainer/Q1 Predictions Min                   12.0425
trainer/Q2 Predictions Mean                 276.929
trainer/Q2 Predictions Std                  101.317
trainer/Q2 Predictions Max                  366.652
trainer/Q2 Predictions Min                   12.4649
trainer/Q Targets Mean                      276.749
trainer/Q Targets Std                       101.274
trainer/Q Targets Max                       365.06
trainer/Q Targets Min                        11.1103
trainer/Log Pis Mean                          6.2429
trainer/Log Pis Std                           4.99875
trainer/Log Pis Max                          21.8118
trainer/Log Pis Min                         -10.1009
trainer/policy/mean Mean                      0.0682438
trainer/policy/mean Std                       0.778188
trainer/policy/mean Max                       0.999337
trainer/policy/mean Min                      -0.999015
trainer/policy/normal/std Mean                0.463307
trainer/policy/normal/std Std                 0.150246
trainer/policy/normal/std Max                 0.947252
trainer/policy/normal/std Min                 0.0922309
trainer/policy/normal/log_std Mean           -0.831851
trainer/policy/normal/log_std Std             0.377663
trainer/policy/normal/log_std Max            -0.0541904
trainer/policy/normal/log_std Min            -2.38346
trainer/Alpha                                 0.107919
trainer/Alpha Loss                            0.540785
expl/num steps total                     170000
expl/num paths total                        170
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.79856
expl/Rewards Std                              1.20059
expl/Rewards Max                              7.72187
expl/Rewards Min                             -1.17656
expl/Returns Mean                          4798.56
expl/Returns Std                              0
expl/Returns Max                           4798.56
expl/Returns Min                           4798.56
expl/Actions Mean                             0.081137
expl/Actions Std                              0.81351
expl/Actions Max                              0.999836
expl/Actions Min                             -0.999815
expl/Num Paths                                1
expl/Average Returns                       4798.56
expl/env_infos/final/reward_run Mean          4.44696
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.44696
expl/env_infos/final/reward_run Min           4.44696
expl/env_infos/initial/reward_run Mean       -0.719879
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.719879
expl/env_infos/initial/reward_run Min        -0.719879
expl/env_infos/reward_run Mean                5.19959
expl/env_infos/reward_run Std                 1.18231
expl/env_infos/reward_run Max                 8.13688
expl/env_infos/reward_run Min                -0.719879
expl/env_infos/final/reward_ctrl Mean        -0.411744
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.411744
expl/env_infos/final/reward_ctrl Min         -0.411744
expl/env_infos/initial/reward_ctrl Mean      -0.456686
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.456686
expl/env_infos/initial/reward_ctrl Min       -0.456686
expl/env_infos/reward_ctrl Mean              -0.401029
expl/env_infos/reward_ctrl Std                0.0884568
expl/env_infos/reward_ctrl Max               -0.0963751
expl/env_infos/reward_ctrl Min               -0.584131
eval/num steps total                     845000
eval/num paths total                        845
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.01946
eval/Rewards Std                              1.2656
eval/Rewards Max                              7.84136
eval/Rewards Min                             -1.0147
eval/Returns Mean                          5019.46
eval/Returns Std                            131.064
eval/Returns Max                           5187.23
eval/Returns Min                           4844.36
eval/Actions Mean                             0.0780954
eval/Actions Std                              0.829345
eval/Actions Max                              0.999078
eval/Actions Min                             -0.999203
eval/Num Paths                                5
eval/Average Returns                       5019.46
eval/env_infos/final/reward_run Mean          5.2574
eval/env_infos/final/reward_run Std           0.954652
eval/env_infos/final/reward_run Max           6.66794
eval/env_infos/final/reward_run Min           4.18167
eval/env_infos/initial/reward_run Mean       -0.448205
eval/env_infos/initial/reward_run Std         0.198408
eval/env_infos/initial/reward_run Max        -0.0670862
eval/env_infos/initial/reward_run Min        -0.608916
eval/env_infos/reward_run Mean                5.43581
eval/env_infos/reward_run Std                 1.24981
eval/env_infos/reward_run Max                 8.29563
eval/env_infos/reward_run Min                -0.608916
eval/env_infos/final/reward_ctrl Mean        -0.423184
eval/env_infos/final/reward_ctrl Std          0.0492965
eval/env_infos/final/reward_ctrl Max         -0.345182
eval/env_infos/final/reward_ctrl Min         -0.490654
eval/env_infos/initial/reward_ctrl Mean      -0.267627
eval/env_infos/initial/reward_ctrl Std        0.101848
eval/env_infos/initial/reward_ctrl Max       -0.134406
eval/env_infos/initial/reward_ctrl Min       -0.419748
eval/env_infos/reward_ctrl Mean              -0.416347
eval/env_infos/reward_ctrl Std                0.0863686
eval/env_infos/reward_ctrl Max               -0.0921058
eval/env_infos/reward_ctrl Min               -0.580923
time/data storing (s)                         0.00474883
time/evaluation sampling (s)                  2.07191
time/exploration sampling (s)                 0.548625
time/logging (s)                              0.0143294
time/sac training (s)                         7.92023
time/saving (s)                               0.00384023
time/training (s)                             5.1582e-05
time/epoch (s)                               10.5637
time/total (s)                             1817.5
Epoch                                       168
---------------------------------------  ---------------
2021-11-24 00:59:41.054867 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 169 finished
---------------------------------------  ---------------
epoch                                       169
replay_buffer/size                       171000
trainer/num train calls                  170000
trainer/QF1 Loss                             10.1906
trainer/QF2 Loss                              7.0741
trainer/Policy Loss                        -274.773
trainer/Q1 Predictions Mean                 275.14
trainer/Q1 Predictions Std                  106.394
trainer/Q1 Predictions Max                  368.093
trainer/Q1 Predictions Min                   10.9383
trainer/Q2 Predictions Mean                 274.783
trainer/Q2 Predictions Std                  106.11
trainer/Q2 Predictions Max                  367.723
trainer/Q2 Predictions Min                   12.5173
trainer/Q Targets Mean                      274.541
trainer/Q Targets Std                       106.213
trainer/Q Targets Max                       369.11
trainer/Q Targets Min                        12.8191
trainer/Log Pis Mean                          5.81646
trainer/Log Pis Std                           5.1172
trainer/Log Pis Max                          21.4568
trainer/Log Pis Min                          -5.42862
trainer/policy/mean Mean                      0.0237163
trainer/policy/mean Std                       0.763112
trainer/policy/mean Max                       0.998949
trainer/policy/mean Min                      -0.999635
trainer/policy/normal/std Mean                0.452852
trainer/policy/normal/std Std                 0.157322
trainer/policy/normal/std Max                 0.894261
trainer/policy/normal/std Min                 0.0899284
trainer/policy/normal/log_std Mean           -0.864519
trainer/policy/normal/log_std Std             0.406656
trainer/policy/normal/log_std Max            -0.111758
trainer/policy/normal/log_std Min            -2.40874
trainer/Alpha                                 0.108512
trainer/Alpha Loss                           -0.407627
expl/num steps total                     171000
expl/num paths total                        171
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.95562
expl/Rewards Std                              1.14284
expl/Rewards Max                              6.92702
expl/Rewards Min                             -0.613389
expl/Returns Mean                          4955.62
expl/Returns Std                              0
expl/Returns Max                           4955.62
expl/Returns Min                           4955.62
expl/Actions Mean                             0.0350893
expl/Actions Std                              0.82085
expl/Actions Max                              0.999775
expl/Actions Min                             -0.999584
expl/Num Paths                                1
expl/Average Returns                       4955.62
expl/env_infos/final/reward_run Mean          5.60074
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.60074
expl/env_infos/final/reward_run Min           5.60074
expl/env_infos/initial/reward_run Mean       -0.263699
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.263699
expl/env_infos/initial/reward_run Min        -0.263699
expl/env_infos/reward_run Mean                5.36063
expl/env_infos/reward_run Std                 1.12162
expl/env_infos/reward_run Max                 7.39589
expl/env_infos/reward_run Min                -0.263699
expl/env_infos/final/reward_ctrl Mean        -0.258704
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.258704
expl/env_infos/final/reward_ctrl Min         -0.258704
expl/env_infos/initial/reward_ctrl Mean      -0.349691
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.349691
expl/env_infos/initial/reward_ctrl Min       -0.349691
expl/env_infos/reward_ctrl Mean              -0.405015
expl/env_infos/reward_ctrl Std                0.0810536
expl/env_infos/reward_ctrl Max               -0.149819
expl/env_infos/reward_ctrl Min               -0.577582
eval/num steps total                     850000
eval/num paths total                        850
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.10823
eval/Rewards Std                              1.24275
eval/Rewards Max                              7.47826
eval/Rewards Min                             -0.805251
eval/Returns Mean                          5108.23
eval/Returns Std                             67.998
eval/Returns Max                           5184.39
eval/Returns Min                           5025.77
eval/Actions Mean                             0.0441565
eval/Actions Std                              0.836911
eval/Actions Max                              0.998766
eval/Actions Min                             -0.999318
eval/Num Paths                                5
eval/Average Returns                       5108.23
eval/env_infos/final/reward_run Mean          6.08804
eval/env_infos/final/reward_run Std           0.625635
eval/env_infos/final/reward_run Max           6.97302
eval/env_infos/final/reward_run Min           5.24583
eval/env_infos/initial/reward_run Mean       -0.324311
eval/env_infos/initial/reward_run Std         0.0981063
eval/env_infos/initial/reward_run Max        -0.14358
eval/env_infos/initial/reward_run Min        -0.419687
eval/env_infos/reward_run Mean                5.52965
eval/env_infos/reward_run Std                 1.22066
eval/env_infos/reward_run Max                 7.8992
eval/env_infos/reward_run Min                -0.419687
eval/env_infos/final/reward_ctrl Mean        -0.416071
eval/env_infos/final/reward_ctrl Std          0.083514
eval/env_infos/final/reward_ctrl Max         -0.295966
eval/env_infos/final/reward_ctrl Min         -0.510747
eval/env_infos/initial/reward_ctrl Mean      -0.304063
eval/env_infos/initial/reward_ctrl Std        0.0454897
eval/env_infos/initial/reward_ctrl Max       -0.260125
eval/env_infos/initial/reward_ctrl Min       -0.385564
eval/env_infos/reward_ctrl Mean              -0.421421
eval/env_infos/reward_ctrl Std                0.0770911
eval/env_infos/reward_ctrl Max               -0.158676
eval/env_infos/reward_ctrl Min               -0.580719
time/data storing (s)                         0.00452768
time/evaluation sampling (s)                  2.05133
time/exploration sampling (s)                 0.540343
time/logging (s)                              0.0137646
time/sac training (s)                         7.9057
time/saving (s)                               0.00376555
time/training (s)                             3.5474e-05
time/epoch (s)                               10.5195
time/total (s)                             1828.35
Epoch                                       169
---------------------------------------  ---------------
2021-11-24 00:59:52.041609 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 170 finished
---------------------------------------  ---------------
epoch                                       170
replay_buffer/size                       172000
trainer/num train calls                  171000
trainer/QF1 Loss                              6.62017
trainer/QF2 Loss                              5.78733
trainer/Policy Loss                        -282.548
trainer/Q1 Predictions Mean                 282.869
trainer/Q1 Predictions Std                   99.6026
trainer/Q1 Predictions Max                  370.532
trainer/Q1 Predictions Min                   11.8018
trainer/Q2 Predictions Mean                 282.872
trainer/Q2 Predictions Std                   99.6223
trainer/Q2 Predictions Max                  369.605
trainer/Q2 Predictions Min                   12.4497
trainer/Q Targets Mean                      283.138
trainer/Q Targets Std                        99.7032
trainer/Q Targets Max                       370.849
trainer/Q Targets Min                        12.1187
trainer/Log Pis Mean                          5.74753
trainer/Log Pis Std                           4.58963
trainer/Log Pis Max                          18.4714
trainer/Log Pis Min                          -5.62699
trainer/policy/mean Mean                      0.0697914
trainer/policy/mean Std                       0.767848
trainer/policy/mean Max                       0.999659
trainer/policy/mean Min                      -0.998378
trainer/policy/normal/std Mean                0.461228
trainer/policy/normal/std Std                 0.144342
trainer/policy/normal/std Max                 0.928319
trainer/policy/normal/std Min                 0.0943872
trainer/policy/normal/log_std Mean           -0.833038
trainer/policy/normal/log_std Std             0.367207
trainer/policy/normal/log_std Max            -0.0743794
trainer/policy/normal/log_std Min            -2.36035
trainer/Alpha                                 0.110153
trainer/Alpha Loss                           -0.556926
expl/num steps total                     172000
expl/num paths total                        172
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.07313
expl/Rewards Std                              1.13911
expl/Rewards Max                              7.28034
expl/Rewards Min                             -0.562281
expl/Returns Mean                          5073.13
expl/Returns Std                              0
expl/Returns Max                           5073.13
expl/Returns Min                           5073.13
expl/Actions Mean                             0.0665745
expl/Actions Std                              0.815541
expl/Actions Max                              0.999443
expl/Actions Min                             -0.999478
expl/Num Paths                                1
expl/Average Returns                       5073.13
expl/env_infos/final/reward_run Mean          3.91294
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.91294
expl/env_infos/final/reward_run Min           3.91294
expl/env_infos/initial/reward_run Mean       -0.205774
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.205774
expl/env_infos/initial/reward_run Min        -0.205774
expl/env_infos/reward_run Mean                5.47486
expl/env_infos/reward_run Std                 1.12823
expl/env_infos/reward_run Max                 7.73894
expl/env_infos/reward_run Min                -0.205774
expl/env_infos/final/reward_ctrl Mean        -0.316146
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.316146
expl/env_infos/final/reward_ctrl Min         -0.316146
expl/env_infos/initial/reward_ctrl Mean      -0.356507
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.356507
expl/env_infos/initial/reward_ctrl Min       -0.356507
expl/env_infos/reward_ctrl Mean              -0.401724
expl/env_infos/reward_ctrl Std                0.0841932
expl/env_infos/reward_ctrl Max               -0.177466
expl/env_infos/reward_ctrl Min               -0.580184
eval/num steps total                     855000
eval/num paths total                        855
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.11974
eval/Rewards Std                              1.20658
eval/Rewards Max                              7.71511
eval/Rewards Min                             -0.982471
eval/Returns Mean                          5119.74
eval/Returns Std                            100.117
eval/Returns Max                           5282.47
eval/Returns Min                           5029.41
eval/Actions Mean                             0.0713825
eval/Actions Std                              0.826559
eval/Actions Max                              0.999058
eval/Actions Min                             -0.997927
eval/Num Paths                                5
eval/Average Returns                       5119.74
eval/env_infos/final/reward_run Mean          5.68111
eval/env_infos/final/reward_run Std           0.911094
eval/env_infos/final/reward_run Max           6.66216
eval/env_infos/final/reward_run Min           4.51418
eval/env_infos/initial/reward_run Mean       -0.353216
eval/env_infos/initial/reward_run Std         0.191666
eval/env_infos/initial/reward_run Max        -0.0192287
eval/env_infos/initial/reward_run Min        -0.592622
eval/env_infos/reward_run Mean                5.53271
eval/env_infos/reward_run Std                 1.19555
eval/env_infos/reward_run Max                 8.19311
eval/env_infos/reward_run Min                -0.592622
eval/env_infos/final/reward_ctrl Mean        -0.418368
eval/env_infos/final/reward_ctrl Std          0.0526962
eval/env_infos/final/reward_ctrl Max         -0.33703
eval/env_infos/final/reward_ctrl Min         -0.50102
eval/env_infos/initial/reward_ctrl Mean      -0.305935
eval/env_infos/initial/reward_ctrl Std        0.0870704
eval/env_infos/initial/reward_ctrl Max       -0.185307
eval/env_infos/initial/reward_ctrl Min       -0.418301
eval/env_infos/reward_ctrl Mean              -0.412977
eval/env_infos/reward_ctrl Std                0.0799339
eval/env_infos/reward_ctrl Max               -0.138701
eval/env_infos/reward_ctrl Min               -0.580705
time/data storing (s)                         0.00456347
time/evaluation sampling (s)                  2.06015
time/exploration sampling (s)                 0.546891
time/logging (s)                              0.0142775
time/sac training (s)                         8.01212
time/saving (s)                               0.00388243
time/training (s)                             4.3693e-05
time/epoch (s)                               10.6419
time/total (s)                             1839.32
Epoch                                       170
---------------------------------------  ---------------
2021-11-24 01:00:02.895549 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 171 finished
---------------------------------------  ---------------
epoch                                       171
replay_buffer/size                       173000
trainer/num train calls                  172000
trainer/QF1 Loss                              8.76092
trainer/QF2 Loss                              7.49462
trainer/Policy Loss                        -276.795
trainer/Q1 Predictions Mean                 277.098
trainer/Q1 Predictions Std                  103.834
trainer/Q1 Predictions Max                  375.787
trainer/Q1 Predictions Min                   13.563
trainer/Q2 Predictions Mean                 277.331
trainer/Q2 Predictions Std                  104.015
trainer/Q2 Predictions Max                  375.729
trainer/Q2 Predictions Min                   13.566
trainer/Q Targets Mean                      277.299
trainer/Q Targets Std                       104.096
trainer/Q Targets Max                       377.935
trainer/Q Targets Min                        12.7282
trainer/Log Pis Mean                          6.30204
trainer/Log Pis Std                           5.09589
trainer/Log Pis Max                          17.0261
trainer/Log Pis Min                          -4.81624
trainer/policy/mean Mean                      0.0321033
trainer/policy/mean Std                       0.773377
trainer/policy/mean Max                       0.999809
trainer/policy/mean Min                      -0.998585
trainer/policy/normal/std Mean                0.45343
trainer/policy/normal/std Std                 0.152848
trainer/policy/normal/std Max                 0.972709
trainer/policy/normal/std Min                 0.0965771
trainer/policy/normal/log_std Mean           -0.858001
trainer/policy/normal/log_std Std             0.390088
trainer/policy/normal/log_std Max            -0.0276704
trainer/policy/normal/log_std Min            -2.33741
trainer/Alpha                                 0.11035
trainer/Alpha Loss                            0.665731
expl/num steps total                     173000
expl/num paths total                        173
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.96235
expl/Rewards Std                              1.12699
expl/Rewards Max                              7.36129
expl/Rewards Min                             -0.487505
expl/Returns Mean                          4962.35
expl/Returns Std                              0
expl/Returns Max                           4962.35
expl/Returns Min                           4962.35
expl/Actions Mean                             0.0508815
expl/Actions Std                              0.824655
expl/Actions Max                              0.999311
expl/Actions Min                             -0.999821
expl/Num Paths                                1
expl/Average Returns                       4962.35
expl/env_infos/final/reward_run Mean          6.72663
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.72663
expl/env_infos/final/reward_run Min           6.72663
expl/env_infos/initial/reward_run Mean       -0.265394
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.265394
expl/env_infos/initial/reward_run Min        -0.265394
expl/env_infos/reward_run Mean                5.37193
expl/env_infos/reward_run Std                 1.11656
expl/env_infos/reward_run Max                 7.81275
expl/env_infos/reward_run Min                -0.265394
expl/env_infos/final/reward_ctrl Mean        -0.485273
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.485273
expl/env_infos/final/reward_ctrl Min         -0.485273
expl/env_infos/initial/reward_ctrl Mean      -0.222111
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.222111
expl/env_infos/initial/reward_ctrl Min       -0.222111
expl/env_infos/reward_ctrl Mean              -0.409586
expl/env_infos/reward_ctrl Std                0.0827749
expl/env_infos/reward_ctrl Max               -0.169492
expl/env_infos/reward_ctrl Min               -0.582425
eval/num steps total                     860000
eval/num paths total                        860
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.21792
eval/Rewards Std                              1.22488
eval/Rewards Max                              7.74944
eval/Rewards Min                             -1.12714
eval/Returns Mean                          5217.92
eval/Returns Std                            125.76
eval/Returns Max                           5428.07
eval/Returns Min                           5081.28
eval/Actions Mean                             0.0431297
eval/Actions Std                              0.83825
eval/Actions Max                              0.998782
eval/Actions Min                             -0.998382
eval/Num Paths                                5
eval/Average Returns                       5217.92
eval/env_infos/final/reward_run Mean          5.75281
eval/env_infos/final/reward_run Std           0.869525
eval/env_infos/final/reward_run Max           7.21109
eval/env_infos/final/reward_run Min           4.70829
eval/env_infos/initial/reward_run Mean       -0.50379
eval/env_infos/initial/reward_run Std         0.193567
eval/env_infos/initial/reward_run Max        -0.132159
eval/env_infos/initial/reward_run Min        -0.666218
eval/env_infos/reward_run Mean                5.64063
eval/env_infos/reward_run Std                 1.21511
eval/env_infos/reward_run Max                 8.21842
eval/env_infos/reward_run Min                -0.666218
eval/env_infos/final/reward_ctrl Mean        -0.443528
eval/env_infos/final/reward_ctrl Std          0.0534154
eval/env_infos/final/reward_ctrl Max         -0.373698
eval/env_infos/final/reward_ctrl Min         -0.508108
eval/env_infos/initial/reward_ctrl Mean      -0.324708
eval/env_infos/initial/reward_ctrl Std        0.0918348
eval/env_infos/initial/reward_ctrl Max       -0.210699
eval/env_infos/initial/reward_ctrl Min       -0.479682
eval/env_infos/reward_ctrl Mean              -0.422714
eval/env_infos/reward_ctrl Std                0.0799011
eval/env_infos/reward_ctrl Max               -0.107507
eval/env_infos/reward_ctrl Min               -0.579388
time/data storing (s)                         0.00455033
time/evaluation sampling (s)                  2.03735
time/exploration sampling (s)                 0.542898
time/logging (s)                              0.0138825
time/sac training (s)                         7.90711
time/saving (s)                               0.00383067
time/training (s)                             3.5888e-05
time/epoch (s)                               10.5097
time/total (s)                             1850.16
Epoch                                       171
---------------------------------------  ---------------
2021-11-24 01:00:13.762591 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 172 finished
---------------------------------------  ---------------
epoch                                       172
replay_buffer/size                       174000
trainer/num train calls                  173000
trainer/QF1 Loss                              6.61219
trainer/QF2 Loss                              5.45069
trainer/Policy Loss                        -279.39
trainer/Q1 Predictions Mean                 279.819
trainer/Q1 Predictions Std                  105.996
trainer/Q1 Predictions Max                  375.86
trainer/Q1 Predictions Min                   12.8859
trainer/Q2 Predictions Mean                 279.583
trainer/Q2 Predictions Std                  105.774
trainer/Q2 Predictions Max                  375.597
trainer/Q2 Predictions Min                   12.701
trainer/Q Targets Mean                      279.313
trainer/Q Targets Std                       105.798
trainer/Q Targets Max                       375.238
trainer/Q Targets Min                        12.7244
trainer/Log Pis Mean                          5.0543
trainer/Log Pis Std                           4.99627
trainer/Log Pis Max                          27.9732
trainer/Log Pis Min                          -6.50448
trainer/policy/mean Mean                      0.0314047
trainer/policy/mean Std                       0.757285
trainer/policy/mean Max                       0.998954
trainer/policy/mean Min                      -0.999977
trainer/policy/normal/std Mean                0.462153
trainer/policy/normal/std Std                 0.158083
trainer/policy/normal/std Max                 1.38852
trainer/policy/normal/std Min                 0.0965622
trainer/policy/normal/log_std Mean           -0.840396
trainer/policy/normal/log_std Std             0.39402
trainer/policy/normal/log_std Max             0.32824
trainer/policy/normal/log_std Min            -2.33757
trainer/Alpha                                 0.108816
trainer/Alpha Loss                           -2.09766
expl/num steps total                     174000
expl/num paths total                        174
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.04382
expl/Rewards Std                              1.19254
expl/Rewards Max                              7.49522
expl/Rewards Min                             -1.13475
expl/Returns Mean                          5043.82
expl/Returns Std                              0
expl/Returns Max                           5043.82
expl/Returns Min                           5043.82
expl/Actions Mean                             0.0364957
expl/Actions Std                              0.819315
expl/Actions Max                              0.999458
expl/Actions Min                             -0.999871
expl/Num Paths                                1
expl/Average Returns                       5043.82
expl/env_infos/final/reward_run Mean          6.71103
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.71103
expl/env_infos/final/reward_run Min           6.71103
expl/env_infos/initial/reward_run Mean       -0.684168
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.684168
expl/env_infos/initial/reward_run Min        -0.684168
expl/env_infos/reward_run Mean                5.44739
expl/env_infos/reward_run Std                 1.17823
expl/env_infos/reward_run Max                 7.87048
expl/env_infos/reward_run Min                -0.684168
expl/env_infos/final/reward_ctrl Mean        -0.46558
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.46558
expl/env_infos/final/reward_ctrl Min         -0.46558
expl/env_infos/initial/reward_ctrl Mean      -0.450586
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.450586
expl/env_infos/initial/reward_ctrl Min       -0.450586
expl/env_infos/reward_ctrl Mean              -0.403565
expl/env_infos/reward_ctrl Std                0.0839459
expl/env_infos/reward_ctrl Max               -0.13589
expl/env_infos/reward_ctrl Min               -0.585994
eval/num steps total                     865000
eval/num paths total                        865
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.20074
eval/Rewards Std                              1.21788
eval/Rewards Max                              7.51796
eval/Rewards Min                             -0.796826
eval/Returns Mean                          5200.74
eval/Returns Std                             90.653
eval/Returns Max                           5344.76
eval/Returns Min                           5111.52
eval/Actions Mean                             0.039677
eval/Actions Std                              0.836228
eval/Actions Max                              0.999033
eval/Actions Min                             -0.998972
eval/Num Paths                                5
eval/Average Returns                       5200.74
eval/env_infos/final/reward_run Mean          6.33529
eval/env_infos/final/reward_run Std           0.819664
eval/env_infos/final/reward_run Max           7.1496
eval/env_infos/final/reward_run Min           4.85577
eval/env_infos/initial/reward_run Mean       -0.177409
eval/env_infos/initial/reward_run Std         0.162028
eval/env_infos/initial/reward_run Max        -0.022287
eval/env_infos/initial/reward_run Min        -0.453333
eval/env_infos/reward_run Mean                5.62125
eval/env_infos/reward_run Std                 1.20236
eval/env_infos/reward_run Max                 7.98573
eval/env_infos/reward_run Min                -0.453333
eval/env_infos/final/reward_ctrl Mean        -0.456449
eval/env_infos/final/reward_ctrl Std          0.0437281
eval/env_infos/final/reward_ctrl Max         -0.40761
eval/env_infos/final/reward_ctrl Min         -0.516627
eval/env_infos/initial/reward_ctrl Mean      -0.263187
eval/env_infos/initial/reward_ctrl Std        0.0556893
eval/env_infos/initial/reward_ctrl Max       -0.17739
eval/env_infos/initial/reward_ctrl Min       -0.335506
eval/env_infos/reward_ctrl Mean              -0.420511
eval/env_infos/reward_ctrl Std                0.0779032
eval/env_infos/reward_ctrl Max               -0.101452
eval/env_infos/reward_ctrl Min               -0.581456
time/data storing (s)                         0.00452133
time/evaluation sampling (s)                  2.07541
time/exploration sampling (s)                 0.528509
time/logging (s)                              0.0136061
time/sac training (s)                         7.89988
time/saving (s)                               0.00378318
time/training (s)                             3.5145e-05
time/epoch (s)                               10.5257
time/total (s)                             1861.01
Epoch                                       172
---------------------------------------  ---------------
2021-11-24 01:00:24.607401 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 173 finished
---------------------------------------  ---------------
epoch                                       173
replay_buffer/size                       175000
trainer/num train calls                  174000
trainer/QF1 Loss                              7.87727
trainer/QF2 Loss                              7.0024
trainer/Policy Loss                        -288.266
trainer/Q1 Predictions Mean                 288.777
trainer/Q1 Predictions Std                   95.6163
trainer/Q1 Predictions Max                  370.827
trainer/Q1 Predictions Min                   13.6408
trainer/Q2 Predictions Mean                 288.97
trainer/Q2 Predictions Std                   95.4928
trainer/Q2 Predictions Max                  368.717
trainer/Q2 Predictions Min                   13.6858
trainer/Q Targets Mean                      288.629
trainer/Q Targets Std                        95.5306
trainer/Q Targets Max                       369.123
trainer/Q Targets Min                        13.6476
trainer/Log Pis Mean                          6.43034
trainer/Log Pis Std                           4.7191
trainer/Log Pis Max                          17.0664
trainer/Log Pis Min                          -4.89988
trainer/policy/mean Mean                      0.0408908
trainer/policy/mean Std                       0.780583
trainer/policy/mean Max                       0.997705
trainer/policy/mean Min                      -0.999387
trainer/policy/normal/std Mean                0.447431
trainer/policy/normal/std Std                 0.14509
trainer/policy/normal/std Max                 0.862774
trainer/policy/normal/std Min                 0.085611
trainer/policy/normal/log_std Mean           -0.869035
trainer/policy/normal/log_std Std             0.388484
trainer/policy/normal/log_std Max            -0.147602
trainer/policy/normal/log_std Min            -2.45794
trainer/Alpha                                 0.111711
trainer/Alpha Loss                            0.943229
expl/num steps total                     175000
expl/num paths total                        175
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.81991
expl/Rewards Std                              1.20569
expl/Rewards Max                              7.32114
expl/Rewards Min                             -1.12023
expl/Returns Mean                          4819.91
expl/Returns Std                              0
expl/Returns Max                           4819.91
expl/Returns Min                           4819.91
expl/Actions Mean                             0.0592542
expl/Actions Std                              0.817601
expl/Actions Max                              0.999628
expl/Actions Min                             -0.999381
expl/Num Paths                                1
expl/Average Returns                       4819.91
expl/env_infos/final/reward_run Mean          5.7338
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.7338
expl/env_infos/final/reward_run Min           5.7338
expl/env_infos/initial/reward_run Mean       -0.733899
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.733899
expl/env_infos/initial/reward_run Min        -0.733899
expl/env_infos/reward_run Mean                5.2231
expl/env_infos/reward_run Std                 1.19817
expl/env_infos/reward_run Max                 7.75861
expl/env_infos/reward_run Min                -0.733899
expl/env_infos/final/reward_ctrl Mean        -0.399963
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.399963
expl/env_infos/final/reward_ctrl Min         -0.399963
expl/env_infos/initial/reward_ctrl Mean      -0.386333
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.386333
expl/env_infos/initial/reward_ctrl Min       -0.386333
expl/env_infos/reward_ctrl Mean              -0.403189
expl/env_infos/reward_ctrl Std                0.083473
expl/env_infos/reward_ctrl Max               -0.136417
expl/env_infos/reward_ctrl Min               -0.581503
eval/num steps total                     870000
eval/num paths total                        870
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.18364
eval/Rewards Std                              1.20932
eval/Rewards Max                              7.64449
eval/Rewards Min                             -0.96854
eval/Returns Mean                          5183.64
eval/Returns Std                             61.9834
eval/Returns Max                           5279.5
eval/Returns Min                           5102.22
eval/Actions Mean                             0.0507274
eval/Actions Std                              0.837183
eval/Actions Max                              0.999486
eval/Actions Min                             -0.997642
eval/Num Paths                                5
eval/Average Returns                       5183.64
eval/env_infos/final/reward_run Mean          6.1247
eval/env_infos/final/reward_run Std           0.722727
eval/env_infos/final/reward_run Max           7.13539
eval/env_infos/final/reward_run Min           5.23564
eval/env_infos/initial/reward_run Mean       -0.441912
eval/env_infos/initial/reward_run Std         0.1047
eval/env_infos/initial/reward_run Max        -0.276786
eval/env_infos/initial/reward_run Min        -0.58135
eval/env_infos/reward_run Mean                5.60571
eval/env_infos/reward_run Std                 1.20267
eval/env_infos/reward_run Max                 8.13351
eval/env_infos/reward_run Min                -0.58135
eval/env_infos/final/reward_ctrl Mean        -0.393363
eval/env_infos/final/reward_ctrl Std          0.0508095
eval/env_infos/final/reward_ctrl Max         -0.345916
eval/env_infos/final/reward_ctrl Min         -0.482201
eval/env_infos/initial/reward_ctrl Mean      -0.313719
eval/env_infos/initial/reward_ctrl Std        0.0895584
eval/env_infos/initial/reward_ctrl Max       -0.215035
eval/env_infos/initial/reward_ctrl Min       -0.446402
eval/env_infos/reward_ctrl Mean              -0.422069
eval/env_infos/reward_ctrl Std                0.0779744
eval/env_infos/reward_ctrl Max               -0.16214
eval/env_infos/reward_ctrl Min               -0.577047
time/data storing (s)                         0.00456817
time/evaluation sampling (s)                  2.0051
time/exploration sampling (s)                 0.535818
time/logging (s)                              0.0142889
time/sac training (s)                         7.93896
time/saving (s)                               0.00403141
time/training (s)                             9.663e-05
time/epoch (s)                               10.5029
time/total (s)                             1871.84
Epoch                                       173
---------------------------------------  ---------------
2021-11-24 01:00:35.523794 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 174 finished
---------------------------------------  ---------------
epoch                                       174
replay_buffer/size                       176000
trainer/num train calls                  175000
trainer/QF1 Loss                              7.4778
trainer/QF2 Loss                              6.34594
trainer/Policy Loss                        -282.283
trainer/Q1 Predictions Mean                 282.728
trainer/Q1 Predictions Std                  106.721
trainer/Q1 Predictions Max                  368.259
trainer/Q1 Predictions Min                   13.4707
trainer/Q2 Predictions Mean                 283.085
trainer/Q2 Predictions Std                  106.771
trainer/Q2 Predictions Max                  369.351
trainer/Q2 Predictions Min                   13.5209
trainer/Q Targets Mean                      282.159
trainer/Q Targets Std                       106.428
trainer/Q Targets Max                       368.389
trainer/Q Targets Min                        13.3625
trainer/Log Pis Mean                          5.72115
trainer/Log Pis Std                           4.90625
trainer/Log Pis Max                          19.8905
trainer/Log Pis Min                          -5.891
trainer/policy/mean Mean                      0.0740255
trainer/policy/mean Std                       0.760258
trainer/policy/mean Max                       0.999312
trainer/policy/mean Min                      -0.998055
trainer/policy/normal/std Mean                0.447963
trainer/policy/normal/std Std                 0.158153
trainer/policy/normal/std Max                 0.951337
trainer/policy/normal/std Min                 0.0884568
trainer/policy/normal/log_std Mean           -0.874786
trainer/policy/normal/log_std Std             0.400618
trainer/policy/normal/log_std Max            -0.0498873
trainer/policy/normal/log_std Min            -2.42524
trainer/Alpha                                 0.110461
trainer/Alpha Loss                           -0.614341
expl/num steps total                     176000
expl/num paths total                        176
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.04557
expl/Rewards Std                              1.19125
expl/Rewards Max                              7.52208
expl/Rewards Min                             -1.04688
expl/Returns Mean                          5045.57
expl/Returns Std                              0
expl/Returns Max                           5045.57
expl/Returns Min                           5045.57
expl/Actions Mean                             0.0677283
expl/Actions Std                              0.814855
expl/Actions Max                              0.999494
expl/Actions Min                             -0.99958
expl/Num Paths                                1
expl/Average Returns                       5045.57
expl/env_infos/final/reward_run Mean          5.49943
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.49943
expl/env_infos/final/reward_run Min           5.49943
expl/env_infos/initial/reward_run Mean        0.188532
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.188532
expl/env_infos/initial/reward_run Min         0.188532
expl/env_infos/reward_run Mean                5.44672
expl/env_infos/reward_run Std                 1.17696
expl/env_infos/reward_run Max                 7.93355
expl/env_infos/reward_run Min                -0.613671
expl/env_infos/final/reward_ctrl Mean        -0.179791
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.179791
expl/env_infos/final/reward_ctrl Min         -0.179791
expl/env_infos/initial/reward_ctrl Mean      -0.243842
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.243842
expl/env_infos/initial/reward_ctrl Min       -0.243842
expl/env_infos/reward_ctrl Mean              -0.401146
expl/env_infos/reward_ctrl Std                0.0873159
expl/env_infos/reward_ctrl Max               -0.0682442
expl/env_infos/reward_ctrl Min               -0.584888
eval/num steps total                     875000
eval/num paths total                        875
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.21308
eval/Rewards Std                              1.21814
eval/Rewards Max                              7.65734
eval/Rewards Min                             -1.1498
eval/Returns Mean                          5213.08
eval/Returns Std                             23.184
eval/Returns Max                           5239.57
eval/Returns Min                           5176.52
eval/Actions Mean                             0.0641038
eval/Actions Std                              0.832278
eval/Actions Max                              0.999438
eval/Actions Min                             -0.9991
eval/Num Paths                                5
eval/Average Returns                       5213.08
eval/env_infos/final/reward_run Mean          6.69752
eval/env_infos/final/reward_run Std           0.685448
eval/env_infos/final/reward_run Max           7.41625
eval/env_infos/final/reward_run Min           5.3883
eval/env_infos/initial/reward_run Mean       -0.293009
eval/env_infos/initial/reward_run Std         0.349273
eval/env_infos/initial/reward_run Max         0.248509
eval/env_infos/initial/reward_run Min        -0.700642
eval/env_infos/reward_run Mean                5.63116
eval/env_infos/reward_run Std                 1.20412
eval/env_infos/reward_run Max                 8.13784
eval/env_infos/reward_run Min                -0.700642
eval/env_infos/final/reward_ctrl Mean        -0.44204
eval/env_infos/final/reward_ctrl Std          0.0170285
eval/env_infos/final/reward_ctrl Max         -0.411176
eval/env_infos/final/reward_ctrl Min         -0.463614
eval/env_infos/initial/reward_ctrl Mean      -0.353504
eval/env_infos/initial/reward_ctrl Std        0.137872
eval/env_infos/initial/reward_ctrl Max       -0.119604
eval/env_infos/initial/reward_ctrl Min       -0.466704
eval/env_infos/reward_ctrl Mean              -0.418078
eval/env_infos/reward_ctrl Std                0.0801961
eval/env_infos/reward_ctrl Max               -0.119604
eval/env_infos/reward_ctrl Min               -0.581529
time/data storing (s)                         0.00453486
time/evaluation sampling (s)                  2.05533
time/exploration sampling (s)                 0.538441
time/logging (s)                              0.0136999
time/sac training (s)                         7.95977
time/saving (s)                               0.00378606
time/training (s)                             3.4938e-05
time/epoch (s)                               10.5756
time/total (s)                             1882.74
Epoch                                       174
---------------------------------------  ---------------
2021-11-24 01:00:46.445094 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 175 finished
---------------------------------------  ---------------
epoch                                       175
replay_buffer/size                       177000
trainer/num train calls                  176000
trainer/QF1 Loss                              8.91324
trainer/QF2 Loss                              7.28283
trainer/Policy Loss                        -286.506
trainer/Q1 Predictions Mean                 287.183
trainer/Q1 Predictions Std                  104.546
trainer/Q1 Predictions Max                  383.637
trainer/Q1 Predictions Min                   14.2687
trainer/Q2 Predictions Mean                 287.004
trainer/Q2 Predictions Std                  104.472
trainer/Q2 Predictions Max                  382.313
trainer/Q2 Predictions Min                   14.7198
trainer/Q Targets Mean                      286.76
trainer/Q Targets Std                       104.497
trainer/Q Targets Max                       380.144
trainer/Q Targets Min                        13.8479
trainer/Log Pis Mean                          6.39055
trainer/Log Pis Std                           4.96689
trainer/Log Pis Max                          15.6383
trainer/Log Pis Min                          -5.20485
trainer/policy/mean Mean                      0.0506573
trainer/policy/mean Std                       0.780747
trainer/policy/mean Max                       0.999703
trainer/policy/mean Min                      -0.998127
trainer/policy/normal/std Mean                0.456879
trainer/policy/normal/std Std                 0.149099
trainer/policy/normal/std Max                 1.09012
trainer/policy/normal/std Min                 0.0815077
trainer/policy/normal/log_std Mean           -0.85085
trainer/policy/normal/log_std Std             0.400492
trainer/policy/normal/log_std Max             0.0862896
trainer/policy/normal/log_std Min            -2.50706
trainer/Alpha                                 0.111098
trainer/Alpha Loss                            0.858173
expl/num steps total                     177000
expl/num paths total                        177
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.80167
expl/Rewards Std                              1.17834
expl/Rewards Max                              6.95634
expl/Rewards Min                             -1.33054
expl/Returns Mean                          4801.67
expl/Returns Std                              0
expl/Returns Max                           4801.67
expl/Returns Min                           4801.67
expl/Actions Mean                             0.0593175
expl/Actions Std                              0.817836
expl/Actions Max                              0.99952
expl/Actions Min                             -0.999644
expl/Num Paths                                1
expl/Average Returns                       4801.67
expl/env_infos/final/reward_run Mean          6.63098
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.63098
expl/env_infos/final/reward_run Min           6.63098
expl/env_infos/initial/reward_run Mean       -0.854779
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.854779
expl/env_infos/initial/reward_run Min        -0.854779
expl/env_infos/reward_run Mean                5.2051
expl/env_infos/reward_run Std                 1.16763
expl/env_infos/reward_run Max                 7.38602
expl/env_infos/reward_run Min                -0.854779
expl/env_infos/final/reward_ctrl Mean        -0.447311
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.447311
expl/env_infos/final/reward_ctrl Min         -0.447311
expl/env_infos/initial/reward_ctrl Mean      -0.475763
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.475763
expl/env_infos/initial/reward_ctrl Min       -0.475763
expl/env_infos/reward_ctrl Mean              -0.403425
expl/env_infos/reward_ctrl Std                0.0869197
expl/env_infos/reward_ctrl Max               -0.135036
expl/env_infos/reward_ctrl Min               -0.586016
eval/num steps total                     880000
eval/num paths total                        880
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.1204
eval/Rewards Std                              1.20991
eval/Rewards Max                              7.82579
eval/Rewards Min                             -1.33277
eval/Returns Mean                          5120.4
eval/Returns Std                             75.0458
eval/Returns Max                           5186.6
eval/Returns Min                           4989.81
eval/Actions Mean                             0.0512029
eval/Actions Std                              0.838145
eval/Actions Max                              0.998069
eval/Actions Min                             -0.997695
eval/Num Paths                                5
eval/Average Returns                       5120.4
eval/env_infos/final/reward_run Mean          6.58356
eval/env_infos/final/reward_run Std           0.701126
eval/env_infos/final/reward_run Max           7.43904
eval/env_infos/final/reward_run Min           5.73901
eval/env_infos/initial/reward_run Mean       -0.555935
eval/env_infos/initial/reward_run Std         0.172216
eval/env_infos/initial/reward_run Max        -0.304157
eval/env_infos/initial/reward_run Min        -0.845073
eval/env_infos/reward_run Mean                5.54346
eval/env_infos/reward_run Std                 1.19848
eval/env_infos/reward_run Max                 8.33314
eval/env_infos/reward_run Min                -0.845073
eval/env_infos/final/reward_ctrl Mean        -0.371913
eval/env_infos/final/reward_ctrl Std          0.10221
eval/env_infos/final/reward_ctrl Max         -0.225645
eval/env_infos/final/reward_ctrl Min         -0.515104
eval/env_infos/initial/reward_ctrl Mean      -0.389715
eval/env_infos/initial/reward_ctrl Std        0.0724868
eval/env_infos/initial/reward_ctrl Max       -0.283304
eval/env_infos/initial/reward_ctrl Min       -0.4877
eval/env_infos/reward_ctrl Mean              -0.423065
eval/env_infos/reward_ctrl Std                0.0805739
eval/env_infos/reward_ctrl Max               -0.131752
eval/env_infos/reward_ctrl Min               -0.584285
time/data storing (s)                         0.00512121
time/evaluation sampling (s)                  2.08193
time/exploration sampling (s)                 0.543122
time/logging (s)                              0.0142615
time/sac training (s)                         7.9306
time/saving (s)                               0.00434378
time/training (s)                             5.3771e-05
time/epoch (s)                               10.5794
time/total (s)                             1893.64
Epoch                                       175
---------------------------------------  ---------------
2021-11-24 01:00:57.446813 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 176 finished
---------------------------------------  ----------------
epoch                                       176
replay_buffer/size                       178000
trainer/num train calls                  177000
trainer/QF1 Loss                              8.91695
trainer/QF2 Loss                              7.84769
trainer/Policy Loss                        -271.036
trainer/Q1 Predictions Mean                 271.077
trainer/Q1 Predictions Std                  115.053
trainer/Q1 Predictions Max                  376.848
trainer/Q1 Predictions Min                   13.0468
trainer/Q2 Predictions Mean                 271.294
trainer/Q2 Predictions Std                  115.003
trainer/Q2 Predictions Max                  377.306
trainer/Q2 Predictions Min                   13.2576
trainer/Q Targets Mean                      270.853
trainer/Q Targets Std                       114.776
trainer/Q Targets Max                       373.902
trainer/Q Targets Min                        12.7501
trainer/Log Pis Mean                          5.70357
trainer/Log Pis Std                           5.09949
trainer/Log Pis Max                          19.7797
trainer/Log Pis Min                          -6.31323
trainer/policy/mean Mean                      0.0578016
trainer/policy/mean Std                       0.755197
trainer/policy/mean Max                       0.998308
trainer/policy/mean Min                      -0.998503
trainer/policy/normal/std Mean                0.46613
trainer/policy/normal/std Std                 0.166941
trainer/policy/normal/std Max                 1.13277
trainer/policy/normal/std Min                 0.0985559
trainer/policy/normal/log_std Mean           -0.837124
trainer/policy/normal/log_std Std             0.406563
trainer/policy/normal/log_std Max             0.124669
trainer/policy/normal/log_std Min            -2.31713
trainer/Alpha                                 0.11193
trainer/Alpha Loss                           -0.649146
expl/num steps total                     178000
expl/num paths total                        178
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.90029
expl/Rewards Std                              1.12886
expl/Rewards Max                              7.19751
expl/Rewards Min                             -1.16278
expl/Returns Mean                          4900.29
expl/Returns Std                              0
expl/Returns Max                           4900.29
expl/Returns Min                           4900.29
expl/Actions Mean                             0.0603316
expl/Actions Std                              0.809027
expl/Actions Max                              0.999785
expl/Actions Min                             -0.999771
expl/Num Paths                                1
expl/Average Returns                       4900.29
expl/env_infos/final/reward_run Mean          5.09898
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.09898
expl/env_infos/final/reward_run Min           5.09898
expl/env_infos/initial/reward_run Mean       -0.740525
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.740525
expl/env_infos/initial/reward_run Min        -0.740525
expl/env_infos/reward_run Mean                5.29519
expl/env_infos/reward_run Std                 1.11542
expl/env_infos/reward_run Max                 7.70199
expl/env_infos/reward_run Min                -0.740525
expl/env_infos/final/reward_ctrl Mean        -0.403458
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.403458
expl/env_infos/final/reward_ctrl Min         -0.403458
expl/env_infos/initial/reward_ctrl Mean      -0.422255
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.422255
expl/env_infos/initial/reward_ctrl Min       -0.422255
expl/env_infos/reward_ctrl Mean              -0.394899
expl/env_infos/reward_ctrl Std                0.0879817
expl/env_infos/reward_ctrl Max               -0.136035
expl/env_infos/reward_ctrl Min               -0.583689
eval/num steps total                     885000
eval/num paths total                        885
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.2484
eval/Rewards Std                              1.19779
eval/Rewards Max                              7.53525
eval/Rewards Min                             -1.35474
eval/Returns Mean                          5248.4
eval/Returns Std                             39.6261
eval/Returns Max                           5288.93
eval/Returns Min                           5194.89
eval/Actions Mean                             0.0493169
eval/Actions Std                              0.83049
eval/Actions Max                              0.99756
eval/Actions Min                             -0.998587
eval/Num Paths                                5
eval/Average Returns                       5248.4
eval/env_infos/final/reward_run Mean          7.02337
eval/env_infos/final/reward_run Std           0.316062
eval/env_infos/final/reward_run Max           7.31586
eval/env_infos/final/reward_run Min           6.47093
eval/env_infos/initial/reward_run Mean       -0.739587
eval/env_infos/initial/reward_run Std         0.104251
eval/env_infos/initial/reward_run Max        -0.577835
eval/env_infos/initial/reward_run Min        -0.902401
eval/env_infos/reward_run Mean                5.66369
eval/env_infos/reward_run Std                 1.18716
eval/env_infos/reward_run Max                 8.03408
eval/env_infos/reward_run Min                -0.902401
eval/env_infos/final/reward_ctrl Mean        -0.477969
eval/env_infos/final/reward_ctrl Std          0.0209887
eval/env_infos/final/reward_ctrl Max         -0.44595
eval/env_infos/final/reward_ctrl Min         -0.509646
eval/env_infos/initial/reward_ctrl Mean      -0.408868
eval/env_infos/initial/reward_ctrl Std        0.0583259
eval/env_infos/initial/reward_ctrl Max       -0.324229
eval/env_infos/initial/reward_ctrl Min       -0.473198
eval/env_infos/reward_ctrl Mean              -0.415288
eval/env_infos/reward_ctrl Std                0.0825845
eval/env_infos/reward_ctrl Max               -0.170012
eval/env_infos/reward_ctrl Min               -0.578406
time/data storing (s)                         0.00454395
time/evaluation sampling (s)                  2.07017
time/exploration sampling (s)                 0.542382
time/logging (s)                              0.0139226
time/sac training (s)                         8.02513
time/saving (s)                               0.00379441
time/training (s)                             3.50529e-05
time/epoch (s)                               10.66
time/total (s)                             1904.63
Epoch                                       176
---------------------------------------  ----------------
2021-11-24 01:01:08.309435 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 177 finished
---------------------------------------  ---------------
epoch                                       177
replay_buffer/size                       179000
trainer/num train calls                  178000
trainer/QF1 Loss                              7.50236
trainer/QF2 Loss                              5.87852
trainer/Policy Loss                        -289.291
trainer/Q1 Predictions Mean                 289.601
trainer/Q1 Predictions Std                  100.191
trainer/Q1 Predictions Max                  373.226
trainer/Q1 Predictions Min                   13.2717
trainer/Q2 Predictions Mean                 289.718
trainer/Q2 Predictions Std                  100.332
trainer/Q2 Predictions Max                  372.125
trainer/Q2 Predictions Min                   12.8162
trainer/Q Targets Mean                      290.418
trainer/Q Targets Std                       100.601
trainer/Q Targets Max                       375.915
trainer/Q Targets Min                        13.3734
trainer/Log Pis Mean                          6.22647
trainer/Log Pis Std                           4.85355
trainer/Log Pis Max                          23.0189
trainer/Log Pis Min                          -5.53904
trainer/policy/mean Mean                      0.0657232
trainer/policy/mean Std                       0.771726
trainer/policy/mean Max                       0.999912
trainer/policy/mean Min                      -0.999569
trainer/policy/normal/std Mean                0.455211
trainer/policy/normal/std Std                 0.154009
trainer/policy/normal/std Max                 1.22443
trainer/policy/normal/std Min                 0.0886817
trainer/policy/normal/log_std Mean           -0.854959
trainer/policy/normal/log_std Std             0.394535
trainer/policy/normal/log_std Max             0.202472
trainer/policy/normal/log_std Min            -2.4227
trainer/Alpha                                 0.110963
trainer/Alpha Loss                            0.497908
expl/num steps total                     179000
expl/num paths total                        179
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.959
expl/Rewards Std                              1.16656
expl/Rewards Max                              7.07235
expl/Rewards Min                             -0.856622
expl/Returns Mean                          4959
expl/Returns Std                              0
expl/Returns Max                           4959
expl/Returns Min                           4959
expl/Actions Mean                             0.064551
expl/Actions Std                              0.815131
expl/Actions Max                              0.99989
expl/Actions Min                             -0.999549
expl/Num Paths                                1
expl/Average Returns                       4959
expl/env_infos/final/reward_run Mean          6.49334
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.49334
expl/env_infos/final/reward_run Min           6.49334
expl/env_infos/initial/reward_run Mean       -0.577522
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.577522
expl/env_infos/initial/reward_run Min        -0.577522
expl/env_infos/reward_run Mean                5.36016
expl/env_infos/reward_run Std                 1.13908
expl/env_infos/reward_run Max                 7.48901
expl/env_infos/reward_run Min                -0.577522
expl/env_infos/final/reward_ctrl Mean        -0.46452
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.46452
expl/env_infos/final/reward_ctrl Min         -0.46452
expl/env_infos/initial/reward_ctrl Mean      -0.2791
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.2791
expl/env_infos/initial/reward_ctrl Min       -0.2791
expl/env_infos/reward_ctrl Mean              -0.401164
expl/env_infos/reward_ctrl Std                0.0944119
expl/env_infos/reward_ctrl Max               -0.147879
expl/env_infos/reward_ctrl Min               -0.578891
eval/num steps total                     890000
eval/num paths total                        890
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.12292
eval/Rewards Std                              1.21012
eval/Rewards Max                              7.59788
eval/Rewards Min                             -1.11508
eval/Returns Mean                          5122.92
eval/Returns Std                             50.376
eval/Returns Max                           5217.12
eval/Returns Min                           5066.39
eval/Actions Mean                             0.0673796
eval/Actions Std                              0.829185
eval/Actions Max                              0.998881
eval/Actions Min                             -0.999706
eval/Num Paths                                5
eval/Average Returns                       5122.92
eval/env_infos/final/reward_run Mean          5.04421
eval/env_infos/final/reward_run Std           0.929078
eval/env_infos/final/reward_run Max           6.08226
eval/env_infos/final/reward_run Min           3.39551
eval/env_infos/initial/reward_run Mean       -0.497013
eval/env_infos/initial/reward_run Std         0.126008
eval/env_infos/initial/reward_run Max        -0.359104
eval/env_infos/initial/reward_run Min        -0.686625
eval/env_infos/reward_run Mean                5.53818
eval/env_infos/reward_run Std                 1.18209
eval/env_infos/reward_run Max                 8.02292
eval/env_infos/reward_run Min                -0.686625
eval/env_infos/final/reward_ctrl Mean        -0.491399
eval/env_infos/final/reward_ctrl Std          0.0626069
eval/env_infos/final/reward_ctrl Max         -0.374497
eval/env_infos/final/reward_ctrl Min         -0.546989
eval/env_infos/initial/reward_ctrl Mean      -0.315556
eval/env_infos/initial/reward_ctrl Std        0.0361608
eval/env_infos/initial/reward_ctrl Max       -0.264731
eval/env_infos/initial/reward_ctrl Min       -0.372305
eval/env_infos/reward_ctrl Mean              -0.415253
eval/env_infos/reward_ctrl Std                0.089217
eval/env_infos/reward_ctrl Max               -0.150464
eval/env_infos/reward_ctrl Min               -0.581022
time/data storing (s)                         0.00498213
time/evaluation sampling (s)                  2.05719
time/exploration sampling (s)                 0.533971
time/logging (s)                              0.0144471
time/sac training (s)                         7.90486
time/saving (s)                               0.00401976
time/training (s)                             9.8806e-05
time/epoch (s)                               10.5196
time/total (s)                             1915.47
Epoch                                       177
---------------------------------------  ---------------
2021-11-24 01:01:19.391937 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 178 finished
---------------------------------------  ---------------
epoch                                       178
replay_buffer/size                       180000
trainer/num train calls                  179000
trainer/QF1 Loss                             14.2388
trainer/QF2 Loss                             10.0174
trainer/Policy Loss                        -285.094
trainer/Q1 Predictions Mean                 285.611
trainer/Q1 Predictions Std                  104.168
trainer/Q1 Predictions Max                  371.141
trainer/Q1 Predictions Min                   13.1611
trainer/Q2 Predictions Mean                 285.401
trainer/Q2 Predictions Std                  104.225
trainer/Q2 Predictions Max                  370.832
trainer/Q2 Predictions Min                   13.9452
trainer/Q Targets Mean                      284.977
trainer/Q Targets Std                       104.427
trainer/Q Targets Max                       373.782
trainer/Q Targets Min                        13.432
trainer/Log Pis Mean                          6.18202
trainer/Log Pis Std                           4.87204
trainer/Log Pis Max                          16.2982
trainer/Log Pis Min                          -4.13978
trainer/policy/mean Mean                      0.0620146
trainer/policy/mean Std                       0.770442
trainer/policy/mean Max                       0.997851
trainer/policy/mean Min                      -0.998748
trainer/policy/normal/std Mean                0.45601
trainer/policy/normal/std Std                 0.159185
trainer/policy/normal/std Max                 1.14736
trainer/policy/normal/std Min                 0.0845503
trainer/policy/normal/log_std Mean           -0.85403
trainer/policy/normal/log_std Std             0.391912
trainer/policy/normal/log_std Max             0.137462
trainer/policy/normal/log_std Min            -2.47041
trainer/Alpha                                 0.112566
trainer/Alpha Loss                            0.397579
expl/num steps total                     180000
expl/num paths total                        180
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.94745
expl/Rewards Std                              1.16178
expl/Rewards Max                              7.17329
expl/Rewards Min                             -0.662954
expl/Returns Mean                          4947.45
expl/Returns Std                              0
expl/Returns Max                           4947.45
expl/Returns Min                           4947.45
expl/Actions Mean                             0.0721589
expl/Actions Std                              0.810482
expl/Actions Max                              0.999605
expl/Actions Min                             -0.999526
expl/Num Paths                                1
expl/Average Returns                       4947.45
expl/env_infos/final/reward_run Mean          6.88188
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.88188
expl/env_infos/final/reward_run Min           6.88188
expl/env_infos/initial/reward_run Mean       -0.404093
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.404093
expl/env_infos/initial/reward_run Min        -0.404093
expl/env_infos/reward_run Mean                5.34471
expl/env_infos/reward_run Std                 1.13953
expl/env_infos/reward_run Max                 7.60751
expl/env_infos/reward_run Min                -0.404093
expl/env_infos/final/reward_ctrl Mean        -0.479893
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.479893
expl/env_infos/final/reward_ctrl Min         -0.479893
expl/env_infos/initial/reward_ctrl Mean      -0.258862
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.258862
expl/env_infos/initial/reward_ctrl Min       -0.258862
expl/env_infos/reward_ctrl Mean              -0.397253
expl/env_infos/reward_ctrl Std                0.083526
expl/env_infos/reward_ctrl Max               -0.135499
expl/env_infos/reward_ctrl Min               -0.576021
eval/num steps total                     895000
eval/num paths total                        895
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.08054
eval/Rewards Std                              1.21524
eval/Rewards Max                              7.37893
eval/Rewards Min                             -1.08986
eval/Returns Mean                          5080.54
eval/Returns Std                             51.4274
eval/Returns Max                           5136.93
eval/Returns Min                           4997.62
eval/Actions Mean                             0.071906
eval/Actions Std                              0.823598
eval/Actions Max                              0.999316
eval/Actions Min                             -0.99805
eval/Num Paths                                5
eval/Average Returns                       5080.54
eval/env_infos/final/reward_run Mean          6.02162
eval/env_infos/final/reward_run Std           0.615332
eval/env_infos/final/reward_run Max           6.76395
eval/env_infos/final/reward_run Min           4.93502
eval/env_infos/initial/reward_run Mean       -0.503741
eval/env_infos/initial/reward_run Std         0.138547
eval/env_infos/initial/reward_run Max        -0.339802
eval/env_infos/initial/reward_run Min        -0.663732
eval/env_infos/reward_run Mean                5.49063
eval/env_infos/reward_run Std                 1.18697
eval/env_infos/reward_run Max                 7.79779
eval/env_infos/reward_run Min                -0.663732
eval/env_infos/final/reward_ctrl Mean        -0.403962
eval/env_infos/final/reward_ctrl Std          0.0541592
eval/env_infos/final/reward_ctrl Max         -0.316805
eval/env_infos/final/reward_ctrl Min         -0.484968
eval/env_infos/initial/reward_ctrl Mean      -0.360094
eval/env_infos/initial/reward_ctrl Std        0.0605588
eval/env_infos/initial/reward_ctrl Max       -0.25112
eval/env_infos/initial/reward_ctrl Min       -0.426127
eval/env_infos/reward_ctrl Mean              -0.41009
eval/env_infos/reward_ctrl Std                0.0788599
eval/env_infos/reward_ctrl Max               -0.128776
eval/env_infos/reward_ctrl Min               -0.578768
time/data storing (s)                         0.00475862
time/evaluation sampling (s)                  2.06725
time/exploration sampling (s)                 0.554837
time/logging (s)                              0.0172451
time/sac training (s)                         8.08437
time/saving (s)                               0.00386591
time/training (s)                             3.4874e-05
time/epoch (s)                               10.7324
time/total (s)                             1926.54
Epoch                                       178
---------------------------------------  ---------------
2021-11-24 01:01:30.257312 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 179 finished
---------------------------------------  ---------------
epoch                                       179
replay_buffer/size                       181000
trainer/num train calls                  180000
trainer/QF1 Loss                              7.19204
trainer/QF2 Loss                              7.13489
trainer/Policy Loss                        -290.399
trainer/Q1 Predictions Mean                 291.06
trainer/Q1 Predictions Std                   96.8209
trainer/Q1 Predictions Max                  378.09
trainer/Q1 Predictions Min                   14.4037
trainer/Q2 Predictions Mean                 290.788
trainer/Q2 Predictions Std                   96.8833
trainer/Q2 Predictions Max                  377.336
trainer/Q2 Predictions Min                   13.1159
trainer/Q Targets Mean                      291.669
trainer/Q Targets Std                        97.1838
trainer/Q Targets Max                       377.207
trainer/Q Targets Min                        12.4847
trainer/Log Pis Mean                          6.36413
trainer/Log Pis Std                           4.77858
trainer/Log Pis Max                          19.7408
trainer/Log Pis Min                          -7.86053
trainer/policy/mean Mean                      0.0303842
trainer/policy/mean Std                       0.783929
trainer/policy/mean Max                       0.998716
trainer/policy/mean Min                      -0.999988
trainer/policy/normal/std Mean                0.451109
trainer/policy/normal/std Std                 0.149615
trainer/policy/normal/std Max                 1.3971
trainer/policy/normal/std Min                 0.101461
trainer/policy/normal/log_std Mean           -0.860485
trainer/policy/normal/log_std Std             0.381998
trainer/policy/normal/log_std Max             0.3344
trainer/policy/normal/log_std Min            -2.28808
trainer/Alpha                                 0.112138
trainer/Alpha Loss                            0.796717
expl/num steps total                     181000
expl/num paths total                        181
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.93018
expl/Rewards Std                              1.1449
expl/Rewards Max                              6.98039
expl/Rewards Min                             -0.636304
expl/Returns Mean                          4930.18
expl/Returns Std                              0
expl/Returns Max                           4930.18
expl/Returns Min                           4930.18
expl/Actions Mean                             0.0268681
expl/Actions Std                              0.824445
expl/Actions Max                              0.999805
expl/Actions Min                             -0.999816
expl/Num Paths                                1
expl/Average Returns                       4930.18
expl/env_infos/final/reward_run Mean          5.29214
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.29214
expl/env_infos/final/reward_run Min           5.29214
expl/env_infos/initial/reward_run Mean       -0.335161
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.335161
expl/env_infos/initial/reward_run Min        -0.335161
expl/env_infos/reward_run Mean                5.33844
expl/env_infos/reward_run Std                 1.13341
expl/env_infos/reward_run Max                 7.4501
expl/env_infos/reward_run Min                -0.335161
expl/env_infos/final/reward_ctrl Mean        -0.496392
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.496392
expl/env_infos/final/reward_ctrl Min         -0.496392
expl/env_infos/initial/reward_ctrl Mean      -0.301143
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.301143
expl/env_infos/initial/reward_ctrl Min       -0.301143
expl/env_infos/reward_ctrl Mean              -0.408258
expl/env_infos/reward_ctrl Std                0.0867529
expl/env_infos/reward_ctrl Max               -0.130805
expl/env_infos/reward_ctrl Min               -0.584484
eval/num steps total                     900000
eval/num paths total                        900
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.21652
eval/Rewards Std                              1.23278
eval/Rewards Max                              7.71078
eval/Rewards Min                             -1.11979
eval/Returns Mean                          5216.52
eval/Returns Std                            105.808
eval/Returns Max                           5373.61
eval/Returns Min                           5067.39
eval/Actions Mean                             0.0371013
eval/Actions Std                              0.842268
eval/Actions Max                              0.998516
eval/Actions Min                             -0.998503
eval/Num Paths                                5
eval/Average Returns                       5216.52
eval/env_infos/final/reward_run Mean          6.63642
eval/env_infos/final/reward_run Std           0.584073
eval/env_infos/final/reward_run Max           7.2564
eval/env_infos/final/reward_run Min           5.91325
eval/env_infos/initial/reward_run Mean       -0.408211
eval/env_infos/initial/reward_run Std         0.265742
eval/env_infos/initial/reward_run Max         0.0689197
eval/env_infos/initial/reward_run Min        -0.740249
eval/env_infos/reward_run Mean                5.643
eval/env_infos/reward_run Std                 1.22302
eval/env_infos/reward_run Max                 8.20298
eval/env_infos/reward_run Min                -0.740249
eval/env_infos/final/reward_ctrl Mean        -0.424568
eval/env_infos/final/reward_ctrl Std          0.0749678
eval/env_infos/final/reward_ctrl Max         -0.282121
eval/env_infos/final/reward_ctrl Min         -0.489277
eval/env_infos/initial/reward_ctrl Mean      -0.292559
eval/env_infos/initial/reward_ctrl Std        0.0889606
eval/env_infos/initial/reward_ctrl Max       -0.17003
eval/env_infos/initial/reward_ctrl Min       -0.409076
eval/env_infos/reward_ctrl Mean              -0.426475
eval/env_infos/reward_ctrl Std                0.0820949
eval/env_infos/reward_ctrl Max               -0.125619
eval/env_infos/reward_ctrl Min               -0.582885
time/data storing (s)                         0.00497833
time/evaluation sampling (s)                  2.06133
time/exploration sampling (s)                 0.544565
time/logging (s)                              0.0150177
time/sac training (s)                         7.89252
time/saving (s)                               0.00385057
time/training (s)                             4.839e-05
time/epoch (s)                               10.5223
time/total (s)                             1937.39
Epoch                                       179
---------------------------------------  ---------------
2021-11-24 01:01:41.139073 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 180 finished
---------------------------------------  ---------------
epoch                                       180
replay_buffer/size                       182000
trainer/num train calls                  181000
trainer/QF1 Loss                              6.55767
trainer/QF2 Loss                              6.0447
trainer/Policy Loss                        -297.674
trainer/Q1 Predictions Mean                 298.052
trainer/Q1 Predictions Std                   88.817
trainer/Q1 Predictions Max                  375.229
trainer/Q1 Predictions Min                   14.2545
trainer/Q2 Predictions Mean                 298.172
trainer/Q2 Predictions Std                   89.0603
trainer/Q2 Predictions Max                  375.343
trainer/Q2 Predictions Min                   14.4908
trainer/Q Targets Mean                      297.963
trainer/Q Targets Std                        88.8938
trainer/Q Targets Max                       376.029
trainer/Q Targets Min                        13.7021
trainer/Log Pis Mean                          6.47616
trainer/Log Pis Std                           4.8402
trainer/Log Pis Max                          16.6229
trainer/Log Pis Min                          -5.80734
trainer/policy/mean Mean                      0.050485
trainer/policy/mean Std                       0.779066
trainer/policy/mean Max                       0.998738
trainer/policy/mean Min                      -0.99799
trainer/policy/normal/std Mean                0.439038
trainer/policy/normal/std Std                 0.148123
trainer/policy/normal/std Max                 0.954532
trainer/policy/normal/std Min                 0.0808441
trainer/policy/normal/log_std Mean           -0.891158
trainer/policy/normal/log_std Std             0.394581
trainer/policy/normal/log_std Max            -0.0465338
trainer/policy/normal/log_std Min            -2.51523
trainer/Alpha                                 0.11188
trainer/Alpha Loss                            1.04295
expl/num steps total                     182000
expl/num paths total                        182
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.93882
expl/Rewards Std                              1.16153
expl/Rewards Max                              7.07513
expl/Rewards Min                             -0.600744
expl/Returns Mean                          4938.82
expl/Returns Std                              0
expl/Returns Max                           4938.82
expl/Returns Min                           4938.82
expl/Actions Mean                             0.0460402
expl/Actions Std                              0.814328
expl/Actions Max                              0.999529
expl/Actions Min                             -0.999645
expl/Num Paths                                1
expl/Average Returns                       4938.82
expl/env_infos/final/reward_run Mean          6.78879
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.78879
expl/env_infos/final/reward_run Min           6.78879
expl/env_infos/initial/reward_run Mean       -0.365855
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.365855
expl/env_infos/initial/reward_run Min        -0.365855
expl/env_infos/reward_run Mean                5.33797
expl/env_infos/reward_run Std                 1.14907
expl/env_infos/reward_run Max                 7.52874
expl/env_infos/reward_run Min                -0.365855
expl/env_infos/final/reward_ctrl Mean        -0.446588
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.446588
expl/env_infos/final/reward_ctrl Min         -0.446588
expl/env_infos/initial/reward_ctrl Mean      -0.234889
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.234889
expl/env_infos/initial/reward_ctrl Min       -0.234889
expl/env_infos/reward_ctrl Mean              -0.39915
expl/env_infos/reward_ctrl Std                0.0891484
expl/env_infos/reward_ctrl Max               -0.124675
expl/env_infos/reward_ctrl Min               -0.58381
eval/num steps total                     905000
eval/num paths total                        905
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.20925
eval/Rewards Std                              1.18855
eval/Rewards Max                              7.50947
eval/Rewards Min                             -1.02173
eval/Returns Mean                          5209.25
eval/Returns Std                             34.2186
eval/Returns Max                           5266.15
eval/Returns Min                           5166.4
eval/Actions Mean                             0.0416937
eval/Actions Std                              0.831962
eval/Actions Max                              0.998349
eval/Actions Min                             -0.998523
eval/Num Paths                                5
eval/Average Returns                       5209.25
eval/env_infos/final/reward_run Mean          6.66418
eval/env_infos/final/reward_run Std           0.724313
eval/env_infos/final/reward_run Max           7.5111
eval/env_infos/final/reward_run Min           5.35851
eval/env_infos/initial/reward_run Mean       -0.435031
eval/env_infos/initial/reward_run Std         0.178143
eval/env_infos/initial/reward_run Max        -0.106816
eval/env_infos/initial/reward_run Min        -0.644792
eval/env_infos/reward_run Mean                5.62559
eval/env_infos/reward_run Std                 1.1736
eval/env_infos/reward_run Max                 8.00035
eval/env_infos/reward_run Min                -0.644792
eval/env_infos/final/reward_ctrl Mean        -0.444729
eval/env_infos/final/reward_ctrl Std          0.0499895
eval/env_infos/final/reward_ctrl Max         -0.362428
eval/env_infos/final/reward_ctrl Min         -0.50943
eval/env_infos/initial/reward_ctrl Mean      -0.290588
eval/env_infos/initial/reward_ctrl Std        0.0880685
eval/env_infos/initial/reward_ctrl Max       -0.166961
eval/env_infos/initial/reward_ctrl Min       -0.384068
eval/env_infos/reward_ctrl Mean              -0.41634
eval/env_infos/reward_ctrl Std                0.0839133
eval/env_infos/reward_ctrl Max               -0.166961
eval/env_infos/reward_ctrl Min               -0.582437
time/data storing (s)                         0.00455593
time/evaluation sampling (s)                  2.07654
time/exploration sampling (s)                 0.545986
time/logging (s)                              0.0138053
time/sac training (s)                         7.89609
time/saving (s)                               0.00378371
time/training (s)                             3.6387e-05
time/epoch (s)                               10.5408
time/total (s)                             1948.26
Epoch                                       180
---------------------------------------  ---------------
2021-11-24 01:01:51.994271 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 181 finished
---------------------------------------  ---------------
epoch                                       181
replay_buffer/size                       183000
trainer/num train calls                  182000
trainer/QF1 Loss                              7.80497
trainer/QF2 Loss                              6.41077
trainer/Policy Loss                        -285.538
trainer/Q1 Predictions Mean                 285.778
trainer/Q1 Predictions Std                  106.764
trainer/Q1 Predictions Max                  379.691
trainer/Q1 Predictions Min                   13.7842
trainer/Q2 Predictions Mean                 285.897
trainer/Q2 Predictions Std                  106.777
trainer/Q2 Predictions Max                  379.163
trainer/Q2 Predictions Min                   14.2965
trainer/Q Targets Mean                      286.227
trainer/Q Targets Std                       107.108
trainer/Q Targets Max                       379.509
trainer/Q Targets Min                        13.3994
trainer/Log Pis Mean                          6.02908
trainer/Log Pis Std                           5.0425
trainer/Log Pis Max                          16.531
trainer/Log Pis Min                          -6.99551
trainer/policy/mean Mean                      0.0441607
trainer/policy/mean Std                       0.773386
trainer/policy/mean Max                       0.999083
trainer/policy/mean Min                      -0.997907
trainer/policy/normal/std Mean                0.451984
trainer/policy/normal/std Std                 0.147432
trainer/policy/normal/std Max                 0.950415
trainer/policy/normal/std Min                 0.0878342
trainer/policy/normal/log_std Mean           -0.858788
trainer/policy/normal/log_std Std             0.386575
trainer/policy/normal/log_std Max            -0.0508562
trainer/policy/normal/log_std Min            -2.4323
trainer/Alpha                                 0.112148
trainer/Alpha Loss                            0.0636144
expl/num steps total                     183000
expl/num paths total                        183
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.02513
expl/Rewards Std                              1.13262
expl/Rewards Max                              7.3004
expl/Rewards Min                             -0.750077
expl/Returns Mean                          5025.13
expl/Returns Std                              0
expl/Returns Max                           5025.13
expl/Returns Min                           5025.13
expl/Actions Mean                             0.0607235
expl/Actions Std                              0.815996
expl/Actions Max                              0.999704
expl/Actions Min                             -0.99922
expl/Num Paths                                1
expl/Average Returns                       5025.13
expl/env_infos/final/reward_run Mean          7.04787
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.04787
expl/env_infos/final/reward_run Min           7.04787
expl/env_infos/initial/reward_run Mean       -0.3635
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.3635
expl/env_infos/initial/reward_run Min        -0.3635
expl/env_infos/reward_run Mean                5.42685
expl/env_infos/reward_run Std                 1.11753
expl/env_infos/reward_run Max                 7.76583
expl/env_infos/reward_run Min                -0.3635
expl/env_infos/final/reward_ctrl Mean        -0.470513
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.470513
expl/env_infos/final/reward_ctrl Min         -0.470513
expl/env_infos/initial/reward_ctrl Mean      -0.386577
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.386577
expl/env_infos/initial/reward_ctrl Min       -0.386577
expl/env_infos/reward_ctrl Mean              -0.401722
expl/env_infos/reward_ctrl Std                0.0871651
expl/env_infos/reward_ctrl Max               -0.138781
expl/env_infos/reward_ctrl Min               -0.581958
eval/num steps total                     910000
eval/num paths total                        910
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.16952
eval/Rewards Std                              1.21135
eval/Rewards Max                              7.62203
eval/Rewards Min                             -1.17298
eval/Returns Mean                          5169.52
eval/Returns Std                             85.9359
eval/Returns Max                           5323.84
eval/Returns Min                           5072.58
eval/Actions Mean                             0.0644714
eval/Actions Std                              0.829281
eval/Actions Max                              0.999644
eval/Actions Min                             -0.99727
eval/Num Paths                                5
eval/Average Returns                       5169.52
eval/env_infos/final/reward_run Mean          6.4519
eval/env_infos/final/reward_run Std           0.474795
eval/env_infos/final/reward_run Max           7.34203
eval/env_infos/final/reward_run Min           6.01367
eval/env_infos/initial/reward_run Mean       -0.435479
eval/env_infos/initial/reward_run Std         0.313017
eval/env_infos/initial/reward_run Max        -0.0139295
eval/env_infos/initial/reward_run Min        -0.769174
eval/env_infos/reward_run Mean                5.58464
eval/env_infos/reward_run Std                 1.19645
eval/env_infos/reward_run Max                 8.11614
eval/env_infos/reward_run Min                -0.769174
eval/env_infos/final/reward_ctrl Mean        -0.440952
eval/env_infos/final/reward_ctrl Std          0.0368329
eval/env_infos/final/reward_ctrl Max         -0.405635
eval/env_infos/final/reward_ctrl Min         -0.511144
eval/env_infos/initial/reward_ctrl Mean      -0.309429
eval/env_infos/initial/reward_ctrl Std        0.0846515
eval/env_infos/initial/reward_ctrl Max       -0.190544
eval/env_infos/initial/reward_ctrl Min       -0.406292
eval/env_infos/reward_ctrl Mean              -0.415118
eval/env_infos/reward_ctrl Std                0.0822978
eval/env_infos/reward_ctrl Max               -0.156215
eval/env_infos/reward_ctrl Min               -0.579899
time/data storing (s)                         0.00446541
time/evaluation sampling (s)                  2.05328
time/exploration sampling (s)                 0.5242
time/logging (s)                              0.0142606
time/sac training (s)                         7.91312
time/saving (s)                               0.00386891
time/training (s)                             4.6934e-05
time/epoch (s)                               10.5132
time/total (s)                             1959.09
Epoch                                       181
---------------------------------------  ---------------
2021-11-24 01:02:02.882070 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 182 finished
---------------------------------------  ---------------
epoch                                       182
replay_buffer/size                       184000
trainer/num train calls                  183000
trainer/QF1 Loss                              7.95682
trainer/QF2 Loss                              5.07077
trainer/Policy Loss                        -288.327
trainer/Q1 Predictions Mean                 288.751
trainer/Q1 Predictions Std                  107.434
trainer/Q1 Predictions Max                  373.905
trainer/Q1 Predictions Min                   14.1396
trainer/Q2 Predictions Mean                 288.692
trainer/Q2 Predictions Std                  107.472
trainer/Q2 Predictions Max                  373.941
trainer/Q2 Predictions Min                   13.4827
trainer/Q Targets Mean                      288.537
trainer/Q Targets Std                       107.372
trainer/Q Targets Max                       374.408
trainer/Q Targets Min                        13.2301
trainer/Log Pis Mean                          6.34533
trainer/Log Pis Std                           5.02677
trainer/Log Pis Max                          18.1061
trainer/Log Pis Min                          -6.36715
trainer/policy/mean Mean                      0.0694405
trainer/policy/mean Std                       0.772906
trainer/policy/mean Max                       0.997582
trainer/policy/mean Min                      -0.999243
trainer/policy/normal/std Mean                0.45394
trainer/policy/normal/std Std                 0.15734
trainer/policy/normal/std Max                 1.08642
trainer/policy/normal/std Min                 0.0696564
trainer/policy/normal/log_std Mean           -0.86443
trainer/policy/normal/log_std Std             0.418721
trainer/policy/normal/log_std Max             0.0828904
trainer/policy/normal/log_std Min            -2.66418
trainer/Alpha                                 0.111052
trainer/Alpha Loss                            0.758946
expl/num steps total                     184000
expl/num paths total                        184
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.90847
expl/Rewards Std                              1.19218
expl/Rewards Max                              7.26047
expl/Rewards Min                             -0.819829
expl/Returns Mean                          4908.47
expl/Returns Std                              0
expl/Returns Max                           4908.47
expl/Returns Min                           4908.47
expl/Actions Mean                             0.0922654
expl/Actions Std                              0.810857
expl/Actions Max                              0.999938
expl/Actions Min                             -0.999681
expl/Num Paths                                1
expl/Average Returns                       4908.47
expl/env_infos/final/reward_run Mean          5.94281
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.94281
expl/env_infos/final/reward_run Min           5.94281
expl/env_infos/initial/reward_run Mean       -0.513896
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.513896
expl/env_infos/initial/reward_run Min        -0.513896
expl/env_infos/reward_run Mean                5.30807
expl/env_infos/reward_run Std                 1.17446
expl/env_infos/reward_run Max                 7.79557
expl/env_infos/reward_run Min                -0.513896
expl/env_infos/final/reward_ctrl Mean        -0.4132
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.4132
expl/env_infos/final/reward_ctrl Min         -0.4132
expl/env_infos/initial/reward_ctrl Mean      -0.305933
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.305933
expl/env_infos/initial/reward_ctrl Min       -0.305933
expl/env_infos/reward_ctrl Mean              -0.399601
expl/env_infos/reward_ctrl Std                0.0874531
expl/env_infos/reward_ctrl Max               -0.130746
expl/env_infos/reward_ctrl Min               -0.579743
eval/num steps total                     915000
eval/num paths total                        915
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.03378
eval/Rewards Std                              1.2204
eval/Rewards Max                              7.77061
eval/Rewards Min                             -0.998548
eval/Returns Mean                          5033.78
eval/Returns Std                             94.0777
eval/Returns Max                           5136.07
eval/Returns Min                           4865.06
eval/Actions Mean                             0.0869098
eval/Actions Std                              0.821453
eval/Actions Max                              0.99901
eval/Actions Min                             -0.998247
eval/Num Paths                                5
eval/Average Returns                       5033.78
eval/env_infos/final/reward_run Mean          6.44482
eval/env_infos/final/reward_run Std           0.981737
eval/env_infos/final/reward_run Max           7.42838
eval/env_infos/final/reward_run Min           4.89326
eval/env_infos/initial/reward_run Mean       -0.535763
eval/env_infos/initial/reward_run Std         0.148029
eval/env_infos/initial/reward_run Max        -0.249318
eval/env_infos/initial/reward_run Min        -0.663857
eval/env_infos/reward_run Mean                5.44318
eval/env_infos/reward_run Std                 1.20114
eval/env_infos/reward_run Max                 8.25295
eval/env_infos/reward_run Min                -0.663857
eval/env_infos/final/reward_ctrl Mean        -0.410438
eval/env_infos/final/reward_ctrl Std          0.0561628
eval/env_infos/final/reward_ctrl Max         -0.315636
eval/env_infos/final/reward_ctrl Min         -0.468153
eval/env_infos/initial/reward_ctrl Mean      -0.327661
eval/env_infos/initial/reward_ctrl Std        0.0385496
eval/env_infos/initial/reward_ctrl Max       -0.267788
eval/env_infos/initial/reward_ctrl Min       -0.371779
eval/env_infos/reward_ctrl Mean              -0.409403
eval/env_infos/reward_ctrl Std                0.0844573
eval/env_infos/reward_ctrl Max               -0.139048
eval/env_infos/reward_ctrl Min               -0.582104
time/data storing (s)                         0.00455214
time/evaluation sampling (s)                  2.08022
time/exploration sampling (s)                 0.550913
time/logging (s)                              0.0137429
time/sac training (s)                         7.89369
time/saving (s)                               0.00381673
time/training (s)                             3.5001e-05
time/epoch (s)                               10.547
time/total (s)                             1969.97
Epoch                                       182
---------------------------------------  ---------------
2021-11-24 01:02:13.737489 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 183 finished
---------------------------------------  ---------------
epoch                                       183
replay_buffer/size                       185000
trainer/num train calls                  184000
trainer/QF1 Loss                              6.83939
trainer/QF2 Loss                              5.90442
trainer/Policy Loss                        -292.856
trainer/Q1 Predictions Mean                 293.239
trainer/Q1 Predictions Std                   95.3066
trainer/Q1 Predictions Max                  388.023
trainer/Q1 Predictions Min                   13.2149
trainer/Q2 Predictions Mean                 293.098
trainer/Q2 Predictions Std                   95.3723
trainer/Q2 Predictions Max                  387.229
trainer/Q2 Predictions Min                   13.3421
trainer/Q Targets Mean                      293.033
trainer/Q Targets Std                        95.2673
trainer/Q Targets Max                       388.968
trainer/Q Targets Min                        13.6253
trainer/Log Pis Mean                          5.60621
trainer/Log Pis Std                           4.41862
trainer/Log Pis Max                          17.7503
trainer/Log Pis Min                         -10.0254
trainer/policy/mean Mean                      0.0429768
trainer/policy/mean Std                       0.763308
trainer/policy/mean Max                       0.996862
trainer/policy/mean Min                      -0.995938
trainer/policy/normal/std Mean                0.442105
trainer/policy/normal/std Std                 0.150492
trainer/policy/normal/std Max                 1.01539
trainer/policy/normal/std Min                 0.0864575
trainer/policy/normal/log_std Mean           -0.883288
trainer/policy/normal/log_std Std             0.387846
trainer/policy/normal/log_std Max             0.0152734
trainer/policy/normal/log_std Min            -2.4481
trainer/Alpha                                 0.113531
trainer/Alpha Loss                           -0.856771
expl/num steps total                     185000
expl/num paths total                        185
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.94588
expl/Rewards Std                              1.17835
expl/Rewards Max                              7.47258
expl/Rewards Min                             -0.987217
expl/Returns Mean                          4945.88
expl/Returns Std                              0
expl/Returns Max                           4945.88
expl/Returns Min                           4945.88
expl/Actions Mean                             0.0554438
expl/Actions Std                              0.81543
expl/Actions Max                              0.999426
expl/Actions Min                             -0.999329
expl/Num Paths                                1
expl/Average Returns                       4945.88
expl/env_infos/final/reward_run Mean          5.35085
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.35085
expl/env_infos/final/reward_run Min           5.35085
expl/env_infos/initial/reward_run Mean       -0.57578
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.57578
expl/env_infos/initial/reward_run Min        -0.57578
expl/env_infos/reward_run Mean                5.34668
expl/env_infos/reward_run Std                 1.16393
expl/env_infos/reward_run Max                 7.962
expl/env_infos/reward_run Min                -0.57578
expl/env_infos/final/reward_ctrl Mean        -0.513654
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.513654
expl/env_infos/final/reward_ctrl Min         -0.513654
expl/env_infos/initial/reward_ctrl Mean      -0.411437
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.411437
expl/env_infos/initial/reward_ctrl Min       -0.411437
expl/env_infos/reward_ctrl Mean              -0.4008
expl/env_infos/reward_ctrl Std                0.0857199
expl/env_infos/reward_ctrl Max               -0.140819
expl/env_infos/reward_ctrl Min               -0.584477
eval/num steps total                     920000
eval/num paths total                        920
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.1174
eval/Rewards Std                              1.2072
eval/Rewards Max                              7.73059
eval/Rewards Min                             -1.38313
eval/Returns Mean                          5117.4
eval/Returns Std                             41.0571
eval/Returns Max                           5170.36
eval/Returns Min                           5080.55
eval/Actions Mean                             0.0593791
eval/Actions Std                              0.831549
eval/Actions Max                              0.998355
eval/Actions Min                             -0.998351
eval/Num Paths                                5
eval/Average Returns                       5117.4
eval/env_infos/final/reward_run Mean          6.01721
eval/env_infos/final/reward_run Std           0.680935
eval/env_infos/final/reward_run Max           6.77964
eval/env_infos/final/reward_run Min           4.95793
eval/env_infos/initial/reward_run Mean       -0.560842
eval/env_infos/initial/reward_run Std         0.304988
eval/env_infos/initial/reward_run Max        -0.0735345
eval/env_infos/initial/reward_run Min        -0.961635
eval/env_infos/reward_run Mean                5.5344
eval/env_infos/reward_run Std                 1.19526
eval/env_infos/reward_run Max                 8.22675
eval/env_infos/reward_run Min                -0.961635
eval/env_infos/final/reward_ctrl Mean        -0.394178
eval/env_infos/final/reward_ctrl Std          0.0356568
eval/env_infos/final/reward_ctrl Max         -0.350475
eval/env_infos/final/reward_ctrl Min         -0.450679
eval/env_infos/initial/reward_ctrl Mean      -0.344115
eval/env_infos/initial/reward_ctrl Std        0.12481
eval/env_infos/initial/reward_ctrl Max       -0.107389
eval/env_infos/initial/reward_ctrl Min       -0.441973
eval/env_infos/reward_ctrl Mean              -0.417
eval/env_infos/reward_ctrl Std                0.0790051
eval/env_infos/reward_ctrl Max               -0.107389
eval/env_infos/reward_ctrl Min               -0.578423
time/data storing (s)                         0.00446456
time/evaluation sampling (s)                  2.06491
time/exploration sampling (s)                 0.536644
time/logging (s)                              0.0136653
time/sac training (s)                         7.89126
time/saving (s)                               0.00385136
time/training (s)                             3.4703e-05
time/epoch (s)                               10.5148
time/total (s)                             1980.81
Epoch                                       183
---------------------------------------  ---------------
2021-11-24 01:02:24.629640 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 184 finished
---------------------------------------  ---------------
epoch                                       184
replay_buffer/size                       186000
trainer/num train calls                  185000
trainer/QF1 Loss                              4.49927
trainer/QF2 Loss                              3.88725
trainer/Policy Loss                        -288.073
trainer/Q1 Predictions Mean                 288.727
trainer/Q1 Predictions Std                  107.594
trainer/Q1 Predictions Max                  372.217
trainer/Q1 Predictions Min                   13.5853
trainer/Q2 Predictions Mean                 288.287
trainer/Q2 Predictions Std                  107.519
trainer/Q2 Predictions Max                  370.736
trainer/Q2 Predictions Min                   13.4306
trainer/Q Targets Mean                      288.874
trainer/Q Targets Std                       107.762
trainer/Q Targets Max                       370.847
trainer/Q Targets Min                        12.742
trainer/Log Pis Mean                          6.17899
trainer/Log Pis Std                           4.62369
trainer/Log Pis Max                          17.5565
trainer/Log Pis Min                          -6.18299
trainer/policy/mean Mean                      0.0586452
trainer/policy/mean Std                       0.775933
trainer/policy/mean Max                       0.998128
trainer/policy/mean Min                      -0.996469
trainer/policy/normal/std Mean                0.448034
trainer/policy/normal/std Std                 0.155364
trainer/policy/normal/std Max                 0.991574
trainer/policy/normal/std Min                 0.0855045
trainer/policy/normal/log_std Mean           -0.873746
trainer/policy/normal/log_std Std             0.401549
trainer/policy/normal/log_std Max            -0.00846171
trainer/policy/normal/log_std Min            -2.45919
trainer/Alpha                                 0.113435
trainer/Alpha Loss                            0.389578
expl/num steps total                     186000
expl/num paths total                        186
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.02154
expl/Rewards Std                              1.15387
expl/Rewards Max                              7.06414
expl/Rewards Min                             -1.1305
expl/Returns Mean                          5021.54
expl/Returns Std                              0
expl/Returns Max                           5021.54
expl/Returns Min                           5021.54
expl/Actions Mean                             0.0599805
expl/Actions Std                              0.821491
expl/Actions Max                              0.999763
expl/Actions Min                             -0.999693
expl/Num Paths                                1
expl/Average Returns                       5021.54
expl/env_infos/final/reward_run Mean          4.23466
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.23466
expl/env_infos/final/reward_run Min           4.23466
expl/env_infos/initial/reward_run Mean       -0.739877
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.739877
expl/env_infos/initial/reward_run Min        -0.739877
expl/env_infos/reward_run Mean                5.42861
expl/env_infos/reward_run Std                 1.1401
expl/env_infos/reward_run Max                 7.51768
expl/env_infos/reward_run Min                -0.739877
expl/env_infos/final/reward_ctrl Mean        -0.534456
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.534456
expl/env_infos/final/reward_ctrl Min         -0.534456
expl/env_infos/initial/reward_ctrl Mean      -0.390625
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.390625
expl/env_infos/initial/reward_ctrl Min       -0.390625
expl/env_infos/reward_ctrl Mean              -0.407067
expl/env_infos/reward_ctrl Std                0.0864217
expl/env_infos/reward_ctrl Max               -0.117036
expl/env_infos/reward_ctrl Min               -0.590791
eval/num steps total                     925000
eval/num paths total                        925
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.16225
eval/Rewards Std                              1.22902
eval/Rewards Max                              7.7327
eval/Rewards Min                             -0.897448
eval/Returns Mean                          5162.25
eval/Returns Std                             79.9468
eval/Returns Max                           5264.58
eval/Returns Min                           5026.02
eval/Actions Mean                             0.0607578
eval/Actions Std                              0.832766
eval/Actions Max                              0.998763
eval/Actions Min                             -0.998818
eval/Num Paths                                5
eval/Average Returns                       5162.25
eval/env_infos/final/reward_run Mean          6.65716
eval/env_infos/final/reward_run Std           1.03692
eval/env_infos/final/reward_run Max           7.50636
eval/env_infos/final/reward_run Min           4.70125
eval/env_infos/initial/reward_run Mean       -0.365968
eval/env_infos/initial/reward_run Std         0.175313
eval/env_infos/initial/reward_run Max        -0.0625667
eval/env_infos/initial/reward_run Min        -0.587251
eval/env_infos/reward_run Mean                5.58056
eval/env_infos/reward_run Std                 1.21652
eval/env_infos/reward_run Max                 8.20668
eval/env_infos/reward_run Min                -0.587251
eval/env_infos/final/reward_ctrl Mean        -0.42668
eval/env_infos/final/reward_ctrl Std          0.00958213
eval/env_infos/final/reward_ctrl Max         -0.411739
eval/env_infos/final/reward_ctrl Min         -0.440009
eval/env_infos/initial/reward_ctrl Mean      -0.262466
eval/env_infos/initial/reward_ctrl Std        0.0386372
eval/env_infos/initial/reward_ctrl Max       -0.202363
eval/env_infos/initial/reward_ctrl Min       -0.310197
eval/env_infos/reward_ctrl Mean              -0.418315
eval/env_infos/reward_ctrl Std                0.0813371
eval/env_infos/reward_ctrl Max               -0.153121
eval/env_infos/reward_ctrl Min               -0.583187
time/data storing (s)                         0.00465395
time/evaluation sampling (s)                  2.05006
time/exploration sampling (s)                 0.543741
time/logging (s)                              0.014248
time/sac training (s)                         7.93229
time/saving (s)                               0.00393214
time/training (s)                             6.0445e-05
time/epoch (s)                               10.549
time/total (s)                             1991.68
Epoch                                       184
---------------------------------------  ---------------
2021-11-24 01:02:35.533119 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 185 finished
---------------------------------------  ---------------
epoch                                       185
replay_buffer/size                       187000
trainer/num train calls                  186000
trainer/QF1 Loss                              8.58668
trainer/QF2 Loss                              6.38068
trainer/Policy Loss                        -278.494
trainer/Q1 Predictions Mean                 279.001
trainer/Q1 Predictions Std                  116.045
trainer/Q1 Predictions Max                  377.298
trainer/Q1 Predictions Min                   12.7393
trainer/Q2 Predictions Mean                 278.546
trainer/Q2 Predictions Std                  115.867
trainer/Q2 Predictions Max                  375.297
trainer/Q2 Predictions Min                   13.3201
trainer/Q Targets Mean                      278.604
trainer/Q Targets Std                       115.995
trainer/Q Targets Max                       378.337
trainer/Q Targets Min                        11.7556
trainer/Log Pis Mean                          5.60321
trainer/Log Pis Std                           4.96518
trainer/Log Pis Max                          17.1416
trainer/Log Pis Min                          -5.51751
trainer/policy/mean Mean                      0.063975
trainer/policy/mean Std                       0.762676
trainer/policy/mean Max                       0.99842
trainer/policy/mean Min                      -0.998405
trainer/policy/normal/std Mean                0.476811
trainer/policy/normal/std Std                 0.162515
trainer/policy/normal/std Max                 0.994769
trainer/policy/normal/std Min                 0.0900223
trainer/policy/normal/log_std Mean           -0.811566
trainer/policy/normal/log_std Std             0.404172
trainer/policy/normal/log_std Max            -0.00524499
trainer/policy/normal/log_std Min            -2.4077
trainer/Alpha                                 0.114003
trainer/Alpha Loss                           -0.861642
expl/num steps total                     187000
expl/num paths total                        187
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.02721
expl/Rewards Std                              1.16622
expl/Rewards Max                              7.46346
expl/Rewards Min                             -1.18181
expl/Returns Mean                          5027.21
expl/Returns Std                              0
expl/Returns Max                           5027.21
expl/Returns Min                           5027.21
expl/Actions Mean                             0.0445998
expl/Actions Std                              0.822464
expl/Actions Max                              0.99951
expl/Actions Min                             -0.999768
expl/Num Paths                                1
expl/Average Returns                       5027.21
expl/env_infos/final/reward_run Mean          4.94195
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.94195
expl/env_infos/final/reward_run Min           4.94195
expl/env_infos/initial/reward_run Mean       -0.810351
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.810351
expl/env_infos/initial/reward_run Min        -0.810351
expl/env_infos/reward_run Mean                5.43427
expl/env_infos/reward_run Std                 1.1509
expl/env_infos/reward_run Max                 7.9698
expl/env_infos/reward_run Min                -0.810351
expl/env_infos/final/reward_ctrl Mean        -0.322924
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.322924
expl/env_infos/final/reward_ctrl Min         -0.322924
expl/env_infos/initial/reward_ctrl Mean      -0.371462
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.371462
expl/env_infos/initial/reward_ctrl Min       -0.371462
expl/env_infos/reward_ctrl Mean              -0.407062
expl/env_infos/reward_ctrl Std                0.0916814
expl/env_infos/reward_ctrl Max               -0.120587
expl/env_infos/reward_ctrl Min               -0.583582
eval/num steps total                     930000
eval/num paths total                        930
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.1946
eval/Rewards Std                              1.20774
eval/Rewards Max                              7.43322
eval/Rewards Min                             -1.17526
eval/Returns Mean                          5194.6
eval/Returns Std                             61.4672
eval/Returns Max                           5262.21
eval/Returns Min                           5085.27
eval/Actions Mean                             0.0447877
eval/Actions Std                              0.834518
eval/Actions Max                              0.998554
eval/Actions Min                             -0.999189
eval/Num Paths                                5
eval/Average Returns                       5194.6
eval/env_infos/final/reward_run Mean          6.26983
eval/env_infos/final/reward_run Std           0.601176
eval/env_infos/final/reward_run Max           6.86141
eval/env_infos/final/reward_run Min           5.12771
eval/env_infos/initial/reward_run Mean       -0.316496
eval/env_infos/initial/reward_run Std         0.506581
eval/env_infos/initial/reward_run Max         0.614218
eval/env_infos/initial/reward_run Min        -0.841483
eval/env_infos/reward_run Mean                5.61365
eval/env_infos/reward_run Std                 1.19534
eval/env_infos/reward_run Max                 7.91764
eval/env_infos/reward_run Min                -0.841483
eval/env_infos/final/reward_ctrl Mean        -0.41418
eval/env_infos/final/reward_ctrl Std          0.0758532
eval/env_infos/final/reward_ctrl Max         -0.289451
eval/env_infos/final/reward_ctrl Min         -0.47941
eval/env_infos/initial/reward_ctrl Mean      -0.28601
eval/env_infos/initial/reward_ctrl Std        0.0601963
eval/env_infos/initial/reward_ctrl Max       -0.189604
eval/env_infos/initial/reward_ctrl Min       -0.357072
eval/env_infos/reward_ctrl Mean              -0.419056
eval/env_infos/reward_ctrl Std                0.0864177
eval/env_infos/reward_ctrl Max               -0.156238
eval/env_infos/reward_ctrl Min               -0.579862
time/data storing (s)                         0.00453199
time/evaluation sampling (s)                  2.04868
time/exploration sampling (s)                 0.544248
time/logging (s)                              0.0138493
time/sac training (s)                         7.9449
time/saving (s)                               0.00381468
time/training (s)                             3.4351e-05
time/epoch (s)                               10.5601
time/total (s)                             2002.57
Epoch                                       185
---------------------------------------  ---------------
2021-11-24 01:02:46.675045 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 186 finished
---------------------------------------  ---------------
epoch                                       186
replay_buffer/size                       188000
trainer/num train calls                  187000
trainer/QF1 Loss                              5.32234
trainer/QF2 Loss                              4.9218
trainer/Policy Loss                        -298.851
trainer/Q1 Predictions Mean                 299.287
trainer/Q1 Predictions Std                   95.3809
trainer/Q1 Predictions Max                  377.729
trainer/Q1 Predictions Min                   13.812
trainer/Q2 Predictions Mean                 299.468
trainer/Q2 Predictions Std                   95.3023
trainer/Q2 Predictions Max                  376.682
trainer/Q2 Predictions Min                   12.4669
trainer/Q Targets Mean                      299.415
trainer/Q Targets Std                        95.4624
trainer/Q Targets Max                       377.958
trainer/Q Targets Min                        12.3884
trainer/Log Pis Mean                          6.31189
trainer/Log Pis Std                           4.56042
trainer/Log Pis Max                          19.3264
trainer/Log Pis Min                          -5.29821
trainer/policy/mean Mean                      0.0891136
trainer/policy/mean Std                       0.772091
trainer/policy/mean Max                       0.998882
trainer/policy/mean Min                      -0.999201
trainer/policy/normal/std Mean                0.455588
trainer/policy/normal/std Std                 0.151931
trainer/policy/normal/std Max                 1.00734
trainer/policy/normal/std Min                 0.0859342
trainer/policy/normal/log_std Mean           -0.854359
trainer/policy/normal/log_std Std             0.397751
trainer/policy/normal/log_std Max             0.00731587
trainer/policy/normal/log_std Min            -2.45417
trainer/Alpha                                 0.113497
trainer/Alpha Loss                            0.67866
expl/num steps total                     188000
expl/num paths total                        188
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.93413
expl/Rewards Std                              1.1514
expl/Rewards Max                              7.29808
expl/Rewards Min                             -0.518803
expl/Returns Mean                          4934.13
expl/Returns Std                              0
expl/Returns Max                           4934.13
expl/Returns Min                           4934.13
expl/Actions Mean                             0.0575842
expl/Actions Std                              0.821459
expl/Actions Max                              0.99967
expl/Actions Min                             -0.999699
expl/Num Paths                                1
expl/Average Returns                       4934.13
expl/env_infos/final/reward_run Mean          5.42075
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.42075
expl/env_infos/final/reward_run Min           5.42075
expl/env_infos/initial/reward_run Mean       -0.273006
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.273006
expl/env_infos/initial/reward_run Min        -0.273006
expl/env_infos/reward_run Mean                5.341
expl/env_infos/reward_run Std                 1.13545
expl/env_infos/reward_run Max                 7.74969
expl/env_infos/reward_run Min                -0.273006
expl/env_infos/final/reward_ctrl Mean        -0.516409
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.516409
expl/env_infos/final/reward_ctrl Min         -0.516409
expl/env_infos/initial/reward_ctrl Mean      -0.245797
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.245797
expl/env_infos/initial/reward_ctrl Min       -0.245797
expl/env_infos/reward_ctrl Mean              -0.406866
expl/env_infos/reward_ctrl Std                0.0841387
expl/env_infos/reward_ctrl Max               -0.149927
expl/env_infos/reward_ctrl Min               -0.584209
eval/num steps total                     935000
eval/num paths total                        935
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.18255
eval/Rewards Std                              1.21725
eval/Rewards Max                              7.63926
eval/Rewards Min                             -0.752536
eval/Returns Mean                          5182.55
eval/Returns Std                             62.0927
eval/Returns Max                           5269.37
eval/Returns Min                           5117.88
eval/Actions Mean                             0.0552808
eval/Actions Std                              0.837531
eval/Actions Max                              0.997346
eval/Actions Min                             -0.999267
eval/Num Paths                                5
eval/Average Returns                       5182.55
eval/env_infos/final/reward_run Mean          5.67305
eval/env_infos/final/reward_run Std           1.32208
eval/env_infos/final/reward_run Max           7.69829
eval/env_infos/final/reward_run Min           4.01073
eval/env_infos/initial/reward_run Mean       -0.158298
eval/env_infos/initial/reward_run Std         0.155358
eval/env_infos/initial/reward_run Max         0.0432094
eval/env_infos/initial/reward_run Min        -0.404308
eval/env_infos/reward_run Mean                5.60526
eval/env_infos/reward_run Std                 1.19847
eval/env_infos/reward_run Max                 8.09723
eval/env_infos/reward_run Min                -0.404308
eval/env_infos/final/reward_ctrl Mean        -0.479184
eval/env_infos/final/reward_ctrl Std          0.056488
eval/env_infos/final/reward_ctrl Max         -0.404437
eval/env_infos/final/reward_ctrl Min         -0.549587
eval/env_infos/initial/reward_ctrl Mean      -0.236145
eval/env_infos/initial/reward_ctrl Std        0.0784237
eval/env_infos/initial/reward_ctrl Max       -0.145523
eval/env_infos/initial/reward_ctrl Min       -0.348228
eval/env_infos/reward_ctrl Mean              -0.422709
eval/env_infos/reward_ctrl Std                0.0795483
eval/env_infos/reward_ctrl Max               -0.145523
eval/env_infos/reward_ctrl Min               -0.581826
time/data storing (s)                         0.00490042
time/evaluation sampling (s)                  2.04257
time/exploration sampling (s)                 0.542329
time/logging (s)                              0.01477
time/sac training (s)                         8.17153
time/saving (s)                               0.0039262
time/training (s)                             5.4096e-05
time/epoch (s)                               10.7801
time/total (s)                             2013.7
Epoch                                       186
---------------------------------------  ---------------
2021-11-24 01:02:57.639040 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 187 finished
---------------------------------------  ---------------
epoch                                       187
replay_buffer/size                       189000
trainer/num train calls                  188000
trainer/QF1 Loss                             15.5028
trainer/QF2 Loss                             14.6748
trainer/Policy Loss                        -292.241
trainer/Q1 Predictions Mean                 292.715
trainer/Q1 Predictions Std                  101.932
trainer/Q1 Predictions Max                  380.988
trainer/Q1 Predictions Min                   13.37
trainer/Q2 Predictions Mean                 292.583
trainer/Q2 Predictions Std                  101.828
trainer/Q2 Predictions Max                  379.494
trainer/Q2 Predictions Min                   14.3126
trainer/Q Targets Mean                      291.706
trainer/Q Targets Std                       102.168
trainer/Q Targets Max                       377.829
trainer/Q Targets Min                        12.067
trainer/Log Pis Mean                          6.1365
trainer/Log Pis Std                           4.85349
trainer/Log Pis Max                          17.8911
trainer/Log Pis Min                          -5.71373
trainer/policy/mean Mean                      0.0656595
trainer/policy/mean Std                       0.771515
trainer/policy/mean Max                       0.999329
trainer/policy/mean Min                      -0.997848
trainer/policy/normal/std Mean                0.454855
trainer/policy/normal/std Std                 0.157559
trainer/policy/normal/std Max                 1.08523
trainer/policy/normal/std Min                 0.0870263
trainer/policy/normal/log_std Mean           -0.858916
trainer/policy/normal/log_std Std             0.404004
trainer/policy/normal/log_std Max             0.0817876
trainer/policy/normal/log_std Min            -2.44154
trainer/Alpha                                 0.115317
trainer/Alpha Loss                            0.294843
expl/num steps total                     189000
expl/num paths total                        189
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.89772
expl/Rewards Std                              1.13833
expl/Rewards Max                              7.00826
expl/Rewards Min                             -0.975022
expl/Returns Mean                          4897.72
expl/Returns Std                              0
expl/Returns Max                           4897.72
expl/Returns Min                           4897.72
expl/Actions Mean                             0.0691912
expl/Actions Std                              0.816963
expl/Actions Max                              0.999511
expl/Actions Min                             -0.999625
expl/Num Paths                                1
expl/Average Returns                       4897.72
expl/env_infos/final/reward_run Mean          6.99738
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.99738
expl/env_infos/final/reward_run Min           6.99738
expl/env_infos/initial/reward_run Mean       -0.593442
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.593442
expl/env_infos/initial/reward_run Min        -0.593442
expl/env_infos/reward_run Mean                5.30105
expl/env_infos/reward_run Std                 1.12378
expl/env_infos/reward_run Max                 7.52767
expl/env_infos/reward_run Min                -0.593442
expl/env_infos/final/reward_ctrl Mean        -0.409973
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.409973
expl/env_infos/final/reward_ctrl Min         -0.409973
expl/env_infos/initial/reward_ctrl Mean      -0.38158
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.38158
expl/env_infos/initial/reward_ctrl Min       -0.38158
expl/env_infos/reward_ctrl Mean              -0.403329
expl/env_infos/reward_ctrl Std                0.0884147
expl/env_infos/reward_ctrl Max               -0.136718
expl/env_infos/reward_ctrl Min               -0.582735
eval/num steps total                     940000
eval/num paths total                        940
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.06187
eval/Rewards Std                              1.20783
eval/Rewards Max                              7.60464
eval/Rewards Min                             -1.09335
eval/Returns Mean                          5061.87
eval/Returns Std                             32.9823
eval/Returns Max                           5125.56
eval/Returns Min                           5036.01
eval/Actions Mean                             0.065821
eval/Actions Std                              0.828964
eval/Actions Max                              0.998841
eval/Actions Min                             -0.998892
eval/Num Paths                                5
eval/Average Returns                       5061.87
eval/env_infos/final/reward_run Mean          5.90374
eval/env_infos/final/reward_run Std           0.646716
eval/env_infos/final/reward_run Max           6.91668
eval/env_infos/final/reward_run Min           5.03207
eval/env_infos/initial/reward_run Mean       -0.583102
eval/env_infos/initial/reward_run Std         0.212354
eval/env_infos/initial/reward_run Max        -0.292746
eval/env_infos/initial/reward_run Min        -0.826331
eval/env_infos/reward_run Mean                5.47678
eval/env_infos/reward_run Std                 1.19584
eval/env_infos/reward_run Max                 8.10429
eval/env_infos/reward_run Min                -0.826331
eval/env_infos/final/reward_ctrl Mean        -0.455743
eval/env_infos/final/reward_ctrl Std          0.0397935
eval/env_infos/final/reward_ctrl Max         -0.380564
eval/env_infos/final/reward_ctrl Min         -0.484653
eval/env_infos/initial/reward_ctrl Mean      -0.298189
eval/env_infos/initial/reward_ctrl Std        0.0710523
eval/env_infos/initial/reward_ctrl Max       -0.179741
eval/env_infos/initial/reward_ctrl Min       -0.378657
eval/env_infos/reward_ctrl Mean              -0.414908
eval/env_infos/reward_ctrl Std                0.0840739
eval/env_infos/reward_ctrl Max               -0.120867
eval/env_infos/reward_ctrl Min               -0.57978
time/data storing (s)                         0.00454701
time/evaluation sampling (s)                  2.05669
time/exploration sampling (s)                 0.544977
time/logging (s)                              0.0137394
time/sac training (s)                         7.98956
time/saving (s)                               0.00381691
time/training (s)                             3.517e-05
time/epoch (s)                               10.6134
time/total (s)                             2024.64
Epoch                                       187
---------------------------------------  ---------------
2021-11-24 01:03:08.638912 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 188 finished
---------------------------------------  ---------------
epoch                                       188
replay_buffer/size                       190000
trainer/num train calls                  189000
trainer/QF1 Loss                              8.6156
trainer/QF2 Loss                              6.66771
trainer/Policy Loss                        -299.328
trainer/Q1 Predictions Mean                 299.844
trainer/Q1 Predictions Std                   95.4956
trainer/Q1 Predictions Max                  380.512
trainer/Q1 Predictions Min                   14.1998
trainer/Q2 Predictions Mean                 299.684
trainer/Q2 Predictions Std                   95.4913
trainer/Q2 Predictions Max                  383.74
trainer/Q2 Predictions Min                   10.1746
trainer/Q Targets Mean                      299.455
trainer/Q Targets Std                        95.3822
trainer/Q Targets Max                       378.796
trainer/Q Targets Min                        14.5789
trainer/Log Pis Mean                          6.07318
trainer/Log Pis Std                           4.40157
trainer/Log Pis Max                          18.8802
trainer/Log Pis Min                          -6.10431
trainer/policy/mean Mean                      0.0736738
trainer/policy/mean Std                       0.773229
trainer/policy/mean Max                       0.999168
trainer/policy/mean Min                      -0.997963
trainer/policy/normal/std Mean                0.443737
trainer/policy/normal/std Std                 0.152315
trainer/policy/normal/std Max                 1.05803
trainer/policy/normal/std Min                 0.0837043
trainer/policy/normal/log_std Mean           -0.883161
trainer/policy/normal/log_std Std             0.402751
trainer/policy/normal/log_std Max             0.0564088
trainer/policy/normal/log_std Min            -2.48046
trainer/Alpha                                 0.1144
trainer/Alpha Loss                            0.158663
expl/num steps total                     190000
expl/num paths total                        190
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.13222
expl/Rewards Std                              1.16052
expl/Rewards Max                              7.23078
expl/Rewards Min                             -0.887427
expl/Returns Mean                          5132.22
expl/Returns Std                              0
expl/Returns Max                           5132.22
expl/Returns Min                           5132.22
expl/Actions Mean                             0.0758411
expl/Actions Std                              0.813186
expl/Actions Max                              0.999564
expl/Actions Min                             -0.999417
expl/Num Paths                                1
expl/Average Returns                       5132.22
expl/env_infos/final/reward_run Mean          6.12822
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.12822
expl/env_infos/final/reward_run Min           6.12822
expl/env_infos/initial/reward_run Mean       -0.380533
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.380533
expl/env_infos/initial/reward_run Min        -0.380533
expl/env_infos/reward_run Mean                5.53243
expl/env_infos/reward_run Std                 1.14821
expl/env_infos/reward_run Max                 7.70978
expl/env_infos/reward_run Min                -0.414983
expl/env_infos/final/reward_ctrl Mean        -0.313194
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.313194
expl/env_infos/final/reward_ctrl Min         -0.313194
expl/env_infos/initial/reward_ctrl Mean      -0.197193
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.197193
expl/env_infos/initial/reward_ctrl Min       -0.197193
expl/env_infos/reward_ctrl Mean              -0.400214
expl/env_infos/reward_ctrl Std                0.0858139
expl/env_infos/reward_ctrl Max               -0.101335
expl/env_infos/reward_ctrl Min               -0.579592
eval/num steps total                     945000
eval/num paths total                        945
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.25087
eval/Rewards Std                              1.21706
eval/Rewards Max                              7.70443
eval/Rewards Min                             -1.03255
eval/Returns Mean                          5250.87
eval/Returns Std                             71.7345
eval/Returns Max                           5368.57
eval/Returns Min                           5153.41
eval/Actions Mean                             0.0780631
eval/Actions Std                              0.825632
eval/Actions Max                              0.998201
eval/Actions Min                             -0.999012
eval/Num Paths                                5
eval/Average Returns                       5250.87
eval/env_infos/final/reward_run Mean          6.08054
eval/env_infos/final/reward_run Std           1.18709
eval/env_infos/final/reward_run Max           7.37073
eval/env_infos/final/reward_run Min           4.20071
eval/env_infos/initial/reward_run Mean       -0.591398
eval/env_infos/initial/reward_run Std         0.0831563
eval/env_infos/initial/reward_run Max        -0.465587
eval/env_infos/initial/reward_run Min        -0.684471
eval/env_infos/reward_run Mean                5.66353
eval/env_infos/reward_run Std                 1.20159
eval/env_infos/reward_run Max                 8.17816
eval/env_infos/reward_run Min                -0.684471
eval/env_infos/final/reward_ctrl Mean        -0.404478
eval/env_infos/final/reward_ctrl Std          0.0470286
eval/env_infos/final/reward_ctrl Max         -0.321531
eval/env_infos/final/reward_ctrl Min         -0.462434
eval/env_infos/initial/reward_ctrl Mean      -0.351878
eval/env_infos/initial/reward_ctrl Std        0.0186974
eval/env_infos/initial/reward_ctrl Max       -0.328368
eval/env_infos/initial/reward_ctrl Min       -0.377678
eval/env_infos/reward_ctrl Mean              -0.412657
eval/env_infos/reward_ctrl Std                0.0812941
eval/env_infos/reward_ctrl Max               -0.152081
eval/env_infos/reward_ctrl Min               -0.583317
time/data storing (s)                         0.00498514
time/evaluation sampling (s)                  2.03845
time/exploration sampling (s)                 0.541974
time/logging (s)                              0.0150309
time/sac training (s)                         8.04621
time/saving (s)                               0.00392787
time/training (s)                             4.1978e-05
time/epoch (s)                               10.6506
time/total (s)                             2035.63
Epoch                                       188
---------------------------------------  ---------------
2021-11-24 01:03:19.631899 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 189 finished
---------------------------------------  ---------------
epoch                                       189
replay_buffer/size                       191000
trainer/num train calls                  190000
trainer/QF1 Loss                              7.47573
trainer/QF2 Loss                              8.55163
trainer/Policy Loss                        -302.697
trainer/Q1 Predictions Mean                 303.251
trainer/Q1 Predictions Std                   93.8667
trainer/Q1 Predictions Max                  383.627
trainer/Q1 Predictions Min                   15.1305
trainer/Q2 Predictions Mean                 302.885
trainer/Q2 Predictions Std                   93.7773
trainer/Q2 Predictions Max                  383.769
trainer/Q2 Predictions Min                   14.77
trainer/Q Targets Mean                      302.972
trainer/Q Targets Std                        93.9902
trainer/Q Targets Max                       384.445
trainer/Q Targets Min                        13.8542
trainer/Log Pis Mean                          5.95728
trainer/Log Pis Std                           4.45714
trainer/Log Pis Max                          16.4948
trainer/Log Pis Min                          -5.86554
trainer/policy/mean Mean                      0.0733589
trainer/policy/mean Std                       0.775532
trainer/policy/mean Max                       0.998973
trainer/policy/mean Min                      -0.999311
trainer/policy/normal/std Mean                0.440504
trainer/policy/normal/std Std                 0.146989
trainer/policy/normal/std Max                 0.970211
trainer/policy/normal/std Min                 0.0765867
trainer/policy/normal/log_std Mean           -0.891329
trainer/policy/normal/log_std Std             0.411806
trainer/policy/normal/log_std Max            -0.0302413
trainer/policy/normal/log_std Min            -2.56933
trainer/Alpha                                 0.115021
trainer/Alpha Loss                           -0.0923786
expl/num steps total                     191000
expl/num paths total                        191
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.01788
expl/Rewards Std                              1.17015
expl/Rewards Max                              7.20632
expl/Rewards Min                             -1.2666
expl/Returns Mean                          5017.88
expl/Returns Std                              0
expl/Returns Max                           5017.88
expl/Returns Min                           5017.88
expl/Actions Mean                             0.0742596
expl/Actions Std                              0.815861
expl/Actions Max                              0.999535
expl/Actions Min                             -0.999626
expl/Num Paths                                1
expl/Average Returns                       5017.88
expl/env_infos/final/reward_run Mean          5.77103
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.77103
expl/env_infos/final/reward_run Min           5.77103
expl/env_infos/initial/reward_run Mean       -0.842378
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.842378
expl/env_infos/initial/reward_run Min        -0.842378
expl/env_infos/reward_run Mean                5.42056
expl/env_infos/reward_run Std                 1.15766
expl/env_infos/reward_run Max                 7.65362
expl/env_infos/reward_run Min                -0.842378
expl/env_infos/final/reward_ctrl Mean        -0.25203
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.25203
expl/env_infos/final/reward_ctrl Min         -0.25203
expl/env_infos/initial/reward_ctrl Mean      -0.424221
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.424221
expl/env_infos/initial/reward_ctrl Min       -0.424221
expl/env_infos/reward_ctrl Mean              -0.402686
expl/env_infos/reward_ctrl Std                0.0860737
expl/env_infos/reward_ctrl Max               -0.152373
expl/env_infos/reward_ctrl Min               -0.580433
eval/num steps total                     950000
eval/num paths total                        950
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.18296
eval/Rewards Std                              1.20984
eval/Rewards Max                              7.68515
eval/Rewards Min                             -0.877031
eval/Returns Mean                          5182.96
eval/Returns Std                             78.677
eval/Returns Max                           5263.85
eval/Returns Min                           5045.84
eval/Actions Mean                             0.0763053
eval/Actions Std                              0.82964
eval/Actions Max                              0.99785
eval/Actions Min                             -0.998073
eval/Num Paths                                5
eval/Average Returns                       5182.96
eval/env_infos/final/reward_run Mean          6.38697
eval/env_infos/final/reward_run Std           0.835012
eval/env_infos/final/reward_run Max           7.65236
eval/env_infos/final/reward_run Min           5.06333
eval/env_infos/initial/reward_run Mean       -0.446401
eval/env_infos/initial/reward_run Std         0.0736363
eval/env_infos/initial/reward_run Max        -0.362014
eval/env_infos/initial/reward_run Min        -0.558275
eval/env_infos/reward_run Mean                5.59944
eval/env_infos/reward_run Std                 1.19598
eval/env_infos/reward_run Max                 8.15428
eval/env_infos/reward_run Min                -0.558275
eval/env_infos/final/reward_ctrl Mean        -0.445491
eval/env_infos/final/reward_ctrl Std          0.0845147
eval/env_infos/final/reward_ctrl Max         -0.27879
eval/env_infos/final/reward_ctrl Min         -0.50005
eval/env_infos/initial/reward_ctrl Mean      -0.314319
eval/env_infos/initial/reward_ctrl Std        0.0234798
eval/env_infos/initial/reward_ctrl Max       -0.286028
eval/env_infos/initial/reward_ctrl Min       -0.349484
eval/env_infos/reward_ctrl Mean              -0.416475
eval/env_infos/reward_ctrl Std                0.0812584
eval/env_infos/reward_ctrl Max               -0.180359
eval/env_infos/reward_ctrl Min               -0.582391
time/data storing (s)                         0.00460656
time/evaluation sampling (s)                  2.06413
time/exploration sampling (s)                 0.541524
time/logging (s)                              0.0138858
time/sac training (s)                         8.016
time/saving (s)                               0.00382913
time/training (s)                             3.5592e-05
time/epoch (s)                               10.644
time/total (s)                             2046.6
Epoch                                       189
---------------------------------------  ---------------
2021-11-24 01:03:30.648956 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 190 finished
---------------------------------------  ---------------
epoch                                       190
replay_buffer/size                       192000
trainer/num train calls                  191000
trainer/QF1 Loss                              6.98672
trainer/QF2 Loss                              5.72188
trainer/Policy Loss                        -291.029
trainer/Q1 Predictions Mean                 291.312
trainer/Q1 Predictions Std                  107.163
trainer/Q1 Predictions Max                  379.41
trainer/Q1 Predictions Min                   14.5123
trainer/Q2 Predictions Mean                 291.41
trainer/Q2 Predictions Std                  107.085
trainer/Q2 Predictions Max                  378.69
trainer/Q2 Predictions Min                   13.2917
trainer/Q Targets Mean                      291.918
trainer/Q Targets Std                       107.279
trainer/Q Targets Max                       380.401
trainer/Q Targets Min                        14.0595
trainer/Log Pis Mean                          5.26282
trainer/Log Pis Std                           4.74275
trainer/Log Pis Max                          25.2156
trainer/Log Pis Min                          -5.51761
trainer/policy/mean Mean                      0.0662225
trainer/policy/mean Std                       0.750339
trainer/policy/mean Max                       0.999061
trainer/policy/mean Min                      -0.999954
trainer/policy/normal/std Mean                0.450115
trainer/policy/normal/std Std                 0.15509
trainer/policy/normal/std Max                 1.05188
trainer/policy/normal/std Min                 0.0741016
trainer/policy/normal/log_std Mean           -0.868416
trainer/policy/normal/log_std Std             0.399587
trainer/policy/normal/log_std Max             0.0505835
trainer/policy/normal/log_std Min            -2.60232
trainer/Alpha                                 0.114214
trainer/Alpha Loss                           -1.59944
expl/num steps total                     192000
expl/num paths total                        192
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.92932
expl/Rewards Std                              1.14013
expl/Rewards Max                              7.08909
expl/Rewards Min                             -0.701244
expl/Returns Mean                          4929.32
expl/Returns Std                              0
expl/Returns Max                           4929.32
expl/Returns Min                           4929.32
expl/Actions Mean                             0.0710314
expl/Actions Std                              0.815964
expl/Actions Max                              0.999013
expl/Actions Min                             -0.999894
expl/Num Paths                                1
expl/Average Returns                       4929.32
expl/env_infos/final/reward_run Mean          4.44597
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.44597
expl/env_infos/final/reward_run Min           4.44597
expl/env_infos/initial/reward_run Mean       -0.364898
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.364898
expl/env_infos/initial/reward_run Min        -0.364898
expl/env_infos/reward_run Mean                5.33182
expl/env_infos/reward_run Std                 1.11694
expl/env_infos/reward_run Max                 7.59692
expl/env_infos/reward_run Min                -0.364898
expl/env_infos/final/reward_ctrl Mean        -0.493218
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.493218
expl/env_infos/final/reward_ctrl Min         -0.493218
expl/env_infos/initial/reward_ctrl Mean      -0.336346
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.336346
expl/env_infos/initial/reward_ctrl Min       -0.336346
expl/env_infos/reward_ctrl Mean              -0.402506
expl/env_infos/reward_ctrl Std                0.0871533
expl/env_infos/reward_ctrl Max               -0.123386
expl/env_infos/reward_ctrl Min               -0.58389
eval/num steps total                     955000
eval/num paths total                        955
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.1773
eval/Rewards Std                              1.2153
eval/Rewards Max                              7.63777
eval/Rewards Min                             -0.811121
eval/Returns Mean                          5177.3
eval/Returns Std                             79.654
eval/Returns Max                           5271.71
eval/Returns Min                           5057.2
eval/Actions Mean                             0.069724
eval/Actions Std                              0.827463
eval/Actions Max                              0.999014
eval/Actions Min                             -0.997844
eval/Num Paths                                5
eval/Average Returns                       5177.3
eval/env_infos/final/reward_run Mean          6.44078
eval/env_infos/final/reward_run Std           0.94565
eval/env_infos/final/reward_run Max           7.5493
eval/env_infos/final/reward_run Min           4.89592
eval/env_infos/initial/reward_run Mean       -0.252057
eval/env_infos/initial/reward_run Std         0.176354
eval/env_infos/initial/reward_run Max         0.036573
eval/env_infos/initial/reward_run Min        -0.440432
eval/env_infos/reward_run Mean                5.59104
eval/env_infos/reward_run Std                 1.19158
eval/env_infos/reward_run Max                 8.09814
eval/env_infos/reward_run Min                -0.440432
eval/env_infos/final/reward_ctrl Mean        -0.412535
eval/env_infos/final/reward_ctrl Std          0.0622535
eval/env_infos/final/reward_ctrl Max         -0.308769
eval/env_infos/final/reward_ctrl Min         -0.476137
eval/env_infos/initial/reward_ctrl Mean      -0.238967
eval/env_infos/initial/reward_ctrl Std        0.0783728
eval/env_infos/initial/reward_ctrl Max       -0.130247
eval/env_infos/initial/reward_ctrl Min       -0.370688
eval/env_infos/reward_ctrl Mean              -0.413733
eval/env_infos/reward_ctrl Std                0.0799736
eval/env_infos/reward_ctrl Max               -0.108793
eval/env_infos/reward_ctrl Min               -0.584661
time/data storing (s)                         0.00454068
time/evaluation sampling (s)                  2.06926
time/exploration sampling (s)                 0.554954
time/logging (s)                              0.0196167
time/sac training (s)                         8.02211
time/saving (s)                               0.00491112
time/training (s)                             6.7912e-05
time/epoch (s)                               10.6755
time/total (s)                             2057.61
Epoch                                       190
---------------------------------------  ---------------
2021-11-24 01:03:42.049193 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 191 finished
---------------------------------------  ---------------
epoch                                       191
replay_buffer/size                       193000
trainer/num train calls                  192000
trainer/QF1 Loss                              7.68495
trainer/QF2 Loss                              7.24248
trainer/Policy Loss                        -286.314
trainer/Q1 Predictions Mean                 286.93
trainer/Q1 Predictions Std                  111.544
trainer/Q1 Predictions Max                  380.125
trainer/Q1 Predictions Min                   14.8852
trainer/Q2 Predictions Mean                 286.451
trainer/Q2 Predictions Std                  111.456
trainer/Q2 Predictions Max                  381.824
trainer/Q2 Predictions Min                   14.7851
trainer/Q Targets Mean                      286.556
trainer/Q Targets Std                       111.516
trainer/Q Targets Max                       380.196
trainer/Q Targets Min                        14.5135
trainer/Log Pis Mean                          5.75997
trainer/Log Pis Std                           4.67967
trainer/Log Pis Max                          15.8005
trainer/Log Pis Min                          -6.59227
trainer/policy/mean Mean                      0.0402339
trainer/policy/mean Std                       0.763743
trainer/policy/mean Max                       0.997939
trainer/policy/mean Min                      -0.998475
trainer/policy/normal/std Mean                0.458467
trainer/policy/normal/std Std                 0.156399
trainer/policy/normal/std Max                 0.936806
trainer/policy/normal/std Min                 0.0845817
trainer/policy/normal/log_std Mean           -0.850019
trainer/policy/normal/log_std Std             0.401162
trainer/policy/normal/log_std Max            -0.0652785
trainer/policy/normal/log_std Min            -2.47004
trainer/Alpha                                 0.114634
trainer/Alpha Loss                           -0.519899
expl/num steps total                     193000
expl/num paths total                        193
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.0713
expl/Rewards Std                              1.21607
expl/Rewards Max                              7.74958
expl/Rewards Min                             -0.524271
expl/Returns Mean                          5071.3
expl/Returns Std                              0
expl/Returns Max                           5071.3
expl/Returns Min                           5071.3
expl/Actions Mean                             0.0606502
expl/Actions Std                              0.819471
expl/Actions Max                              0.999523
expl/Actions Min                             -0.999769
expl/Num Paths                                1
expl/Average Returns                       5071.3
expl/env_infos/final/reward_run Mean          7.26727
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.26727
expl/env_infos/final/reward_run Min           7.26727
expl/env_infos/initial/reward_run Mean       -0.274816
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.274816
expl/env_infos/initial/reward_run Min        -0.274816
expl/env_infos/reward_run Mean                5.47643
expl/env_infos/reward_run Std                 1.20259
expl/env_infos/reward_run Max                 8.18105
expl/env_infos/reward_run Min                -0.274816
expl/env_infos/final/reward_ctrl Mean        -0.424325
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.424325
expl/env_infos/final/reward_ctrl Min         -0.424325
expl/env_infos/initial/reward_ctrl Mean      -0.249455
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.249455
expl/env_infos/initial/reward_ctrl Min       -0.249455
expl/env_infos/reward_ctrl Mean              -0.405127
expl/env_infos/reward_ctrl Std                0.083999
expl/env_infos/reward_ctrl Max               -0.120909
expl/env_infos/reward_ctrl Min               -0.573418
eval/num steps total                     960000
eval/num paths total                        960
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.14097
eval/Rewards Std                              1.22184
eval/Rewards Max                              7.60278
eval/Rewards Min                             -1.08369
eval/Returns Mean                          5140.97
eval/Returns Std                             86.8869
eval/Returns Max                           5259.52
eval/Returns Min                           5039.47
eval/Actions Mean                             0.0601493
eval/Actions Std                              0.831496
eval/Actions Max                              0.999611
eval/Actions Min                             -0.99832
eval/Num Paths                                5
eval/Average Returns                       5140.97
eval/env_infos/final/reward_run Mean          6.14306
eval/env_infos/final/reward_run Std           0.78578
eval/env_infos/final/reward_run Max           7.25309
eval/env_infos/final/reward_run Min           5.26412
eval/env_infos/initial/reward_run Mean       -0.477435
eval/env_infos/initial/reward_run Std         0.208144
eval/env_infos/initial/reward_run Max        -0.214634
eval/env_infos/initial/reward_run Min        -0.695032
eval/env_infos/reward_run Mean                5.55797
eval/env_infos/reward_run Std                 1.19767
eval/env_infos/reward_run Max                 7.99912
eval/env_infos/reward_run Min                -0.695032
eval/env_infos/final/reward_ctrl Mean        -0.425373
eval/env_infos/final/reward_ctrl Std          0.083146
eval/env_infos/final/reward_ctrl Max         -0.273036
eval/env_infos/final/reward_ctrl Min         -0.525659
eval/env_infos/initial/reward_ctrl Mean      -0.335597
eval/env_infos/initial/reward_ctrl Std        0.081863
eval/env_infos/initial/reward_ctrl Max       -0.204548
eval/env_infos/initial/reward_ctrl Min       -0.426918
eval/env_infos/reward_ctrl Mean              -0.417002
eval/env_infos/reward_ctrl Std                0.0830521
eval/env_infos/reward_ctrl Max               -0.113396
eval/env_infos/reward_ctrl Min               -0.578765
time/data storing (s)                         0.00633153
time/evaluation sampling (s)                  2.3419
time/exploration sampling (s)                 0.678293
time/logging (s)                              0.0142397
time/sac training (s)                         7.99931
time/saving (s)                               0.00391193
time/training (s)                             4.8976e-05
time/epoch (s)                               11.044
time/total (s)                             2068.99
Epoch                                       191
---------------------------------------  ---------------
2021-11-24 01:03:52.737942 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 192 finished
---------------------------------------  ---------------
epoch                                       192
replay_buffer/size                       194000
trainer/num train calls                  193000
trainer/QF1 Loss                              7.03174
trainer/QF2 Loss                              6.35426
trainer/Policy Loss                        -306.021
trainer/Q1 Predictions Mean                 306.39
trainer/Q1 Predictions Std                   95.447
trainer/Q1 Predictions Max                  377
trainer/Q1 Predictions Min                   14.6337
trainer/Q2 Predictions Mean                 306.567
trainer/Q2 Predictions Std                   95.3145
trainer/Q2 Predictions Max                  378.231
trainer/Q2 Predictions Min                   14.6113
trainer/Q Targets Mean                      305.782
trainer/Q Targets Std                        95.2239
trainer/Q Targets Max                       377.114
trainer/Q Targets Min                        14.0784
trainer/Log Pis Mean                          6.81795
trainer/Log Pis Std                           4.85227
trainer/Log Pis Max                          20.3318
trainer/Log Pis Min                          -6.30566
trainer/policy/mean Mean                      0.0749146
trainer/policy/mean Std                       0.785997
trainer/policy/mean Max                       0.99991
trainer/policy/mean Min                      -0.996929
trainer/policy/normal/std Mean                0.44993
trainer/policy/normal/std Std                 0.152841
trainer/policy/normal/std Max                 1.18501
trainer/policy/normal/std Min                 0.0844369
trainer/policy/normal/log_std Mean           -0.870074
trainer/policy/normal/log_std Std             0.408458
trainer/policy/normal/log_std Max             0.169754
trainer/policy/normal/log_std Min            -2.47175
trainer/Alpha                                 0.114215
trainer/Alpha Loss                            1.77468
expl/num steps total                     194000
expl/num paths total                        194
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.94692
expl/Rewards Std                              1.14803
expl/Rewards Max                              7.17173
expl/Rewards Min                             -0.937574
expl/Returns Mean                          4946.92
expl/Returns Std                              0
expl/Returns Max                           4946.92
expl/Returns Min                           4946.92
expl/Actions Mean                             0.0676324
expl/Actions Std                              0.810801
expl/Actions Max                              0.999691
expl/Actions Min                             -0.999508
expl/Num Paths                                1
expl/Average Returns                       4946.92
expl/env_infos/final/reward_run Mean          5.08216
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.08216
expl/env_infos/final/reward_run Min           5.08216
expl/env_infos/initial/reward_run Mean       -0.420435
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.420435
expl/env_infos/initial/reward_run Min        -0.420435
expl/env_infos/reward_run Mean                5.3441
expl/env_infos/reward_run Std                 1.12572
expl/env_infos/reward_run Max                 7.55323
expl/env_infos/reward_run Min                -0.425767
expl/env_infos/final/reward_ctrl Mean        -0.376432
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.376432
expl/env_infos/final/reward_ctrl Min         -0.376432
expl/env_infos/initial/reward_ctrl Mean      -0.1998
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.1998
expl/env_infos/initial/reward_ctrl Min       -0.1998
expl/env_infos/reward_ctrl Mean              -0.397183
expl/env_infos/reward_ctrl Std                0.0853013
expl/env_infos/reward_ctrl Max               -0.1353
expl/env_infos/reward_ctrl Min               -0.586821
eval/num steps total                     965000
eval/num paths total                        965
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.25108
eval/Rewards Std                              1.26033
eval/Rewards Max                              7.80759
eval/Rewards Min                             -0.872178
eval/Returns Mean                          5251.08
eval/Returns Std                             93.141
eval/Returns Max                           5374.82
eval/Returns Min                           5121.78
eval/Actions Mean                             0.0623856
eval/Actions Std                              0.831196
eval/Actions Max                              0.998243
eval/Actions Min                             -0.998738
eval/Num Paths                                5
eval/Average Returns                       5251.08
eval/env_infos/final/reward_run Mean          5.9698
eval/env_infos/final/reward_run Std           0.626114
eval/env_infos/final/reward_run Max           6.86774
eval/env_infos/final/reward_run Min           5.11215
eval/env_infos/initial/reward_run Mean       -0.327871
eval/env_infos/initial/reward_run Std         0.202382
eval/env_infos/initial/reward_run Max        -0.0390779
eval/env_infos/initial/reward_run Min        -0.543853
eval/env_infos/reward_run Mean                5.66794
eval/env_infos/reward_run Std                 1.23821
eval/env_infos/reward_run Max                 8.29092
eval/env_infos/reward_run Min                -0.543853
eval/env_infos/final/reward_ctrl Mean        -0.440338
eval/env_infos/final/reward_ctrl Std          0.0767133
eval/env_infos/final/reward_ctrl Max         -0.304202
eval/env_infos/final/reward_ctrl Min         -0.522367
eval/env_infos/initial/reward_ctrl Mean      -0.273956
eval/env_infos/initial/reward_ctrl Std        0.0705399
eval/env_infos/initial/reward_ctrl Max       -0.190011
eval/env_infos/initial/reward_ctrl Min       -0.374042
eval/env_infos/reward_ctrl Mean              -0.416868
eval/env_infos/reward_ctrl Std                0.0827199
eval/env_infos/reward_ctrl Max               -0.102322
eval/env_infos/reward_ctrl Min               -0.583903
time/data storing (s)                         0.00449048
time/evaluation sampling (s)                  1.9898
time/exploration sampling (s)                 0.532614
time/logging (s)                              0.0160791
time/sac training (s)                         7.80378
time/saving (s)                               0.00419007
time/training (s)                             5.0468e-05
time/epoch (s)                               10.351
time/total (s)                             2079.66
Epoch                                       192
---------------------------------------  ---------------
2021-11-24 01:04:03.443256 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 193 finished
---------------------------------------  ---------------
epoch                                       193
replay_buffer/size                       195000
trainer/num train calls                  194000
trainer/QF1 Loss                              8.00205
trainer/QF2 Loss                              7.23546
trainer/Policy Loss                        -307.77
trainer/Q1 Predictions Mean                 308.206
trainer/Q1 Predictions Std                   95.7183
trainer/Q1 Predictions Max                  391.887
trainer/Q1 Predictions Min                   14.2818
trainer/Q2 Predictions Mean                 308.186
trainer/Q2 Predictions Std                   95.81
trainer/Q2 Predictions Max                  390.261
trainer/Q2 Predictions Min                   13.609
trainer/Q Targets Mean                      307.781
trainer/Q Targets Std                        95.6899
trainer/Q Targets Max                       389.102
trainer/Q Targets Min                        12.7236
trainer/Log Pis Mean                          6.02316
trainer/Log Pis Std                           4.57834
trainer/Log Pis Max                          25.3667
trainer/Log Pis Min                          -5.59455
trainer/policy/mean Mean                      0.0550391
trainer/policy/mean Std                       0.77403
trainer/policy/mean Max                       0.999865
trainer/policy/mean Min                      -0.998712
trainer/policy/normal/std Mean                0.439338
trainer/policy/normal/std Std                 0.14866
trainer/policy/normal/std Max                 0.96855
trainer/policy/normal/std Min                 0.0826642
trainer/policy/normal/log_std Mean           -0.892341
trainer/policy/normal/log_std Std             0.40155
trainer/policy/normal/log_std Max            -0.0319548
trainer/policy/normal/log_std Min            -2.49297
trainer/Alpha                                 0.11703
trainer/Alpha Loss                            0.0496942
expl/num steps total                     195000
expl/num paths total                        195
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.88023
expl/Rewards Std                              1.11008
expl/Rewards Max                              7.00182
expl/Rewards Min                             -0.667177
expl/Returns Mean                          4880.23
expl/Returns Std                              0
expl/Returns Max                           4880.23
expl/Returns Min                           4880.23
expl/Actions Mean                             0.0731141
expl/Actions Std                              0.811158
expl/Actions Max                              0.999614
expl/Actions Min                             -0.99932
expl/Num Paths                                1
expl/Average Returns                       4880.23
expl/env_infos/final/reward_run Mean          4.55885
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.55885
expl/env_infos/final/reward_run Min           4.55885
expl/env_infos/initial/reward_run Mean       -0.448505
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.448505
expl/env_infos/initial/reward_run Min        -0.448505
expl/env_infos/reward_run Mean                5.27823
expl/env_infos/reward_run Std                 1.09966
expl/env_infos/reward_run Max                 7.48214
expl/env_infos/reward_run Min                -0.448505
expl/env_infos/final/reward_ctrl Mean        -0.442598
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.442598
expl/env_infos/final/reward_ctrl Min         -0.442598
expl/env_infos/initial/reward_ctrl Mean      -0.218672
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.218672
expl/env_infos/initial/reward_ctrl Min       -0.218672
expl/env_infos/reward_ctrl Mean              -0.397994
expl/env_infos/reward_ctrl Std                0.0815375
expl/env_infos/reward_ctrl Max               -0.142106
expl/env_infos/reward_ctrl Min               -0.580075
eval/num steps total                     970000
eval/num paths total                        970
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.22581
eval/Rewards Std                              1.19011
eval/Rewards Max                              7.65798
eval/Rewards Min                             -0.927545
eval/Returns Mean                          5225.81
eval/Returns Std                             84.8459
eval/Returns Max                           5311.69
eval/Returns Min                           5113.46
eval/Actions Mean                             0.0622517
eval/Actions Std                              0.828384
eval/Actions Max                              0.997328
eval/Actions Min                             -0.997532
eval/Num Paths                                5
eval/Average Returns                       5225.81
eval/env_infos/final/reward_run Mean          6.16953
eval/env_infos/final/reward_run Std           0.691194
eval/env_infos/final/reward_run Max           7.06986
eval/env_infos/final/reward_run Min           5.37043
eval/env_infos/initial/reward_run Mean       -0.589773
eval/env_infos/initial/reward_run Std         0.0236972
eval/env_infos/initial/reward_run Max        -0.550687
eval/env_infos/initial/reward_run Min        -0.609405
eval/env_infos/reward_run Mean                5.63986
eval/env_infos/reward_run Std                 1.18209
eval/env_infos/reward_run Max                 8.13832
eval/env_infos/reward_run Min                -0.609405
eval/env_infos/final/reward_ctrl Mean        -0.402417
eval/env_infos/final/reward_ctrl Std          0.083964
eval/env_infos/final/reward_ctrl Max         -0.242925
eval/env_infos/final/reward_ctrl Min         -0.477787
eval/env_infos/initial/reward_ctrl Mean      -0.278397
eval/env_infos/initial/reward_ctrl Std        0.0329604
eval/env_infos/initial/reward_ctrl Max       -0.234583
eval/env_infos/initial/reward_ctrl Min       -0.31814
eval/env_infos/reward_ctrl Mean              -0.414058
eval/env_infos/reward_ctrl Std                0.0780274
eval/env_infos/reward_ctrl Max               -0.115874
eval/env_infos/reward_ctrl Min               -0.578169
time/data storing (s)                         0.00451293
time/evaluation sampling (s)                  2.05628
time/exploration sampling (s)                 0.526779
time/logging (s)                              0.0136994
time/sac training (s)                         7.76101
time/saving (s)                               0.00377612
time/training (s)                             3.4967e-05
time/epoch (s)                               10.3661
time/total (s)                             2090.35
Epoch                                       193
---------------------------------------  ---------------
2021-11-24 01:04:14.096483 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 194 finished
---------------------------------------  ---------------
epoch                                       194
replay_buffer/size                       196000
trainer/num train calls                  195000
trainer/QF1 Loss                              6.52069
trainer/QF2 Loss                              6.66694
trainer/Policy Loss                        -302.235
trainer/Q1 Predictions Mean                 302.67
trainer/Q1 Predictions Std                  100.468
trainer/Q1 Predictions Max                  393.036
trainer/Q1 Predictions Min                   15.6408
trainer/Q2 Predictions Mean                 302.704
trainer/Q2 Predictions Std                  100.512
trainer/Q2 Predictions Max                  395.033
trainer/Q2 Predictions Min                   17.2744
trainer/Q Targets Mean                      302.135
trainer/Q Targets Std                       100.079
trainer/Q Targets Max                       392.678
trainer/Q Targets Min                        16.4357
trainer/Log Pis Mean                          6.36044
trainer/Log Pis Std                           5.04377
trainer/Log Pis Max                          21.1098
trainer/Log Pis Min                          -6.47759
trainer/policy/mean Mean                      0.0387632
trainer/policy/mean Std                       0.779025
trainer/policy/mean Max                       0.999411
trainer/policy/mean Min                      -0.999211
trainer/policy/normal/std Mean                0.450387
trainer/policy/normal/std Std                 0.154032
trainer/policy/normal/std Max                 1.17829
trainer/policy/normal/std Min                 0.0715289
trainer/policy/normal/log_std Mean           -0.868368
trainer/policy/normal/log_std Std             0.403671
trainer/policy/normal/log_std Max             0.164061
trainer/policy/normal/log_std Min            -2.63765
trainer/Alpha                                 0.115158
trainer/Alpha Loss                            0.779083
expl/num steps total                     196000
expl/num paths total                        196
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.99557
expl/Rewards Std                              1.19925
expl/Rewards Max                              7.47504
expl/Rewards Min                             -0.659005
expl/Returns Mean                          4995.57
expl/Returns Std                              0
expl/Returns Max                           4995.57
expl/Returns Min                           4995.57
expl/Actions Mean                             0.0776382
expl/Actions Std                              0.826256
expl/Actions Max                              0.999494
expl/Actions Min                             -0.999681
expl/Num Paths                                1
expl/Average Returns                       4995.57
expl/env_infos/final/reward_run Mean          5.49253
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.49253
expl/env_infos/final/reward_run Min           5.49253
expl/env_infos/initial/reward_run Mean       -0.39939
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.39939
expl/env_infos/initial/reward_run Min        -0.39939
expl/env_infos/reward_run Mean                5.4088
expl/env_infos/reward_run Std                 1.17781
expl/env_infos/reward_run Max                 7.96884
expl/env_infos/reward_run Min                -0.39939
expl/env_infos/final/reward_ctrl Mean        -0.408948
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.408948
expl/env_infos/final/reward_ctrl Min         -0.408948
expl/env_infos/initial/reward_ctrl Mean      -0.259616
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.259616
expl/env_infos/initial/reward_ctrl Min       -0.259616
expl/env_infos/reward_ctrl Mean              -0.413236
expl/env_infos/reward_ctrl Std                0.084357
expl/env_infos/reward_ctrl Max               -0.163151
expl/env_infos/reward_ctrl Min               -0.585773
eval/num steps total                     975000
eval/num paths total                        975
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.17835
eval/Rewards Std                              1.25906
eval/Rewards Max                              7.71103
eval/Rewards Min                             -0.774577
eval/Returns Mean                          5178.35
eval/Returns Std                             91.6769
eval/Returns Max                           5306.18
eval/Returns Min                           5060.13
eval/Actions Mean                             0.074434
eval/Actions Std                              0.836564
eval/Actions Max                              0.998974
eval/Actions Min                             -0.999046
eval/Num Paths                                5
eval/Average Returns                       5178.35
eval/env_infos/final/reward_run Mean          6.23978
eval/env_infos/final/reward_run Std           0.815453
eval/env_infos/final/reward_run Max           7.24357
eval/env_infos/final/reward_run Min           5.36871
eval/env_infos/initial/reward_run Mean       -0.343016
eval/env_infos/initial/reward_run Std         0.106988
eval/env_infos/initial/reward_run Max        -0.135423
eval/env_infos/initial/reward_run Min        -0.442262
eval/env_infos/reward_run Mean                5.60158
eval/env_infos/reward_run Std                 1.23882
eval/env_infos/reward_run Max                 8.15828
eval/env_infos/reward_run Min                -0.442262
eval/env_infos/final/reward_ctrl Mean        -0.400113
eval/env_infos/final/reward_ctrl Std          0.047593
eval/env_infos/final/reward_ctrl Max         -0.323573
eval/env_infos/final/reward_ctrl Min         -0.4692
eval/env_infos/initial/reward_ctrl Mean      -0.240439
eval/env_infos/initial/reward_ctrl Std        0.069284
eval/env_infos/initial/reward_ctrl Max       -0.127897
eval/env_infos/initial/reward_ctrl Min       -0.332315
eval/env_infos/reward_ctrl Mean              -0.423228
eval/env_infos/reward_ctrl Std                0.0806941
eval/env_infos/reward_ctrl Max               -0.111469
eval/env_infos/reward_ctrl Min               -0.585723
time/data storing (s)                         0.00505057
time/evaluation sampling (s)                  2.02528
time/exploration sampling (s)                 0.532727
time/logging (s)                              0.0178311
time/sac training (s)                         7.73698
time/saving (s)                               0.00382335
time/training (s)                             4.2183e-05
time/epoch (s)                               10.3217
time/total (s)                             2100.99
Epoch                                       194
---------------------------------------  ---------------
2021-11-24 01:04:24.913864 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 195 finished
---------------------------------------  ---------------
epoch                                       195
replay_buffer/size                       197000
trainer/num train calls                  196000
trainer/QF1 Loss                              4.91577
trainer/QF2 Loss                              4.43758
trainer/Policy Loss                        -308.058
trainer/Q1 Predictions Mean                 308.48
trainer/Q1 Predictions Std                   95.109
trainer/Q1 Predictions Max                  389.439
trainer/Q1 Predictions Min                   14.7613
trainer/Q2 Predictions Mean                 309.028
trainer/Q2 Predictions Std                   95.2942
trainer/Q2 Predictions Max                  389.068
trainer/Q2 Predictions Min                   15.2533
trainer/Q Targets Mean                      308.6
trainer/Q Targets Std                        95.1414
trainer/Q Targets Max                       387.845
trainer/Q Targets Min                        15.599
trainer/Log Pis Mean                          5.45442
trainer/Log Pis Std                           4.26676
trainer/Log Pis Max                          17.7224
trainer/Log Pis Min                          -5.73182
trainer/policy/mean Mean                      0.0365897
trainer/policy/mean Std                       0.770312
trainer/policy/mean Max                       0.996663
trainer/policy/mean Min                      -0.996817
trainer/policy/normal/std Mean                0.439395
trainer/policy/normal/std Std                 0.140344
trainer/policy/normal/std Max                 0.823533
trainer/policy/normal/std Min                 0.0858308
trainer/policy/normal/log_std Mean           -0.886262
trainer/policy/normal/log_std Std             0.386853
trainer/policy/normal/log_std Max            -0.194152
trainer/policy/normal/log_std Min            -2.45538
trainer/Alpha                                 0.116237
trainer/Alpha Loss                           -1.17415
expl/num steps total                     197000
expl/num paths total                        197
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.15994
expl/Rewards Std                              1.18108
expl/Rewards Max                              7.38762
expl/Rewards Min                             -0.936484
expl/Returns Mean                          5159.94
expl/Returns Std                              0
expl/Returns Max                           5159.94
expl/Returns Min                           5159.94
expl/Actions Mean                             0.0396675
expl/Actions Std                              0.813225
expl/Actions Max                              0.99973
expl/Actions Min                             -0.999754
expl/Num Paths                                1
expl/Average Returns                       5159.94
expl/env_infos/final/reward_run Mean          6.48042
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.48042
expl/env_infos/final/reward_run Min           6.48042
expl/env_infos/initial/reward_run Mean       -0.624227
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.624227
expl/env_infos/initial/reward_run Min        -0.624227
expl/env_infos/reward_run Mean                5.55769
expl/env_infos/reward_run Std                 1.17045
expl/env_infos/reward_run Max                 7.86429
expl/env_infos/reward_run Min                -0.624227
expl/env_infos/final/reward_ctrl Mean        -0.352695
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.352695
expl/env_infos/final/reward_ctrl Min         -0.352695
expl/env_infos/initial/reward_ctrl Mean      -0.312257
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.312257
expl/env_infos/initial/reward_ctrl Min       -0.312257
expl/env_infos/reward_ctrl Mean              -0.397745
expl/env_infos/reward_ctrl Std                0.0800962
expl/env_infos/reward_ctrl Max               -0.167991
expl/env_infos/reward_ctrl Min               -0.577985
eval/num steps total                     980000
eval/num paths total                        980
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.25426
eval/Rewards Std                              1.21016
eval/Rewards Max                              7.89635
eval/Rewards Min                             -0.994785
eval/Returns Mean                          5254.26
eval/Returns Std                             43.8618
eval/Returns Max                           5319.19
eval/Returns Min                           5190.31
eval/Actions Mean                             0.0455126
eval/Actions Std                              0.826517
eval/Actions Max                              0.998821
eval/Actions Min                             -0.997933
eval/Num Paths                                5
eval/Average Returns                       5254.26
eval/env_infos/final/reward_run Mean          5.89921
eval/env_infos/final/reward_run Std           0.875659
eval/env_infos/final/reward_run Max           7.14467
eval/env_infos/final/reward_run Min           5.05844
eval/env_infos/initial/reward_run Mean       -0.492363
eval/env_infos/initial/reward_run Std         0.135323
eval/env_infos/initial/reward_run Max        -0.283371
eval/env_infos/initial/reward_run Min        -0.6903
eval/env_infos/reward_run Mean                5.66538
eval/env_infos/reward_run Std                 1.19814
eval/env_infos/reward_run Max                 8.37717
eval/env_infos/reward_run Min                -0.6903
eval/env_infos/final/reward_ctrl Mean        -0.386386
eval/env_infos/final/reward_ctrl Std          0.0504659
eval/env_infos/final/reward_ctrl Max         -0.301721
eval/env_infos/final/reward_ctrl Min         -0.429692
eval/env_infos/initial/reward_ctrl Mean      -0.295029
eval/env_infos/initial/reward_ctrl Std        0.0440336
eval/env_infos/initial/reward_ctrl Max       -0.213804
eval/env_infos/initial/reward_ctrl Min       -0.341345
eval/env_infos/reward_ctrl Mean              -0.411121
eval/env_infos/reward_ctrl Std                0.0758662
eval/env_infos/reward_ctrl Max               -0.159538
eval/env_infos/reward_ctrl Min               -0.572376
time/data storing (s)                         0.0045775
time/evaluation sampling (s)                  2.06088
time/exploration sampling (s)                 0.54684
time/logging (s)                              0.0137983
time/sac training (s)                         7.84051
time/saving (s)                               0.00377053
time/training (s)                             3.4526e-05
time/epoch (s)                               10.4704
time/total (s)                             2111.79
Epoch                                       195
---------------------------------------  ---------------
2021-11-24 01:04:35.661527 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 196 finished
---------------------------------------  ---------------
epoch                                       196
replay_buffer/size                       198000
trainer/num train calls                  197000
trainer/QF1 Loss                             11.4726
trainer/QF2 Loss                             10.9232
trainer/Policy Loss                        -300.946
trainer/Q1 Predictions Mean                 301.365
trainer/Q1 Predictions Std                  100.833
trainer/Q1 Predictions Max                  380.829
trainer/Q1 Predictions Min                   15.4428
trainer/Q2 Predictions Mean                 301.249
trainer/Q2 Predictions Std                  100.709
trainer/Q2 Predictions Max                  381.442
trainer/Q2 Predictions Min                   15.2653
trainer/Q Targets Mean                      301.274
trainer/Q Targets Std                       100.498
trainer/Q Targets Max                       380.288
trainer/Q Targets Min                        15.6565
trainer/Log Pis Mean                          6.0592
trainer/Log Pis Std                           4.42204
trainer/Log Pis Max                          16.6861
trainer/Log Pis Min                          -5.42183
trainer/policy/mean Mean                      0.0434815
trainer/policy/mean Std                       0.777117
trainer/policy/mean Max                       0.998673
trainer/policy/mean Min                      -0.998442
trainer/policy/normal/std Mean                0.453171
trainer/policy/normal/std Std                 0.150622
trainer/policy/normal/std Max                 0.889372
trainer/policy/normal/std Min                 0.0852306
trainer/policy/normal/log_std Mean           -0.860231
trainer/policy/normal/log_std Std             0.400152
trainer/policy/normal/log_std Max            -0.117239
trainer/policy/normal/log_std Min            -2.46239
trainer/Alpha                                 0.117369
trainer/Alpha Loss                            0.126826
expl/num steps total                     198000
expl/num paths total                        198
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.1282
expl/Rewards Std                              1.15137
expl/Rewards Max                              7.30828
expl/Rewards Min                             -0.643285
expl/Returns Mean                          5128.2
expl/Returns Std                              0
expl/Returns Max                           5128.2
expl/Returns Min                           5128.2
expl/Actions Mean                             0.0410722
expl/Actions Std                              0.814532
expl/Actions Max                              0.999652
expl/Actions Min                             -0.99992
expl/Num Paths                                1
expl/Average Returns                       5128.2
expl/env_infos/final/reward_run Mean          6.92034
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.92034
expl/env_infos/final/reward_run Min           6.92034
expl/env_infos/initial/reward_run Mean       -0.50241
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.50241
expl/env_infos/initial/reward_run Min        -0.50241
expl/env_infos/reward_run Mean                5.52729
expl/env_infos/reward_run Std                 1.13185
expl/env_infos/reward_run Max                 7.75164
expl/env_infos/reward_run Min                -0.50241
expl/env_infos/final/reward_ctrl Mean        -0.288663
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.288663
expl/env_infos/final/reward_ctrl Min         -0.288663
expl/env_infos/initial/reward_ctrl Mean      -0.140875
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.140875
expl/env_infos/initial/reward_ctrl Min       -0.140875
expl/env_infos/reward_ctrl Mean              -0.399089
expl/env_infos/reward_ctrl Std                0.0898074
expl/env_infos/reward_ctrl Max               -0.138859
expl/env_infos/reward_ctrl Min               -0.584783
eval/num steps total                     985000
eval/num paths total                        985
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.19005
eval/Rewards Std                              1.19349
eval/Rewards Max                              7.95427
eval/Rewards Min                             -0.887136
eval/Returns Mean                          5190.05
eval/Returns Std                             61.1214
eval/Returns Max                           5305.56
eval/Returns Min                           5135.1
eval/Actions Mean                             0.041117
eval/Actions Std                              0.830615
eval/Actions Max                              0.997165
eval/Actions Min                             -0.998326
eval/Num Paths                                5
eval/Average Returns                       5190.05
eval/env_infos/final/reward_run Mean          5.28356
eval/env_infos/final/reward_run Std           0.838037
eval/env_infos/final/reward_run Max           6.74496
eval/env_infos/final/reward_run Min           4.18249
eval/env_infos/initial/reward_run Mean       -0.484081
eval/env_infos/initial/reward_run Std         0.133964
eval/env_infos/initial/reward_run Max        -0.230229
eval/env_infos/initial/reward_run Min        -0.611274
eval/env_infos/reward_run Mean                5.60502
eval/env_infos/reward_run Std                 1.17242
eval/env_infos/reward_run Max                 8.3945
eval/env_infos/reward_run Min                -0.611274
eval/env_infos/final/reward_ctrl Mean        -0.492229
eval/env_infos/final/reward_ctrl Std          0.05272
eval/env_infos/final/reward_ctrl Max         -0.400916
eval/env_infos/final/reward_ctrl Min         -0.556306
eval/env_infos/initial/reward_ctrl Mean      -0.257393
eval/env_infos/initial/reward_ctrl Std        0.0277493
eval/env_infos/initial/reward_ctrl Max       -0.203121
eval/env_infos/initial/reward_ctrl Min       -0.275862
eval/env_infos/reward_ctrl Mean              -0.414968
eval/env_infos/reward_ctrl Std                0.0843315
eval/env_infos/reward_ctrl Max               -0.134949
eval/env_infos/reward_ctrl Min               -0.582647
time/data storing (s)                         0.00445054
time/evaluation sampling (s)                  2.04912
time/exploration sampling (s)                 0.523207
time/logging (s)                              0.0136047
time/sac training (s)                         7.81197
time/saving (s)                               0.00380547
time/training (s)                             3.4938e-05
time/epoch (s)                               10.4062
time/total (s)                             2122.52
Epoch                                       196
---------------------------------------  ---------------
2021-11-24 01:04:46.435164 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 197 finished
---------------------------------------  ----------------
epoch                                       197
replay_buffer/size                       199000
trainer/num train calls                  198000
trainer/QF1 Loss                              6.10598
trainer/QF2 Loss                              4.74568
trainer/Policy Loss                        -310.913
trainer/Q1 Predictions Mean                 311.39
trainer/Q1 Predictions Std                   93.7493
trainer/Q1 Predictions Max                  387.677
trainer/Q1 Predictions Min                   17.5065
trainer/Q2 Predictions Mean                 311.662
trainer/Q2 Predictions Std                   93.8778
trainer/Q2 Predictions Max                  389.439
trainer/Q2 Predictions Min                   17.0458
trainer/Q Targets Mean                      311.65
trainer/Q Targets Std                        93.73
trainer/Q Targets Max                       389.26
trainer/Q Targets Min                        17.6171
trainer/Log Pis Mean                          6.31227
trainer/Log Pis Std                           4.595
trainer/Log Pis Max                          18.625
trainer/Log Pis Min                          -4.96944
trainer/policy/mean Mean                      0.0788112
trainer/policy/mean Std                       0.767917
trainer/policy/mean Max                       0.999063
trainer/policy/mean Min                      -0.997426
trainer/policy/normal/std Mean                0.437387
trainer/policy/normal/std Std                 0.151392
trainer/policy/normal/std Max                 0.923094
trainer/policy/normal/std Min                 0.082625
trainer/policy/normal/log_std Mean           -0.900387
trainer/policy/normal/log_std Std             0.41239
trainer/policy/normal/log_std Max            -0.0800244
trainer/policy/normal/log_std Min            -2.49344
trainer/Alpha                                 0.118293
trainer/Alpha Loss                            0.666569
expl/num steps total                     199000
expl/num paths total                        199
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.12373
expl/Rewards Std                              1.18546
expl/Rewards Max                              7.56667
expl/Rewards Min                             -0.49508
expl/Returns Mean                          5123.73
expl/Returns Std                              0
expl/Returns Max                           5123.73
expl/Returns Min                           5123.73
expl/Actions Mean                             0.0645997
expl/Actions Std                              0.819089
expl/Actions Max                              0.999616
expl/Actions Min                             -0.999395
expl/Num Paths                                1
expl/Average Returns                       5123.73
expl/env_infos/final/reward_run Mean          5.27466
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.27466
expl/env_infos/final/reward_run Min           5.27466
expl/env_infos/initial/reward_run Mean       -0.322022
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.322022
expl/env_infos/initial/reward_run Min        -0.322022
expl/env_infos/reward_run Mean                5.52878
expl/env_infos/reward_run Std                 1.16891
expl/env_infos/reward_run Max                 7.90901
expl/env_infos/reward_run Min                -0.322022
expl/env_infos/final/reward_ctrl Mean        -0.543014
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.543014
expl/env_infos/final/reward_ctrl Min         -0.543014
expl/env_infos/initial/reward_ctrl Mean      -0.173058
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.173058
expl/env_infos/initial/reward_ctrl Min       -0.173058
expl/env_infos/reward_ctrl Mean              -0.405048
expl/env_infos/reward_ctrl Std                0.0906275
expl/env_infos/reward_ctrl Max               -0.115332
expl/env_infos/reward_ctrl Min               -0.577403
eval/num steps total                     990000
eval/num paths total                        990
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.23468
eval/Rewards Std                              1.22103
eval/Rewards Max                              7.74366
eval/Rewards Min                             -1.15331
eval/Returns Mean                          5234.68
eval/Returns Std                             57.1448
eval/Returns Max                           5296.78
eval/Returns Min                           5140.5
eval/Actions Mean                             0.0668478
eval/Actions Std                              0.829083
eval/Actions Max                              0.997952
eval/Actions Min                             -0.99812
eval/Num Paths                                5
eval/Average Returns                       5234.68
eval/env_infos/final/reward_run Mean          5.88287
eval/env_infos/final/reward_run Std           1.00851
eval/env_infos/final/reward_run Max           7.62715
eval/env_infos/final/reward_run Min           4.81443
eval/env_infos/initial/reward_run Mean       -0.394003
eval/env_infos/initial/reward_run Std         0.271177
eval/env_infos/initial/reward_run Max        -0.049995
eval/env_infos/initial/reward_run Min        -0.825726
eval/env_infos/reward_run Mean                5.64979
eval/env_infos/reward_run Std                 1.19726
eval/env_infos/reward_run Max                 8.22199
eval/env_infos/reward_run Min                -0.825726
eval/env_infos/final/reward_ctrl Mean        -0.439529
eval/env_infos/final/reward_ctrl Std          0.107583
eval/env_infos/final/reward_ctrl Max         -0.230639
eval/env_infos/final/reward_ctrl Min         -0.541427
eval/env_infos/initial/reward_ctrl Mean      -0.234371
eval/env_infos/initial/reward_ctrl Std        0.0699305
eval/env_infos/initial/reward_ctrl Max       -0.130386
eval/env_infos/initial/reward_ctrl Min       -0.327582
eval/env_infos/reward_ctrl Mean              -0.415109
eval/env_infos/reward_ctrl Std                0.0892149
eval/env_infos/reward_ctrl Max               -0.130386
eval/env_infos/reward_ctrl Min               -0.5805
time/data storing (s)                         0.0045597
time/evaluation sampling (s)                  2.06291
time/exploration sampling (s)                 0.543209
time/logging (s)                              0.0149236
time/sac training (s)                         7.80574
time/saving (s)                               0.0038835
time/training (s)                             4.29749e-05
time/epoch (s)                               10.4353
time/total (s)                             2133.28
Epoch                                       197
---------------------------------------  ----------------
2021-11-24 01:04:57.191377 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 198 finished
---------------------------------------  ---------------
epoch                                       198
replay_buffer/size                       200000
trainer/num train calls                  199000
trainer/QF1 Loss                              7.83222
trainer/QF2 Loss                              6.28306
trainer/Policy Loss                        -301.6
trainer/Q1 Predictions Mean                 301.924
trainer/Q1 Predictions Std                  103.046
trainer/Q1 Predictions Max                  380.631
trainer/Q1 Predictions Min                   13.7246
trainer/Q2 Predictions Mean                 302.245
trainer/Q2 Predictions Std                  103.277
trainer/Q2 Predictions Max                  380.166
trainer/Q2 Predictions Min                   15.2036
trainer/Q Targets Mean                      302.268
trainer/Q Targets Std                       103.399
trainer/Q Targets Max                       386.831
trainer/Q Targets Min                        15.0119
trainer/Log Pis Mean                          5.94277
trainer/Log Pis Std                           5.02382
trainer/Log Pis Max                          18.8257
trainer/Log Pis Min                          -5.66864
trainer/policy/mean Mean                      0.0686763
trainer/policy/mean Std                       0.765955
trainer/policy/mean Max                       0.999644
trainer/policy/mean Min                      -0.998016
trainer/policy/normal/std Mean                0.451465
trainer/policy/normal/std Std                 0.149647
trainer/policy/normal/std Max                 1.02156
trainer/policy/normal/std Min                 0.0815018
trainer/policy/normal/log_std Mean           -0.862868
trainer/policy/normal/log_std Std             0.395661
trainer/policy/normal/log_std Max             0.0213321
trainer/policy/normal/log_std Min            -2.50713
trainer/Alpha                                 0.117551
trainer/Alpha Loss                           -0.122517
expl/num steps total                     200000
expl/num paths total                        200
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.25638
expl/Rewards Std                              1.18104
expl/Rewards Max                              7.57824
expl/Rewards Min                             -0.945806
expl/Returns Mean                          5256.38
expl/Returns Std                              0
expl/Returns Max                           5256.38
expl/Returns Min                           5256.38
expl/Actions Mean                             0.0825547
expl/Actions Std                              0.812748
expl/Actions Max                              0.999555
expl/Actions Min                             -0.999351
expl/Num Paths                                1
expl/Average Returns                       5256.38
expl/env_infos/final/reward_run Mean          5.31494
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.31494
expl/env_infos/final/reward_run Min           5.31494
expl/env_infos/initial/reward_run Mean       -0.699637
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.699637
expl/env_infos/initial/reward_run Min        -0.699637
expl/env_infos/reward_run Mean                5.6568
expl/env_infos/reward_run Std                 1.15805
expl/env_infos/reward_run Max                 7.97801
expl/env_infos/reward_run Min                -0.699637
expl/env_infos/final/reward_ctrl Mean        -0.408017
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.408017
expl/env_infos/final/reward_ctrl Min         -0.408017
expl/env_infos/initial/reward_ctrl Mean      -0.246168
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.246168
expl/env_infos/initial/reward_ctrl Min       -0.246168
expl/env_infos/reward_ctrl Mean              -0.400424
expl/env_infos/reward_ctrl Std                0.0905215
expl/env_infos/reward_ctrl Max               -0.120186
expl/env_infos/reward_ctrl Min               -0.588192
eval/num steps total                     995000
eval/num paths total                        995
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.27948
eval/Rewards Std                              1.22486
eval/Rewards Max                              7.72845
eval/Rewards Min                             -0.825094
eval/Returns Mean                          5279.48
eval/Returns Std                             45.0292
eval/Returns Max                           5344.88
eval/Returns Min                           5217.12
eval/Actions Mean                             0.0850884
eval/Actions Std                              0.822657
eval/Actions Max                              0.998142
eval/Actions Min                             -0.998275
eval/Num Paths                                5
eval/Average Returns                       5279.48
eval/env_infos/final/reward_run Mean          6.29212
eval/env_infos/final/reward_run Std           1.12317
eval/env_infos/final/reward_run Max           7.57382
eval/env_infos/final/reward_run Min           4.6341
eval/env_infos/initial/reward_run Mean       -0.35002
eval/env_infos/initial/reward_run Std         0.203603
eval/env_infos/initial/reward_run Max         0.0217676
eval/env_infos/initial/reward_run Min        -0.577763
eval/env_infos/reward_run Mean                5.68988
eval/env_infos/reward_run Std                 1.19937
eval/env_infos/reward_run Max                 8.18004
eval/env_infos/reward_run Min                -0.577763
eval/env_infos/final/reward_ctrl Mean        -0.442567
eval/env_infos/final/reward_ctrl Std          0.0576236
eval/env_infos/final/reward_ctrl Max         -0.377124
eval/env_infos/final/reward_ctrl Min         -0.525396
eval/env_infos/initial/reward_ctrl Mean      -0.243312
eval/env_infos/initial/reward_ctrl Std        0.0344099
eval/env_infos/initial/reward_ctrl Max       -0.20513
eval/env_infos/initial/reward_ctrl Min       -0.301894
eval/env_infos/reward_ctrl Mean              -0.410402
eval/env_infos/reward_ctrl Std                0.088554
eval/env_infos/reward_ctrl Max               -0.126594
eval/env_infos/reward_ctrl Min               -0.581393
time/data storing (s)                         0.00449569
time/evaluation sampling (s)                  2.01451
time/exploration sampling (s)                 0.525468
time/logging (s)                              0.0137772
time/sac training (s)                         7.85296
time/saving (s)                               0.00375946
time/training (s)                             3.5222e-05
time/epoch (s)                               10.415
time/total (s)                             2144.02
Epoch                                       198
---------------------------------------  ---------------
2021-11-24 01:05:07.915897 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 199 finished
---------------------------------------  ---------------
epoch                                       199
replay_buffer/size                       201000
trainer/num train calls                  200000
trainer/QF1 Loss                              6.7844
trainer/QF2 Loss                              6.99088
trainer/Policy Loss                        -303.523
trainer/Q1 Predictions Mean                 303.865
trainer/Q1 Predictions Std                  104.021
trainer/Q1 Predictions Max                  382.146
trainer/Q1 Predictions Min                   14.5057
trainer/Q2 Predictions Mean                 304.22
trainer/Q2 Predictions Std                  103.977
trainer/Q2 Predictions Max                  380.04
trainer/Q2 Predictions Min                   15.5856
trainer/Q Targets Mean                      304.285
trainer/Q Targets Std                       104.431
trainer/Q Targets Max                       382.55
trainer/Q Targets Min                        14.7038
trainer/Log Pis Mean                          6.57806
trainer/Log Pis Std                           4.94021
trainer/Log Pis Max                          19.7546
trainer/Log Pis Min                          -5.03345
trainer/policy/mean Mean                      0.0285143
trainer/policy/mean Std                       0.789995
trainer/policy/mean Max                       0.999082
trainer/policy/mean Min                      -0.999987
trainer/policy/normal/std Mean                0.452062
trainer/policy/normal/std Std                 0.146663
trainer/policy/normal/std Max                 1.0473
trainer/policy/normal/std Min                 0.0803854
trainer/policy/normal/log_std Mean           -0.859601
trainer/policy/normal/log_std Std             0.393164
trainer/policy/normal/log_std Max             0.0462146
trainer/policy/normal/log_std Min            -2.52092
trainer/Alpha                                 0.11728
trainer/Alpha Loss                            1.23889
expl/num steps total                     201000
expl/num paths total                        201
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.16772
expl/Rewards Std                              1.22917
expl/Rewards Max                              7.66193
expl/Rewards Min                             -0.856336
expl/Returns Mean                          5167.72
expl/Returns Std                              0
expl/Returns Max                           5167.72
expl/Returns Min                           5167.72
expl/Actions Mean                             0.0538143
expl/Actions Std                              0.820972
expl/Actions Max                              0.99991
expl/Actions Min                             -0.999982
expl/Num Paths                                1
expl/Average Returns                       5167.72
expl/env_infos/final/reward_run Mean          6.87445
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.87445
expl/env_infos/final/reward_run Min           6.87445
expl/env_infos/initial/reward_run Mean       -0.542672
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.542672
expl/env_infos/initial/reward_run Min        -0.542672
expl/env_infos/reward_run Mean                5.57386
expl/env_infos/reward_run Std                 1.22381
expl/env_infos/reward_run Max                 8.13579
expl/env_infos/reward_run Min                -0.542672
expl/env_infos/final/reward_ctrl Mean        -0.522617
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.522617
expl/env_infos/final/reward_ctrl Min         -0.522617
expl/env_infos/initial/reward_ctrl Mean      -0.313664
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.313664
expl/env_infos/initial/reward_ctrl Min       -0.313664
expl/env_infos/reward_ctrl Mean              -0.406134
expl/env_infos/reward_ctrl Std                0.0900944
expl/env_infos/reward_ctrl Max               -0.126651
expl/env_infos/reward_ctrl Min               -0.585128
eval/num steps total                          1e+06
eval/num paths total                       1000
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.40096
eval/Rewards Std                              1.22103
eval/Rewards Max                              7.85064
eval/Rewards Min                             -0.921007
eval/Returns Mean                          5400.96
eval/Returns Std                             71.4276
eval/Returns Max                           5509.57
eval/Returns Min                           5297.11
eval/Actions Mean                             0.040551
eval/Actions Std                              0.836464
eval/Actions Max                              0.998603
eval/Actions Min                             -0.998756
eval/Num Paths                                5
eval/Average Returns                       5400.96
eval/env_infos/final/reward_run Mean          7.08415
eval/env_infos/final/reward_run Std           0.615143
eval/env_infos/final/reward_run Max           7.78584
eval/env_infos/final/reward_run Min           6.15396
eval/env_infos/initial/reward_run Mean       -0.349143
eval/env_infos/initial/reward_run Std         0.243996
eval/env_infos/initial/reward_run Max         0.0631571
eval/env_infos/initial/reward_run Min        -0.621301
eval/env_infos/reward_run Mean                5.82175
eval/env_infos/reward_run Std                 1.21523
eval/env_infos/reward_run Max                 8.3484
eval/env_infos/reward_run Min                -0.621301
eval/env_infos/final/reward_ctrl Mean        -0.483098
eval/env_infos/final/reward_ctrl Std          0.0301557
eval/env_infos/final/reward_ctrl Max         -0.429489
eval/env_infos/final/reward_ctrl Min         -0.519868
eval/env_infos/initial/reward_ctrl Mean      -0.202637
eval/env_infos/initial/reward_ctrl Std        0.0521067
eval/env_infos/initial/reward_ctrl Max       -0.156517
eval/env_infos/initial/reward_ctrl Min       -0.299706
eval/env_infos/reward_ctrl Mean              -0.42079
eval/env_infos/reward_ctrl Std                0.0880625
eval/env_infos/reward_ctrl Max               -0.0905229
eval/env_infos/reward_ctrl Min               -0.582553
time/data storing (s)                         0.00447969
time/evaluation sampling (s)                  2.05296
time/exploration sampling (s)                 0.531717
time/logging (s)                              0.0151269
time/sac training (s)                         7.77984
time/saving (s)                               0.00383855
time/training (s)                             4.6696e-05
time/epoch (s)                               10.388
time/total (s)                             2154.73
Epoch                                       199
---------------------------------------  ---------------
2021-11-24 01:05:18.682851 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 200 finished
---------------------------------------  ---------------
epoch                                       200
replay_buffer/size                       202000
trainer/num train calls                  201000
trainer/QF1 Loss                              5.62065
trainer/QF2 Loss                              5.05338
trainer/Policy Loss                        -313.437
trainer/Q1 Predictions Mean                 314.12
trainer/Q1 Predictions Std                   93.1741
trainer/Q1 Predictions Max                  386.456
trainer/Q1 Predictions Min                   17.5169
trainer/Q2 Predictions Mean                 313.771
trainer/Q2 Predictions Std                   93.0467
trainer/Q2 Predictions Max                  386.027
trainer/Q2 Predictions Min                   16.9597
trainer/Q Targets Mean                      313.469
trainer/Q Targets Std                        93.0565
trainer/Q Targets Max                       387.516
trainer/Q Targets Min                        16.2164
trainer/Log Pis Mean                          5.96974
trainer/Log Pis Std                           4.43719
trainer/Log Pis Max                          17.1265
trainer/Log Pis Min                          -8.28526
trainer/policy/mean Mean                      0.0643232
trainer/policy/mean Std                       0.775044
trainer/policy/mean Max                       0.999887
trainer/policy/mean Min                      -0.997141
trainer/policy/normal/std Mean                0.440559
trainer/policy/normal/std Std                 0.146451
trainer/policy/normal/std Max                 0.867599
trainer/policy/normal/std Min                 0.0866245
trainer/policy/normal/log_std Mean           -0.887502
trainer/policy/normal/log_std Std             0.395746
trainer/policy/normal/log_std Max            -0.142025
trainer/policy/normal/log_std Min            -2.44617
trainer/Alpha                                 0.118355
trainer/Alpha Loss                           -0.0645721
expl/num steps total                     202000
expl/num paths total                        202
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.06775
expl/Rewards Std                              1.16575
expl/Rewards Max                              7.17975
expl/Rewards Min                             -1.00782
expl/Returns Mean                          5067.75
expl/Returns Std                              0
expl/Returns Max                           5067.75
expl/Returns Min                           5067.75
expl/Actions Mean                             0.0780028
expl/Actions Std                              0.81204
expl/Actions Max                              0.999745
expl/Actions Min                             -0.99966
expl/Num Paths                                1
expl/Average Returns                       5067.75
expl/env_infos/final/reward_run Mean          6.50352
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.50352
expl/env_infos/final/reward_run Min           6.50352
expl/env_infos/initial/reward_run Mean       -0.772825
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.772825
expl/env_infos/initial/reward_run Min        -0.772825
expl/env_infos/reward_run Mean                5.46704
expl/env_infos/reward_run Std                 1.15453
expl/env_infos/reward_run Max                 7.61089
expl/env_infos/reward_run Min                -0.772825
expl/env_infos/final/reward_ctrl Mean        -0.451306
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.451306
expl/env_infos/final/reward_ctrl Min         -0.451306
expl/env_infos/initial/reward_ctrl Mean      -0.234995
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.234995
expl/env_infos/initial/reward_ctrl Min       -0.234995
expl/env_infos/reward_ctrl Mean              -0.399296
expl/env_infos/reward_ctrl Std                0.0878243
expl/env_infos/reward_ctrl Max               -0.109493
expl/env_infos/reward_ctrl Min               -0.572646
eval/num steps total                          1.005e+06
eval/num paths total                       1005
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.34105
eval/Rewards Std                              1.24059
eval/Rewards Max                              8.00684
eval/Rewards Min                             -0.729851
eval/Returns Mean                          5341.05
eval/Returns Std                            109.958
eval/Returns Max                           5510.58
eval/Returns Min                           5172.93
eval/Actions Mean                             0.0805707
eval/Actions Std                              0.826297
eval/Actions Max                              0.998414
eval/Actions Min                             -0.998773
eval/Num Paths                                5
eval/Average Returns                       5341.05
eval/env_infos/final/reward_run Mean          5.8491
eval/env_infos/final/reward_run Std           0.659786
eval/env_infos/final/reward_run Max           6.66371
eval/env_infos/final/reward_run Min           5.06821
eval/env_infos/initial/reward_run Mean       -0.292118
eval/env_infos/initial/reward_run Std         0.141733
eval/env_infos/initial/reward_run Max        -0.0588366
eval/env_infos/initial/reward_run Min        -0.443721
eval/env_infos/reward_run Mean                5.75461
eval/env_infos/reward_run Std                 1.22484
eval/env_infos/reward_run Max                 8.49828
eval/env_infos/reward_run Min                -0.443721
eval/env_infos/final/reward_ctrl Mean        -0.445229
eval/env_infos/final/reward_ctrl Std          0.0441636
eval/env_infos/final/reward_ctrl Max         -0.39765
eval/env_infos/final/reward_ctrl Min         -0.52087
eval/env_infos/initial/reward_ctrl Mean      -0.225004
eval/env_infos/initial/reward_ctrl Std        0.0595223
eval/env_infos/initial/reward_ctrl Max       -0.125116
eval/env_infos/initial/reward_ctrl Min       -0.305166
eval/env_infos/reward_ctrl Mean              -0.413555
eval/env_infos/reward_ctrl Std                0.0797868
eval/env_infos/reward_ctrl Max               -0.125116
eval/env_infos/reward_ctrl Min               -0.578375
time/data storing (s)                         0.00497711
time/evaluation sampling (s)                  2.0327
time/exploration sampling (s)                 0.548748
time/logging (s)                              0.0143046
time/sac training (s)                         7.82042
time/saving (s)                               0.0039095
time/training (s)                             3.911e-05
time/epoch (s)                               10.4251
time/total (s)                             2165.48
Epoch                                       200
---------------------------------------  ---------------
2021-11-24 01:05:29.380069 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 201 finished
---------------------------------------  ---------------
epoch                                       201
replay_buffer/size                       203000
trainer/num train calls                  202000
trainer/QF1 Loss                              6.68277
trainer/QF2 Loss                              6.85753
trainer/Policy Loss                        -309.917
trainer/Q1 Predictions Mean                 310.599
trainer/Q1 Predictions Std                   96.0076
trainer/Q1 Predictions Max                  390.982
trainer/Q1 Predictions Min                   16.693
trainer/Q2 Predictions Mean                 310.424
trainer/Q2 Predictions Std                   96.003
trainer/Q2 Predictions Max                  392.162
trainer/Q2 Predictions Min                   16.2879
trainer/Q Targets Mean                      310.359
trainer/Q Targets Std                        95.9619
trainer/Q Targets Max                       392.707
trainer/Q Targets Min                        16.0635
trainer/Log Pis Mean                          5.87946
trainer/Log Pis Std                           5.1285
trainer/Log Pis Max                          31.752
trainer/Log Pis Min                          -9.04346
trainer/policy/mean Mean                      0.0796983
trainer/policy/mean Std                       0.773724
trainer/policy/mean Max                       0.99995
trainer/policy/mean Min                      -0.999985
trainer/policy/normal/std Mean                0.456612
trainer/policy/normal/std Std                 0.148785
trainer/policy/normal/std Max                 1.23135
trainer/policy/normal/std Min                 0.0809032
trainer/policy/normal/log_std Mean           -0.846511
trainer/policy/normal/log_std Std             0.377985
trainer/policy/normal/log_std Max             0.208111
trainer/policy/normal/log_std Min            -2.5145
trainer/Alpha                                 0.119558
trainer/Alpha Loss                           -0.256027
expl/num steps total                     203000
expl/num paths total                        203
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.16674
expl/Rewards Std                              1.21712
expl/Rewards Max                              7.29896
expl/Rewards Min                             -0.744259
expl/Returns Mean                          5166.74
expl/Returns Std                              0
expl/Returns Max                           5166.74
expl/Returns Min                           5166.74
expl/Actions Mean                             0.086128
expl/Actions Std                              0.815859
expl/Actions Max                              0.999643
expl/Actions Min                             -0.999717
expl/Num Paths                                1
expl/Average Returns                       5166.74
expl/env_infos/final/reward_run Mean          6.50834
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.50834
expl/env_infos/final/reward_run Min           6.50834
expl/env_infos/initial/reward_run Mean       -0.521648
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.521648
expl/env_infos/initial/reward_run Min        -0.521648
expl/env_infos/reward_run Mean                5.57056
expl/env_infos/reward_run Std                 1.2075
expl/env_infos/reward_run Max                 7.78408
expl/env_infos/reward_run Min                -0.521648
expl/env_infos/final/reward_ctrl Mean        -0.49489
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.49489
expl/env_infos/final/reward_ctrl Min         -0.49489
expl/env_infos/initial/reward_ctrl Mean      -0.222611
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.222611
expl/env_infos/initial/reward_ctrl Min       -0.222611
expl/env_infos/reward_ctrl Mean              -0.403826
expl/env_infos/reward_ctrl Std                0.091692
expl/env_infos/reward_ctrl Max               -0.0950924
expl/env_infos/reward_ctrl Min               -0.579551
eval/num steps total                          1.01e+06
eval/num paths total                       1010
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.41055
eval/Rewards Std                              1.23724
eval/Rewards Max                              7.8773
eval/Rewards Min                             -0.735278
eval/Returns Mean                          5410.55
eval/Returns Std                             33.0626
eval/Returns Max                           5445.3
eval/Returns Min                           5355.08
eval/Actions Mean                             0.0828069
eval/Actions Std                              0.826735
eval/Actions Max                              0.998377
eval/Actions Min                             -0.996081
eval/Num Paths                                5
eval/Average Returns                       5410.55
eval/env_infos/final/reward_run Mean          5.6242
eval/env_infos/final/reward_run Std           0.314719
eval/env_infos/final/reward_run Max           5.89438
eval/env_infos/final/reward_run Min           5.03713
eval/env_infos/initial/reward_run Mean       -0.268962
eval/env_infos/initial/reward_run Std         0.161313
eval/env_infos/initial/reward_run Max        -0.0906568
eval/env_infos/initial/reward_run Min        -0.494171
eval/env_infos/reward_run Mean                5.82476
eval/env_infos/reward_run Std                 1.22624
eval/env_infos/reward_run Max                 8.38532
eval/env_infos/reward_run Min                -0.494171
eval/env_infos/final/reward_ctrl Mean        -0.427358
eval/env_infos/final/reward_ctrl Std          0.0686614
eval/env_infos/final/reward_ctrl Max         -0.342052
eval/env_infos/final/reward_ctrl Min         -0.50065
eval/env_infos/initial/reward_ctrl Mean      -0.20824
eval/env_infos/initial/reward_ctrl Std        0.035818
eval/env_infos/initial/reward_ctrl Max       -0.155384
eval/env_infos/initial/reward_ctrl Min       -0.254753
eval/env_infos/reward_ctrl Mean              -0.414209
eval/env_infos/reward_ctrl Std                0.0874308
eval/env_infos/reward_ctrl Max               -0.100887
eval/env_infos/reward_ctrl Min               -0.580521
time/data storing (s)                         0.00447737
time/evaluation sampling (s)                  2.04998
time/exploration sampling (s)                 0.541206
time/logging (s)                              0.0142111
time/sac training (s)                         7.74636
time/saving (s)                               0.0038381
time/training (s)                             3.4083e-05
time/epoch (s)                               10.3601
time/total (s)                             2176.16
Epoch                                       201
---------------------------------------  ---------------
2021-11-24 01:05:40.161930 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 202 finished
---------------------------------------  ---------------
epoch                                       202
replay_buffer/size                       204000
trainer/num train calls                  203000
trainer/QF1 Loss                              7.3343
trainer/QF2 Loss                              5.29538
trainer/Policy Loss                        -319.482
trainer/Q1 Predictions Mean                 319.589
trainer/Q1 Predictions Std                   80.2343
trainer/Q1 Predictions Max                  393.682
trainer/Q1 Predictions Min                   17.1442
trainer/Q2 Predictions Mean                 319.324
trainer/Q2 Predictions Std                   80.1726
trainer/Q2 Predictions Max                  392.027
trainer/Q2 Predictions Min                   16.1933
trainer/Q Targets Mean                      319.35
trainer/Q Targets Std                        79.9782
trainer/Q Targets Max                       391.413
trainer/Q Targets Min                        16.7343
trainer/Log Pis Mean                          6.02253
trainer/Log Pis Std                           4.44973
trainer/Log Pis Max                          19.7029
trainer/Log Pis Min                          -5.1175
trainer/policy/mean Mean                      0.0557589
trainer/policy/mean Std                       0.781081
trainer/policy/mean Max                       0.998951
trainer/policy/mean Min                      -0.99689
trainer/policy/normal/std Mean                0.437271
trainer/policy/normal/std Std                 0.143641
trainer/policy/normal/std Max                 1.04149
trainer/policy/normal/std Min                 0.0754743
trainer/policy/normal/log_std Mean           -0.894338
trainer/policy/normal/log_std Std             0.396438
trainer/policy/normal/log_std Max             0.0406483
trainer/policy/normal/log_std Min            -2.58396
trainer/Alpha                                 0.118007
trainer/Alpha Loss                            0.0481521
expl/num steps total                     204000
expl/num paths total                        204
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.17492
expl/Rewards Std                              1.19307
expl/Rewards Max                              7.49947
expl/Rewards Min                             -0.670148
expl/Returns Mean                          5174.92
expl/Returns Std                              0
expl/Returns Max                           5174.92
expl/Returns Min                           5174.92
expl/Actions Mean                             0.0454626
expl/Actions Std                              0.815397
expl/Actions Max                              0.999754
expl/Actions Min                             -0.999545
expl/Num Paths                                1
expl/Average Returns                       5174.92
expl/env_infos/final/reward_run Mean          7.03278
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.03278
expl/env_infos/final/reward_run Min           7.03278
expl/env_infos/initial/reward_run Mean       -0.453498
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.453498
expl/env_infos/initial/reward_run Min        -0.453498
expl/env_infos/reward_run Mean                5.57509
expl/env_infos/reward_run Std                 1.18468
expl/env_infos/reward_run Max                 7.96149
expl/env_infos/reward_run Min                -0.453498
expl/env_infos/final/reward_ctrl Mean        -0.366257
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.366257
expl/env_infos/final/reward_ctrl Min         -0.366257
expl/env_infos/initial/reward_ctrl Mean      -0.216649
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.216649
expl/env_infos/initial/reward_ctrl Min       -0.216649
expl/env_infos/reward_ctrl Mean              -0.400163
expl/env_infos/reward_ctrl Std                0.0927763
expl/env_infos/reward_ctrl Max               -0.131388
expl/env_infos/reward_ctrl Min               -0.583687
eval/num steps total                          1.015e+06
eval/num paths total                       1015
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.36606
eval/Rewards Std                              1.2159
eval/Rewards Max                              7.68955
eval/Rewards Min                             -0.798247
eval/Returns Mean                          5366.06
eval/Returns Std                             73.7947
eval/Returns Max                           5454.05
eval/Returns Min                           5281.02
eval/Actions Mean                             0.0511964
eval/Actions Std                              0.830509
eval/Actions Max                              0.998006
eval/Actions Min                             -0.998226
eval/Num Paths                                5
eval/Average Returns                       5366.06
eval/env_infos/final/reward_run Mean          6.43234
eval/env_infos/final/reward_run Std           0.64241
eval/env_infos/final/reward_run Max           7.2226
eval/env_infos/final/reward_run Min           5.50825
eval/env_infos/initial/reward_run Mean       -0.303531
eval/env_infos/initial/reward_run Std         0.2082
eval/env_infos/initial/reward_run Max         0.0675386
eval/env_infos/initial/reward_run Min        -0.501408
eval/env_infos/reward_run Mean                5.78148
eval/env_infos/reward_run Std                 1.20301
eval/env_infos/reward_run Max                 8.17756
eval/env_infos/reward_run Min                -0.501408
eval/env_infos/final/reward_ctrl Mean        -0.401042
eval/env_infos/final/reward_ctrl Std          0.0936481
eval/env_infos/final/reward_ctrl Max         -0.250652
eval/env_infos/final/reward_ctrl Min         -0.483999
eval/env_infos/initial/reward_ctrl Mean      -0.189757
eval/env_infos/initial/reward_ctrl Std        0.0729203
eval/env_infos/initial/reward_ctrl Max       -0.0863115
eval/env_infos/initial/reward_ctrl Min       -0.28841
eval/env_infos/reward_ctrl Mean              -0.415419
eval/env_infos/reward_ctrl Std                0.0873285
eval/env_infos/reward_ctrl Max               -0.0863115
eval/env_infos/reward_ctrl Min               -0.573424
time/data storing (s)                         0.0045157
time/evaluation sampling (s)                  2.04976
time/exploration sampling (s)                 0.533173
time/logging (s)                              0.0135853
time/sac training (s)                         7.83792
time/saving (s)                               0.00383604
time/training (s)                             3.4419e-05
time/epoch (s)                               10.4428
time/total (s)                             2186.93
Epoch                                       202
---------------------------------------  ---------------
2021-11-24 01:05:50.796621 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 203 finished
---------------------------------------  ---------------
epoch                                       203
replay_buffer/size                       205000
trainer/num train calls                  204000
trainer/QF1 Loss                              8.26177
trainer/QF2 Loss                              7.60972
trainer/Policy Loss                        -310.442
trainer/Q1 Predictions Mean                 310.946
trainer/Q1 Predictions Std                  102.533
trainer/Q1 Predictions Max                  389.665
trainer/Q1 Predictions Min                   16.1019
trainer/Q2 Predictions Mean                 311.06
trainer/Q2 Predictions Std                  102.576
trainer/Q2 Predictions Max                  389.444
trainer/Q2 Predictions Min                   17.2667
trainer/Q Targets Mean                      309.749
trainer/Q Targets Std                       102.078
trainer/Q Targets Max                       389.83
trainer/Q Targets Min                        17.1669
trainer/Log Pis Mean                          5.52583
trainer/Log Pis Std                           4.50442
trainer/Log Pis Max                          17.0842
trainer/Log Pis Min                          -9.11138
trainer/policy/mean Mean                      0.106622
trainer/policy/mean Std                       0.76251
trainer/policy/mean Max                       0.996944
trainer/policy/mean Min                      -0.996465
trainer/policy/normal/std Mean                0.448826
trainer/policy/normal/std Std                 0.146363
trainer/policy/normal/std Max                 0.876789
trainer/policy/normal/std Min                 0.0741633
trainer/policy/normal/log_std Mean           -0.867445
trainer/policy/normal/log_std Std             0.394125
trainer/policy/normal/log_std Max            -0.131489
trainer/policy/normal/log_std Min            -2.60149
trainer/Alpha                                 0.118272
trainer/Alpha Loss                           -1.01225
expl/num steps total                     205000
expl/num paths total                        205
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.00544
expl/Rewards Std                              1.13069
expl/Rewards Max                              7.2556
expl/Rewards Min                             -0.534277
expl/Returns Mean                          5005.44
expl/Returns Std                              0
expl/Returns Max                           5005.44
expl/Returns Min                           5005.44
expl/Actions Mean                             0.117227
expl/Actions Std                              0.7984
expl/Actions Max                              0.999873
expl/Actions Min                             -0.999557
expl/Num Paths                                1
expl/Average Returns                       5005.44
expl/env_infos/final/reward_run Mean          6.89089
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.89089
expl/env_infos/final/reward_run Min           6.89089
expl/env_infos/initial/reward_run Mean       -0.106245
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.106245
expl/env_infos/initial/reward_run Min        -0.106245
expl/env_infos/reward_run Mean                5.39615
expl/env_infos/reward_run Std                 1.11195
expl/env_infos/reward_run Max                 7.63517
expl/env_infos/reward_run Min                -0.106245
expl/env_infos/final/reward_ctrl Mean        -0.426814
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.426814
expl/env_infos/final/reward_ctrl Min         -0.426814
expl/env_infos/initial/reward_ctrl Mean      -0.428032
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.428032
expl/env_infos/initial/reward_ctrl Min       -0.428032
expl/env_infos/reward_ctrl Mean              -0.390711
expl/env_infos/reward_ctrl Std                0.0854086
expl/env_infos/reward_ctrl Max               -0.103664
expl/env_infos/reward_ctrl Min               -0.576141
eval/num steps total                          1.02e+06
eval/num paths total                       1020
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.12573
eval/Rewards Std                              1.2203
eval/Rewards Max                              7.59048
eval/Rewards Min                             -0.914149
eval/Returns Mean                          5125.73
eval/Returns Std                             98.8428
eval/Returns Max                           5229.69
eval/Returns Min                           5004.89
eval/Actions Mean                             0.130684
eval/Actions Std                              0.810116
eval/Actions Max                              0.998832
eval/Actions Min                             -0.996836
eval/Num Paths                                5
eval/Average Returns                       5125.73
eval/env_infos/final/reward_run Mean          6.11815
eval/env_infos/final/reward_run Std           0.930815
eval/env_infos/final/reward_run Max           7.18361
eval/env_infos/final/reward_run Min           4.64952
eval/env_infos/initial/reward_run Mean       -0.301914
eval/env_infos/initial/reward_run Std         0.194803
eval/env_infos/initial/reward_run Max        -0.0806183
eval/env_infos/initial/reward_run Min        -0.617882
eval/env_infos/reward_run Mean                5.52975
eval/env_infos/reward_run Std                 1.20023
eval/env_infos/reward_run Max                 8.06052
eval/env_infos/reward_run Min                -0.617882
eval/env_infos/final/reward_ctrl Mean        -0.43219
eval/env_infos/final/reward_ctrl Std          0.0478744
eval/env_infos/final/reward_ctrl Max         -0.382601
eval/env_infos/final/reward_ctrl Min         -0.506895
eval/env_infos/initial/reward_ctrl Mean      -0.216791
eval/env_infos/initial/reward_ctrl Std        0.0601939
eval/env_infos/initial/reward_ctrl Max       -0.138279
eval/env_infos/initial/reward_ctrl Min       -0.296267
eval/env_infos/reward_ctrl Mean              -0.40402
eval/env_infos/reward_ctrl Std                0.0815506
eval/env_infos/reward_ctrl Max               -0.138279
eval/env_infos/reward_ctrl Min               -0.574984
time/data storing (s)                         0.00453495
time/evaluation sampling (s)                  2.0166
time/exploration sampling (s)                 0.613945
time/logging (s)                              0.0149275
time/sac training (s)                         7.66163
time/saving (s)                               0.00381551
time/training (s)                             3.8609e-05
time/epoch (s)                               10.3155
time/total (s)                             2197.55
Epoch                                       203
---------------------------------------  ---------------
2021-11-24 01:06:01.736137 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 204 finished
---------------------------------------  ----------------
epoch                                       204
replay_buffer/size                       206000
trainer/num train calls                  205000
trainer/QF1 Loss                              7.88754
trainer/QF2 Loss                              8.20444
trainer/Policy Loss                        -309.551
trainer/Q1 Predictions Mean                 309.614
trainer/Q1 Predictions Std                   93.3367
trainer/Q1 Predictions Max                  394.121
trainer/Q1 Predictions Min                   15.962
trainer/Q2 Predictions Mean                 309.678
trainer/Q2 Predictions Std                   93.3776
trainer/Q2 Predictions Max                  392.777
trainer/Q2 Predictions Min                   15.3691
trainer/Q Targets Mean                      309.504
trainer/Q Targets Std                        93.2565
trainer/Q Targets Max                       390.671
trainer/Q Targets Min                        14.3768
trainer/Log Pis Mean                          5.77584
trainer/Log Pis Std                           4.37747
trainer/Log Pis Max                          15.6726
trainer/Log Pis Min                          -4.60402
trainer/policy/mean Mean                      0.070473
trainer/policy/mean Std                       0.757717
trainer/policy/mean Max                       0.997824
trainer/policy/mean Min                      -0.998875
trainer/policy/normal/std Mean                0.445324
trainer/policy/normal/std Std                 0.147234
trainer/policy/normal/std Max                 0.864276
trainer/policy/normal/std Min                 0.0741239
trainer/policy/normal/log_std Mean           -0.878492
trainer/policy/normal/log_std Std             0.405277
trainer/policy/normal/log_std Max            -0.145863
trainer/policy/normal/log_std Min            -2.60202
trainer/Alpha                                 0.116574
trainer/Alpha Loss                           -0.48178
expl/num steps total                     206000
expl/num paths total                        206
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.1255
expl/Rewards Std                              1.17247
expl/Rewards Max                              7.34138
expl/Rewards Min                             -0.821771
expl/Returns Mean                          5125.5
expl/Returns Std                              0
expl/Returns Max                           5125.5
expl/Returns Min                           5125.5
expl/Actions Mean                             0.0756205
expl/Actions Std                              0.8097
expl/Actions Max                              0.99995
expl/Actions Min                             -0.999673
expl/Num Paths                                1
expl/Average Returns                       5125.5
expl/env_infos/final/reward_run Mean          5.5742
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.5742
expl/env_infos/final/reward_run Min           5.5742
expl/env_infos/initial/reward_run Mean       -0.599892
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.599892
expl/env_infos/initial/reward_run Min        -0.599892
expl/env_infos/reward_run Mean                5.5223
expl/env_infos/reward_run Std                 1.16238
expl/env_infos/reward_run Max                 7.8018
expl/env_infos/reward_run Min                -0.599892
expl/env_infos/final/reward_ctrl Mean        -0.543628
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.543628
expl/env_infos/final/reward_ctrl Min         -0.543628
expl/env_infos/initial/reward_ctrl Mean      -0.221879
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.221879
expl/env_infos/initial/reward_ctrl Min       -0.221879
expl/env_infos/reward_ctrl Mean              -0.396799
expl/env_infos/reward_ctrl Std                0.0936142
expl/env_infos/reward_ctrl Max               -0.110023
expl/env_infos/reward_ctrl Min               -0.572967
eval/num steps total                          1.025e+06
eval/num paths total                       1025
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.47515
eval/Rewards Std                              1.22761
eval/Rewards Max                              7.92359
eval/Rewards Min                             -1.04949
eval/Returns Mean                          5475.15
eval/Returns Std                             39.24
eval/Returns Max                           5511.82
eval/Returns Min                           5399.56
eval/Actions Mean                             0.0741256
eval/Actions Std                              0.822912
eval/Actions Max                              0.998827
eval/Actions Min                             -0.999771
eval/Num Paths                                5
eval/Average Returns                       5475.15
eval/env_infos/final/reward_run Mean          5.21806
eval/env_infos/final/reward_run Std           0.672441
eval/env_infos/final/reward_run Max           6.29368
eval/env_infos/final/reward_run Min           4.21571
eval/env_infos/initial/reward_run Mean       -0.402076
eval/env_infos/initial/reward_run Std         0.188726
eval/env_infos/initial/reward_run Max        -0.15867
eval/env_infos/initial/reward_run Min        -0.720501
eval/env_infos/reward_run Mean                5.88476
eval/env_infos/reward_run Std                 1.21815
eval/env_infos/reward_run Max                 8.43826
eval/env_infos/reward_run Min                -0.720501
eval/env_infos/final/reward_ctrl Mean        -0.456821
eval/env_infos/final/reward_ctrl Std          0.0180263
eval/env_infos/final/reward_ctrl Max         -0.435024
eval/env_infos/final/reward_ctrl Min         -0.488436
eval/env_infos/initial/reward_ctrl Mean      -0.241732
eval/env_infos/initial/reward_ctrl Std        0.054279
eval/env_infos/initial/reward_ctrl Max       -0.189856
eval/env_infos/initial/reward_ctrl Min       -0.328985
eval/env_infos/reward_ctrl Mean              -0.409608
eval/env_infos/reward_ctrl Std                0.0905885
eval/env_infos/reward_ctrl Max               -0.0606947
eval/env_infos/reward_ctrl Min               -0.580369
time/data storing (s)                         0.00669219
time/evaluation sampling (s)                  2.08867
time/exploration sampling (s)                 0.537974
time/logging (s)                              0.0143346
time/sac training (s)                         7.93799
time/saving (s)                               0.00378597
time/training (s)                             3.59589e-05
time/epoch (s)                               10.5895
time/total (s)                             2208.47
Epoch                                       204
---------------------------------------  ----------------
2021-11-24 01:06:12.199231 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 205 finished
---------------------------------------  ---------------
epoch                                       205
replay_buffer/size                       207000
trainer/num train calls                  206000
trainer/QF1 Loss                              6.84545
trainer/QF2 Loss                              4.94192
trainer/Policy Loss                        -314.001
trainer/Q1 Predictions Mean                 314.465
trainer/Q1 Predictions Std                   99.9763
trainer/Q1 Predictions Max                  399.365
trainer/Q1 Predictions Min                   15.7473
trainer/Q2 Predictions Mean                 314.475
trainer/Q2 Predictions Std                   99.948
trainer/Q2 Predictions Max                  397.378
trainer/Q2 Predictions Min                   16.1082
trainer/Q Targets Mean                      314.24
trainer/Q Targets Std                        99.8507
trainer/Q Targets Max                       397.718
trainer/Q Targets Min                        16.6019
trainer/Log Pis Mean                          6.31159
trainer/Log Pis Std                           4.62635
trainer/Log Pis Max                          19.6113
trainer/Log Pis Min                          -5.45256
trainer/policy/mean Mean                      0.071287
trainer/policy/mean Std                       0.776004
trainer/policy/mean Max                       0.998381
trainer/policy/mean Min                      -0.997962
trainer/policy/normal/std Mean                0.451528
trainer/policy/normal/std Std                 0.146567
trainer/policy/normal/std Max                 0.920382
trainer/policy/normal/std Min                 0.069926
trainer/policy/normal/log_std Mean           -0.861788
trainer/policy/normal/log_std Std             0.396589
trainer/policy/normal/log_std Max            -0.0829667
trainer/policy/normal/log_std Min            -2.66032
trainer/Alpha                                 0.118536
trainer/Alpha Loss                            0.664467
expl/num steps total                     207000
expl/num paths total                        207
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.31193
expl/Rewards Std                              1.1699
expl/Rewards Max                              7.5123
expl/Rewards Min                             -0.949675
expl/Returns Mean                          5311.93
expl/Returns Std                              0
expl/Returns Max                           5311.93
expl/Returns Min                           5311.93
expl/Actions Mean                             0.0712444
expl/Actions Std                              0.817622
expl/Actions Max                              0.999706
expl/Actions Min                             -0.999449
expl/Num Paths                                1
expl/Average Returns                       5311.93
expl/env_infos/final/reward_run Mean          5.12265
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.12265
expl/env_infos/final/reward_run Min           5.12265
expl/env_infos/initial/reward_run Mean       -0.568
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.568
expl/env_infos/initial/reward_run Min        -0.568
expl/env_infos/reward_run Mean                5.71607
expl/env_infos/reward_run Std                 1.1622
expl/env_infos/reward_run Max                 7.94115
expl/env_infos/reward_run Min                -0.568
expl/env_infos/final/reward_ctrl Mean        -0.334681
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.334681
expl/env_infos/final/reward_ctrl Min         -0.334681
expl/env_infos/initial/reward_ctrl Mean      -0.381675
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.381675
expl/env_infos/initial/reward_ctrl Min       -0.381675
expl/env_infos/reward_ctrl Mean              -0.404149
expl/env_infos/reward_ctrl Std                0.089182
expl/env_infos/reward_ctrl Max               -0.138845
expl/env_infos/reward_ctrl Min               -0.585074
eval/num steps total                          1.03e+06
eval/num paths total                       1030
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.56047
eval/Rewards Std                              1.24203
eval/Rewards Max                              7.93006
eval/Rewards Min                             -0.802887
eval/Returns Mean                          5560.47
eval/Returns Std                             43.3906
eval/Returns Max                           5629.75
eval/Returns Min                           5510.7
eval/Actions Mean                             0.0822985
eval/Actions Std                              0.829904
eval/Actions Max                              0.998292
eval/Actions Min                             -0.998512
eval/Num Paths                                5
eval/Average Returns                       5560.47
eval/env_infos/final/reward_run Mean          6.09701
eval/env_infos/final/reward_run Std           0.854616
eval/env_infos/final/reward_run Max           7.12718
eval/env_infos/final/reward_run Min           5.0278
eval/env_infos/initial/reward_run Mean       -0.302798
eval/env_infos/initial/reward_run Std         0.135903
eval/env_infos/initial/reward_run Max        -0.162448
eval/env_infos/initial/reward_run Min        -0.531229
eval/env_infos/reward_run Mean                5.97778
eval/env_infos/reward_run Std                 1.231
eval/env_infos/reward_run Max                 8.43795
eval/env_infos/reward_run Min                -0.531229
eval/env_infos/final/reward_ctrl Mean        -0.425333
eval/env_infos/final/reward_ctrl Std          0.0726304
eval/env_infos/final/reward_ctrl Max         -0.310999
eval/env_infos/final/reward_ctrl Min         -0.503951
eval/env_infos/initial/reward_ctrl Mean      -0.225775
eval/env_infos/initial/reward_ctrl Std        0.0625773
eval/env_infos/initial/reward_ctrl Max       -0.113742
eval/env_infos/initial/reward_ctrl Min       -0.295826
eval/env_infos/reward_ctrl Mean              -0.417308
eval/env_infos/reward_ctrl Std                0.0868678
eval/env_infos/reward_ctrl Max               -0.113742
eval/env_infos/reward_ctrl Min               -0.581839
time/data storing (s)                         0.00447132
time/evaluation sampling (s)                  2.02418
time/exploration sampling (s)                 0.532745
time/logging (s)                              0.0136271
time/sac training (s)                         7.57074
time/saving (s)                               0.00381057
time/training (s)                             3.5785e-05
time/epoch (s)                               10.1496
time/total (s)                             2218.92
Epoch                                       205
---------------------------------------  ---------------
2021-11-24 01:06:22.404496 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 206 finished
---------------------------------------  ---------------
epoch                                       206
replay_buffer/size                       208000
trainer/num train calls                  207000
trainer/QF1 Loss                              4.6876
trainer/QF2 Loss                              4.71237
trainer/Policy Loss                        -309.476
trainer/Q1 Predictions Mean                 309.564
trainer/Q1 Predictions Std                  104.724
trainer/Q1 Predictions Max                  391.461
trainer/Q1 Predictions Min                   17.054
trainer/Q2 Predictions Mean                 309.883
trainer/Q2 Predictions Std                  104.891
trainer/Q2 Predictions Max                  392.314
trainer/Q2 Predictions Min                   17.762
trainer/Q Targets Mean                      309.364
trainer/Q Targets Std                       104.723
trainer/Q Targets Max                       393.038
trainer/Q Targets Min                        16.0458
trainer/Log Pis Mean                          6.25511
trainer/Log Pis Std                           4.76728
trainer/Log Pis Max                          21.3352
trainer/Log Pis Min                          -6.64264
trainer/policy/mean Mean                      0.0872128
trainer/policy/mean Std                       0.770551
trainer/policy/mean Max                       0.996992
trainer/policy/mean Min                      -0.998581
trainer/policy/normal/std Mean                0.456993
trainer/policy/normal/std Std                 0.152423
trainer/policy/normal/std Max                 0.967053
trainer/policy/normal/std Min                 0.0771006
trainer/policy/normal/log_std Mean           -0.854236
trainer/policy/normal/log_std Std             0.411286
trainer/policy/normal/log_std Max            -0.033502
trainer/policy/normal/log_std Min            -2.56264
trainer/Alpha                                 0.119042
trainer/Alpha Loss                            0.54295
expl/num steps total                     208000
expl/num paths total                        208
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.08222
expl/Rewards Std                              1.18268
expl/Rewards Max                              7.56241
expl/Rewards Min                             -0.524771
expl/Returns Mean                          5082.22
expl/Returns Std                              0
expl/Returns Max                           5082.22
expl/Returns Min                           5082.22
expl/Actions Mean                             0.0644623
expl/Actions Std                              0.81361
expl/Actions Max                              0.99972
expl/Actions Min                             -0.999762
expl/Num Paths                                1
expl/Average Returns                       5082.22
expl/env_infos/final/reward_run Mean          6.37087
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.37087
expl/env_infos/final/reward_run Min           6.37087
expl/env_infos/initial/reward_run Mean       -0.334828
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.334828
expl/env_infos/initial/reward_run Min        -0.334828
expl/env_infos/reward_run Mean                5.48189
expl/env_infos/reward_run Std                 1.17169
expl/env_infos/reward_run Max                 7.97938
expl/env_infos/reward_run Min                -0.334828
expl/env_infos/final/reward_ctrl Mean        -0.446477
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.446477
expl/env_infos/final/reward_ctrl Min         -0.446477
expl/env_infos/initial/reward_ctrl Mean      -0.189943
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.189943
expl/env_infos/initial/reward_ctrl Min       -0.189943
expl/env_infos/reward_ctrl Mean              -0.39967
expl/env_infos/reward_ctrl Std                0.0890627
expl/env_infos/reward_ctrl Max               -0.0604453
expl/env_infos/reward_ctrl Min               -0.581981
eval/num steps total                          1.035e+06
eval/num paths total                       1035
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.27148
eval/Rewards Std                              1.23316
eval/Rewards Max                              8.31725
eval/Rewards Min                             -0.777634
eval/Returns Mean                          5271.48
eval/Returns Std                            113.185
eval/Returns Max                           5420.4
eval/Returns Min                           5097.42
eval/Actions Mean                             0.0711226
eval/Actions Std                              0.831207
eval/Actions Max                              0.997877
eval/Actions Min                             -0.998971
eval/Num Paths                                5
eval/Average Returns                       5271.48
eval/env_infos/final/reward_run Mean          6.2126
eval/env_infos/final/reward_run Std           1.0687
eval/env_infos/final/reward_run Max           7.45965
eval/env_infos/final/reward_run Min           4.55534
eval/env_infos/initial/reward_run Mean       -0.304468
eval/env_infos/initial/reward_run Std         0.19318
eval/env_infos/initial/reward_run Max         0.0735236
eval/env_infos/initial/reward_run Min        -0.462881
eval/env_infos/reward_run Mean                5.68906
eval/env_infos/reward_run Std                 1.21989
eval/env_infos/reward_run Max                 8.81235
eval/env_infos/reward_run Min                -0.462881
eval/env_infos/final/reward_ctrl Mean        -0.460536
eval/env_infos/final/reward_ctrl Std          0.0569975
eval/env_infos/final/reward_ctrl Max         -0.383755
eval/env_infos/final/reward_ctrl Min         -0.527394
eval/env_infos/initial/reward_ctrl Mean      -0.25563
eval/env_infos/initial/reward_ctrl Std        0.0675457
eval/env_infos/initial/reward_ctrl Max       -0.159599
eval/env_infos/initial/reward_ctrl Min       -0.335903
eval/env_infos/reward_ctrl Mean              -0.417578
eval/env_infos/reward_ctrl Std                0.0832007
eval/env_infos/reward_ctrl Max               -0.110716
eval/env_infos/reward_ctrl Min               -0.582535
time/data storing (s)                         0.00456568
time/evaluation sampling (s)                  1.97976
time/exploration sampling (s)                 0.524401
time/logging (s)                              0.0138408
time/sac training (s)                         7.38711
time/saving (s)                               0.00417172
time/training (s)                             3.9738e-05
time/epoch (s)                                9.91389
time/total (s)                             2229.11
Epoch                                       206
---------------------------------------  ---------------
2021-11-24 01:06:32.635770 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 207 finished
---------------------------------------  ---------------
epoch                                       207
replay_buffer/size                       209000
trainer/num train calls                  208000
trainer/QF1 Loss                              8.32858
trainer/QF2 Loss                              7.57266
trainer/Policy Loss                        -318.322
trainer/Q1 Predictions Mean                 318.744
trainer/Q1 Predictions Std                   94.7318
trainer/Q1 Predictions Max                  403.098
trainer/Q1 Predictions Min                   17.2692
trainer/Q2 Predictions Mean                 318.96
trainer/Q2 Predictions Std                   94.9907
trainer/Q2 Predictions Max                  400.911
trainer/Q2 Predictions Min                   18.0652
trainer/Q Targets Mean                      319.285
trainer/Q Targets Std                        95.2563
trainer/Q Targets Max                       403.964
trainer/Q Targets Min                        16.4239
trainer/Log Pis Mean                          6.37036
trainer/Log Pis Std                           4.33918
trainer/Log Pis Max                          16.0514
trainer/Log Pis Min                          -4.31521
trainer/policy/mean Mean                      0.0820377
trainer/policy/mean Std                       0.780452
trainer/policy/mean Max                       0.997597
trainer/policy/mean Min                      -0.998105
trainer/policy/normal/std Mean                0.43865
trainer/policy/normal/std Std                 0.145723
trainer/policy/normal/std Max                 1.12606
trainer/policy/normal/std Min                 0.0762131
trainer/policy/normal/log_std Mean           -0.894255
trainer/policy/normal/log_std Std             0.408072
trainer/policy/normal/log_std Max             0.118726
trainer/policy/normal/log_std Min            -2.57422
trainer/Alpha                                 0.118206
trainer/Alpha Loss                            0.79083
expl/num steps total                     209000
expl/num paths total                        209
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.07762
expl/Rewards Std                              1.18925
expl/Rewards Max                              7.60343
expl/Rewards Min                             -1.09809
expl/Returns Mean                          5077.62
expl/Returns Std                              0
expl/Returns Max                           5077.62
expl/Returns Min                           5077.62
expl/Actions Mean                             0.0764835
expl/Actions Std                              0.818077
expl/Actions Max                              0.999882
expl/Actions Min                             -0.99955
expl/Num Paths                                1
expl/Average Returns                       5077.62
expl/env_infos/final/reward_run Mean          6.4318
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.4318
expl/env_infos/final/reward_run Min           6.4318
expl/env_infos/initial/reward_run Mean       -0.810827
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.810827
expl/env_infos/initial/reward_run Min        -0.810827
expl/env_infos/reward_run Mean                5.48268
expl/env_infos/reward_run Std                 1.182
expl/env_infos/reward_run Max                 8.10278
expl/env_infos/reward_run Min                -0.810827
expl/env_infos/final/reward_ctrl Mean        -0.372636
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.372636
expl/env_infos/final/reward_ctrl Min         -0.372636
expl/env_infos/initial/reward_ctrl Mean      -0.287265
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.287265
expl/env_infos/initial/reward_ctrl Min       -0.287265
expl/env_infos/reward_ctrl Mean              -0.40506
expl/env_infos/reward_ctrl Std                0.0908527
expl/env_infos/reward_ctrl Max               -0.0766526
expl/env_infos/reward_ctrl Min               -0.58099
eval/num steps total                          1.04e+06
eval/num paths total                       1040
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.41435
eval/Rewards Std                              1.22403
eval/Rewards Max                              7.68144
eval/Rewards Min                             -0.909158
eval/Returns Mean                          5414.35
eval/Returns Std                             81.0483
eval/Returns Max                           5489.62
eval/Returns Min                           5266.96
eval/Actions Mean                             0.0661771
eval/Actions Std                              0.833356
eval/Actions Max                              0.999248
eval/Actions Min                             -0.998701
eval/Num Paths                                5
eval/Average Returns                       5414.35
eval/env_infos/final/reward_run Mean          5.96032
eval/env_infos/final/reward_run Std           0.707658
eval/env_infos/final/reward_run Max           7.33241
eval/env_infos/final/reward_run Min           5.32379
eval/env_infos/initial/reward_run Mean       -0.316441
eval/env_infos/initial/reward_run Std         0.192483
eval/env_infos/initial/reward_run Max        -0.162028
eval/env_infos/initial/reward_run Min        -0.678823
eval/env_infos/reward_run Mean                5.83367
eval/env_infos/reward_run Std                 1.20936
eval/env_infos/reward_run Max                 8.13703
eval/env_infos/reward_run Min                -0.678823
eval/env_infos/final/reward_ctrl Mean        -0.448581
eval/env_infos/final/reward_ctrl Std          0.0742508
eval/env_infos/final/reward_ctrl Max         -0.319506
eval/env_infos/final/reward_ctrl Min         -0.5371
eval/env_infos/initial/reward_ctrl Mean      -0.213116
eval/env_infos/initial/reward_ctrl Std        0.0621881
eval/env_infos/initial/reward_ctrl Max       -0.137038
eval/env_infos/initial/reward_ctrl Min       -0.317811
eval/env_infos/reward_ctrl Mean              -0.419317
eval/env_infos/reward_ctrl Std                0.0869715
eval/env_infos/reward_ctrl Max               -0.137038
eval/env_infos/reward_ctrl Min               -0.584287
time/data storing (s)                         0.00451766
time/evaluation sampling (s)                  2.00516
time/exploration sampling (s)                 0.524777
time/logging (s)                              0.0137517
time/sac training (s)                         7.38697
time/saving (s)                               0.0037758
time/training (s)                             3.364e-05
time/epoch (s)                                9.93898
time/total (s)                             2239.33
Epoch                                       207
---------------------------------------  ---------------
2021-11-24 01:06:42.830037 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 208 finished
---------------------------------------  ---------------
epoch                                       208
replay_buffer/size                       210000
trainer/num train calls                  209000
trainer/QF1 Loss                              4.78132
trainer/QF2 Loss                              3.32725
trainer/Policy Loss                        -309.863
trainer/Q1 Predictions Mean                 310.164
trainer/Q1 Predictions Std                  103.501
trainer/Q1 Predictions Max                  394.161
trainer/Q1 Predictions Min                   16.3755
trainer/Q2 Predictions Mean                 310.362
trainer/Q2 Predictions Std                  103.702
trainer/Q2 Predictions Max                  396.244
trainer/Q2 Predictions Min                   16.7413
trainer/Q Targets Mean                      310.268
trainer/Q Targets Std                       103.631
trainer/Q Targets Max                       399.839
trainer/Q Targets Min                        16.1069
trainer/Log Pis Mean                          5.4586
trainer/Log Pis Std                           4.65458
trainer/Log Pis Max                          18.1858
trainer/Log Pis Min                          -5.89482
trainer/policy/mean Mean                      0.0896397
trainer/policy/mean Std                       0.757139
trainer/policy/mean Max                       0.997548
trainer/policy/mean Min                      -0.997591
trainer/policy/normal/std Mean                0.446464
trainer/policy/normal/std Std                 0.148533
trainer/policy/normal/std Max                 0.961988
trainer/policy/normal/std Min                 0.081907
trainer/policy/normal/log_std Mean           -0.87694
trainer/policy/normal/log_std Std             0.40811
trainer/policy/normal/log_std Max            -0.0387533
trainer/policy/normal/log_std Min            -2.50217
trainer/Alpha                                 0.118891
trainer/Alpha Loss                           -1.15293
expl/num steps total                     210000
expl/num paths total                        210
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.25331
expl/Rewards Std                              1.21596
expl/Rewards Max                              7.5339
expl/Rewards Min                             -1.12695
expl/Returns Mean                          5253.31
expl/Returns Std                              0
expl/Returns Max                           5253.31
expl/Returns Min                           5253.31
expl/Actions Mean                             0.0820018
expl/Actions Std                              0.810721
expl/Actions Max                              0.999513
expl/Actions Min                             -0.999482
expl/Num Paths                                1
expl/Average Returns                       5253.31
expl/env_infos/final/reward_run Mean          5.47813
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.47813
expl/env_infos/final/reward_run Min           5.47813
expl/env_infos/initial/reward_run Mean       -0.706341
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.706341
expl/env_infos/initial/reward_run Min        -0.706341
expl/env_infos/reward_run Mean                5.65171
expl/env_infos/reward_run Std                 1.20275
expl/env_infos/reward_run Max                 7.99611
expl/env_infos/reward_run Min                -0.706341
expl/env_infos/final/reward_ctrl Mean        -0.199534
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.199534
expl/env_infos/final/reward_ctrl Min         -0.199534
expl/env_infos/initial/reward_ctrl Mean      -0.420613
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.420613
expl/env_infos/initial/reward_ctrl Min       -0.420613
expl/env_infos/reward_ctrl Mean              -0.398396
expl/env_infos/reward_ctrl Std                0.0891495
expl/env_infos/reward_ctrl Max               -0.115527
expl/env_infos/reward_ctrl Min               -0.579839
eval/num steps total                          1.045e+06
eval/num paths total                       1045
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.49447
eval/Rewards Std                              1.25293
eval/Rewards Max                              8.08732
eval/Rewards Min                             -0.664993
eval/Returns Mean                          5494.47
eval/Returns Std                            133.118
eval/Returns Max                           5673.96
eval/Returns Min                           5302.35
eval/Actions Mean                             0.077049
eval/Actions Std                              0.825105
eval/Actions Max                              0.998316
eval/Actions Min                             -0.998309
eval/Num Paths                                5
eval/Average Returns                       5494.47
eval/env_infos/final/reward_run Mean          5.92924
eval/env_infos/final/reward_run Std           0.948089
eval/env_infos/final/reward_run Max           6.96846
eval/env_infos/final/reward_run Min           4.21445
eval/env_infos/initial/reward_run Mean       -0.213873
eval/env_infos/initial/reward_run Std         0.177454
eval/env_infos/initial/reward_run Max         0.11813
eval/env_infos/initial/reward_run Min        -0.379026
eval/env_infos/reward_run Mean                5.90652
eval/env_infos/reward_run Std                 1.23953
eval/env_infos/reward_run Max                 8.59082
eval/env_infos/reward_run Min                -0.379026
eval/env_infos/final/reward_ctrl Mean        -0.454071
eval/env_infos/final/reward_ctrl Std          0.065781
eval/env_infos/final/reward_ctrl Max         -0.35343
eval/env_infos/final/reward_ctrl Min         -0.526289
eval/env_infos/initial/reward_ctrl Mean      -0.243749
eval/env_infos/initial/reward_ctrl Std        0.0479987
eval/env_infos/initial/reward_ctrl Max       -0.162834
eval/env_infos/initial/reward_ctrl Min       -0.297515
eval/env_infos/reward_ctrl Mean              -0.412041
eval/env_infos/reward_ctrl Std                0.0866966
eval/env_infos/reward_ctrl Max               -0.0980597
eval/env_infos/reward_ctrl Min               -0.582295
time/data storing (s)                         0.00446052
time/evaluation sampling (s)                  1.9817
time/exploration sampling (s)                 0.533601
time/logging (s)                              0.0138058
time/sac training (s)                         7.36681
time/saving (s)                               0.00378836
time/training (s)                             3.4233e-05
time/epoch (s)                                9.90421
time/total (s)                             2249.51
Epoch                                       208
---------------------------------------  ---------------
2021-11-24 01:06:53.292156 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 209 finished
---------------------------------------  ---------------
epoch                                       209
replay_buffer/size                       211000
trainer/num train calls                  210000
trainer/QF1 Loss                             12.6825
trainer/QF2 Loss                             10.856
trainer/Policy Loss                        -318.141
trainer/Q1 Predictions Mean                 318.896
trainer/Q1 Predictions Std                   89.4123
trainer/Q1 Predictions Max                  396.24
trainer/Q1 Predictions Min                   15.6656
trainer/Q2 Predictions Mean                 318.19
trainer/Q2 Predictions Std                   89.2957
trainer/Q2 Predictions Max                  397.228
trainer/Q2 Predictions Min                   16.7969
trainer/Q Targets Mean                      319.521
trainer/Q Targets Std                        89.9344
trainer/Q Targets Max                       394.868
trainer/Q Targets Min                        16.9289
trainer/Log Pis Mean                          6.44026
trainer/Log Pis Std                           4.63176
trainer/Log Pis Max                          19.1498
trainer/Log Pis Min                          -5.21932
trainer/policy/mean Mean                      0.0872143
trainer/policy/mean Std                       0.782769
trainer/policy/mean Max                       0.999645
trainer/policy/mean Min                      -0.998216
trainer/policy/normal/std Mean                0.447966
trainer/policy/normal/std Std                 0.145051
trainer/policy/normal/std Max                 1.01297
trainer/policy/normal/std Min                 0.0718176
trainer/policy/normal/log_std Mean           -0.868881
trainer/policy/normal/log_std Std             0.393217
trainer/policy/normal/log_std Max             0.0128858
trainer/policy/normal/log_std Min            -2.63363
trainer/Alpha                                 0.119104
trainer/Alpha Loss                            0.936763
expl/num steps total                     211000
expl/num paths total                        211
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33067
expl/Rewards Std                              1.21347
expl/Rewards Max                              7.54203
expl/Rewards Min                             -0.448681
expl/Returns Mean                          5330.67
expl/Returns Std                              0
expl/Returns Max                           5330.67
expl/Returns Min                           5330.67
expl/Actions Mean                             0.0840695
expl/Actions Std                              0.810771
expl/Actions Max                              0.999417
expl/Actions Min                             -0.999539
expl/Num Paths                                1
expl/Average Returns                       5330.67
expl/env_infos/final/reward_run Mean          4.03541
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.03541
expl/env_infos/final/reward_run Min           4.03541
expl/env_infos/initial/reward_run Mean       -0.218478
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.218478
expl/env_infos/initial/reward_run Min        -0.218478
expl/env_infos/reward_run Mean                5.72932
expl/env_infos/reward_run Std                 1.20532
expl/env_infos/reward_run Max                 7.98691
expl/env_infos/reward_run Min                -0.218478
expl/env_infos/final/reward_ctrl Mean        -0.531053
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.531053
expl/env_infos/final/reward_ctrl Min         -0.531053
expl/env_infos/initial/reward_ctrl Mean      -0.230203
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.230203
expl/env_infos/initial/reward_ctrl Min       -0.230203
expl/env_infos/reward_ctrl Mean              -0.398651
expl/env_infos/reward_ctrl Std                0.0879706
expl/env_infos/reward_ctrl Max               -0.101357
expl/env_infos/reward_ctrl Min               -0.586106
eval/num steps total                          1.05e+06
eval/num paths total                       1050
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.52225
eval/Rewards Std                              1.26706
eval/Rewards Max                              8.02856
eval/Rewards Min                             -0.802503
eval/Returns Mean                          5522.25
eval/Returns Std                             49.5224
eval/Returns Max                           5578.22
eval/Returns Min                           5432.23
eval/Actions Mean                             0.0947929
eval/Actions Std                              0.821732
eval/Actions Max                              0.999053
eval/Actions Min                             -0.998095
eval/Num Paths                                5
eval/Average Returns                       5522.25
eval/env_infos/final/reward_run Mean          6.63407
eval/env_infos/final/reward_run Std           1.16882
eval/env_infos/final/reward_run Max           7.93909
eval/env_infos/final/reward_run Min           5.00796
eval/env_infos/initial/reward_run Mean       -0.284848
eval/env_infos/initial/reward_run Std         0.144384
eval/env_infos/initial/reward_run Max        -0.0513941
eval/env_infos/initial/reward_run Min        -0.470693
eval/env_infos/reward_run Mean                5.93279
eval/env_infos/reward_run Std                 1.25292
eval/env_infos/reward_run Max                 8.5333
eval/env_infos/reward_run Min                -0.470693
eval/env_infos/final/reward_ctrl Mean        -0.399513
eval/env_infos/final/reward_ctrl Std          0.0695354
eval/env_infos/final/reward_ctrl Max         -0.277965
eval/env_infos/final/reward_ctrl Min         -0.485204
eval/env_infos/initial/reward_ctrl Mean      -0.284158
eval/env_infos/initial/reward_ctrl Std        0.0498206
eval/env_infos/initial/reward_ctrl Max       -0.204084
eval/env_infos/initial/reward_ctrl Min       -0.33181
eval/env_infos/reward_ctrl Mean              -0.410538
eval/env_infos/reward_ctrl Std                0.0875574
eval/env_infos/reward_ctrl Max               -0.127543
eval/env_infos/reward_ctrl Min               -0.584028
time/data storing (s)                         0.00449346
time/evaluation sampling (s)                  1.9904
time/exploration sampling (s)                 0.521012
time/logging (s)                              0.0145958
time/sac training (s)                         7.61123
time/saving (s)                               0.00390832
time/training (s)                             4.7188e-05
time/epoch (s)                               10.1457
time/total (s)                             2259.96
Epoch                                       209
---------------------------------------  ---------------
2021-11-24 01:07:03.491777 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 210 finished
---------------------------------------  ---------------
epoch                                       210
replay_buffer/size                       212000
trainer/num train calls                  211000
trainer/QF1 Loss                              5.28125
trainer/QF2 Loss                              5.37784
trainer/Policy Loss                        -321.122
trainer/Q1 Predictions Mean                 321.148
trainer/Q1 Predictions Std                   95.6374
trainer/Q1 Predictions Max                  395.111
trainer/Q1 Predictions Min                   17.4375
trainer/Q2 Predictions Mean                 321.738
trainer/Q2 Predictions Std                   95.643
trainer/Q2 Predictions Max                  393.906
trainer/Q2 Predictions Min                   17.1324
trainer/Q Targets Mean                      321.157
trainer/Q Targets Std                        95.6233
trainer/Q Targets Max                       394.121
trainer/Q Targets Min                        15.8845
trainer/Log Pis Mean                          6.39499
trainer/Log Pis Std                           4.69578
trainer/Log Pis Max                          19.2966
trainer/Log Pis Min                          -5.07295
trainer/policy/mean Mean                      0.0992224
trainer/policy/mean Std                       0.775044
trainer/policy/mean Max                       0.997696
trainer/policy/mean Min                      -0.999097
trainer/policy/normal/std Mean                0.447149
trainer/policy/normal/std Std                 0.137035
trainer/policy/normal/std Max                 0.812102
trainer/policy/normal/std Min                 0.0780747
trainer/policy/normal/log_std Mean           -0.86524
trainer/policy/normal/log_std Std             0.379052
trainer/policy/normal/log_std Max            -0.208129
trainer/policy/normal/log_std Min            -2.55009
trainer/Alpha                                 0.118124
trainer/Alpha Loss                            0.843698
expl/num steps total                     212000
expl/num paths total                        212
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.92786
expl/Rewards Std                              1.18681
expl/Rewards Max                              7.34047
expl/Rewards Min                             -0.372455
expl/Returns Mean                          4927.86
expl/Returns Std                              0
expl/Returns Max                           4927.86
expl/Returns Min                           4927.86
expl/Actions Mean                             0.130843
expl/Actions Std                              0.799094
expl/Actions Max                              0.999856
expl/Actions Min                             -0.999622
expl/Num Paths                                1
expl/Average Returns                       4927.86
expl/env_infos/final/reward_run Mean          5.6192
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.6192
expl/env_infos/final/reward_run Min           5.6192
expl/env_infos/initial/reward_run Mean       -0.228078
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.228078
expl/env_infos/initial/reward_run Min        -0.228078
expl/env_infos/reward_run Mean                5.32126
expl/env_infos/reward_run Std                 1.17121
expl/env_infos/reward_run Max                 7.76289
expl/env_infos/reward_run Min                -0.228078
expl/env_infos/final/reward_ctrl Mean        -0.457542
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.457542
expl/env_infos/final/reward_ctrl Min         -0.457542
expl/env_infos/initial/reward_ctrl Mean      -0.144376
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.144376
expl/env_infos/initial/reward_ctrl Min       -0.144376
expl/env_infos/reward_ctrl Mean              -0.393403
expl/env_infos/reward_ctrl Std                0.0903103
expl/env_infos/reward_ctrl Max               -0.0353667
expl/env_infos/reward_ctrl Min               -0.580763
eval/num steps total                          1.055e+06
eval/num paths total                       1055
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.23862
eval/Rewards Std                              1.2416
eval/Rewards Max                              7.93521
eval/Rewards Min                             -0.965939
eval/Returns Mean                          5238.62
eval/Returns Std                             88.5994
eval/Returns Max                           5339.97
eval/Returns Min                           5086.38
eval/Actions Mean                             0.133526
eval/Actions Std                              0.813386
eval/Actions Max                              0.997665
eval/Actions Min                             -0.997177
eval/Num Paths                                5
eval/Average Returns                       5238.62
eval/env_infos/final/reward_run Mean          5.71141
eval/env_infos/final/reward_run Std           0.8089
eval/env_infos/final/reward_run Max           7.32188
eval/env_infos/final/reward_run Min           5.18959
eval/env_infos/initial/reward_run Mean       -0.375051
eval/env_infos/initial/reward_run Std         0.157049
eval/env_infos/initial/reward_run Max        -0.175469
eval/env_infos/initial/reward_run Min        -0.658175
eval/env_infos/reward_run Mean                5.64627
eval/env_infos/reward_run Std                 1.2231
eval/env_infos/reward_run Max                 8.42286
eval/env_infos/reward_run Min                -0.658175
eval/env_infos/final/reward_ctrl Mean        -0.457665
eval/env_infos/final/reward_ctrl Std          0.0496355
eval/env_infos/final/reward_ctrl Max         -0.3706
eval/env_infos/final/reward_ctrl Min         -0.505208
eval/env_infos/initial/reward_ctrl Mean      -0.251359
eval/env_infos/initial/reward_ctrl Std        0.04149
eval/env_infos/initial/reward_ctrl Max       -0.201663
eval/env_infos/initial/reward_ctrl Min       -0.307763
eval/env_infos/reward_ctrl Mean              -0.407656
eval/env_infos/reward_ctrl Std                0.084373
eval/env_infos/reward_ctrl Max               -0.135626
eval/env_infos/reward_ctrl Min               -0.578576
time/data storing (s)                         0.00452892
time/evaluation sampling (s)                  1.97687
time/exploration sampling (s)                 0.519163
time/logging (s)                              0.0137345
time/sac training (s)                         7.39033
time/saving (s)                               0.00376093
time/training (s)                             3.3702e-05
time/epoch (s)                                9.90841
time/total (s)                             2270.15
Epoch                                       210
---------------------------------------  ---------------
2021-11-24 01:07:13.688719 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 211 finished
---------------------------------------  ---------------
epoch                                       211
replay_buffer/size                       213000
trainer/num train calls                  212000
trainer/QF1 Loss                              6.27459
trainer/QF2 Loss                              6.37513
trainer/Policy Loss                        -323.825
trainer/Q1 Predictions Mean                 324.395
trainer/Q1 Predictions Std                   89.1237
trainer/Q1 Predictions Max                  399.854
trainer/Q1 Predictions Min                   18.9961
trainer/Q2 Predictions Mean                 324.365
trainer/Q2 Predictions Std                   89.2892
trainer/Q2 Predictions Max                  400.851
trainer/Q2 Predictions Min                   18.4057
trainer/Q Targets Mean                      324.625
trainer/Q Targets Std                        89.266
trainer/Q Targets Max                       398.204
trainer/Q Targets Min                        18.13
trainer/Log Pis Mean                          6.08318
trainer/Log Pis Std                           4.52585
trainer/Log Pis Max                          17.2298
trainer/Log Pis Min                          -7.30456
trainer/policy/mean Mean                      0.0633767
trainer/policy/mean Std                       0.776894
trainer/policy/mean Max                       0.997782
trainer/policy/mean Min                      -0.996822
trainer/policy/normal/std Mean                0.444915
trainer/policy/normal/std Std                 0.138636
trainer/policy/normal/std Max                 0.827895
trainer/policy/normal/std Min                 0.0812896
trainer/policy/normal/log_std Mean           -0.873184
trainer/policy/normal/log_std Std             0.389093
trainer/policy/normal/log_std Max            -0.188868
trainer/policy/normal/log_std Min            -2.50974
trainer/Alpha                                 0.122407
trainer/Alpha Loss                            0.174709
expl/num steps total                     213000
expl/num paths total                        213
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.13628
expl/Rewards Std                              1.18977
expl/Rewards Max                              7.68076
expl/Rewards Min                             -0.816761
expl/Returns Mean                          5136.28
expl/Returns Std                              0
expl/Returns Max                           5136.28
expl/Returns Min                           5136.28
expl/Actions Mean                             0.0937553
expl/Actions Std                              0.810717
expl/Actions Max                              0.999406
expl/Actions Min                             -0.99968
expl/Num Paths                                1
expl/Average Returns                       5136.28
expl/env_infos/final/reward_run Mean          5.65151
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.65151
expl/env_infos/final/reward_run Min           5.65151
expl/env_infos/initial/reward_run Mean       -0.467721
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.467721
expl/env_infos/initial/reward_run Min        -0.467721
expl/env_infos/reward_run Mean                5.53591
expl/env_infos/reward_run Std                 1.18096
expl/env_infos/reward_run Max                 8.15617
expl/env_infos/reward_run Min                -0.467721
expl/env_infos/final/reward_ctrl Mean        -0.442662
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.442662
expl/env_infos/final/reward_ctrl Min         -0.442662
expl/env_infos/initial/reward_ctrl Mean      -0.34904
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.34904
expl/env_infos/initial/reward_ctrl Min       -0.34904
expl/env_infos/reward_ctrl Mean              -0.399631
expl/env_infos/reward_ctrl Std                0.0919651
expl/env_infos/reward_ctrl Max               -0.0855672
expl/env_infos/reward_ctrl Min               -0.582858
eval/num steps total                          1.06e+06
eval/num paths total                       1060
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.4365
eval/Rewards Std                              1.27487
eval/Rewards Max                              7.99606
eval/Rewards Min                             -0.516935
eval/Returns Mean                          5436.5
eval/Returns Std                             74.411
eval/Returns Max                           5575.67
eval/Returns Min                           5357.14
eval/Actions Mean                             0.095803
eval/Actions Std                              0.823655
eval/Actions Max                              0.999242
eval/Actions Min                             -0.998521
eval/Num Paths                                5
eval/Average Returns                       5436.5
eval/env_infos/final/reward_run Mean          7.02487
eval/env_infos/final/reward_run Std           0.885664
eval/env_infos/final/reward_run Max           7.89423
eval/env_infos/final/reward_run Min           5.40128
eval/env_infos/initial/reward_run Mean       -0.168392
eval/env_infos/initial/reward_run Std         0.102043
eval/env_infos/initial/reward_run Max         0.0167669
eval/env_infos/initial/reward_run Min        -0.266058
eval/env_infos/reward_run Mean                5.84905
eval/env_infos/reward_run Std                 1.26001
eval/env_infos/reward_run Max                 8.48659
eval/env_infos/reward_run Min                -0.266058
eval/env_infos/final/reward_ctrl Mean        -0.468593
eval/env_infos/final/reward_ctrl Std          0.043362
eval/env_infos/final/reward_ctrl Max         -0.411644
eval/env_infos/final/reward_ctrl Min         -0.534141
eval/env_infos/initial/reward_ctrl Mean      -0.220335
eval/env_infos/initial/reward_ctrl Std        0.0589384
eval/env_infos/initial/reward_ctrl Max       -0.128487
eval/env_infos/initial/reward_ctrl Min       -0.306375
eval/env_infos/reward_ctrl Mean              -0.412552
eval/env_infos/reward_ctrl Std                0.0883635
eval/env_infos/reward_ctrl Max               -0.12831
eval/env_infos/reward_ctrl Min               -0.586115
time/data storing (s)                         0.00449521
time/evaluation sampling (s)                  1.99218
time/exploration sampling (s)                 0.516445
time/logging (s)                              0.0138201
time/sac training (s)                         7.37663
time/saving (s)                               0.00381054
time/training (s)                             3.3248e-05
time/epoch (s)                                9.90741
time/total (s)                             2280.33
Epoch                                       211
---------------------------------------  ---------------
2021-11-24 01:07:23.910352 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 212 finished
---------------------------------------  ---------------
epoch                                       212
replay_buffer/size                       214000
trainer/num train calls                  213000
trainer/QF1 Loss                             10.2889
trainer/QF2 Loss                              8.16789
trainer/Policy Loss                        -310.35
trainer/Q1 Predictions Mean                 310.666
trainer/Q1 Predictions Std                  107.225
trainer/Q1 Predictions Max                  396.758
trainer/Q1 Predictions Min                   16.3433
trainer/Q2 Predictions Mean                 310.978
trainer/Q2 Predictions Std                  107.219
trainer/Q2 Predictions Max                  395.614
trainer/Q2 Predictions Min                   16.3347
trainer/Q Targets Mean                      310.691
trainer/Q Targets Std                       107.364
trainer/Q Targets Max                       401.361
trainer/Q Targets Min                        16.3346
trainer/Log Pis Mean                          5.91628
trainer/Log Pis Std                           4.7741
trainer/Log Pis Max                          22.0533
trainer/Log Pis Min                          -5.52668
trainer/policy/mean Mean                      0.0720371
trainer/policy/mean Std                       0.759895
trainer/policy/mean Max                       0.999543
trainer/policy/mean Min                      -0.999278
trainer/policy/normal/std Mean                0.453528
trainer/policy/normal/std Std                 0.149731
trainer/policy/normal/std Max                 0.911439
trainer/policy/normal/std Min                 0.0747438
trainer/policy/normal/log_std Mean           -0.858372
trainer/policy/normal/log_std Std             0.397899
trainer/policy/normal/log_std Max            -0.0927306
trainer/policy/normal/log_std Min            -2.59369
trainer/Alpha                                 0.118726
trainer/Alpha Loss                           -0.178394
expl/num steps total                     214000
expl/num paths total                        214
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.29701
expl/Rewards Std                              1.19829
expl/Rewards Max                              7.60588
expl/Rewards Min                             -0.530816
expl/Returns Mean                          5297.01
expl/Returns Std                              0
expl/Returns Max                           5297.01
expl/Returns Min                           5297.01
expl/Actions Mean                             0.0893062
expl/Actions Std                              0.813268
expl/Actions Max                              0.999549
expl/Actions Min                             -0.999778
expl/Num Paths                                1
expl/Average Returns                       5297.01
expl/env_infos/final/reward_run Mean          4.85887
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.85887
expl/env_infos/final/reward_run Min           4.85887
expl/env_infos/initial/reward_run Mean       -0.209336
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.209336
expl/env_infos/initial/reward_run Min        -0.209336
expl/env_infos/reward_run Mean                5.69863
expl/env_infos/reward_run Std                 1.19033
expl/env_infos/reward_run Max                 8.13397
expl/env_infos/reward_run Min                -0.209336
expl/env_infos/final/reward_ctrl Mean        -0.470516
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.470516
expl/env_infos/final/reward_ctrl Min         -0.470516
expl/env_infos/initial/reward_ctrl Mean      -0.242232
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.242232
expl/env_infos/initial/reward_ctrl Min       -0.242232
expl/env_infos/reward_ctrl Mean              -0.401628
expl/env_infos/reward_ctrl Std                0.0887709
expl/env_infos/reward_ctrl Max               -0.0816588
expl/env_infos/reward_ctrl Min               -0.579217
eval/num steps total                          1.065e+06
eval/num paths total                       1065
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.49245
eval/Rewards Std                              1.24908
eval/Rewards Max                              7.85269
eval/Rewards Min                             -0.76286
eval/Returns Mean                          5492.45
eval/Returns Std                             94.8507
eval/Returns Max                           5596.14
eval/Returns Min                           5353.54
eval/Actions Mean                             0.0939953
eval/Actions Std                              0.82594
eval/Actions Max                              0.997814
eval/Actions Min                             -0.99809
eval/Num Paths                                5
eval/Average Returns                       5492.45
eval/env_infos/final/reward_run Mean          5.97579
eval/env_infos/final/reward_run Std           0.942068
eval/env_infos/final/reward_run Max           7.32728
eval/env_infos/final/reward_run Min           4.69162
eval/env_infos/initial/reward_run Mean       -0.259757
eval/env_infos/initial/reward_run Std         0.109867
eval/env_infos/initial/reward_run Max        -0.0805809
eval/env_infos/initial/reward_run Min        -0.385725
eval/env_infos/reward_run Mean                5.90705
eval/env_infos/reward_run Std                 1.23643
eval/env_infos/reward_run Max                 8.32384
eval/env_infos/reward_run Min                -0.385725
eval/env_infos/final/reward_ctrl Mean        -0.386745
eval/env_infos/final/reward_ctrl Std          0.0528635
eval/env_infos/final/reward_ctrl Max         -0.316777
eval/env_infos/final/reward_ctrl Min         -0.447333
eval/env_infos/initial/reward_ctrl Mean      -0.263673
eval/env_infos/initial/reward_ctrl Std        0.0645885
eval/env_infos/initial/reward_ctrl Max       -0.189028
eval/env_infos/initial/reward_ctrl Min       -0.36374
eval/env_infos/reward_ctrl Mean              -0.414607
eval/env_infos/reward_ctrl Std                0.0853942
eval/env_infos/reward_ctrl Max               -0.156155
eval/env_infos/reward_ctrl Min               -0.583182
time/data storing (s)                         0.00447528
time/evaluation sampling (s)                  1.99762
time/exploration sampling (s)                 0.527038
time/logging (s)                              0.0137747
time/sac training (s)                         7.38352
time/saving (s)                               0.00377038
time/training (s)                             3.412e-05
time/epoch (s)                                9.93023
time/total (s)                             2290.54
Epoch                                       212
---------------------------------------  ---------------
2021-11-24 01:07:34.143133 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 213 finished
---------------------------------------  ---------------
epoch                                       213
replay_buffer/size                       215000
trainer/num train calls                  214000
trainer/QF1 Loss                              7.41666
trainer/QF2 Loss                              5.73926
trainer/Policy Loss                        -320.832
trainer/Q1 Predictions Mean                 320.893
trainer/Q1 Predictions Std                   95.115
trainer/Q1 Predictions Max                  395.473
trainer/Q1 Predictions Min                   15.5357
trainer/Q2 Predictions Mean                 321.306
trainer/Q2 Predictions Std                   95.2755
trainer/Q2 Predictions Max                  397.199
trainer/Q2 Predictions Min                   15.0168
trainer/Q Targets Mean                      320.655
trainer/Q Targets Std                        95.1263
trainer/Q Targets Max                       400.456
trainer/Q Targets Min                        14.7373
trainer/Log Pis Mean                          5.81076
trainer/Log Pis Std                           4.684
trainer/Log Pis Max                          16.9134
trainer/Log Pis Min                          -6.72405
trainer/policy/mean Mean                      0.101293
trainer/policy/mean Std                       0.760053
trainer/policy/mean Max                       0.997871
trainer/policy/mean Min                      -0.996671
trainer/policy/normal/std Mean                0.443173
trainer/policy/normal/std Std                 0.148884
trainer/policy/normal/std Max                 1.08816
trainer/policy/normal/std Min                 0.0817564
trainer/policy/normal/log_std Mean           -0.884659
trainer/policy/normal/log_std Std             0.408114
trainer/policy/normal/log_std Max             0.0844859
trainer/policy/normal/log_std Min            -2.50401
trainer/Alpha                                 0.119551
trainer/Alpha Loss                           -0.401946
expl/num steps total                     215000
expl/num paths total                        215
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.10667
expl/Rewards Std                              1.21118
expl/Rewards Max                              7.74738
expl/Rewards Min                             -0.447027
expl/Returns Mean                          5106.67
expl/Returns Std                              0
expl/Returns Max                           5106.67
expl/Returns Min                           5106.67
expl/Actions Mean                             0.0862919
expl/Actions Std                              0.812367
expl/Actions Max                              0.999738
expl/Actions Min                             -0.999595
expl/Num Paths                                1
expl/Average Returns                       5106.67
expl/env_infos/final/reward_run Mean          6.6515
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.6515
expl/env_infos/final/reward_run Min           6.6515
expl/env_infos/initial/reward_run Mean       -0.188488
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.188488
expl/env_infos/initial/reward_run Min        -0.188488
expl/env_infos/reward_run Mean                5.5071
expl/env_infos/reward_run Std                 1.1951
expl/env_infos/reward_run Max                 8.19788
expl/env_infos/reward_run Min                -0.188488
expl/env_infos/final/reward_ctrl Mean        -0.429198
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.429198
expl/env_infos/final/reward_ctrl Min         -0.429198
expl/env_infos/initial/reward_ctrl Mean      -0.228494
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.228494
expl/env_infos/initial/reward_ctrl Min       -0.228494
expl/env_infos/reward_ctrl Mean              -0.400432
expl/env_infos/reward_ctrl Std                0.092243
expl/env_infos/reward_ctrl Max               -0.116779
expl/env_infos/reward_ctrl Min               -0.585538
eval/num steps total                          1.07e+06
eval/num paths total                       1070
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.38396
eval/Rewards Std                              1.23719
eval/Rewards Max                              8.06597
eval/Rewards Min                             -0.514144
eval/Returns Mean                          5383.96
eval/Returns Std                             70.8697
eval/Returns Max                           5442.41
eval/Returns Min                           5247.57
eval/Actions Mean                             0.0927778
eval/Actions Std                              0.826954
eval/Actions Max                              0.99943
eval/Actions Min                             -0.998781
eval/Num Paths                                5
eval/Average Returns                       5383.96
eval/env_infos/final/reward_run Mean          6.24621
eval/env_infos/final/reward_run Std           0.456342
eval/env_infos/final/reward_run Max           6.82095
eval/env_infos/final/reward_run Min           5.64394
eval/env_infos/initial/reward_run Mean       -0.136124
eval/env_infos/initial/reward_run Std         0.151902
eval/env_infos/initial/reward_run Max         0.0950391
eval/env_infos/initial/reward_run Min        -0.289682
eval/env_infos/reward_run Mean                5.79943
eval/env_infos/reward_run Std                 1.21817
eval/env_infos/reward_run Max                 8.57432
eval/env_infos/reward_run Min                -0.289682
eval/env_infos/final/reward_ctrl Mean        -0.477567
eval/env_infos/final/reward_ctrl Std          0.0397083
eval/env_infos/final/reward_ctrl Max         -0.421635
eval/env_infos/final/reward_ctrl Min         -0.545381
eval/env_infos/initial/reward_ctrl Mean      -0.218473
eval/env_infos/initial/reward_ctrl Std        0.0193841
eval/env_infos/initial/reward_ctrl Max       -0.181651
eval/env_infos/initial/reward_ctrl Min       -0.237875
eval/env_infos/reward_ctrl Mean              -0.415476
eval/env_infos/reward_ctrl Std                0.0922971
eval/env_infos/reward_ctrl Max               -0.106867
eval/env_infos/reward_ctrl Min               -0.583661
time/data storing (s)                         0.00450492
time/evaluation sampling (s)                  1.97706
time/exploration sampling (s)                 0.523885
time/logging (s)                              0.0135646
time/sac training (s)                         7.42013
time/saving (s)                               0.00376786
time/training (s)                             3.5477e-05
time/epoch (s)                                9.94294
time/total (s)                             2300.76
Epoch                                       213
---------------------------------------  ---------------
2021-11-24 01:07:44.514962 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 214 finished
---------------------------------------  ---------------
epoch                                       214
replay_buffer/size                       216000
trainer/num train calls                  215000
trainer/QF1 Loss                              9.38817
trainer/QF2 Loss                             10.31
trainer/Policy Loss                        -316.8
trainer/Q1 Predictions Mean                 317.227
trainer/Q1 Predictions Std                  102.709
trainer/Q1 Predictions Max                  395.715
trainer/Q1 Predictions Min                   15.4603
trainer/Q2 Predictions Mean                 317.221
trainer/Q2 Predictions Std                  102.691
trainer/Q2 Predictions Max                  394.359
trainer/Q2 Predictions Min                   16.9923
trainer/Q Targets Mean                      317.229
trainer/Q Targets Std                       103.011
trainer/Q Targets Max                       396.255
trainer/Q Targets Min                        15.562
trainer/Log Pis Mean                          5.80902
trainer/Log Pis Std                           4.61643
trainer/Log Pis Max                          18.4271
trainer/Log Pis Min                          -4.68096
trainer/policy/mean Mean                      0.0263487
trainer/policy/mean Std                       0.773882
trainer/policy/mean Max                       0.997595
trainer/policy/mean Min                      -0.999196
trainer/policy/normal/std Mean                0.452638
trainer/policy/normal/std Std                 0.147655
trainer/policy/normal/std Max                 1.01114
trainer/policy/normal/std Min                 0.0809511
trainer/policy/normal/log_std Mean           -0.860278
trainer/policy/normal/log_std Std             0.399642
trainer/policy/normal/log_std Max             0.0110737
trainer/policy/normal/log_std Min            -2.51391
trainer/Alpha                                 0.121243
trainer/Alpha Loss                           -0.402965
expl/num steps total                     216000
expl/num paths total                        216
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.22762
expl/Rewards Std                              1.1964
expl/Rewards Max                              7.74322
expl/Rewards Min                             -0.798596
expl/Returns Mean                          5227.62
expl/Returns Std                              0
expl/Returns Max                           5227.62
expl/Returns Min                           5227.62
expl/Actions Mean                             0.0600404
expl/Actions Std                              0.812759
expl/Actions Max                              0.9993
expl/Actions Min                             -0.999445
expl/Num Paths                                1
expl/Average Returns                       5227.62
expl/env_infos/final/reward_run Mean          6.62199
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.62199
expl/env_infos/final/reward_run Min           6.62199
expl/env_infos/initial/reward_run Mean       -0.500278
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.500278
expl/env_infos/initial/reward_run Min        -0.500278
expl/env_infos/reward_run Mean                5.62613
expl/env_infos/reward_run Std                 1.18516
expl/env_infos/reward_run Max                 8.20432
expl/env_infos/reward_run Min                -0.500278
expl/env_infos/final/reward_ctrl Mean        -0.449841
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.449841
expl/env_infos/final/reward_ctrl Min         -0.449841
expl/env_infos/initial/reward_ctrl Mean      -0.298318
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.298318
expl/env_infos/initial/reward_ctrl Min       -0.298318
expl/env_infos/reward_ctrl Mean              -0.39851
expl/env_infos/reward_ctrl Std                0.0935853
expl/env_infos/reward_ctrl Max               -0.0871819
expl/env_infos/reward_ctrl Min               -0.582005
eval/num steps total                          1.075e+06
eval/num paths total                       1075
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.44855
eval/Rewards Std                              1.22725
eval/Rewards Max                              7.80159
eval/Rewards Min                             -0.793252
eval/Returns Mean                          5448.55
eval/Returns Std                             58.739
eval/Returns Max                           5504.86
eval/Returns Min                           5341.51
eval/Actions Mean                             0.0573234
eval/Actions Std                              0.830524
eval/Actions Max                              0.99879
eval/Actions Min                             -0.997875
eval/Num Paths                                5
eval/Average Returns                       5448.55
eval/env_infos/final/reward_run Mean          5.6643
eval/env_infos/final/reward_run Std           0.549661
eval/env_infos/final/reward_run Max           6.21155
eval/env_infos/final/reward_run Min           4.70506
eval/env_infos/initial/reward_run Mean       -0.33646
eval/env_infos/initial/reward_run Std         0.107917
eval/env_infos/initial/reward_run Max        -0.178097
eval/env_infos/initial/reward_run Min        -0.467542
eval/env_infos/reward_run Mean                5.86439
eval/env_infos/reward_run Std                 1.21068
eval/env_infos/reward_run Max                 8.30895
eval/env_infos/reward_run Min                -0.467542
eval/env_infos/final/reward_ctrl Mean        -0.451198
eval/env_infos/final/reward_ctrl Std          0.0672087
eval/env_infos/final/reward_ctrl Max         -0.357612
eval/env_infos/final/reward_ctrl Min         -0.562613
eval/env_infos/initial/reward_ctrl Mean      -0.251666
eval/env_infos/initial/reward_ctrl Std        0.0597164
eval/env_infos/initial/reward_ctrl Max       -0.203609
eval/env_infos/initial/reward_ctrl Min       -0.368542
eval/env_infos/reward_ctrl Mean              -0.415833
eval/env_infos/reward_ctrl Std                0.0932732
eval/env_infos/reward_ctrl Max               -0.102778
eval/env_infos/reward_ctrl Min               -0.577564
time/data storing (s)                         0.00442887
time/evaluation sampling (s)                  1.97783
time/exploration sampling (s)                 0.511377
time/logging (s)                              0.0138724
time/sac training (s)                         7.56527
time/saving (s)                               0.00379639
time/training (s)                             3.8355e-05
time/epoch (s)                               10.0766
time/total (s)                             2311.12
Epoch                                       214
---------------------------------------  ---------------
2021-11-24 01:07:54.812840 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 215 finished
---------------------------------------  ---------------
epoch                                       215
replay_buffer/size                       217000
trainer/num train calls                  216000
trainer/QF1 Loss                              9.51316
trainer/QF2 Loss                             10.4943
trainer/Policy Loss                        -310.52
trainer/Q1 Predictions Mean                 310.502
trainer/Q1 Predictions Std                  103.981
trainer/Q1 Predictions Max                  402.434
trainer/Q1 Predictions Min                   15.9957
trainer/Q2 Predictions Mean                 310.554
trainer/Q2 Predictions Std                  103.978
trainer/Q2 Predictions Max                  402.566
trainer/Q2 Predictions Min                   17.0975
trainer/Q Targets Mean                      310.955
trainer/Q Targets Std                       103.852
trainer/Q Targets Max                       401.666
trainer/Q Targets Min                        16.0497
trainer/Log Pis Mean                          5.81068
trainer/Log Pis Std                           4.5756
trainer/Log Pis Max                          15.9254
trainer/Log Pis Min                          -5.81885
trainer/policy/mean Mean                      0.072348
trainer/policy/mean Std                       0.765704
trainer/policy/mean Max                       0.997893
trainer/policy/mean Min                      -0.997071
trainer/policy/normal/std Mean                0.445387
trainer/policy/normal/std Std                 0.149006
trainer/policy/normal/std Max                 1.09743
trainer/policy/normal/std Min                 0.079371
trainer/policy/normal/log_std Mean           -0.877879
trainer/policy/normal/log_std Std             0.402114
trainer/policy/normal/log_std Max             0.0929676
trainer/policy/normal/log_std Min            -2.53362
trainer/Alpha                                 0.118378
trainer/Alpha Loss                           -0.403984
expl/num steps total                     217000
expl/num paths total                        217
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.3064
expl/Rewards Std                              1.254
expl/Rewards Max                              7.58063
expl/Rewards Min                             -0.789588
expl/Returns Mean                          5306.4
expl/Returns Std                              0
expl/Returns Max                           5306.4
expl/Returns Min                           5306.4
expl/Actions Mean                             0.0773204
expl/Actions Std                              0.805298
expl/Actions Max                              0.999761
expl/Actions Min                             -0.999242
expl/Num Paths                                1
expl/Average Returns                       5306.4
expl/env_infos/final/reward_run Mean          4.13727
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.13727
expl/env_infos/final/reward_run Min           4.13727
expl/env_infos/initial/reward_run Mean       -0.559419
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.559419
expl/env_infos/initial/reward_run Min        -0.559419
expl/env_infos/reward_run Mean                5.69909
expl/env_infos/reward_run Std                 1.24852
expl/env_infos/reward_run Max                 8.03298
expl/env_infos/reward_run Min                -0.559419
expl/env_infos/final/reward_ctrl Mean        -0.432549
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.432549
expl/env_infos/final/reward_ctrl Min         -0.432549
expl/env_infos/initial/reward_ctrl Mean      -0.230169
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.230169
expl/env_infos/initial/reward_ctrl Min       -0.230169
expl/env_infos/reward_ctrl Mean              -0.39269
expl/env_infos/reward_ctrl Std                0.0911147
expl/env_infos/reward_ctrl Max               -0.127752
expl/env_infos/reward_ctrl Min               -0.586516
eval/num steps total                          1.08e+06
eval/num paths total                       1080
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.51932
eval/Rewards Std                              1.26115
eval/Rewards Max                              8.0169
eval/Rewards Min                             -0.926734
eval/Returns Mean                          5519.32
eval/Returns Std                             88.3045
eval/Returns Max                           5660.56
eval/Returns Min                           5424.1
eval/Actions Mean                             0.0895968
eval/Actions Std                              0.819062
eval/Actions Max                              0.997847
eval/Actions Min                             -0.996115
eval/Num Paths                                5
eval/Average Returns                       5519.32
eval/env_infos/final/reward_run Mean          5.82831
eval/env_infos/final/reward_run Std           0.189222
eval/env_infos/final/reward_run Max           6.17896
eval/env_infos/final/reward_run Min           5.62581
eval/env_infos/initial/reward_run Mean       -0.426164
eval/env_infos/initial/reward_run Std         0.133754
eval/env_infos/initial/reward_run Max        -0.272053
eval/env_infos/initial/reward_run Min        -0.641912
eval/env_infos/reward_run Mean                5.92666
eval/env_infos/reward_run Std                 1.25054
eval/env_infos/reward_run Max                 8.54108
eval/env_infos/reward_run Min                -0.641912
eval/env_infos/final/reward_ctrl Mean        -0.4323
eval/env_infos/final/reward_ctrl Std          0.0385606
eval/env_infos/final/reward_ctrl Max         -0.388976
eval/env_infos/final/reward_ctrl Min         -0.488679
eval/env_infos/initial/reward_ctrl Mean      -0.287501
eval/env_infos/initial/reward_ctrl Std        0.0425722
eval/env_infos/initial/reward_ctrl Max       -0.229885
eval/env_infos/initial/reward_ctrl Min       -0.36069
eval/env_infos/reward_ctrl Mean              -0.407334
eval/env_infos/reward_ctrl Std                0.0891856
eval/env_infos/reward_ctrl Max               -0.125469
eval/env_infos/reward_ctrl Min               -0.578379
time/data storing (s)                         0.00455644
time/evaluation sampling (s)                  2.04098
time/exploration sampling (s)                 0.541907
time/logging (s)                              0.0138098
time/sac training (s)                         7.40092
time/saving (s)                               0.00380241
time/training (s)                             3.4333e-05
time/epoch (s)                               10.006
time/total (s)                             2321.4
Epoch                                       215
---------------------------------------  ---------------
2021-11-24 01:08:05.072783 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 216 finished
---------------------------------------  ---------------
epoch                                       216
replay_buffer/size                       218000
trainer/num train calls                  217000
trainer/QF1 Loss                              5.16231
trainer/QF2 Loss                              6.35477
trainer/Policy Loss                        -321.461
trainer/Q1 Predictions Mean                 322.119
trainer/Q1 Predictions Std                   98.7837
trainer/Q1 Predictions Max                  404.693
trainer/Q1 Predictions Min                   15.7633
trainer/Q2 Predictions Mean                 321.851
trainer/Q2 Predictions Std                   98.7586
trainer/Q2 Predictions Max                  405.449
trainer/Q2 Predictions Min                   17.4844
trainer/Q Targets Mean                      322.232
trainer/Q Targets Std                        98.8981
trainer/Q Targets Max                       405.488
trainer/Q Targets Min                        17.7278
trainer/Log Pis Mean                          5.43358
trainer/Log Pis Std                           4.47154
trainer/Log Pis Max                          16.8266
trainer/Log Pis Min                          -4.48172
trainer/policy/mean Mean                      0.069431
trainer/policy/mean Std                       0.763117
trainer/policy/mean Max                       0.996925
trainer/policy/mean Min                      -0.997264
trainer/policy/normal/std Mean                0.446317
trainer/policy/normal/std Std                 0.150195
trainer/policy/normal/std Max                 0.953801
trainer/policy/normal/std Min                 0.0749834
trainer/policy/normal/log_std Mean           -0.878453
trainer/policy/normal/log_std Std             0.412288
trainer/policy/normal/log_std Max            -0.0473003
trainer/policy/normal/log_std Min            -2.59049
trainer/Alpha                                 0.117382
trainer/Alpha Loss                           -1.21346
expl/num steps total                     218000
expl/num paths total                        218
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.26503
expl/Rewards Std                              1.2365
expl/Rewards Max                              7.75054
expl/Rewards Min                             -0.576054
expl/Returns Mean                          5265.03
expl/Returns Std                              0
expl/Returns Max                           5265.03
expl/Returns Min                           5265.03
expl/Actions Mean                             0.0732488
expl/Actions Std                              0.814597
expl/Actions Max                              0.999748
expl/Actions Min                             -0.999958
expl/Num Paths                                1
expl/Average Returns                       5265.03
expl/env_infos/final/reward_run Mean          6.88397
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.88397
expl/env_infos/final/reward_run Min           6.88397
expl/env_infos/initial/reward_run Mean       -0.230384
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.230384
expl/env_infos/initial/reward_run Min        -0.230384
expl/env_infos/reward_run Mean                5.66639
expl/env_infos/reward_run Std                 1.22271
expl/env_infos/reward_run Max                 8.24055
expl/env_infos/reward_run Min                -0.309635
expl/env_infos/final/reward_ctrl Mean        -0.241284
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.241284
expl/env_infos/final/reward_ctrl Min         -0.241284
expl/env_infos/initial/reward_ctrl Mean      -0.298611
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.298611
expl/env_infos/initial/reward_ctrl Min       -0.298611
expl/env_infos/reward_ctrl Mean              -0.40136
expl/env_infos/reward_ctrl Std                0.0975043
expl/env_infos/reward_ctrl Max               -0.103936
expl/env_infos/reward_ctrl Min               -0.588421
eval/num steps total                          1.085e+06
eval/num paths total                       1085
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.67695
eval/Rewards Std                              1.27931
eval/Rewards Max                              8.11322
eval/Rewards Min                             -0.622784
eval/Returns Mean                          5676.95
eval/Returns Std                             90.3747
eval/Returns Max                           5786.05
eval/Returns Min                           5578.08
eval/Actions Mean                             0.0823228
eval/Actions Std                              0.829403
eval/Actions Max                              0.99808
eval/Actions Min                             -0.997752
eval/Num Paths                                5
eval/Average Returns                       5676.95
eval/env_infos/final/reward_run Mean          7.29372
eval/env_infos/final/reward_run Std           0.56792
eval/env_infos/final/reward_run Max           8.00318
eval/env_infos/final/reward_run Min           6.25876
eval/env_infos/initial/reward_run Mean       -0.145278
eval/env_infos/initial/reward_run Std         0.104839
eval/env_infos/initial/reward_run Max        -0.0232787
eval/env_infos/initial/reward_run Min        -0.281589
eval/env_infos/reward_run Mean                6.09376
eval/env_infos/reward_run Std                 1.25961
eval/env_infos/reward_run Max                 8.62065
eval/env_infos/reward_run Min                -0.296449
eval/env_infos/final/reward_ctrl Mean        -0.452545
eval/env_infos/final/reward_ctrl Std          0.048935
eval/env_infos/final/reward_ctrl Max         -0.371346
eval/env_infos/final/reward_ctrl Min         -0.519352
eval/env_infos/initial/reward_ctrl Mean      -0.195769
eval/env_infos/initial/reward_ctrl Std        0.0432936
eval/env_infos/initial/reward_ctrl Max       -0.117558
eval/env_infos/initial/reward_ctrl Min       -0.234636
eval/env_infos/reward_ctrl Mean              -0.416812
eval/env_infos/reward_ctrl Std                0.0949175
eval/env_infos/reward_ctrl Max               -0.113285
eval/env_infos/reward_ctrl Min               -0.583465
time/data storing (s)                         0.00448392
time/evaluation sampling (s)                  1.98431
time/exploration sampling (s)                 0.518377
time/logging (s)                              0.0136588
time/sac training (s)                         7.44583
time/saving (s)                               0.00375579
time/training (s)                             3.4037e-05
time/epoch (s)                                9.97045
time/total (s)                             2331.65
Epoch                                       216
---------------------------------------  ---------------
2021-11-24 01:08:15.389198 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 217 finished
---------------------------------------  ---------------
epoch                                       217
replay_buffer/size                       219000
trainer/num train calls                  218000
trainer/QF1 Loss                              6.985
trainer/QF2 Loss                              5.32266
trainer/Policy Loss                        -325.442
trainer/Q1 Predictions Mean                 325.775
trainer/Q1 Predictions Std                   95.1017
trainer/Q1 Predictions Max                  407.163
trainer/Q1 Predictions Min                   17.3158
trainer/Q2 Predictions Mean                 325.915
trainer/Q2 Predictions Std                   95.0864
trainer/Q2 Predictions Max                  406.922
trainer/Q2 Predictions Min                   19.2118
trainer/Q Targets Mean                      325.665
trainer/Q Targets Std                        95.1661
trainer/Q Targets Max                       404.82
trainer/Q Targets Min                        15.4829
trainer/Log Pis Mean                          6.01394
trainer/Log Pis Std                           4.65406
trainer/Log Pis Max                          21.0011
trainer/Log Pis Min                          -6.86393
trainer/policy/mean Mean                      0.0922991
trainer/policy/mean Std                       0.757568
trainer/policy/mean Max                       0.997265
trainer/policy/mean Min                      -0.996495
trainer/policy/normal/std Mean                0.443624
trainer/policy/normal/std Std                 0.145652
trainer/policy/normal/std Max                 1.07926
trainer/policy/normal/std Min                 0.0664149
trainer/policy/normal/log_std Mean           -0.883402
trainer/policy/normal/log_std Std             0.413568
trainer/policy/normal/log_std Max             0.0762725
trainer/policy/normal/log_std Min            -2.71183
trainer/Alpha                                 0.117482
trainer/Alpha Loss                            0.0298491
expl/num steps total                     219000
expl/num paths total                        219
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.24616
expl/Rewards Std                              1.21537
expl/Rewards Max                              7.57785
expl/Rewards Min                             -0.435042
expl/Returns Mean                          5246.16
expl/Returns Std                              0
expl/Returns Max                           5246.16
expl/Returns Min                           5246.16
expl/Actions Mean                             0.115043
expl/Actions Std                              0.807128
expl/Actions Max                              0.999526
expl/Actions Min                             -0.999429
expl/Num Paths                                1
expl/Average Returns                       5246.16
expl/env_infos/final/reward_run Mean          5.30769
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.30769
expl/env_infos/final/reward_run Min           5.30769
expl/env_infos/initial/reward_run Mean       -0.233797
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.233797
expl/env_infos/initial/reward_run Min        -0.233797
expl/env_infos/reward_run Mean                5.64498
expl/env_infos/reward_run Std                 1.1979
expl/env_infos/reward_run Max                 8.0255
expl/env_infos/reward_run Min                -0.233797
expl/env_infos/final/reward_ctrl Mean        -0.392987
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.392987
expl/env_infos/final/reward_ctrl Min         -0.392987
expl/env_infos/initial/reward_ctrl Mean      -0.201246
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.201246
expl/env_infos/initial/reward_ctrl Min       -0.201246
expl/env_infos/reward_ctrl Mean              -0.398815
expl/env_infos/reward_ctrl Std                0.089414
expl/env_infos/reward_ctrl Max               -0.111561
expl/env_infos/reward_ctrl Min               -0.583985
eval/num steps total                          1.09e+06
eval/num paths total                       1090
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.32168
eval/Rewards Std                              1.27866
eval/Rewards Max                              7.87706
eval/Rewards Min                             -0.806038
eval/Returns Mean                          5321.68
eval/Returns Std                             64.0892
eval/Returns Max                           5383.62
eval/Returns Min                           5236.61
eval/Actions Mean                             0.125666
eval/Actions Std                              0.816287
eval/Actions Max                              0.999047
eval/Actions Min                             -0.99872
eval/Num Paths                                5
eval/Average Returns                       5321.68
eval/env_infos/final/reward_run Mean          5.75518
eval/env_infos/final/reward_run Std           0.899447
eval/env_infos/final/reward_run Max           6.95459
eval/env_infos/final/reward_run Min           4.82216
eval/env_infos/initial/reward_run Mean       -0.258423
eval/env_infos/initial/reward_run Std         0.146165
eval/env_infos/initial/reward_run Max        -0.0888699
eval/env_infos/initial/reward_run Min        -0.490985
eval/env_infos/reward_run Mean                5.73095
eval/env_infos/reward_run Std                 1.25298
eval/env_infos/reward_run Max                 8.3561
eval/env_infos/reward_run Min                -0.490985
eval/env_infos/final/reward_ctrl Mean        -0.416912
eval/env_infos/final/reward_ctrl Std          0.0625285
eval/env_infos/final/reward_ctrl Max         -0.352471
eval/env_infos/final/reward_ctrl Min         -0.502478
eval/env_infos/initial/reward_ctrl Mean      -0.260006
eval/env_infos/initial/reward_ctrl Std        0.0628399
eval/env_infos/initial/reward_ctrl Max       -0.16763
eval/env_infos/initial/reward_ctrl Min       -0.324184
eval/env_infos/reward_ctrl Mean              -0.40927
eval/env_infos/reward_ctrl Std                0.0879066
eval/env_infos/reward_ctrl Max               -0.134488
eval/env_infos/reward_ctrl Min               -0.582191
time/data storing (s)                         0.00447801
time/evaluation sampling (s)                  1.99203
time/exploration sampling (s)                 0.536231
time/logging (s)                              0.0150511
time/sac training (s)                         7.46908
time/saving (s)                               0.00400322
time/training (s)                             3.5072e-05
time/epoch (s)                               10.0209
time/total (s)                             2341.95
Epoch                                       217
---------------------------------------  ---------------
2021-11-24 01:08:25.600070 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 218 finished
---------------------------------------  ---------------
epoch                                       218
replay_buffer/size                       220000
trainer/num train calls                  219000
trainer/QF1 Loss                              8.39076
trainer/QF2 Loss                              6.36071
trainer/Policy Loss                        -309.077
trainer/Q1 Predictions Mean                 309.415
trainer/Q1 Predictions Std                  117.932
trainer/Q1 Predictions Max                  405.821
trainer/Q1 Predictions Min                   17.9871
trainer/Q2 Predictions Mean                 309.556
trainer/Q2 Predictions Std                  117.854
trainer/Q2 Predictions Max                  404.381
trainer/Q2 Predictions Min                   17.8149
trainer/Q Targets Mean                      309.344
trainer/Q Targets Std                       117.979
trainer/Q Targets Max                       406.866
trainer/Q Targets Min                        17.7709
trainer/Log Pis Mean                          5.30564
trainer/Log Pis Std                           4.65575
trainer/Log Pis Max                          16.331
trainer/Log Pis Min                          -5.08922
trainer/policy/mean Mean                      0.0800199
trainer/policy/mean Std                       0.74813
trainer/policy/mean Max                       0.99907
trainer/policy/mean Min                      -0.995481
trainer/policy/normal/std Mean                0.450371
trainer/policy/normal/std Std                 0.151472
trainer/policy/normal/std Max                 0.954505
trainer/policy/normal/std Min                 0.0685565
trainer/policy/normal/log_std Mean           -0.871442
trainer/policy/normal/log_std Std             0.42145
trainer/policy/normal/log_std Max            -0.0465624
trainer/policy/normal/log_std Min            -2.6801
trainer/Alpha                                 0.118198
trainer/Alpha Loss                           -1.48274
expl/num steps total                     220000
expl/num paths total                        220
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.40172
expl/Rewards Std                              1.22058
expl/Rewards Max                              7.96514
expl/Rewards Min                             -0.388507
expl/Returns Mean                          5401.72
expl/Returns Std                              0
expl/Returns Max                           5401.72
expl/Returns Min                           5401.72
expl/Actions Mean                             0.105282
expl/Actions Std                              0.806165
expl/Actions Max                              0.999364
expl/Actions Min                             -0.999849
expl/Num Paths                                1
expl/Average Returns                       5401.72
expl/env_infos/final/reward_run Mean          6.22635
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.22635
expl/env_infos/final/reward_run Min           6.22635
expl/env_infos/initial/reward_run Mean       -0.197677
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.197677
expl/env_infos/initial/reward_run Min        -0.197677
expl/env_infos/reward_run Mean                5.79831
expl/env_infos/reward_run Std                 1.19992
expl/env_infos/reward_run Max                 8.35383
expl/env_infos/reward_run Min                -0.197677
expl/env_infos/final/reward_ctrl Mean        -0.336331
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.336331
expl/env_infos/final/reward_ctrl Min         -0.336331
expl/env_infos/initial/reward_ctrl Mean      -0.19083
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.19083
expl/env_infos/initial/reward_ctrl Min       -0.19083
expl/env_infos/reward_ctrl Mean              -0.396591
expl/env_infos/reward_ctrl Std                0.0923523
expl/env_infos/reward_ctrl Max               -0.101952
expl/env_infos/reward_ctrl Min               -0.577934
eval/num steps total                          1.095e+06
eval/num paths total                       1095
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.65499
eval/Rewards Std                              1.27091
eval/Rewards Max                              8.02774
eval/Rewards Min                             -0.771068
eval/Returns Mean                          5654.99
eval/Returns Std                             50.8533
eval/Returns Max                           5742.76
eval/Returns Min                           5610.19
eval/Actions Mean                             0.115529
eval/Actions Std                              0.814627
eval/Actions Max                              0.99852
eval/Actions Min                             -0.998392
eval/Num Paths                                5
eval/Average Returns                       5654.99
eval/env_infos/final/reward_run Mean          5.44008
eval/env_infos/final/reward_run Std           0.306014
eval/env_infos/final/reward_run Max           5.92888
eval/env_infos/final/reward_run Min           5.07729
eval/env_infos/initial/reward_run Mean       -0.430243
eval/env_infos/initial/reward_run Std         0.118101
eval/env_infos/initial/reward_run Max        -0.282693
eval/env_infos/initial/reward_run Min        -0.565223
eval/env_infos/reward_run Mean                6.06116
eval/env_infos/reward_run Std                 1.2483
eval/env_infos/reward_run Max                 8.48418
eval/env_infos/reward_run Min                -0.565223
eval/env_infos/final/reward_ctrl Mean        -0.400376
eval/env_infos/final/reward_ctrl Std          0.0628591
eval/env_infos/final/reward_ctrl Max         -0.339793
eval/env_infos/final/reward_ctrl Min         -0.482048
eval/env_infos/initial/reward_ctrl Mean      -0.260424
eval/env_infos/initial/reward_ctrl Std        0.0376322
eval/env_infos/initial/reward_ctrl Max       -0.205845
eval/env_infos/initial/reward_ctrl Min       -0.310953
eval/env_infos/reward_ctrl Mean              -0.406178
eval/env_infos/reward_ctrl Std                0.088893
eval/env_infos/reward_ctrl Max               -0.130346
eval/env_infos/reward_ctrl Min               -0.577215
time/data storing (s)                         0.00450957
time/evaluation sampling (s)                  2.0084
time/exploration sampling (s)                 0.529668
time/logging (s)                              0.0142261
time/sac training (s)                         7.36183
time/saving (s)                               0.00377592
time/training (s)                             3.4309e-05
time/epoch (s)                                9.92245
time/total (s)                             2352.15
Epoch                                       218
---------------------------------------  ---------------
2021-11-24 01:08:35.848513 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 219 finished
---------------------------------------  ---------------
epoch                                       219
replay_buffer/size                       221000
trainer/num train calls                  220000
trainer/QF1 Loss                              6.14683
trainer/QF2 Loss                              5.78694
trainer/Policy Loss                        -325.185
trainer/Q1 Predictions Mean                 325.672
trainer/Q1 Predictions Std                  101.825
trainer/Q1 Predictions Max                  402.289
trainer/Q1 Predictions Min                   18.2045
trainer/Q2 Predictions Mean                 325.875
trainer/Q2 Predictions Std                  101.876
trainer/Q2 Predictions Max                  405.906
trainer/Q2 Predictions Min                   18.7677
trainer/Q Targets Mean                      325.614
trainer/Q Targets Std                       101.859
trainer/Q Targets Max                       406.922
trainer/Q Targets Min                        18.1455
trainer/Log Pis Mean                          5.80191
trainer/Log Pis Std                           4.39474
trainer/Log Pis Max                          17.5484
trainer/Log Pis Min                          -5.67569
trainer/policy/mean Mean                      0.060239
trainer/policy/mean Std                       0.776709
trainer/policy/mean Max                       0.999692
trainer/policy/mean Min                      -0.998261
trainer/policy/normal/std Mean                0.460242
trainer/policy/normal/std Std                 0.147214
trainer/policy/normal/std Max                 1.39795
trainer/policy/normal/std Min                 0.0767327
trainer/policy/normal/log_std Mean           -0.840424
trainer/policy/normal/log_std Std             0.390549
trainer/policy/normal/log_std Max             0.335006
trainer/policy/normal/log_std Min            -2.56743
trainer/Alpha                                 0.11944
trainer/Alpha Loss                           -0.420924
expl/num steps total                     221000
expl/num paths total                        221
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.14588
expl/Rewards Std                              1.15351
expl/Rewards Max                              7.09061
expl/Rewards Min                             -0.508294
expl/Returns Mean                          5145.88
expl/Returns Std                              0
expl/Returns Max                           5145.88
expl/Returns Min                           5145.88
expl/Actions Mean                             0.0585362
expl/Actions Std                              0.809662
expl/Actions Max                              0.999676
expl/Actions Min                             -0.999417
expl/Num Paths                                1
expl/Average Returns                       5145.88
expl/env_infos/final/reward_run Mean          5.03824
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.03824
expl/env_infos/final/reward_run Min           5.03824
expl/env_infos/initial/reward_run Mean       -0.191426
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.191426
expl/env_infos/initial/reward_run Min        -0.191426
expl/env_infos/reward_run Mean                5.54127
expl/env_infos/reward_run Std                 1.13892
expl/env_infos/reward_run Max                 7.54984
expl/env_infos/reward_run Min                -0.191426
expl/env_infos/final/reward_ctrl Mean        -0.429487
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.429487
expl/env_infos/final/reward_ctrl Min         -0.429487
expl/env_infos/initial/reward_ctrl Mean      -0.316868
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.316868
expl/env_infos/initial/reward_ctrl Min       -0.316868
expl/env_infos/reward_ctrl Mean              -0.395387
expl/env_infos/reward_ctrl Std                0.0947883
expl/env_infos/reward_ctrl Max               -0.069468
expl/env_infos/reward_ctrl Min               -0.583158
eval/num steps total                          1.1e+06
eval/num paths total                       1100
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.43211
eval/Rewards Std                              1.2281
eval/Rewards Max                              7.65536
eval/Rewards Min                             -0.774388
eval/Returns Mean                          5432.11
eval/Returns Std                             86.8761
eval/Returns Max                           5554.15
eval/Returns Min                           5303.94
eval/Actions Mean                             0.0501001
eval/Actions Std                              0.824032
eval/Actions Max                              0.996841
eval/Actions Min                             -0.998715
eval/Num Paths                                5
eval/Average Returns                       5432.11
eval/env_infos/final/reward_run Mean          6.30824
eval/env_infos/final/reward_run Std           0.568575
eval/env_infos/final/reward_run Max           7.1792
eval/env_infos/final/reward_run Min           5.76686
eval/env_infos/initial/reward_run Mean       -0.202238
eval/env_infos/initial/reward_run Std         0.191509
eval/env_infos/initial/reward_run Max         0.104493
eval/env_infos/initial/reward_run Min        -0.444596
eval/env_infos/reward_run Mean                5.84103
eval/env_infos/reward_run Std                 1.21017
eval/env_infos/reward_run Max                 8.16917
eval/env_infos/reward_run Min                -0.444596
eval/env_infos/final/reward_ctrl Mean        -0.461077
eval/env_infos/final/reward_ctrl Std          0.110122
eval/env_infos/final/reward_ctrl Max         -0.251291
eval/env_infos/final/reward_ctrl Min         -0.557662
eval/env_infos/initial/reward_ctrl Mean      -0.269642
eval/env_infos/initial/reward_ctrl Std        0.0458162
eval/env_infos/initial/reward_ctrl Max       -0.190642
eval/env_infos/initial/reward_ctrl Min       -0.329792
eval/env_infos/reward_ctrl Mean              -0.408923
eval/env_infos/reward_ctrl Std                0.0906151
eval/env_infos/reward_ctrl Max               -0.132634
eval/env_infos/reward_ctrl Min               -0.58144
time/data storing (s)                         0.00446846
time/evaluation sampling (s)                  2.01525
time/exploration sampling (s)                 0.530777
time/logging (s)                              0.0147261
time/sac training (s)                         7.39238
time/saving (s)                               0.00377113
time/training (s)                             3.4669e-05
time/epoch (s)                                9.96141
time/total (s)                             2362.39
Epoch                                       219
---------------------------------------  ---------------
2021-11-24 01:08:46.079650 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 220 finished
---------------------------------------  ---------------
epoch                                       220
replay_buffer/size                       222000
trainer/num train calls                  221000
trainer/QF1 Loss                              9.58872
trainer/QF2 Loss                              8.90354
trainer/Policy Loss                        -326.46
trainer/Q1 Predictions Mean                 326.796
trainer/Q1 Predictions Std                   94.1684
trainer/Q1 Predictions Max                  411.568
trainer/Q1 Predictions Min                   17.3245
trainer/Q2 Predictions Mean                 326.893
trainer/Q2 Predictions Std                   94.1375
trainer/Q2 Predictions Max                  410.839
trainer/Q2 Predictions Min                   16.9644
trainer/Q Targets Mean                      326.524
trainer/Q Targets Std                        94.1522
trainer/Q Targets Max                       408.351
trainer/Q Targets Min                        15.2105
trainer/Log Pis Mean                          6.21773
trainer/Log Pis Std                           4.79036
trainer/Log Pis Max                          17.2194
trainer/Log Pis Min                          -7.43775
trainer/policy/mean Mean                      0.0623782
trainer/policy/mean Std                       0.771703
trainer/policy/mean Max                       0.996909
trainer/policy/mean Min                      -0.998746
trainer/policy/normal/std Mean                0.447668
trainer/policy/normal/std Std                 0.138799
trainer/policy/normal/std Max                 0.872277
trainer/policy/normal/std Min                 0.0739844
trainer/policy/normal/log_std Mean           -0.865385
trainer/policy/normal/log_std Std             0.382501
trainer/policy/normal/log_std Max            -0.136648
trainer/policy/normal/log_std Min            -2.6039
trainer/Alpha                                 0.120532
trainer/Alpha Loss                            0.460676
expl/num steps total                     222000
expl/num paths total                        222
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.32285
expl/Rewards Std                              1.21342
expl/Rewards Max                              7.72285
expl/Rewards Min                             -0.57416
expl/Returns Mean                          5322.85
expl/Returns Std                              0
expl/Returns Max                           5322.85
expl/Returns Min                           5322.85
expl/Actions Mean                             0.0993298
expl/Actions Std                              0.802129
expl/Actions Max                              0.999893
expl/Actions Min                             -0.999112
expl/Num Paths                                1
expl/Average Returns                       5322.85
expl/env_infos/final/reward_run Mean          5.07899
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.07899
expl/env_infos/final/reward_run Min           5.07899
expl/env_infos/initial/reward_run Mean       -0.349727
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.349727
expl/env_infos/initial/reward_run Min        -0.349727
expl/env_infos/reward_run Mean                5.71481
expl/env_infos/reward_run Std                 1.19528
expl/env_infos/reward_run Max                 8.22223
expl/env_infos/reward_run Min                -0.349727
expl/env_infos/final/reward_ctrl Mean        -0.381663
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.381663
expl/env_infos/final/reward_ctrl Min         -0.381663
expl/env_infos/initial/reward_ctrl Mean      -0.224434
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.224434
expl/env_infos/initial/reward_ctrl Min       -0.224434
expl/env_infos/reward_ctrl Mean              -0.391966
expl/env_infos/reward_ctrl Std                0.0937325
expl/env_infos/reward_ctrl Max               -0.0849213
expl/env_infos/reward_ctrl Min               -0.588592
eval/num steps total                          1.105e+06
eval/num paths total                       1105
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.53216
eval/Rewards Std                              1.28011
eval/Rewards Max                              8.10762
eval/Rewards Min                             -0.780173
eval/Returns Mean                          5532.16
eval/Returns Std                             79.2295
eval/Returns Max                           5687.29
eval/Returns Min                           5474.16
eval/Actions Mean                             0.117142
eval/Actions Std                              0.81366
eval/Actions Max                              0.998596
eval/Actions Min                             -0.997636
eval/Num Paths                                5
eval/Average Returns                       5532.16
eval/env_infos/final/reward_run Mean          6.22803
eval/env_infos/final/reward_run Std           0.18158
eval/env_infos/final/reward_run Max           6.54653
eval/env_infos/final/reward_run Min           6.04533
eval/env_infos/initial/reward_run Mean       -0.293675
eval/env_infos/initial/reward_run Std         0.109162
eval/env_infos/initial/reward_run Max        -0.172677
eval/env_infos/initial/reward_run Min        -0.499243
eval/env_infos/reward_run Mean                5.93762
eval/env_infos/reward_run Std                 1.25767
eval/env_infos/reward_run Max                 8.58586
eval/env_infos/reward_run Min                -0.499243
eval/env_infos/final/reward_ctrl Mean        -0.420175
eval/env_infos/final/reward_ctrl Std          0.0933784
eval/env_infos/final/reward_ctrl Max         -0.263257
eval/env_infos/final/reward_ctrl Min         -0.501765
eval/env_infos/initial/reward_ctrl Mean      -0.266527
eval/env_infos/initial/reward_ctrl Std        0.0530894
eval/env_infos/initial/reward_ctrl Max       -0.183319
eval/env_infos/initial/reward_ctrl Min       -0.335499
eval/env_infos/reward_ctrl Mean              -0.405459
eval/env_infos/reward_ctrl Std                0.0921608
eval/env_infos/reward_ctrl Max               -0.128913
eval/env_infos/reward_ctrl Min               -0.582242
time/data storing (s)                         0.00450177
time/evaluation sampling (s)                  2.01601
time/exploration sampling (s)                 0.532482
time/logging (s)                              0.0139743
time/sac training (s)                         7.37105
time/saving (s)                               0.00377677
time/training (s)                             3.4165e-05
time/epoch (s)                                9.94183
time/total (s)                             2372.6
Epoch                                       220
---------------------------------------  ---------------
2021-11-24 01:08:56.308184 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 221 finished
---------------------------------------  ---------------
epoch                                       221
replay_buffer/size                       223000
trainer/num train calls                  222000
trainer/QF1 Loss                              5.86513
trainer/QF2 Loss                              4.90191
trainer/Policy Loss                        -326.424
trainer/Q1 Predictions Mean                 326.615
trainer/Q1 Predictions Std                  102.126
trainer/Q1 Predictions Max                  410.828
trainer/Q1 Predictions Min                   17.3817
trainer/Q2 Predictions Mean                 327.03
trainer/Q2 Predictions Std                  102.251
trainer/Q2 Predictions Max                  409.848
trainer/Q2 Predictions Min                   16.7232
trainer/Q Targets Mean                      327.292
trainer/Q Targets Std                       102.283
trainer/Q Targets Max                       410.108
trainer/Q Targets Min                        17.6052
trainer/Log Pis Mean                          6.30157
trainer/Log Pis Std                           4.92245
trainer/Log Pis Max                          19.924
trainer/Log Pis Min                          -8.12005
trainer/policy/mean Mean                      0.0716601
trainer/policy/mean Std                       0.778675
trainer/policy/mean Max                       0.997674
trainer/policy/mean Min                      -0.99769
trainer/policy/normal/std Mean                0.456049
trainer/policy/normal/std Std                 0.143468
trainer/policy/normal/std Max                 0.845285
trainer/policy/normal/std Min                 0.0774914
trainer/policy/normal/log_std Mean           -0.848967
trainer/policy/normal/log_std Std             0.389117
trainer/policy/normal/log_std Max            -0.168082
trainer/policy/normal/log_std Min            -2.55759
trainer/Alpha                                 0.119771
trainer/Alpha Loss                            0.639977
expl/num steps total                     223000
expl/num paths total                        223
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.32268
expl/Rewards Std                              1.18628
expl/Rewards Max                              7.58202
expl/Rewards Min                             -0.673226
expl/Returns Mean                          5322.68
expl/Returns Std                              0
expl/Returns Max                           5322.68
expl/Returns Min                           5322.68
expl/Actions Mean                             0.0789078
expl/Actions Std                              0.81303
expl/Actions Max                              0.999843
expl/Actions Min                             -0.999675
expl/Num Paths                                1
expl/Average Returns                       5322.68
expl/env_infos/final/reward_run Mean          5.05656
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.05656
expl/env_infos/final/reward_run Min           5.05656
expl/env_infos/initial/reward_run Mean       -0.313282
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.313282
expl/env_infos/initial/reward_run Min        -0.313282
expl/env_infos/reward_run Mean                5.72303
expl/env_infos/reward_run Std                 1.16967
expl/env_infos/reward_run Max                 8.02585
expl/env_infos/reward_run Min                -0.313282
expl/env_infos/final/reward_ctrl Mean        -0.362066
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.362066
expl/env_infos/final/reward_ctrl Min         -0.362066
expl/env_infos/initial/reward_ctrl Mean      -0.359945
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.359945
expl/env_infos/initial/reward_ctrl Min       -0.359945
expl/env_infos/reward_ctrl Mean              -0.400347
expl/env_infos/reward_ctrl Std                0.0892705
expl/env_infos/reward_ctrl Max               -0.123744
expl/env_infos/reward_ctrl Min               -0.585814
eval/num steps total                          1.11e+06
eval/num paths total                       1110
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.57278
eval/Rewards Std                              1.28642
eval/Rewards Max                              7.97262
eval/Rewards Min                             -0.866577
eval/Returns Mean                          5572.78
eval/Returns Std                             77.5987
eval/Returns Max                           5659.66
eval/Returns Min                           5438.41
eval/Actions Mean                             0.0886256
eval/Actions Std                              0.819873
eval/Actions Max                              0.997788
eval/Actions Min                             -0.998382
eval/Num Paths                                5
eval/Average Returns                       5572.78
eval/env_infos/final/reward_run Mean          6.11017
eval/env_infos/final/reward_run Std           0.84497
eval/env_infos/final/reward_run Max           7.15304
eval/env_infos/final/reward_run Min           5.18269
eval/env_infos/initial/reward_run Mean       -0.43578
eval/env_infos/initial/reward_run Std         0.117905
eval/env_infos/initial/reward_run Max        -0.221026
eval/env_infos/initial/reward_run Min        -0.555164
eval/env_infos/reward_run Mean                5.98081
eval/env_infos/reward_run Std                 1.26811
eval/env_infos/reward_run Max                 8.45936
eval/env_infos/reward_run Min                -0.555164
eval/env_infos/final/reward_ctrl Mean        -0.472639
eval/env_infos/final/reward_ctrl Std          0.09071
eval/env_infos/final/reward_ctrl Max         -0.337118
eval/env_infos/final/reward_ctrl Min         -0.566986
eval/env_infos/initial/reward_ctrl Mean      -0.320322
eval/env_infos/initial/reward_ctrl Std        0.0252387
eval/env_infos/initial/reward_ctrl Max       -0.295212
eval/env_infos/initial/reward_ctrl Min       -0.367017
eval/env_infos/reward_ctrl Mean              -0.408028
eval/env_infos/reward_ctrl Std                0.0900658
eval/env_infos/reward_ctrl Max               -0.115604
eval/env_infos/reward_ctrl Min               -0.58795
time/data storing (s)                         0.00449646
time/evaluation sampling (s)                  1.99609
time/exploration sampling (s)                 0.530562
time/logging (s)                              0.0146299
time/sac training (s)                         7.39035
time/saving (s)                               0.00376662
time/training (s)                             3.4142e-05
time/epoch (s)                                9.93994
time/total (s)                             2382.82
Epoch                                       221
---------------------------------------  ---------------
2021-11-24 01:09:06.537366 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 222 finished
---------------------------------------  ---------------
epoch                                       222
replay_buffer/size                       224000
trainer/num train calls                  223000
trainer/QF1 Loss                              6.0078
trainer/QF2 Loss                              5.19209
trainer/Policy Loss                        -329.174
trainer/Q1 Predictions Mean                 329.859
trainer/Q1 Predictions Std                  104.205
trainer/Q1 Predictions Max                  415.697
trainer/Q1 Predictions Min                   18.5433
trainer/Q2 Predictions Mean                 329.702
trainer/Q2 Predictions Std                  104.118
trainer/Q2 Predictions Max                  414.675
trainer/Q2 Predictions Min                   17.7169
trainer/Q Targets Mean                      329.368
trainer/Q Targets Std                       103.919
trainer/Q Targets Max                       413.669
trainer/Q Targets Min                        17.2036
trainer/Log Pis Mean                          6.1298
trainer/Log Pis Std                           4.98214
trainer/Log Pis Max                          20.9623
trainer/Log Pis Min                          -6.34321
trainer/policy/mean Mean                      0.0810508
trainer/policy/mean Std                       0.784052
trainer/policy/mean Max                       0.999371
trainer/policy/mean Min                      -0.998109
trainer/policy/normal/std Mean                0.455113
trainer/policy/normal/std Std                 0.145687
trainer/policy/normal/std Max                 1.12256
trainer/policy/normal/std Min                 0.0747244
trainer/policy/normal/log_std Mean           -0.854333
trainer/policy/normal/log_std Std             0.401567
trainer/policy/normal/log_std Max             0.115608
trainer/policy/normal/log_std Min            -2.59395
trainer/Alpha                                 0.12087
trainer/Alpha Loss                            0.27428
expl/num steps total                     224000
expl/num paths total                        224
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.30846
expl/Rewards Std                              1.20762
expl/Rewards Max                              7.64082
expl/Rewards Min                             -0.796311
expl/Returns Mean                          5308.46
expl/Returns Std                              0
expl/Returns Max                           5308.46
expl/Returns Min                           5308.46
expl/Actions Mean                             0.105251
expl/Actions Std                              0.807192
expl/Actions Max                              0.999373
expl/Actions Min                             -0.999385
expl/Num Paths                                1
expl/Average Returns                       5308.46
expl/env_infos/final/reward_run Mean          5.36464
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.36464
expl/env_infos/final/reward_run Min           5.36464
expl/env_infos/initial/reward_run Mean       -0.469464
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.469464
expl/env_infos/initial/reward_run Min        -0.469464
expl/env_infos/reward_run Mean                5.70604
expl/env_infos/reward_run Std                 1.20072
expl/env_infos/reward_run Max                 8.14486
expl/env_infos/reward_run Min                -0.469464
expl/env_infos/final/reward_ctrl Mean        -0.449463
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.449463
expl/env_infos/final/reward_ctrl Min         -0.449463
expl/env_infos/initial/reward_ctrl Mean      -0.326847
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.326847
expl/env_infos/initial/reward_ctrl Min       -0.326847
expl/env_infos/reward_ctrl Mean              -0.397582
expl/env_infos/reward_ctrl Std                0.0949585
expl/env_infos/reward_ctrl Max               -0.0537519
expl/env_infos/reward_ctrl Min               -0.587918
eval/num steps total                          1.115e+06
eval/num paths total                       1115
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.49703
eval/Rewards Std                              1.27531
eval/Rewards Max                              7.94353
eval/Rewards Min                             -0.940756
eval/Returns Mean                          5497.03
eval/Returns Std                             67.136
eval/Returns Max                           5587.91
eval/Returns Min                           5388.62
eval/Actions Mean                             0.109049
eval/Actions Std                              0.818897
eval/Actions Max                              0.999251
eval/Actions Min                             -0.997302
eval/Num Paths                                5
eval/Average Returns                       5497.03
eval/env_infos/final/reward_run Mean          6.53786
eval/env_infos/final/reward_run Std           0.994014
eval/env_infos/final/reward_run Max           7.63921
eval/env_infos/final/reward_run Min           4.81053
eval/env_infos/initial/reward_run Mean       -0.351409
eval/env_infos/initial/reward_run Std         0.17091
eval/env_infos/initial/reward_run Max        -0.216845
eval/env_infos/initial/reward_run Min        -0.687434
eval/env_infos/reward_run Mean                5.90652
eval/env_infos/reward_run Std                 1.26203
eval/env_infos/reward_run Max                 8.45703
eval/env_infos/reward_run Min                -0.687434
eval/env_infos/final/reward_ctrl Mean        -0.444317
eval/env_infos/final/reward_ctrl Std          0.0544567
eval/env_infos/final/reward_ctrl Max         -0.34581
eval/env_infos/final/reward_ctrl Min         -0.497822
eval/env_infos/initial/reward_ctrl Mean      -0.219768
eval/env_infos/initial/reward_ctrl Std        0.0422454
eval/env_infos/initial/reward_ctrl Max       -0.160745
eval/env_infos/initial/reward_ctrl Min       -0.273596
eval/env_infos/reward_ctrl Mean              -0.409491
eval/env_infos/reward_ctrl Std                0.0894003
eval/env_infos/reward_ctrl Max               -0.105034
eval/env_infos/reward_ctrl Min               -0.581171
time/data storing (s)                         0.00457039
time/evaluation sampling (s)                  2.00867
time/exploration sampling (s)                 0.532346
time/logging (s)                              0.0140637
time/sac training (s)                         7.37659
time/saving (s)                               0.00377751
time/training (s)                             3.4041e-05
time/epoch (s)                                9.94005
time/total (s)                             2393.04
Epoch                                       222
---------------------------------------  ---------------
2021-11-24 01:09:16.761941 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 223 finished
---------------------------------------  ---------------
epoch                                       223
replay_buffer/size                       225000
trainer/num train calls                  224000
trainer/QF1 Loss                              5.31422
trainer/QF2 Loss                              5.49789
trainer/Policy Loss                        -321.507
trainer/Q1 Predictions Mean                 321.625
trainer/Q1 Predictions Std                  108.128
trainer/Q1 Predictions Max                  412.132
trainer/Q1 Predictions Min                   17.3139
trainer/Q2 Predictions Mean                 322.181
trainer/Q2 Predictions Std                  108.365
trainer/Q2 Predictions Max                  412.375
trainer/Q2 Predictions Min                   18.3154
trainer/Q Targets Mean                      321.965
trainer/Q Targets Std                       108.131
trainer/Q Targets Max                       413.123
trainer/Q Targets Min                        17.8921
trainer/Log Pis Mean                          5.80059
trainer/Log Pis Std                           4.67371
trainer/Log Pis Max                          18.4315
trainer/Log Pis Min                          -8.63577
trainer/policy/mean Mean                      0.0847764
trainer/policy/mean Std                       0.764524
trainer/policy/mean Max                       0.997049
trainer/policy/mean Min                      -0.999143
trainer/policy/normal/std Mean                0.442017
trainer/policy/normal/std Std                 0.156268
trainer/policy/normal/std Max                 1.19174
trainer/policy/normal/std Min                 0.0708403
trainer/policy/normal/log_std Mean           -0.89284
trainer/policy/normal/log_std Std             0.423479
trainer/policy/normal/log_std Max             0.175415
trainer/policy/normal/log_std Min            -2.64733
trainer/Alpha                                 0.119862
trainer/Alpha Loss                           -0.423026
expl/num steps total                     225000
expl/num paths total                        225
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.41409
expl/Rewards Std                              1.1832
expl/Rewards Max                              7.33775
expl/Rewards Min                             -0.659789
expl/Returns Mean                          5414.09
expl/Returns Std                              0
expl/Returns Max                           5414.09
expl/Returns Min                           5414.09
expl/Actions Mean                             0.0837864
expl/Actions Std                              0.808093
expl/Actions Max                              0.999632
expl/Actions Min                             -0.999608
expl/Num Paths                                1
expl/Average Returns                       5414.09
expl/env_infos/final/reward_run Mean          5.69112
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.69112
expl/env_infos/final/reward_run Min           5.69112
expl/env_infos/initial/reward_run Mean       -0.442435
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.442435
expl/env_infos/initial/reward_run Min        -0.442435
expl/env_infos/reward_run Mean                5.81011
expl/env_infos/reward_run Std                 1.16224
expl/env_infos/reward_run Max                 7.82503
expl/env_infos/reward_run Min                -0.442435
expl/env_infos/final/reward_ctrl Mean        -0.509169
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.509169
expl/env_infos/final/reward_ctrl Min         -0.509169
expl/env_infos/initial/reward_ctrl Mean      -0.217354
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.217354
expl/env_infos/initial/reward_ctrl Min       -0.217354
expl/env_infos/reward_ctrl Mean              -0.39602
expl/env_infos/reward_ctrl Std                0.0930427
expl/env_infos/reward_ctrl Max               -0.0419432
expl/env_infos/reward_ctrl Min               -0.57971
eval/num steps total                          1.12e+06
eval/num paths total                       1120
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.56218
eval/Rewards Std                              1.27374
eval/Rewards Max                              8.35536
eval/Rewards Min                             -0.875767
eval/Returns Mean                          5562.18
eval/Returns Std                             26.4437
eval/Returns Max                           5595.31
eval/Returns Min                           5533.42
eval/Actions Mean                             0.0914369
eval/Actions Std                              0.821292
eval/Actions Max                              0.997589
eval/Actions Min                             -0.998278
eval/Num Paths                                5
eval/Average Returns                       5562.18
eval/env_infos/final/reward_run Mean          5.89096
eval/env_infos/final/reward_run Std           0.291515
eval/env_infos/final/reward_run Max           6.31575
eval/env_infos/final/reward_run Min           5.60152
eval/env_infos/initial/reward_run Mean       -0.33218
eval/env_infos/initial/reward_run Std         0.126695
eval/env_infos/initial/reward_run Max        -0.215967
eval/env_infos/initial/reward_run Min        -0.555547
eval/env_infos/reward_run Mean                5.97191
eval/env_infos/reward_run Std                 1.24681
eval/env_infos/reward_run Max                 8.82954
eval/env_infos/reward_run Min                -0.555547
eval/env_infos/final/reward_ctrl Mean        -0.437562
eval/env_infos/final/reward_ctrl Std          0.0248518
eval/env_infos/final/reward_ctrl Max         -0.393683
eval/env_infos/final/reward_ctrl Min         -0.462386
eval/env_infos/initial/reward_ctrl Mean      -0.253702
eval/env_infos/initial/reward_ctrl Std        0.0581803
eval/env_infos/initial/reward_ctrl Max       -0.201364
eval/env_infos/initial/reward_ctrl Min       -0.329035
eval/env_infos/reward_ctrl Mean              -0.409729
eval/env_infos/reward_ctrl Std                0.0901778
eval/env_infos/reward_ctrl Max               -0.0940189
eval/env_infos/reward_ctrl Min               -0.582395
time/data storing (s)                         0.00446604
time/evaluation sampling (s)                  2.00227
time/exploration sampling (s)                 0.526073
time/logging (s)                              0.0136584
time/sac training (s)                         7.38569
time/saving (s)                               0.00376374
time/training (s)                             3.4153e-05
time/epoch (s)                                9.93595
time/total (s)                             2403.25
Epoch                                       223
---------------------------------------  ---------------
2021-11-24 01:09:26.980727 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 224 finished
---------------------------------------  ---------------
epoch                                       224
replay_buffer/size                       226000
trainer/num train calls                  225000
trainer/QF1 Loss                              7.80261
trainer/QF2 Loss                              7.50519
trainer/Policy Loss                        -331.453
trainer/Q1 Predictions Mean                 331.999
trainer/Q1 Predictions Std                   93.0972
trainer/Q1 Predictions Max                  411.082
trainer/Q1 Predictions Min                   19.1797
trainer/Q2 Predictions Mean                 331.808
trainer/Q2 Predictions Std                   93.1315
trainer/Q2 Predictions Max                  407.813
trainer/Q2 Predictions Min                   19.8281
trainer/Q Targets Mean                      332.07
trainer/Q Targets Std                        93.0895
trainer/Q Targets Max                       413.994
trainer/Q Targets Min                        19.6474
trainer/Log Pis Mean                          6.05912
trainer/Log Pis Std                           4.42726
trainer/Log Pis Max                          19.1882
trainer/Log Pis Min                          -5.93652
trainer/policy/mean Mean                      0.0660901
trainer/policy/mean Std                       0.772883
trainer/policy/mean Max                       0.99988
trainer/policy/mean Min                      -0.998652
trainer/policy/normal/std Mean                0.446742
trainer/policy/normal/std Std                 0.14455
trainer/policy/normal/std Max                 1.69768
trainer/policy/normal/std Min                 0.0848997
trainer/policy/normal/log_std Mean           -0.869504
trainer/policy/normal/log_std Std             0.385351
trainer/policy/normal/log_std Max             0.529265
trainer/policy/normal/log_std Min            -2.46628
trainer/Alpha                                 0.12106
trainer/Alpha Loss                            0.124824
expl/num steps total                     226000
expl/num paths total                        226
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.34837
expl/Rewards Std                              1.23566
expl/Rewards Max                              7.55758
expl/Rewards Min                             -0.818868
expl/Returns Mean                          5348.37
expl/Returns Std                              0
expl/Returns Max                           5348.37
expl/Returns Min                           5348.37
expl/Actions Mean                             0.0773781
expl/Actions Std                              0.812954
expl/Actions Max                              0.999663
expl/Actions Min                             -0.999654
expl/Num Paths                                1
expl/Average Returns                       5348.37
expl/env_infos/final/reward_run Mean          4.15818
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.15818
expl/env_infos/final/reward_run Min           4.15818
expl/env_infos/initial/reward_run Mean       -0.494359
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.494359
expl/env_infos/initial/reward_run Min        -0.494359
expl/env_infos/reward_run Mean                5.7485
expl/env_infos/reward_run Std                 1.21846
expl/env_infos/reward_run Max                 8.03491
expl/env_infos/reward_run Min                -0.494359
expl/env_infos/final/reward_ctrl Mean        -0.506257
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.506257
expl/env_infos/final/reward_ctrl Min         -0.506257
expl/env_infos/initial/reward_ctrl Mean      -0.324509
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.324509
expl/env_infos/initial/reward_ctrl Min       -0.324509
expl/env_infos/reward_ctrl Mean              -0.400129
expl/env_infos/reward_ctrl Std                0.0911304
expl/env_infos/reward_ctrl Max               -0.087268
expl/env_infos/reward_ctrl Min               -0.57819
eval/num steps total                          1.125e+06
eval/num paths total                       1125
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.57613
eval/Rewards Std                              1.30243
eval/Rewards Max                              8.09662
eval/Rewards Min                             -0.84558
eval/Returns Mean                          5576.13
eval/Returns Std                             41.557
eval/Returns Max                           5632.63
eval/Returns Min                           5509.63
eval/Actions Mean                             0.0846694
eval/Actions Std                              0.827223
eval/Actions Max                              0.999205
eval/Actions Min                             -0.99866
eval/Num Paths                                5
eval/Average Returns                       5576.13
eval/env_infos/final/reward_run Mean          5.58601
eval/env_infos/final/reward_run Std           0.645998
eval/env_infos/final/reward_run Max           6.77551
eval/env_infos/final/reward_run Min           4.88576
eval/env_infos/initial/reward_run Mean       -0.370527
eval/env_infos/initial/reward_run Std         0.0901804
eval/env_infos/initial/reward_run Max        -0.266642
eval/env_infos/initial/reward_run Min        -0.473935
eval/env_infos/reward_run Mean                5.99101
eval/env_infos/reward_run Std                 1.28283
eval/env_infos/reward_run Max                 8.57429
eval/env_infos/reward_run Min                -0.473935
eval/env_infos/final/reward_ctrl Mean        -0.481088
eval/env_infos/final/reward_ctrl Std          0.0722232
eval/env_infos/final/reward_ctrl Max         -0.339642
eval/env_infos/final/reward_ctrl Min         -0.540545
eval/env_infos/initial/reward_ctrl Mean      -0.286162
eval/env_infos/initial/reward_ctrl Std        0.0537937
eval/env_infos/initial/reward_ctrl Max       -0.208765
eval/env_infos/initial/reward_ctrl Min       -0.376704
eval/env_infos/reward_ctrl Mean              -0.41488
eval/env_infos/reward_ctrl Std                0.0883842
eval/env_infos/reward_ctrl Max               -0.138379
eval/env_infos/reward_ctrl Min               -0.575901
time/data storing (s)                         0.00443693
time/evaluation sampling (s)                  2.00185
time/exploration sampling (s)                 0.530151
time/logging (s)                              0.0136026
time/sac training (s)                         7.37776
time/saving (s)                               0.00375293
time/training (s)                             3.4566e-05
time/epoch (s)                                9.93158
time/total (s)                             2413.45
Epoch                                       224
---------------------------------------  ---------------
2021-11-24 01:09:37.259404 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 225 finished
---------------------------------------  ---------------
epoch                                       225
replay_buffer/size                       227000
trainer/num train calls                  226000
trainer/QF1 Loss                              9.16211
trainer/QF2 Loss                              9.04246
trainer/Policy Loss                        -334.219
trainer/Q1 Predictions Mean                 334.774
trainer/Q1 Predictions Std                   95.4855
trainer/Q1 Predictions Max                  409.122
trainer/Q1 Predictions Min                   18.8792
trainer/Q2 Predictions Mean                 334.802
trainer/Q2 Predictions Std                   95.5386
trainer/Q2 Predictions Max                  408.357
trainer/Q2 Predictions Min                   18.7341
trainer/Q Targets Mean                      334.425
trainer/Q Targets Std                        95.2976
trainer/Q Targets Max                       408.664
trainer/Q Targets Min                        19.1121
trainer/Log Pis Mean                          6.47197
trainer/Log Pis Std                           4.68813
trainer/Log Pis Max                          19.8143
trainer/Log Pis Min                          -4.23869
trainer/policy/mean Mean                      0.044024
trainer/policy/mean Std                       0.782411
trainer/policy/mean Max                       0.998953
trainer/policy/mean Min                      -0.99808
trainer/policy/normal/std Mean                0.445487
trainer/policy/normal/std Std                 0.144504
trainer/policy/normal/std Max                 1.02715
trainer/policy/normal/std Min                 0.0796024
trainer/policy/normal/log_std Mean           -0.875984
trainer/policy/normal/log_std Std             0.399453
trainer/policy/normal/log_std Max             0.0267835
trainer/policy/normal/log_std Min            -2.53071
trainer/Alpha                                 0.121071
trainer/Alpha Loss                            0.996512
expl/num steps total                     227000
expl/num paths total                        227
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.26522
expl/Rewards Std                              1.17533
expl/Rewards Max                              7.63922
expl/Rewards Min                             -0.639695
expl/Returns Mean                          5265.22
expl/Returns Std                              0
expl/Returns Max                           5265.22
expl/Returns Min                           5265.22
expl/Actions Mean                             0.0851495
expl/Actions Std                              0.806941
expl/Actions Max                              0.999685
expl/Actions Min                             -0.999384
expl/Num Paths                                1
expl/Average Returns                       5265.22
expl/env_infos/final/reward_run Mean          5.55406
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.55406
expl/env_infos/final/reward_run Min           5.55406
expl/env_infos/initial/reward_run Mean       -0.435682
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.435682
expl/env_infos/initial/reward_run Min        -0.435682
expl/env_infos/reward_run Mean                5.66027
expl/env_infos/reward_run Std                 1.16366
expl/env_infos/reward_run Max                 8.10312
expl/env_infos/reward_run Min                -0.435682
expl/env_infos/final/reward_ctrl Mean        -0.360747
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.360747
expl/env_infos/final/reward_ctrl Min         -0.360747
expl/env_infos/initial/reward_ctrl Mean      -0.204013
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.204013
expl/env_infos/initial/reward_ctrl Min       -0.204013
expl/env_infos/reward_ctrl Mean              -0.395043
expl/env_infos/reward_ctrl Std                0.0880816
expl/env_infos/reward_ctrl Max               -0.037415
expl/env_infos/reward_ctrl Min               -0.580767
eval/num steps total                          1.13e+06
eval/num paths total                       1130
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.6257
eval/Rewards Std                              1.2669
eval/Rewards Max                              8.0769
eval/Rewards Min                             -0.554748
eval/Returns Mean                          5625.7
eval/Returns Std                             81.9133
eval/Returns Max                           5747.69
eval/Returns Min                           5531.43
eval/Actions Mean                             0.0893707
eval/Actions Std                              0.82305
eval/Actions Max                              0.999434
eval/Actions Min                             -0.997725
eval/Num Paths                                5
eval/Average Returns                       5625.7
eval/env_infos/final/reward_run Mean          5.54255
eval/env_infos/final/reward_run Std           0.967279
eval/env_infos/final/reward_run Max           6.95726
eval/env_infos/final/reward_run Min           4.50221
eval/env_infos/initial/reward_run Mean       -0.188784
eval/env_infos/initial/reward_run Std         0.05928
eval/env_infos/initial/reward_run Max        -0.10288
eval/env_infos/initial/reward_run Min        -0.261551
eval/env_infos/reward_run Mean                6.03694
eval/env_infos/reward_run Std                 1.25565
eval/env_infos/reward_run Max                 8.57356
eval/env_infos/reward_run Min                -0.261551
eval/env_infos/final/reward_ctrl Mean        -0.422776
eval/env_infos/final/reward_ctrl Std          0.0383218
eval/env_infos/final/reward_ctrl Max         -0.353491
eval/env_infos/final/reward_ctrl Min         -0.466229
eval/env_infos/initial/reward_ctrl Mean      -0.224737
eval/env_infos/initial/reward_ctrl Std        0.0520717
eval/env_infos/initial/reward_ctrl Max       -0.172067
eval/env_infos/initial/reward_ctrl Min       -0.317314
eval/env_infos/reward_ctrl Mean              -0.411239
eval/env_infos/reward_ctrl Std                0.0858349
eval/env_infos/reward_ctrl Max               -0.141293
eval/env_infos/reward_ctrl Min               -0.579022
time/data storing (s)                         0.00447807
time/evaluation sampling (s)                  2.0035
time/exploration sampling (s)                 0.541368
time/logging (s)                              0.0135748
time/sac training (s)                         7.42403
time/saving (s)                               0.00374991
time/training (s)                             3.3866e-05
time/epoch (s)                                9.99073
time/total (s)                             2423.72
Epoch                                       225
---------------------------------------  ---------------
2021-11-24 01:09:47.475682 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 226 finished
---------------------------------------  ---------------
epoch                                       226
replay_buffer/size                       228000
trainer/num train calls                  227000
trainer/QF1 Loss                              8.64489
trainer/QF2 Loss                              5.87456
trainer/Policy Loss                        -320.47
trainer/Q1 Predictions Mean                 320.785
trainer/Q1 Predictions Std                  108.303
trainer/Q1 Predictions Max                  414.297
trainer/Q1 Predictions Min                   17.6737
trainer/Q2 Predictions Mean                 321.052
trainer/Q2 Predictions Std                  108.359
trainer/Q2 Predictions Max                  416.091
trainer/Q2 Predictions Min                   17.7901
trainer/Q Targets Mean                      321.275
trainer/Q Targets Std                       108.405
trainer/Q Targets Max                       417.542
trainer/Q Targets Min                        18.5335
trainer/Log Pis Mean                          5.77222
trainer/Log Pis Std                           4.87626
trainer/Log Pis Max                          18.863
trainer/Log Pis Min                          -5.3506
trainer/policy/mean Mean                      0.0635949
trainer/policy/mean Std                       0.7627
trainer/policy/mean Max                       0.995656
trainer/policy/mean Min                      -0.998359
trainer/policy/normal/std Mean                0.45298
trainer/policy/normal/std Std                 0.147638
trainer/policy/normal/std Max                 1.03051
trainer/policy/normal/std Min                 0.0733426
trainer/policy/normal/log_std Mean           -0.8596
trainer/policy/normal/log_std Std             0.401549
trainer/policy/normal/log_std Max             0.0300576
trainer/policy/normal/log_std Min            -2.61261
trainer/Alpha                                 0.121455
trainer/Alpha Loss                           -0.480207
expl/num steps total                     228000
expl/num paths total                        228
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.32983
expl/Rewards Std                              1.24063
expl/Rewards Max                              7.72966
expl/Rewards Min                             -0.717413
expl/Returns Mean                          5329.83
expl/Returns Std                              0
expl/Returns Max                           5329.83
expl/Returns Min                           5329.83
expl/Actions Mean                             0.0748498
expl/Actions Std                              0.810656
expl/Actions Max                              0.999204
expl/Actions Min                             -0.998943
expl/Num Paths                                1
expl/Average Returns                       5329.83
expl/env_infos/final/reward_run Mean          5.58778
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.58778
expl/env_infos/final/reward_run Min           5.58778
expl/env_infos/initial/reward_run Mean       -0.356028
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.356028
expl/env_infos/initial/reward_run Min        -0.356028
expl/env_infos/reward_run Mean                5.72749
expl/env_infos/reward_run Std                 1.22063
expl/env_infos/reward_run Max                 8.22031
expl/env_infos/reward_run Min                -0.356028
expl/env_infos/final/reward_ctrl Mean        -0.405084
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.405084
expl/env_infos/final/reward_ctrl Min         -0.405084
expl/env_infos/initial/reward_ctrl Mean      -0.309006
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.309006
expl/env_infos/initial/reward_ctrl Min       -0.309006
expl/env_infos/reward_ctrl Mean              -0.39766
expl/env_infos/reward_ctrl Std                0.0921022
expl/env_infos/reward_ctrl Max               -0.0832708
expl/env_infos/reward_ctrl Min               -0.58311
eval/num steps total                          1.135e+06
eval/num paths total                       1135
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.60058
eval/Rewards Std                              1.27793
eval/Rewards Max                              8.07995
eval/Rewards Min                             -0.68108
eval/Returns Mean                          5600.58
eval/Returns Std                             64.1241
eval/Returns Max                           5698.59
eval/Returns Min                           5533.13
eval/Actions Mean                             0.0893163
eval/Actions Std                              0.821714
eval/Actions Max                              0.997705
eval/Actions Min                             -0.99724
eval/Num Paths                                5
eval/Average Returns                       5600.58
eval/env_infos/final/reward_run Mean          5.53805
eval/env_infos/final/reward_run Std           0.551383
eval/env_infos/final/reward_run Max           6.31275
eval/env_infos/final/reward_run Min           4.8407
eval/env_infos/initial/reward_run Mean       -0.264484
eval/env_infos/initial/reward_run Std         0.133473
eval/env_infos/initial/reward_run Max        -0.061889
eval/env_infos/initial/reward_run Min        -0.448522
eval/env_infos/reward_run Mean                6.0105
eval/env_infos/reward_run Std                 1.25375
eval/env_infos/reward_run Max                 8.55998
eval/env_infos/reward_run Min                -0.448522
eval/env_infos/final/reward_ctrl Mean        -0.485101
eval/env_infos/final/reward_ctrl Std          0.0412312
eval/env_infos/final/reward_ctrl Max         -0.426684
eval/env_infos/final/reward_ctrl Min         -0.529723
eval/env_infos/initial/reward_ctrl Mean      -0.25897
eval/env_infos/initial/reward_ctrl Std        0.058047
eval/env_infos/initial/reward_ctrl Max       -0.214075
eval/env_infos/initial/reward_ctrl Min       -0.372729
eval/env_infos/reward_ctrl Mean              -0.409915
eval/env_infos/reward_ctrl Std                0.0924497
eval/env_infos/reward_ctrl Max               -0.10342
eval/env_infos/reward_ctrl Min               -0.585518
time/data storing (s)                         0.00453482
time/evaluation sampling (s)                  2.00511
time/exploration sampling (s)                 0.52659
time/logging (s)                              0.0138122
time/sac training (s)                         7.37288
time/saving (s)                               0.00375773
time/training (s)                             3.4419e-05
time/epoch (s)                                9.92671
time/total (s)                             2433.92
Epoch                                       226
---------------------------------------  ---------------
2021-11-24 01:09:57.680220 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 227 finished
---------------------------------------  ---------------
epoch                                       227
replay_buffer/size                       229000
trainer/num train calls                  228000
trainer/QF1 Loss                             10.6603
trainer/QF2 Loss                              7.46131
trainer/Policy Loss                        -332.837
trainer/Q1 Predictions Mean                 333.495
trainer/Q1 Predictions Std                   94.7551
trainer/Q1 Predictions Max                  404.881
trainer/Q1 Predictions Min                   18.5293
trainer/Q2 Predictions Mean                 333.156
trainer/Q2 Predictions Std                   94.6575
trainer/Q2 Predictions Max                  407.001
trainer/Q2 Predictions Min                   18.7532
trainer/Q Targets Mean                      333.32
trainer/Q Targets Std                        94.8936
trainer/Q Targets Max                       408.818
trainer/Q Targets Min                        17.9264
trainer/Log Pis Mean                          6.06326
trainer/Log Pis Std                           4.73244
trainer/Log Pis Max                          17.0375
trainer/Log Pis Min                          -6.99009
trainer/policy/mean Mean                      0.0764216
trainer/policy/mean Std                       0.772311
trainer/policy/mean Max                       0.998067
trainer/policy/mean Min                      -0.998519
trainer/policy/normal/std Mean                0.442338
trainer/policy/normal/std Std                 0.144263
trainer/policy/normal/std Max                 0.932939
trainer/policy/normal/std Min                 0.0781519
trainer/policy/normal/log_std Mean           -0.88207
trainer/policy/normal/log_std Std             0.394847
trainer/policy/normal/log_std Max            -0.0694156
trainer/policy/normal/log_std Min            -2.5491
trainer/Alpha                                 0.121679
trainer/Alpha Loss                            0.133252
expl/num steps total                     229000
expl/num paths total                        229
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.26366
expl/Rewards Std                              1.2144
expl/Rewards Max                              7.49093
expl/Rewards Min                             -0.51375
expl/Returns Mean                          5263.66
expl/Returns Std                              0
expl/Returns Max                           5263.66
expl/Returns Min                           5263.66
expl/Actions Mean                             0.114937
expl/Actions Std                              0.801084
expl/Actions Max                              0.999717
expl/Actions Min                             -0.999419
expl/Num Paths                                1
expl/Average Returns                       5263.66
expl/env_infos/final/reward_run Mean          5.4894
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.4894
expl/env_infos/final/reward_run Min           5.4894
expl/env_infos/initial/reward_run Mean       -0.152312
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.152312
expl/env_infos/initial/reward_run Min        -0.152312
expl/env_infos/reward_run Mean                5.65663
expl/env_infos/reward_run Std                 1.20316
expl/env_infos/reward_run Max                 7.91771
expl/env_infos/reward_run Min                -0.152312
expl/env_infos/final/reward_ctrl Mean        -0.369421
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.369421
expl/env_infos/final/reward_ctrl Min         -0.369421
expl/env_infos/initial/reward_ctrl Mean      -0.292041
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.292041
expl/env_infos/initial/reward_ctrl Min       -0.292041
expl/env_infos/reward_ctrl Mean              -0.392967
expl/env_infos/reward_ctrl Std                0.0919887
expl/env_infos/reward_ctrl Max               -0.0941688
expl/env_infos/reward_ctrl Min               -0.584743
eval/num steps total                          1.14e+06
eval/num paths total                       1140
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.46946
eval/Rewards Std                              1.24294
eval/Rewards Max                              7.92382
eval/Rewards Min                             -0.923334
eval/Returns Mean                          5469.46
eval/Returns Std                             87.0675
eval/Returns Max                           5591.27
eval/Returns Min                           5324.64
eval/Actions Mean                             0.119309
eval/Actions Std                              0.812872
eval/Actions Max                              0.99766
eval/Actions Min                             -0.998093
eval/Num Paths                                5
eval/Average Returns                       5469.46
eval/env_infos/final/reward_run Mean          6.1878
eval/env_infos/final/reward_run Std           0.961447
eval/env_infos/final/reward_run Max           7.35254
eval/env_infos/final/reward_run Min           4.85586
eval/env_infos/initial/reward_run Mean       -0.46212
eval/env_infos/initial/reward_run Std         0.0563729
eval/env_infos/initial/reward_run Max        -0.374536
eval/env_infos/initial/reward_run Min        -0.527894
eval/env_infos/reward_run Mean                5.87446
eval/env_infos/reward_run Std                 1.2292
eval/env_infos/reward_run Max                 8.41236
eval/env_infos/reward_run Min                -0.527894
eval/env_infos/final/reward_ctrl Mean        -0.386405
eval/env_infos/final/reward_ctrl Std          0.0667803
eval/env_infos/final/reward_ctrl Max         -0.296115
eval/env_infos/final/reward_ctrl Min         -0.462363
eval/env_infos/initial/reward_ctrl Mean      -0.348404
eval/env_infos/initial/reward_ctrl Std        0.0409889
eval/env_infos/initial/reward_ctrl Max       -0.282591
eval/env_infos/initial/reward_ctrl Min       -0.39544
eval/env_infos/reward_ctrl Mean              -0.404998
eval/env_infos/reward_ctrl Std                0.0910925
eval/env_infos/reward_ctrl Max               -0.088703
eval/env_infos/reward_ctrl Min               -0.579174
time/data storing (s)                         0.00451367
time/evaluation sampling (s)                  1.99479
time/exploration sampling (s)                 0.527833
time/logging (s)                              0.0136031
time/sac training (s)                         7.37225
time/saving (s)                               0.00374741
time/training (s)                             3.4351e-05
time/epoch (s)                                9.91678
time/total (s)                             2444.11
Epoch                                       227
---------------------------------------  ---------------
2021-11-24 01:10:07.933643 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 228 finished
---------------------------------------  ----------------
epoch                                       228
replay_buffer/size                       230000
trainer/num train calls                  229000
trainer/QF1 Loss                              8.68644
trainer/QF2 Loss                              6.80613
trainer/Policy Loss                        -328.058
trainer/Q1 Predictions Mean                 328.729
trainer/Q1 Predictions Std                  110.841
trainer/Q1 Predictions Max                  417.067
trainer/Q1 Predictions Min                   17.2049
trainer/Q2 Predictions Mean                 328.463
trainer/Q2 Predictions Std                  110.828
trainer/Q2 Predictions Max                  418.124
trainer/Q2 Predictions Min                   16.536
trainer/Q Targets Mean                      328.172
trainer/Q Targets Std                       110.614
trainer/Q Targets Max                       416.941
trainer/Q Targets Min                        16.971
trainer/Log Pis Mean                          5.71912
trainer/Log Pis Std                           4.33904
trainer/Log Pis Max                          16.5647
trainer/Log Pis Min                          -5.61929
trainer/policy/mean Mean                      0.0823243
trainer/policy/mean Std                       0.761344
trainer/policy/mean Max                       0.996193
trainer/policy/mean Min                      -0.998597
trainer/policy/normal/std Mean                0.44469
trainer/policy/normal/std Std                 0.151491
trainer/policy/normal/std Max                 0.923345
trainer/policy/normal/std Min                 0.0732828
trainer/policy/normal/log_std Mean           -0.884965
trainer/policy/normal/log_std Std             0.422817
trainer/policy/normal/log_std Max            -0.0797523
trainer/policy/normal/log_std Min            -2.61343
trainer/Alpha                                 0.121537
trainer/Alpha Loss                           -0.59197
expl/num steps total                     230000
expl/num paths total                        230
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.27722
expl/Rewards Std                              1.19936
expl/Rewards Max                              7.54786
expl/Rewards Min                             -0.639611
expl/Returns Mean                          5277.22
expl/Returns Std                              0
expl/Returns Max                           5277.22
expl/Returns Min                           5277.22
expl/Actions Mean                             0.0835265
expl/Actions Std                              0.806383
expl/Actions Max                              0.999392
expl/Actions Min                             -0.999575
expl/Num Paths                                1
expl/Average Returns                       5277.22
expl/env_infos/final/reward_run Mean          7.9003
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.9003
expl/env_infos/final/reward_run Min           7.9003
expl/env_infos/initial/reward_run Mean       -0.30656
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.30656
expl/env_infos/initial/reward_run Min        -0.30656
expl/env_infos/reward_run Mean                5.67156
expl/env_infos/reward_run Std                 1.19093
expl/env_infos/reward_run Max                 8.00366
expl/env_infos/reward_run Min                -0.30656
expl/env_infos/final/reward_ctrl Mean        -0.393431
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.393431
expl/env_infos/final/reward_ctrl Min         -0.393431
expl/env_infos/initial/reward_ctrl Mean      -0.333052
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.333052
expl/env_infos/initial/reward_ctrl Min       -0.333052
expl/env_infos/reward_ctrl Mean              -0.394338
expl/env_infos/reward_ctrl Std                0.0885566
expl/env_infos/reward_ctrl Max               -0.0923232
expl/env_infos/reward_ctrl Min               -0.577339
eval/num steps total                          1.145e+06
eval/num paths total                       1145
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.59984
eval/Rewards Std                              1.25435
eval/Rewards Max                              7.97211
eval/Rewards Min                             -0.911028
eval/Returns Mean                          5599.84
eval/Returns Std                             34.7058
eval/Returns Max                           5656
eval/Returns Min                           5549.39
eval/Actions Mean                             0.108528
eval/Actions Std                              0.815854
eval/Actions Max                              0.999457
eval/Actions Min                             -0.999224
eval/Num Paths                                5
eval/Average Returns                       5599.84
eval/env_infos/final/reward_run Mean          6.03312
eval/env_infos/final/reward_run Std           0.638895
eval/env_infos/final/reward_run Max           7.15155
eval/env_infos/final/reward_run Min           5.39147
eval/env_infos/initial/reward_run Mean       -0.267912
eval/env_infos/initial/reward_run Std         0.165416
eval/env_infos/initial/reward_run Max        -0.0582961
eval/env_infos/initial/reward_run Min        -0.523581
eval/env_infos/reward_run Mean                6.00628
eval/env_infos/reward_run Std                 1.23988
eval/env_infos/reward_run Max                 8.4568
eval/env_infos/reward_run Min                -0.523581
eval/env_infos/final/reward_ctrl Mean        -0.424952
eval/env_infos/final/reward_ctrl Std          0.0225965
eval/env_infos/final/reward_ctrl Max         -0.400819
eval/env_infos/final/reward_ctrl Min         -0.465099
eval/env_infos/initial/reward_ctrl Mean      -0.287016
eval/env_infos/initial/reward_ctrl Std        0.0546295
eval/env_infos/initial/reward_ctrl Max       -0.224916
eval/env_infos/initial/reward_ctrl Min       -0.387447
eval/env_infos/reward_ctrl Mean              -0.406437
eval/env_infos/reward_ctrl Std                0.0882698
eval/env_infos/reward_ctrl Max               -0.0328311
eval/env_infos/reward_ctrl Min               -0.580303
time/data storing (s)                         0.00449924
time/evaluation sampling (s)                  2.01184
time/exploration sampling (s)                 0.530728
time/logging (s)                              0.0135928
time/sac training (s)                         7.40204
time/saving (s)                               0.00375424
time/training (s)                             3.44311e-05
time/epoch (s)                                9.96649
time/total (s)                             2454.35
Epoch                                       228
---------------------------------------  ----------------
2021-11-24 01:10:18.154915 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 229 finished
---------------------------------------  ---------------
epoch                                       229
replay_buffer/size                       231000
trainer/num train calls                  230000
trainer/QF1 Loss                              6.37275
trainer/QF2 Loss                              5.87158
trainer/Policy Loss                        -331.111
trainer/Q1 Predictions Mean                 331.521
trainer/Q1 Predictions Std                  106.439
trainer/Q1 Predictions Max                  413.32
trainer/Q1 Predictions Min                   13.2339
trainer/Q2 Predictions Mean                 331.534
trainer/Q2 Predictions Std                  106.409
trainer/Q2 Predictions Max                  412.373
trainer/Q2 Predictions Min                   17.0932
trainer/Q Targets Mean                      331.539
trainer/Q Targets Std                       106.341
trainer/Q Targets Max                       412.067
trainer/Q Targets Min                        17.4149
trainer/Log Pis Mean                          5.97478
trainer/Log Pis Std                           4.84113
trainer/Log Pis Max                          18.3822
trainer/Log Pis Min                          -6.48784
trainer/policy/mean Mean                      0.104655
trainer/policy/mean Std                       0.769267
trainer/policy/mean Max                       0.998062
trainer/policy/mean Min                      -0.998831
trainer/policy/normal/std Mean                0.441288
trainer/policy/normal/std Std                 0.143756
trainer/policy/normal/std Max                 0.976004
trainer/policy/normal/std Min                 0.073244
trainer/policy/normal/log_std Mean           -0.884529
trainer/policy/normal/log_std Std             0.396007
trainer/policy/normal/log_std Max            -0.0242886
trainer/policy/normal/log_std Min            -2.61396
trainer/Alpha                                 0.122149
trainer/Alpha Loss                           -0.0530153
expl/num steps total                     231000
expl/num paths total                        231
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.16646
expl/Rewards Std                              1.4124
expl/Rewards Max                              7.74572
expl/Rewards Min                             -0.860001
expl/Returns Mean                          5166.46
expl/Returns Std                              0
expl/Returns Max                           5166.46
expl/Returns Min                           5166.46
expl/Actions Mean                             0.0670469
expl/Actions Std                              0.800592
expl/Actions Max                              0.999529
expl/Actions Min                             -0.999949
expl/Num Paths                                1
expl/Average Returns                       5166.46
expl/env_infos/final/reward_run Mean          4.40589
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.40589
expl/env_infos/final/reward_run Min           4.40589
expl/env_infos/initial/reward_run Mean       -0.428787
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.428787
expl/env_infos/initial/reward_run Min        -0.428787
expl/env_infos/reward_run Mean                5.55373
expl/env_infos/reward_run Std                 1.41175
expl/env_infos/reward_run Max                 8.25873
expl/env_infos/reward_run Min                -0.428787
expl/env_infos/final/reward_ctrl Mean        -0.515874
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.515874
expl/env_infos/final/reward_ctrl Min         -0.515874
expl/env_infos/initial/reward_ctrl Mean      -0.431214
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.431214
expl/env_infos/initial/reward_ctrl Min       -0.431214
expl/env_infos/reward_ctrl Mean              -0.387265
expl/env_infos/reward_ctrl Std                0.0952467
expl/env_infos/reward_ctrl Max               -0.0833827
expl/env_infos/reward_ctrl Min               -0.575248
eval/num steps total                          1.15e+06
eval/num paths total                       1150
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.63689
eval/Rewards Std                              1.2729
eval/Rewards Max                              8.10101
eval/Rewards Min                             -0.962368
eval/Returns Mean                          5636.89
eval/Returns Std                             93.9582
eval/Returns Max                           5760.88
eval/Returns Min                           5503.95
eval/Actions Mean                             0.0848546
eval/Actions Std                              0.818412
eval/Actions Max                              0.998904
eval/Actions Min                             -0.997446
eval/Num Paths                                5
eval/Average Returns                       5636.89
eval/env_infos/final/reward_run Mean          5.81975
eval/env_infos/final/reward_run Std           0.941615
eval/env_infos/final/reward_run Max           7.20514
eval/env_infos/final/reward_run Min           4.28618
eval/env_infos/initial/reward_run Mean       -0.393586
eval/env_infos/initial/reward_run Std         0.129429
eval/env_infos/initial/reward_run Max        -0.257164
eval/env_infos/initial/reward_run Min        -0.596508
eval/env_infos/reward_run Mean                6.04309
eval/env_infos/reward_run Std                 1.26012
eval/env_infos/reward_run Max                 8.60717
eval/env_infos/reward_run Min                -0.596508
eval/env_infos/final/reward_ctrl Mean        -0.41262
eval/env_infos/final/reward_ctrl Std          0.100329
eval/env_infos/final/reward_ctrl Max         -0.228646
eval/env_infos/final/reward_ctrl Min         -0.516445
eval/env_infos/initial/reward_ctrl Mean      -0.316517
eval/env_infos/initial/reward_ctrl Std        0.0324545
eval/env_infos/initial/reward_ctrl Max       -0.27946
eval/env_infos/initial/reward_ctrl Min       -0.36586
eval/env_infos/reward_ctrl Mean              -0.406199
eval/env_infos/reward_ctrl Std                0.0930063
eval/env_infos/reward_ctrl Max               -0.116144
eval/env_infos/reward_ctrl Min               -0.585716
time/data storing (s)                         0.00448651
time/evaluation sampling (s)                  2.00321
time/exploration sampling (s)                 0.531436
time/logging (s)                              0.0137507
time/sac training (s)                         7.3781
time/saving (s)                               0.00373958
time/training (s)                             3.388e-05
time/epoch (s)                                9.93476
time/total (s)                             2464.56
Epoch                                       229
---------------------------------------  ---------------
2021-11-24 01:10:28.471573 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 230 finished
---------------------------------------  ---------------
epoch                                       230
replay_buffer/size                       232000
trainer/num train calls                  231000
trainer/QF1 Loss                              8.85055
trainer/QF2 Loss                              8.69375
trainer/Policy Loss                        -339.985
trainer/Q1 Predictions Mean                 340.387
trainer/Q1 Predictions Std                   97.7385
trainer/Q1 Predictions Max                  417.448
trainer/Q1 Predictions Min                   19.1741
trainer/Q2 Predictions Mean                 340.736
trainer/Q2 Predictions Std                   97.8754
trainer/Q2 Predictions Max                  417.857
trainer/Q2 Predictions Min                   19.0286
trainer/Q Targets Mean                      340.255
trainer/Q Targets Std                        97.9356
trainer/Q Targets Max                       419.137
trainer/Q Targets Min                        18.9902
trainer/Log Pis Mean                          6.60161
trainer/Log Pis Std                           4.8279
trainer/Log Pis Max                          16.7312
trainer/Log Pis Min                          -7.17932
trainer/policy/mean Mean                      0.0818917
trainer/policy/mean Std                       0.778255
trainer/policy/mean Max                       0.998485
trainer/policy/mean Min                      -0.996465
trainer/policy/normal/std Mean                0.44766
trainer/policy/normal/std Std                 0.145065
trainer/policy/normal/std Max                 1.05939
trainer/policy/normal/std Min                 0.0628385
trainer/policy/normal/log_std Mean           -0.871081
trainer/policy/normal/log_std Std             0.401298
trainer/policy/normal/log_std Max             0.0576977
trainer/policy/normal/log_std Min            -2.76719
trainer/Alpha                                 0.122537
trainer/Alpha Loss                            1.26297
expl/num steps total                     232000
expl/num paths total                        232
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33992
expl/Rewards Std                              1.19885
expl/Rewards Max                              7.73778
expl/Rewards Min                             -0.70901
expl/Returns Mean                          5339.92
expl/Returns Std                              0
expl/Returns Max                           5339.92
expl/Returns Min                           5339.92
expl/Actions Mean                             0.0933215
expl/Actions Std                              0.806671
expl/Actions Max                              0.999699
expl/Actions Min                             -0.999354
expl/Num Paths                                1
expl/Average Returns                       5339.92
expl/env_infos/final/reward_run Mean          6.90038
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.90038
expl/env_infos/final/reward_run Min           6.90038
expl/env_infos/initial/reward_run Mean        0.152328
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.152328
expl/env_infos/initial/reward_run Min         0.152328
expl/env_infos/reward_run Mean                5.73557
expl/env_infos/reward_run Std                 1.18988
expl/env_infos/reward_run Max                 8.21322
expl/env_infos/reward_run Min                -0.36773
expl/env_infos/final/reward_ctrl Mean        -0.402036
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.402036
expl/env_infos/final/reward_ctrl Min         -0.402036
expl/env_infos/initial/reward_ctrl Mean      -0.291008
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.291008
expl/env_infos/initial/reward_ctrl Min       -0.291008
expl/env_infos/reward_ctrl Mean              -0.395656
expl/env_infos/reward_ctrl Std                0.0886618
expl/env_infos/reward_ctrl Max               -0.109738
expl/env_infos/reward_ctrl Min               -0.580548
eval/num steps total                          1.155e+06
eval/num paths total                       1155
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.55954
eval/Rewards Std                              1.25011
eval/Rewards Max                              8.16372
eval/Rewards Min                             -0.698684
eval/Returns Mean                          5559.54
eval/Returns Std                            127.363
eval/Returns Max                           5701.24
eval/Returns Min                           5370.66
eval/Actions Mean                             0.10709
eval/Actions Std                              0.81843
eval/Actions Max                              0.998801
eval/Actions Min                             -0.997813
eval/Num Paths                                5
eval/Average Returns                       5559.54
eval/env_infos/final/reward_run Mean          6.17899
eval/env_infos/final/reward_run Std           1.00779
eval/env_infos/final/reward_run Max           7.41512
eval/env_infos/final/reward_run Min           4.78307
eval/env_infos/initial/reward_run Mean       -0.220449
eval/env_infos/initial/reward_run Std         0.115735
eval/env_infos/initial/reward_run Max        -0.108398
eval/env_infos/initial/reward_run Min        -0.393391
eval/env_infos/reward_run Mean                5.96831
eval/env_infos/reward_run Std                 1.23303
eval/env_infos/reward_run Max                 8.65359
eval/env_infos/reward_run Min                -0.393391
eval/env_infos/final/reward_ctrl Mean        -0.43537
eval/env_infos/final/reward_ctrl Std          0.0343859
eval/env_infos/final/reward_ctrl Max         -0.395599
eval/env_infos/final/reward_ctrl Min         -0.477383
eval/env_infos/initial/reward_ctrl Mean      -0.244147
eval/env_infos/initial/reward_ctrl Std        0.0535485
eval/env_infos/initial/reward_ctrl Max       -0.162142
eval/env_infos/initial/reward_ctrl Min       -0.305294
eval/env_infos/reward_ctrl Mean              -0.408778
eval/env_infos/reward_ctrl Std                0.0854978
eval/env_infos/reward_ctrl Max               -0.113593
eval/env_infos/reward_ctrl Min               -0.58269
time/data storing (s)                         0.00452291
time/evaluation sampling (s)                  2.02271
time/exploration sampling (s)                 0.530816
time/logging (s)                              0.0137773
time/sac training (s)                         7.45214
time/saving (s)                               0.00378036
time/training (s)                             3.45e-05
time/epoch (s)                               10.0278
time/total (s)                             2474.87
Epoch                                       230
---------------------------------------  ---------------
2021-11-24 01:10:38.732696 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 231 finished
---------------------------------------  ---------------
epoch                                       231
replay_buffer/size                       233000
trainer/num train calls                  232000
trainer/QF1 Loss                              6.48186
trainer/QF2 Loss                              6.50108
trainer/Policy Loss                        -341.608
trainer/Q1 Predictions Mean                 342.044
trainer/Q1 Predictions Std                   91.2064
trainer/Q1 Predictions Max                  419.107
trainer/Q1 Predictions Min                   19.0093
trainer/Q2 Predictions Mean                 342.117
trainer/Q2 Predictions Std                   91.2374
trainer/Q2 Predictions Max                  419.858
trainer/Q2 Predictions Min                   18.9981
trainer/Q Targets Mean                      341.645
trainer/Q Targets Std                        91.2332
trainer/Q Targets Max                       419.469
trainer/Q Targets Min                        17.7831
trainer/Log Pis Mean                          5.99151
trainer/Log Pis Std                           4.47922
trainer/Log Pis Max                          17.4102
trainer/Log Pis Min                          -5.81129
trainer/policy/mean Mean                      0.0768179
trainer/policy/mean Std                       0.768507
trainer/policy/mean Max                       0.999431
trainer/policy/mean Min                      -0.997418
trainer/policy/normal/std Mean                0.430308
trainer/policy/normal/std Std                 0.139384
trainer/policy/normal/std Max                 0.990536
trainer/policy/normal/std Min                 0.0668054
trainer/policy/normal/log_std Mean           -0.909984
trainer/policy/normal/log_std Std             0.397229
trainer/policy/normal/log_std Max            -0.00950873
trainer/policy/normal/log_std Min            -2.70597
trainer/Alpha                                 0.122898
trainer/Alpha Loss                           -0.0177924
expl/num steps total                     233000
expl/num paths total                        233
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33917
expl/Rewards Std                              1.20187
expl/Rewards Max                              7.4693
expl/Rewards Min                             -0.758947
expl/Returns Mean                          5339.17
expl/Returns Std                              0
expl/Returns Max                           5339.17
expl/Returns Min                           5339.17
expl/Actions Mean                             0.0889289
expl/Actions Std                              0.802519
expl/Actions Max                              0.99984
expl/Actions Min                             -0.999253
expl/Num Paths                                1
expl/Average Returns                       5339.17
expl/env_infos/final/reward_run Mean          5.75286
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.75286
expl/env_infos/final/reward_run Min           5.75286
expl/env_infos/initial/reward_run Mean       -0.398974
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.398974
expl/env_infos/initial/reward_run Min        -0.398974
expl/env_infos/reward_run Mean                5.73033
expl/env_infos/reward_run Std                 1.19464
expl/env_infos/reward_run Max                 7.91311
expl/env_infos/reward_run Min                -0.398974
expl/env_infos/final/reward_ctrl Mean        -0.341565
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.341565
expl/env_infos/final/reward_ctrl Min         -0.341565
expl/env_infos/initial/reward_ctrl Mean      -0.359973
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.359973
expl/env_infos/initial/reward_ctrl Min       -0.359973
expl/env_infos/reward_ctrl Mean              -0.391167
expl/env_infos/reward_ctrl Std                0.0913598
expl/env_infos/reward_ctrl Max               -0.110677
expl/env_infos/reward_ctrl Min               -0.581664
eval/num steps total                          1.16e+06
eval/num paths total                       1160
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.54488
eval/Rewards Std                              1.23113
eval/Rewards Max                              8.12422
eval/Rewards Min                             -0.893097
eval/Returns Mean                          5544.88
eval/Returns Std                             40.0079
eval/Returns Max                           5622
eval/Returns Min                           5505.19
eval/Actions Mean                             0.0984993
eval/Actions Std                              0.816048
eval/Actions Max                              0.999027
eval/Actions Min                             -0.995964
eval/Num Paths                                5
eval/Average Returns                       5544.88
eval/env_infos/final/reward_run Mean          6.30048
eval/env_infos/final/reward_run Std           0.764471
eval/env_infos/final/reward_run Max           7.06155
eval/env_infos/final/reward_run Min           5.14214
eval/env_infos/initial/reward_run Mean       -0.418612
eval/env_infos/initial/reward_run Std         0.106327
eval/env_infos/initial/reward_run Max        -0.312432
eval/env_infos/initial/reward_run Min        -0.617813
eval/env_infos/reward_run Mean                5.95026
eval/env_infos/reward_run Std                 1.21896
eval/env_infos/reward_run Max                 8.60503
eval/env_infos/reward_run Min                -0.617813
eval/env_infos/final/reward_ctrl Mean        -0.430641
eval/env_infos/final/reward_ctrl Std          0.110457
eval/env_infos/final/reward_ctrl Max         -0.241304
eval/env_infos/final/reward_ctrl Min         -0.571808
eval/env_infos/initial/reward_ctrl Mean      -0.286922
eval/env_infos/initial/reward_ctrl Std        0.0623957
eval/env_infos/initial/reward_ctrl Max       -0.179394
eval/env_infos/initial/reward_ctrl Min       -0.371474
eval/env_infos/reward_ctrl Mean              -0.405382
eval/env_infos/reward_ctrl Std                0.0888593
eval/env_infos/reward_ctrl Max               -0.120954
eval/env_infos/reward_ctrl Min               -0.585258
time/data storing (s)                         0.00444399
time/evaluation sampling (s)                  2.05567
time/exploration sampling (s)                 0.534933
time/logging (s)                              0.0137957
time/sac training (s)                         7.35988
time/saving (s)                               0.00377334
time/training (s)                             3.4012e-05
time/epoch (s)                                9.97253
time/total (s)                             2485.11
Epoch                                       231
---------------------------------------  ---------------
2021-11-24 01:10:48.943355 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 232 finished
---------------------------------------  ---------------
epoch                                       232
replay_buffer/size                       234000
trainer/num train calls                  233000
trainer/QF1 Loss                              7.0636
trainer/QF2 Loss                              5.62153
trainer/Policy Loss                        -340.055
trainer/Q1 Predictions Mean                 340.613
trainer/Q1 Predictions Std                   94.4627
trainer/Q1 Predictions Max                  419.978
trainer/Q1 Predictions Min                   18.5156
trainer/Q2 Predictions Mean                 340.441
trainer/Q2 Predictions Std                   94.5022
trainer/Q2 Predictions Max                  417.93
trainer/Q2 Predictions Min                   17.6778
trainer/Q Targets Mean                      340.486
trainer/Q Targets Std                        94.48
trainer/Q Targets Max                       418.08
trainer/Q Targets Min                        17.1899
trainer/Log Pis Mean                          6.02138
trainer/Log Pis Std                           4.75282
trainer/Log Pis Max                          17.6251
trainer/Log Pis Min                          -6.53272
trainer/policy/mean Mean                      0.0541966
trainer/policy/mean Std                       0.777737
trainer/policy/mean Max                       0.996672
trainer/policy/mean Min                      -0.998139
trainer/policy/normal/std Mean                0.449344
trainer/policy/normal/std Std                 0.15005
trainer/policy/normal/std Max                 0.980259
trainer/policy/normal/std Min                 0.0742153
trainer/policy/normal/log_std Mean           -0.871093
trainer/policy/normal/log_std Std             0.412145
trainer/policy/normal/log_std Max            -0.0199388
trainer/policy/normal/log_std Min            -2.60078
trainer/Alpha                                 0.12309
trainer/Alpha Loss                            0.04478
expl/num steps total                     234000
expl/num paths total                        234
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.39538
expl/Rewards Std                              1.20649
expl/Rewards Max                              7.72694
expl/Rewards Min                             -0.505049
expl/Returns Mean                          5395.38
expl/Returns Std                              0
expl/Returns Max                           5395.38
expl/Returns Min                           5395.38
expl/Actions Mean                             0.0656042
expl/Actions Std                              0.807809
expl/Actions Max                              0.999252
expl/Actions Min                             -0.999475
expl/Num Paths                                1
expl/Average Returns                       5395.38
expl/env_infos/final/reward_run Mean          5.52127
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.52127
expl/env_infos/final/reward_run Min           5.52127
expl/env_infos/initial/reward_run Mean       -0.230056
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.230056
expl/env_infos/initial/reward_run Min        -0.230056
expl/env_infos/reward_run Mean                5.7895
expl/env_infos/reward_run Std                 1.19894
expl/env_infos/reward_run Max                 8.23018
expl/env_infos/reward_run Min                -0.230056
expl/env_infos/final/reward_ctrl Mean        -0.445419
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.445419
expl/env_infos/final/reward_ctrl Min         -0.445419
expl/env_infos/initial/reward_ctrl Mean      -0.274993
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.274993
expl/env_infos/initial/reward_ctrl Min       -0.274993
expl/env_infos/reward_ctrl Mean              -0.394116
expl/env_infos/reward_ctrl Std                0.0917643
expl/env_infos/reward_ctrl Max               -0.0727818
expl/env_infos/reward_ctrl Min               -0.583952
eval/num steps total                          1.165e+06
eval/num paths total                       1165
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.69403
eval/Rewards Std                              1.25873
eval/Rewards Max                              8.11633
eval/Rewards Min                             -0.576577
eval/Returns Mean                          5694.03
eval/Returns Std                             63.6718
eval/Returns Max                           5779.54
eval/Returns Min                           5622.13
eval/Actions Mean                             0.0809502
eval/Actions Std                              0.82393
eval/Actions Max                              0.998882
eval/Actions Min                             -0.996631
eval/Num Paths                                5
eval/Average Returns                       5694.03
eval/env_infos/final/reward_run Mean          6.91003
eval/env_infos/final/reward_run Std           0.705851
eval/env_infos/final/reward_run Max           7.6016
eval/env_infos/final/reward_run Min           5.72373
eval/env_infos/initial/reward_run Mean       -0.184238
eval/env_infos/initial/reward_run Std         0.0784989
eval/env_infos/initial/reward_run Max        -0.062016
eval/env_infos/initial/reward_run Min        -0.273984
eval/env_infos/reward_run Mean                6.10528
eval/env_infos/reward_run Std                 1.25021
eval/env_infos/reward_run Max                 8.61824
eval/env_infos/reward_run Min                -0.273984
eval/env_infos/final/reward_ctrl Mean        -0.418814
eval/env_infos/final/reward_ctrl Std          0.055145
eval/env_infos/final/reward_ctrl Max         -0.313386
eval/env_infos/final/reward_ctrl Min         -0.461867
eval/env_infos/initial/reward_ctrl Mean      -0.2805
eval/env_infos/initial/reward_ctrl Std        0.045623
eval/env_infos/initial/reward_ctrl Max       -0.241279
eval/env_infos/initial/reward_ctrl Min       -0.354246
eval/env_infos/reward_ctrl Mean              -0.411248
eval/env_infos/reward_ctrl Std                0.0884679
eval/env_infos/reward_ctrl Max               -0.107416
eval/env_infos/reward_ctrl Min               -0.583297
time/data storing (s)                         0.00445426
time/evaluation sampling (s)                  2.00531
time/exploration sampling (s)                 0.533156
time/logging (s)                              0.0135684
time/sac training (s)                         7.36147
time/saving (s)                               0.00376232
time/training (s)                             3.4326e-05
time/epoch (s)                                9.92176
time/total (s)                             2495.31
Epoch                                       232
---------------------------------------  ---------------
2021-11-24 01:10:59.160500 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 233 finished
---------------------------------------  ---------------
epoch                                       233
replay_buffer/size                       235000
trainer/num train calls                  234000
trainer/QF1 Loss                              7.38044
trainer/QF2 Loss                              5.86747
trainer/Policy Loss                        -338.723
trainer/Q1 Predictions Mean                 339.444
trainer/Q1 Predictions Std                   96.3895
trainer/Q1 Predictions Max                  413.763
trainer/Q1 Predictions Min                   18.2714
trainer/Q2 Predictions Mean                 339.258
trainer/Q2 Predictions Std                   96.4932
trainer/Q2 Predictions Max                  411.504
trainer/Q2 Predictions Min                   18.5843
trainer/Q Targets Mean                      339.106
trainer/Q Targets Std                        96.5115
trainer/Q Targets Max                       412.204
trainer/Q Targets Min                        17.2481
trainer/Log Pis Mean                          6.05118
trainer/Log Pis Std                           4.53385
trainer/Log Pis Max                          19.8672
trainer/Log Pis Min                          -6.89385
trainer/policy/mean Mean                      0.0623938
trainer/policy/mean Std                       0.776228
trainer/policy/mean Max                       0.997272
trainer/policy/mean Min                      -0.997655
trainer/policy/normal/std Mean                0.439097
trainer/policy/normal/std Std                 0.14211
trainer/policy/normal/std Max                 1.19145
trainer/policy/normal/std Min                 0.0748802
trainer/policy/normal/log_std Mean           -0.890615
trainer/policy/normal/log_std Std             0.402499
trainer/policy/normal/log_std Max             0.175171
trainer/policy/normal/log_std Min            -2.59187
trainer/Alpha                                 0.122943
trainer/Alpha Loss                            0.107285
expl/num steps total                     235000
expl/num paths total                        235
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.26881
expl/Rewards Std                              1.19156
expl/Rewards Max                              7.51697
expl/Rewards Min                             -0.984926
expl/Returns Mean                          5268.81
expl/Returns Std                              0
expl/Returns Max                           5268.81
expl/Returns Min                           5268.81
expl/Actions Mean                             0.0878425
expl/Actions Std                              0.804898
expl/Actions Max                              0.999206
expl/Actions Min                             -0.998903
expl/Num Paths                                1
expl/Average Returns                       5268.81
expl/env_infos/final/reward_run Mean          7.17549
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.17549
expl/env_infos/final/reward_run Min           7.17549
expl/env_infos/initial/reward_run Mean       -0.627738
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.627738
expl/env_infos/initial/reward_run Min        -0.627738
expl/env_infos/reward_run Mean                5.66216
expl/env_infos/reward_run Std                 1.18209
expl/env_infos/reward_run Max                 7.97502
expl/env_infos/reward_run Min                -0.627738
expl/env_infos/final/reward_ctrl Mean        -0.477968
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.477968
expl/env_infos/final/reward_ctrl Min         -0.477968
expl/env_infos/initial/reward_ctrl Mean      -0.357188
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.357188
expl/env_infos/initial/reward_ctrl Min       -0.357188
expl/env_infos/reward_ctrl Mean              -0.393346
expl/env_infos/reward_ctrl Std                0.088034
expl/env_infos/reward_ctrl Max               -0.0576508
expl/env_infos/reward_ctrl Min               -0.587123
eval/num steps total                          1.17e+06
eval/num paths total                       1170
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.67106
eval/Rewards Std                              1.25349
eval/Rewards Max                              8.06693
eval/Rewards Min                             -0.814301
eval/Returns Mean                          5671.06
eval/Returns Std                             87.6664
eval/Returns Max                           5776.18
eval/Returns Min                           5564.34
eval/Actions Mean                             0.103312
eval/Actions Std                              0.818309
eval/Actions Max                              0.997864
eval/Actions Min                             -0.995127
eval/Num Paths                                5
eval/Average Returns                       5671.06
eval/env_infos/final/reward_run Mean          5.80753
eval/env_infos/final/reward_run Std           0.507073
eval/env_infos/final/reward_run Max           6.54379
eval/env_infos/final/reward_run Min           4.98537
eval/env_infos/initial/reward_run Mean       -0.24689
eval/env_infos/initial/reward_run Std         0.169906
eval/env_infos/initial/reward_run Max        -0.0339358
eval/env_infos/initial/reward_run Min        -0.482229
eval/env_infos/reward_run Mean                6.07924
eval/env_infos/reward_run Std                 1.24171
eval/env_infos/reward_run Max                 8.54917
eval/env_infos/reward_run Min                -0.482229
eval/env_infos/final/reward_ctrl Mean        -0.443638
eval/env_infos/final/reward_ctrl Std          0.0522722
eval/env_infos/final/reward_ctrl Max         -0.377253
eval/env_infos/final/reward_ctrl Min         -0.520248
eval/env_infos/initial/reward_ctrl Mean      -0.276723
eval/env_infos/initial/reward_ctrl Std        0.0304769
eval/env_infos/initial/reward_ctrl Max       -0.241975
eval/env_infos/initial/reward_ctrl Min       -0.332073
eval/env_infos/reward_ctrl Mean              -0.408182
eval/env_infos/reward_ctrl Std                0.0871779
eval/env_infos/reward_ctrl Max               -0.12939
eval/env_infos/reward_ctrl Min               -0.581709
time/data storing (s)                         0.00451873
time/evaluation sampling (s)                  1.99899
time/exploration sampling (s)                 0.528926
time/logging (s)                              0.0135767
time/sac training (s)                         7.37679
time/saving (s)                               0.00376367
time/training (s)                             3.3519e-05
time/epoch (s)                                9.9266
time/total (s)                             2505.51
Epoch                                       233
---------------------------------------  ---------------
2021-11-24 01:11:09.369478 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 234 finished
---------------------------------------  ---------------
epoch                                       234
replay_buffer/size                       236000
trainer/num train calls                  235000
trainer/QF1 Loss                              9.62692
trainer/QF2 Loss                              8.34081
trainer/Policy Loss                        -336.436
trainer/Q1 Predictions Mean                 336.87
trainer/Q1 Predictions Std                   97.7516
trainer/Q1 Predictions Max                  415.624
trainer/Q1 Predictions Min                   17.7074
trainer/Q2 Predictions Mean                 336.601
trainer/Q2 Predictions Std                   97.6205
trainer/Q2 Predictions Max                  415.966
trainer/Q2 Predictions Min                   17.4832
trainer/Q Targets Mean                      337.615
trainer/Q Targets Std                        97.8295
trainer/Q Targets Max                       417.593
trainer/Q Targets Min                        18.4872
trainer/Log Pis Mean                          5.9104
trainer/Log Pis Std                           4.9726
trainer/Log Pis Max                          17.8359
trainer/Log Pis Min                          -5.98316
trainer/policy/mean Mean                      0.0636517
trainer/policy/mean Std                       0.773662
trainer/policy/mean Max                       0.999887
trainer/policy/mean Min                      -0.997074
trainer/policy/normal/std Mean                0.449903
trainer/policy/normal/std Std                 0.149078
trainer/policy/normal/std Max                 1.37955
trainer/policy/normal/std Min                 0.0739555
trainer/policy/normal/log_std Mean           -0.869432
trainer/policy/normal/log_std Std             0.411519
trainer/policy/normal/log_std Max             0.321758
trainer/policy/normal/log_std Min            -2.60429
trainer/Alpha                                 0.124156
trainer/Alpha Loss                           -0.186915
expl/num steps total                     236000
expl/num paths total                        236
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.23458
expl/Rewards Std                              1.19049
expl/Rewards Max                              7.40924
expl/Rewards Min                             -0.786005
expl/Returns Mean                          5234.58
expl/Returns Std                              0
expl/Returns Max                           5234.58
expl/Returns Min                           5234.58
expl/Actions Mean                             0.0654097
expl/Actions Std                              0.805995
expl/Actions Max                              0.999369
expl/Actions Min                             -0.999289
expl/Num Paths                                1
expl/Average Returns                       5234.58
expl/env_infos/final/reward_run Mean          4.47599
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.47599
expl/env_infos/final/reward_run Min           4.47599
expl/env_infos/initial/reward_run Mean       -0.472799
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.472799
expl/env_infos/initial/reward_run Min        -0.472799
expl/env_infos/reward_run Mean                5.62692
expl/env_infos/reward_run Std                 1.17784
expl/env_infos/reward_run Max                 7.88506
expl/env_infos/reward_run Min                -0.472799
expl/env_infos/final/reward_ctrl Mean        -0.548927
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.548927
expl/env_infos/final/reward_ctrl Min         -0.548927
expl/env_infos/initial/reward_ctrl Mean      -0.313206
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.313206
expl/env_infos/initial/reward_ctrl Min       -0.313206
expl/env_infos/reward_ctrl Mean              -0.392344
expl/env_infos/reward_ctrl Std                0.0959699
expl/env_infos/reward_ctrl Max               -0.10288
expl/env_infos/reward_ctrl Min               -0.579822
eval/num steps total                          1.175e+06
eval/num paths total                       1175
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.6278
eval/Rewards Std                              1.24153
eval/Rewards Max                              8.00635
eval/Rewards Min                             -0.886728
eval/Returns Mean                          5627.8
eval/Returns Std                             32.038
eval/Returns Max                           5663.23
eval/Returns Min                           5586.81
eval/Actions Mean                             0.0856777
eval/Actions Std                              0.824812
eval/Actions Max                              0.998217
eval/Actions Min                             -0.995883
eval/Num Paths                                5
eval/Average Returns                       5627.8
eval/env_infos/final/reward_run Mean          6.8846
eval/env_infos/final/reward_run Std           0.680633
eval/env_infos/final/reward_run Max           7.6018
eval/env_infos/final/reward_run Min           6.02262
eval/env_infos/initial/reward_run Mean       -0.339748
eval/env_infos/initial/reward_run Std         0.136853
eval/env_infos/initial/reward_run Max        -0.194559
eval/env_infos/initial/reward_run Min        -0.536635
eval/env_infos/reward_run Mean                6.04039
eval/env_infos/reward_run Std                 1.22492
eval/env_infos/reward_run Max                 8.49075
eval/env_infos/reward_run Min                -0.536635
eval/env_infos/final/reward_ctrl Mean        -0.435435
eval/env_infos/final/reward_ctrl Std          0.0497251
eval/env_infos/final/reward_ctrl Max         -0.37113
eval/env_infos/final/reward_ctrl Min         -0.494686
eval/env_infos/initial/reward_ctrl Mean      -0.272194
eval/env_infos/initial/reward_ctrl Std        0.0582976
eval/env_infos/initial/reward_ctrl Max       -0.217775
eval/env_infos/initial/reward_ctrl Min       -0.350093
eval/env_infos/reward_ctrl Mean              -0.412594
eval/env_infos/reward_ctrl Std                0.0909159
eval/env_infos/reward_ctrl Max               -0.115046
eval/env_infos/reward_ctrl Min               -0.580826
time/data storing (s)                         0.0045
time/evaluation sampling (s)                  1.9965
time/exploration sampling (s)                 0.533362
time/logging (s)                              0.0137856
time/sac training (s)                         7.36766
time/saving (s)                               0.00375697
time/training (s)                             3.4663e-05
time/epoch (s)                                9.9196
time/total (s)                             2515.71
Epoch                                       234
---------------------------------------  ---------------
2021-11-24 01:11:19.593595 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 235 finished
---------------------------------------  ---------------
epoch                                       235
replay_buffer/size                       237000
trainer/num train calls                  236000
trainer/QF1 Loss                              7.72847
trainer/QF2 Loss                              6.05012
trainer/Policy Loss                        -340.491
trainer/Q1 Predictions Mean                 340.677
trainer/Q1 Predictions Std                   93.4368
trainer/Q1 Predictions Max                  418.521
trainer/Q1 Predictions Min                   20.1462
trainer/Q2 Predictions Mean                 340.912
trainer/Q2 Predictions Std                   93.4692
trainer/Q2 Predictions Max                  416.833
trainer/Q2 Predictions Min                   18.2967
trainer/Q Targets Mean                      341.309
trainer/Q Targets Std                        93.8
trainer/Q Targets Max                       419.937
trainer/Q Targets Min                        18.6125
trainer/Log Pis Mean                          6.43868
trainer/Log Pis Std                           4.7833
trainer/Log Pis Max                          18.256
trainer/Log Pis Min                          -8.01623
trainer/policy/mean Mean                      0.0574725
trainer/policy/mean Std                       0.7801
trainer/policy/mean Max                       0.998029
trainer/policy/mean Min                      -0.997932
trainer/policy/normal/std Mean                0.439742
trainer/policy/normal/std Std                 0.143981
trainer/policy/normal/std Max                 1.33675
trainer/policy/normal/std Min                 0.0761712
trainer/policy/normal/log_std Mean           -0.890027
trainer/policy/normal/log_std Std             0.40444
trainer/policy/normal/log_std Max             0.290239
trainer/policy/normal/log_std Min            -2.57477
trainer/Alpha                                 0.126223
trainer/Alpha Loss                            0.907941
expl/num steps total                     237000
expl/num paths total                        237
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33897
expl/Rewards Std                              1.20037
expl/Rewards Max                              7.85838
expl/Rewards Min                             -1.00403
expl/Returns Mean                          5338.97
expl/Returns Std                              0
expl/Returns Max                           5338.97
expl/Returns Min                           5338.97
expl/Actions Mean                             0.0766371
expl/Actions Std                              0.80244
expl/Actions Max                              0.999529
expl/Actions Min                             -0.999632
expl/Num Paths                                1
expl/Average Returns                       5338.97
expl/env_infos/final/reward_run Mean          5.51585
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.51585
expl/env_infos/final/reward_run Min           5.51585
expl/env_infos/initial/reward_run Mean       -0.648864
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.648864
expl/env_infos/initial/reward_run Min        -0.648864
expl/env_infos/reward_run Mean                5.72884
expl/env_infos/reward_run Std                 1.19284
expl/env_infos/reward_run Max                 8.26284
expl/env_infos/reward_run Min                -0.648864
expl/env_infos/final/reward_ctrl Mean        -0.395158
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.395158
expl/env_infos/final/reward_ctrl Min         -0.395158
expl/env_infos/initial/reward_ctrl Mean      -0.35517
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.35517
expl/env_infos/initial/reward_ctrl Min       -0.35517
expl/env_infos/reward_ctrl Mean              -0.38987
expl/env_infos/reward_ctrl Std                0.0942214
expl/env_infos/reward_ctrl Max               -0.085816
expl/env_infos/reward_ctrl Min               -0.578602
eval/num steps total                          1.18e+06
eval/num paths total                       1180
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.62908
eval/Rewards Std                              1.25911
eval/Rewards Max                              8.06599
eval/Rewards Min                             -0.937993
eval/Returns Mean                          5629.08
eval/Returns Std                             60.3567
eval/Returns Max                           5672.45
eval/Returns Min                           5509.6
eval/Actions Mean                             0.0933023
eval/Actions Std                              0.819163
eval/Actions Max                              0.997697
eval/Actions Min                             -0.997944
eval/Num Paths                                5
eval/Average Returns                       5629.08
eval/env_infos/final/reward_run Mean          6.68558
eval/env_infos/final/reward_run Std           0.696374
eval/env_infos/final/reward_run Max           7.82715
eval/env_infos/final/reward_run Min           5.99712
eval/env_infos/initial/reward_run Mean       -0.429481
eval/env_infos/initial/reward_run Std         0.170905
eval/env_infos/initial/reward_run Max        -0.221871
eval/env_infos/initial/reward_run Min        -0.614295
eval/env_infos/reward_run Mean                6.03692
eval/env_infos/reward_run Std                 1.24525
eval/env_infos/reward_run Max                 8.54638
eval/env_infos/reward_run Min                -0.614295
eval/env_infos/final/reward_ctrl Mean        -0.453788
eval/env_infos/final/reward_ctrl Std          0.0533136
eval/env_infos/final/reward_ctrl Max         -0.363893
eval/env_infos/final/reward_ctrl Min         -0.515759
eval/env_infos/initial/reward_ctrl Mean      -0.30002
eval/env_infos/initial/reward_ctrl Std        0.0386917
eval/env_infos/initial/reward_ctrl Max       -0.233826
eval/env_infos/initial/reward_ctrl Min       -0.35014
eval/env_infos/reward_ctrl Mean              -0.40784
eval/env_infos/reward_ctrl Std                0.0947979
eval/env_infos/reward_ctrl Max               -0.115131
eval/env_infos/reward_ctrl Min               -0.584542
time/data storing (s)                         0.00453194
time/evaluation sampling (s)                  2.00434
time/exploration sampling (s)                 0.533346
time/logging (s)                              0.0137379
time/sac training (s)                         7.37549
time/saving (s)                               0.00377281
time/training (s)                             3.4078e-05
time/epoch (s)                                9.93526
time/total (s)                             2525.92
Epoch                                       235
---------------------------------------  ---------------
2021-11-24 01:11:29.830815 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 236 finished
---------------------------------------  ---------------
epoch                                       236
replay_buffer/size                       238000
trainer/num train calls                  237000
trainer/QF1 Loss                              4.91382
trainer/QF2 Loss                              5.97208
trainer/Policy Loss                        -342.138
trainer/Q1 Predictions Mean                 342.841
trainer/Q1 Predictions Std                   94.7991
trainer/Q1 Predictions Max                  416.634
trainer/Q1 Predictions Min                   17.4305
trainer/Q2 Predictions Mean                 342.616
trainer/Q2 Predictions Std                   94.7683
trainer/Q2 Predictions Max                  416.456
trainer/Q2 Predictions Min                   17.7351
trainer/Q Targets Mean                      342.907
trainer/Q Targets Std                        94.753
trainer/Q Targets Max                       417.796
trainer/Q Targets Min                        15.9808
trainer/Log Pis Mean                          5.90485
trainer/Log Pis Std                           4.75095
trainer/Log Pis Max                          19.21
trainer/Log Pis Min                          -7.28687
trainer/policy/mean Mean                      0.0926337
trainer/policy/mean Std                       0.759603
trainer/policy/mean Max                       0.998411
trainer/policy/mean Min                      -0.999375
trainer/policy/normal/std Mean                0.43927
trainer/policy/normal/std Std                 0.14418
trainer/policy/normal/std Max                 0.920538
trainer/policy/normal/std Min                 0.0802187
trainer/policy/normal/log_std Mean           -0.89267
trainer/policy/normal/log_std Std             0.409339
trainer/policy/normal/log_std Max            -0.0827974
trainer/policy/normal/log_std Min            -2.523
trainer/Alpha                                 0.12413
trainer/Alpha Loss                           -0.198515
expl/num steps total                     238000
expl/num paths total                        238
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.5726
expl/Rewards Std                              1.24921
expl/Rewards Max                              7.86245
expl/Rewards Min                             -0.765534
expl/Returns Mean                          5572.6
expl/Returns Std                              0
expl/Returns Max                           5572.6
expl/Returns Min                           5572.6
expl/Actions Mean                             0.113853
expl/Actions Std                              0.804988
expl/Actions Max                              0.999666
expl/Actions Min                             -0.999208
expl/Num Paths                                1
expl/Average Returns                       5572.6
expl/env_infos/final/reward_run Mean          6.93554
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.93554
expl/env_infos/final/reward_run Min           6.93554
expl/env_infos/initial/reward_run Mean        0.0681437
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0681437
expl/env_infos/initial/reward_run Min         0.0681437
expl/env_infos/reward_run Mean                5.96918
expl/env_infos/reward_run Std                 1.24043
expl/env_infos/reward_run Max                 8.29989
expl/env_infos/reward_run Min                -0.554452
expl/env_infos/final/reward_ctrl Mean        -0.156334
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.156334
expl/env_infos/final/reward_ctrl Min         -0.156334
expl/env_infos/initial/reward_ctrl Mean      -0.304536
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.304536
expl/env_infos/initial/reward_ctrl Min       -0.304536
expl/env_infos/reward_ctrl Mean              -0.396581
expl/env_infos/reward_ctrl Std                0.0895103
expl/env_infos/reward_ctrl Max               -0.10931
expl/env_infos/reward_ctrl Min               -0.585508
eval/num steps total                          1.185e+06
eval/num paths total                       1185
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.59426
eval/Rewards Std                              1.2528
eval/Rewards Max                              8.0636
eval/Rewards Min                             -0.786308
eval/Returns Mean                          5594.26
eval/Returns Std                             23.628
eval/Returns Max                           5620.91
eval/Returns Min                           5554.72
eval/Actions Mean                             0.124225
eval/Actions Std                              0.813175
eval/Actions Max                              0.998807
eval/Actions Min                             -0.997217
eval/Num Paths                                5
eval/Average Returns                       5594.26
eval/env_infos/final/reward_run Mean          5.6427
eval/env_infos/final/reward_run Std           0.939705
eval/env_infos/final/reward_run Max           7.23329
eval/env_infos/final/reward_run Min           4.34016
eval/env_infos/initial/reward_run Mean       -0.295475
eval/env_infos/initial/reward_run Std         0.1164
eval/env_infos/initial/reward_run Max        -0.148822
eval/env_infos/initial/reward_run Min        -0.465973
eval/env_infos/reward_run Mean                6.00027
eval/env_infos/reward_run Std                 1.23683
eval/env_infos/reward_run Max                 8.53215
eval/env_infos/reward_run Min                -0.465973
eval/env_infos/final/reward_ctrl Mean        -0.466462
eval/env_infos/final/reward_ctrl Std          0.0452642
eval/env_infos/final/reward_ctrl Max         -0.415086
eval/env_infos/final/reward_ctrl Min         -0.538778
eval/env_infos/initial/reward_ctrl Mean      -0.257079
eval/env_infos/initial/reward_ctrl Std        0.0487302
eval/env_infos/initial/reward_ctrl Max       -0.179431
eval/env_infos/initial/reward_ctrl Min       -0.320335
eval/env_infos/reward_ctrl Mean              -0.406011
eval/env_infos/reward_ctrl Std                0.0853503
eval/env_infos/reward_ctrl Max               -0.146979
eval/env_infos/reward_ctrl Min               -0.581702
time/data storing (s)                         0.00445333
time/evaluation sampling (s)                  1.99755
time/exploration sampling (s)                 0.531131
time/logging (s)                              0.0137702
time/sac training (s)                         7.39687
time/saving (s)                               0.00378076
time/training (s)                             3.3856e-05
time/epoch (s)                                9.9476
time/total (s)                             2536.15
Epoch                                       236
---------------------------------------  ---------------
2021-11-24 01:11:40.067093 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 237 finished
---------------------------------------  ---------------
epoch                                       237
replay_buffer/size                       239000
trainer/num train calls                  238000
trainer/QF1 Loss                              6.29756
trainer/QF2 Loss                              7.29476
trainer/Policy Loss                        -349.438
trainer/Q1 Predictions Mean                 349.779
trainer/Q1 Predictions Std                   87.6006
trainer/Q1 Predictions Max                  421.228
trainer/Q1 Predictions Min                   17.802
trainer/Q2 Predictions Mean                 350.143
trainer/Q2 Predictions Std                   87.7118
trainer/Q2 Predictions Max                  421.462
trainer/Q2 Predictions Min                   18.4976
trainer/Q Targets Mean                      349.562
trainer/Q Targets Std                        87.5472
trainer/Q Targets Max                       423.005
trainer/Q Targets Min                        17.5006
trainer/Log Pis Mean                          6.77635
trainer/Log Pis Std                           4.38802
trainer/Log Pis Max                          17.7834
trainer/Log Pis Min                          -4.00452
trainer/policy/mean Mean                      0.0667255
trainer/policy/mean Std                       0.793958
trainer/policy/mean Max                       0.998416
trainer/policy/mean Min                      -0.998391
trainer/policy/normal/std Mean                0.433741
trainer/policy/normal/std Std                 0.139694
trainer/policy/normal/std Max                 1.34952
trainer/policy/normal/std Min                 0.0664174
trainer/policy/normal/log_std Mean           -0.902209
trainer/policy/normal/log_std Std             0.402097
trainer/policy/normal/log_std Max             0.299747
trainer/policy/normal/log_std Min            -2.7118
trainer/Alpha                                 0.121845
trainer/Alpha Loss                            1.63423
expl/num steps total                     239000
expl/num paths total                        239
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33276
expl/Rewards Std                              1.21228
expl/Rewards Max                              7.50958
expl/Rewards Min                             -0.708521
expl/Returns Mean                          5332.76
expl/Returns Std                              0
expl/Returns Max                           5332.76
expl/Returns Min                           5332.76
expl/Actions Mean                             0.0893646
expl/Actions Std                              0.807881
expl/Actions Max                              0.999683
expl/Actions Min                             -0.999108
expl/Num Paths                                1
expl/Average Returns                       5332.76
expl/env_infos/final/reward_run Mean          4.64906
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.64906
expl/env_infos/final/reward_run Min           4.64906
expl/env_infos/initial/reward_run Mean       -0.373184
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.373184
expl/env_infos/initial/reward_run Min        -0.373184
expl/env_infos/reward_run Mean                5.72915
expl/env_infos/reward_run Std                 1.20622
expl/env_infos/reward_run Max                 7.99188
expl/env_infos/reward_run Min                -0.373184
expl/env_infos/final/reward_ctrl Mean        -0.442909
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.442909
expl/env_infos/final/reward_ctrl Min         -0.442909
expl/env_infos/initial/reward_ctrl Mean      -0.335337
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.335337
expl/env_infos/initial/reward_ctrl Min       -0.335337
expl/env_infos/reward_ctrl Mean              -0.396394
expl/env_infos/reward_ctrl Std                0.0906194
expl/env_infos/reward_ctrl Max               -0.101616
expl/env_infos/reward_ctrl Min               -0.576148
eval/num steps total                          1.19e+06
eval/num paths total                       1190
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.63431
eval/Rewards Std                              1.26966
eval/Rewards Max                              8.27813
eval/Rewards Min                             -1.14061
eval/Returns Mean                          5634.31
eval/Returns Std                             71.0794
eval/Returns Max                           5752.82
eval/Returns Min                           5531.87
eval/Actions Mean                             0.0928773
eval/Actions Std                              0.822607
eval/Actions Max                              0.998422
eval/Actions Min                             -0.996332
eval/Num Paths                                5
eval/Average Returns                       5634.31
eval/env_infos/final/reward_run Mean          6.67504
eval/env_infos/final/reward_run Std           1.09319
eval/env_infos/final/reward_run Max           7.79547
eval/env_infos/final/reward_run Min           4.91111
eval/env_infos/initial/reward_run Mean       -0.313711
eval/env_infos/initial/reward_run Std         0.232929
eval/env_infos/initial/reward_run Max        -0.0464669
eval/env_infos/initial/reward_run Min        -0.72347
eval/env_infos/reward_run Mean                6.0455
eval/env_infos/reward_run Std                 1.26079
eval/env_infos/reward_run Max                 8.7334
eval/env_infos/reward_run Min                -0.72347
eval/env_infos/final/reward_ctrl Mean        -0.425838
eval/env_infos/final/reward_ctrl Std          0.0593201
eval/env_infos/final/reward_ctrl Max         -0.366379
eval/env_infos/final/reward_ctrl Min         -0.510914
eval/env_infos/initial/reward_ctrl Mean      -0.285179
eval/env_infos/initial/reward_ctrl Std        0.0822281
eval/env_infos/initial/reward_ctrl Max       -0.182762
eval/env_infos/initial/reward_ctrl Min       -0.417144
eval/env_infos/reward_ctrl Mean              -0.411185
eval/env_infos/reward_ctrl Std                0.089311
eval/env_infos/reward_ctrl Max               -0.120529
eval/env_infos/reward_ctrl Min               -0.581863
time/data storing (s)                         0.00451395
time/evaluation sampling (s)                  2.0014
time/exploration sampling (s)                 0.517601
time/logging (s)                              0.0136094
time/sac training (s)                         7.40759
time/saving (s)                               0.00376341
time/training (s)                             3.4276e-05
time/epoch (s)                                9.94851
time/total (s)                             2546.37
Epoch                                       237
---------------------------------------  ---------------
2021-11-24 01:11:50.298533 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 238 finished
---------------------------------------  ---------------
epoch                                       238
replay_buffer/size                       240000
trainer/num train calls                  239000
trainer/QF1 Loss                              5.07269
trainer/QF2 Loss                              7.33832
trainer/Policy Loss                        -332.787
trainer/Q1 Predictions Mean                 333.169
trainer/Q1 Predictions Std                  107.148
trainer/Q1 Predictions Max                  422.746
trainer/Q1 Predictions Min                   17.1288
trainer/Q2 Predictions Mean                 332.743
trainer/Q2 Predictions Std                  106.891
trainer/Q2 Predictions Max                  419.793
trainer/Q2 Predictions Min                   17.3676
trainer/Q Targets Mean                      333.25
trainer/Q Targets Std                       106.933
trainer/Q Targets Max                       419.794
trainer/Q Targets Min                        18.2288
trainer/Log Pis Mean                          6.09951
trainer/Log Pis Std                           4.81433
trainer/Log Pis Max                          18.9459
trainer/Log Pis Min                          -6.21409
trainer/policy/mean Mean                      0.0390484
trainer/policy/mean Std                       0.778653
trainer/policy/mean Max                       0.999614
trainer/policy/mean Min                      -0.996917
trainer/policy/normal/std Mean                0.45441
trainer/policy/normal/std Std                 0.147818
trainer/policy/normal/std Max                 0.984455
trainer/policy/normal/std Min                 0.0757473
trainer/policy/normal/log_std Mean           -0.855523
trainer/policy/normal/log_std Std             0.397829
trainer/policy/normal/log_std Max            -0.0156675
trainer/policy/normal/log_std Min            -2.58035
trainer/Alpha                                 0.123764
trainer/Alpha Loss                            0.207906
expl/num steps total                     240000
expl/num paths total                        240
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.53732
expl/Rewards Std                              1.24004
expl/Rewards Max                              7.81178
expl/Rewards Min                             -0.673792
expl/Returns Mean                          5537.32
expl/Returns Std                              0
expl/Returns Max                           5537.32
expl/Returns Min                           5537.32
expl/Actions Mean                             0.0479079
expl/Actions Std                              0.813038
expl/Actions Max                              0.999789
expl/Actions Min                             -0.999722
expl/Num Paths                                1
expl/Average Returns                       5537.32
expl/env_infos/final/reward_run Mean          5.57558
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.57558
expl/env_infos/final/reward_run Min           5.57558
expl/env_infos/initial/reward_run Mean       -0.372423
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.372423
expl/env_infos/initial/reward_run Min        -0.372423
expl/env_infos/reward_run Mean                5.93531
expl/env_infos/reward_run Std                 1.23294
expl/env_infos/reward_run Max                 8.30642
expl/env_infos/reward_run Min                -0.372423
expl/env_infos/final/reward_ctrl Mean        -0.434703
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.434703
expl/env_infos/final/reward_ctrl Min         -0.434703
expl/env_infos/initial/reward_ctrl Mean      -0.301369
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.301369
expl/env_infos/initial/reward_ctrl Min       -0.301369
expl/env_infos/reward_ctrl Mean              -0.397995
expl/env_infos/reward_ctrl Std                0.092878
expl/env_infos/reward_ctrl Max               -0.0735454
expl/env_infos/reward_ctrl Min               -0.584227
eval/num steps total                          1.195e+06
eval/num paths total                       1195
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.65849
eval/Rewards Std                              1.24558
eval/Rewards Max                              8.00754
eval/Rewards Min                             -0.851076
eval/Returns Mean                          5658.49
eval/Returns Std                            107.508
eval/Returns Max                           5802.99
eval/Returns Min                           5533.68
eval/Actions Mean                             0.0576282
eval/Actions Std                              0.826694
eval/Actions Max                              0.999517
eval/Actions Min                             -0.999939
eval/Num Paths                                5
eval/Average Returns                       5658.49
eval/env_infos/final/reward_run Mean          6.68893
eval/env_infos/final/reward_run Std           0.78545
eval/env_infos/final/reward_run Max           7.9069
eval/env_infos/final/reward_run Min           5.80616
eval/env_infos/initial/reward_run Mean       -0.301498
eval/env_infos/initial/reward_run Std         0.138032
eval/env_infos/initial/reward_run Max        -0.124177
eval/env_infos/initial/reward_run Min        -0.547223
eval/env_infos/reward_run Mean                6.07053
eval/env_infos/reward_run Std                 1.23048
eval/env_infos/reward_run Max                 8.50282
eval/env_infos/reward_run Min                -0.547223
eval/env_infos/final/reward_ctrl Mean        -0.447832
eval/env_infos/final/reward_ctrl Std          0.0414178
eval/env_infos/final/reward_ctrl Max         -0.380217
eval/env_infos/final/reward_ctrl Min         -0.501705
eval/env_infos/initial/reward_ctrl Mean      -0.300303
eval/env_infos/initial/reward_ctrl Std        0.0229954
eval/env_infos/initial/reward_ctrl Max       -0.271913
eval/env_infos/initial/reward_ctrl Min       -0.327609
eval/env_infos/reward_ctrl Mean              -0.412046
eval/env_infos/reward_ctrl Std                0.0959744
eval/env_infos/reward_ctrl Max               -0.0884924
eval/env_infos/reward_ctrl Min               -0.58452
time/data storing (s)                         0.00444916
time/evaluation sampling (s)                  2.00856
time/exploration sampling (s)                 0.532973
time/logging (s)                              0.0136069
time/sac training (s)                         7.37931
time/saving (s)                               0.00375166
time/training (s)                             3.4946e-05
time/epoch (s)                                9.94269
time/total (s)                             2556.59
Epoch                                       238
---------------------------------------  ---------------
2021-11-24 01:12:00.472217 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 239 finished
---------------------------------------  ---------------
epoch                                       239
replay_buffer/size                       241000
trainer/num train calls                  240000
trainer/QF1 Loss                              5.11546
trainer/QF2 Loss                              4.25572
trainer/Policy Loss                        -347.442
trainer/Q1 Predictions Mean                 347.883
trainer/Q1 Predictions Std                   93.3339
trainer/Q1 Predictions Max                  416.062
trainer/Q1 Predictions Min                   18.2403
trainer/Q2 Predictions Mean                 348.03
trainer/Q2 Predictions Std                   93.444
trainer/Q2 Predictions Max                  416.962
trainer/Q2 Predictions Min                   17.3204
trainer/Q Targets Mean                      347.741
trainer/Q Targets Std                        93.2193
trainer/Q Targets Max                       418.052
trainer/Q Targets Min                        18.7597
trainer/Log Pis Mean                          5.95018
trainer/Log Pis Std                           4.44024
trainer/Log Pis Max                          17.7821
trainer/Log Pis Min                          -6.39614
trainer/policy/mean Mean                      0.0784454
trainer/policy/mean Std                       0.770916
trainer/policy/mean Max                       0.997985
trainer/policy/mean Min                      -0.99809
trainer/policy/normal/std Mean                0.444416
trainer/policy/normal/std Std                 0.144255
trainer/policy/normal/std Max                 1.21969
trainer/policy/normal/std Min                 0.0736171
trainer/policy/normal/log_std Mean           -0.877184
trainer/policy/normal/log_std Std             0.395901
trainer/policy/normal/log_std Max             0.198594
trainer/policy/normal/log_std Min            -2.60888
trainer/Alpha                                 0.124883
trainer/Alpha Loss                           -0.103649
expl/num steps total                     241000
expl/num paths total                        241
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.35
expl/Rewards Std                              1.15866
expl/Rewards Max                              7.60297
expl/Rewards Min                             -0.44334
expl/Returns Mean                          5350
expl/Returns Std                              0
expl/Returns Max                           5350
expl/Returns Min                           5350
expl/Actions Mean                             0.0873258
expl/Actions Std                              0.806239
expl/Actions Max                              0.999266
expl/Actions Min                             -0.999667
expl/Num Paths                                1
expl/Average Returns                       5350
expl/env_infos/final/reward_run Mean          5.51327
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.51327
expl/env_infos/final/reward_run Min           5.51327
expl/env_infos/initial/reward_run Mean       -0.174631
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.174631
expl/env_infos/initial/reward_run Min        -0.174631
expl/env_infos/reward_run Mean                5.74459
expl/env_infos/reward_run Std                 1.14445
expl/env_infos/reward_run Max                 7.98453
expl/env_infos/reward_run Min                -0.174631
expl/env_infos/final/reward_ctrl Mean        -0.416714
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.416714
expl/env_infos/final/reward_ctrl Min         -0.416714
expl/env_infos/initial/reward_ctrl Mean      -0.268709
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.268709
expl/env_infos/initial/reward_ctrl Min       -0.268709
expl/env_infos/reward_ctrl Mean              -0.394588
expl/env_infos/reward_ctrl Std                0.0918581
expl/env_infos/reward_ctrl Max               -0.12178
expl/env_infos/reward_ctrl Min               -0.578687
eval/num steps total                          1.2e+06
eval/num paths total                       1200
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.66737
eval/Rewards Std                              1.24868
eval/Rewards Max                              7.83796
eval/Rewards Min                             -0.796984
eval/Returns Mean                          5667.37
eval/Returns Std                             53.6852
eval/Returns Max                           5735.41
eval/Returns Min                           5597.19
eval/Actions Mean                             0.0968078
eval/Actions Std                              0.812334
eval/Actions Max                              0.999215
eval/Actions Min                             -0.997905
eval/Num Paths                                5
eval/Average Returns                       5667.37
eval/env_infos/final/reward_run Mean          5.82944
eval/env_infos/final/reward_run Std           0.84432
eval/env_infos/final/reward_run Max           7.3611
eval/env_infos/final/reward_run Min           4.799
eval/env_infos/initial/reward_run Mean       -0.291555
eval/env_infos/initial/reward_run Std         0.0844592
eval/env_infos/initial/reward_run Max        -0.187004
eval/env_infos/initial/reward_run Min        -0.43358
eval/env_infos/reward_run Mean                6.06893
eval/env_infos/reward_run Std                 1.2282
eval/env_infos/reward_run Max                 8.30176
eval/env_infos/reward_run Min                -0.43358
eval/env_infos/final/reward_ctrl Mean        -0.442964
eval/env_infos/final/reward_ctrl Std          0.0718371
eval/env_infos/final/reward_ctrl Max         -0.349487
eval/env_infos/final/reward_ctrl Min         -0.54533
eval/env_infos/initial/reward_ctrl Mean      -0.291171
eval/env_infos/initial/reward_ctrl Std        0.0518335
eval/env_infos/initial/reward_ctrl Max       -0.231092
eval/env_infos/initial/reward_ctrl Min       -0.363404
eval/env_infos/reward_ctrl Mean              -0.401555
eval/env_infos/reward_ctrl Std                0.093801
eval/env_infos/reward_ctrl Max               -0.118418
eval/env_infos/reward_ctrl Min               -0.580938
time/data storing (s)                         0.00449129
time/evaluation sampling (s)                  1.96949
time/exploration sampling (s)                 0.520859
time/logging (s)                              0.0137772
time/sac training (s)                         7.37256
time/saving (s)                               0.00377102
time/training (s)                             3.4817e-05
time/epoch (s)                                9.88498
time/total (s)                             2566.75
Epoch                                       239
---------------------------------------  ---------------
2021-11-24 01:12:10.658178 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 240 finished
---------------------------------------  ---------------
epoch                                       240
replay_buffer/size                       242000
trainer/num train calls                  241000
trainer/QF1 Loss                              7.30648
trainer/QF2 Loss                              6.53108
trainer/Policy Loss                        -336.487
trainer/Q1 Predictions Mean                 336.545
trainer/Q1 Predictions Std                  106.971
trainer/Q1 Predictions Max                  424.942
trainer/Q1 Predictions Min                   18.7366
trainer/Q2 Predictions Mean                 336.661
trainer/Q2 Predictions Std                  107.236
trainer/Q2 Predictions Max                  424.937
trainer/Q2 Predictions Min                   17.2353
trainer/Q Targets Mean                      336.412
trainer/Q Targets Std                       107.003
trainer/Q Targets Max                       426.488
trainer/Q Targets Min                        18.1829
trainer/Log Pis Mean                          6.19033
trainer/Log Pis Std                           4.76172
trainer/Log Pis Max                          20.2438
trainer/Log Pis Min                          -3.68783
trainer/policy/mean Mean                      0.118471
trainer/policy/mean Std                       0.76282
trainer/policy/mean Max                       0.998366
trainer/policy/mean Min                      -0.999813
trainer/policy/normal/std Mean                0.446492
trainer/policy/normal/std Std                 0.147918
trainer/policy/normal/std Max                 0.992817
trainer/policy/normal/std Min                 0.072034
trainer/policy/normal/log_std Mean           -0.877843
trainer/policy/normal/log_std Std             0.414909
trainer/policy/normal/log_std Max            -0.00720918
trainer/policy/normal/log_std Min            -2.63062
trainer/Alpha                                 0.124112
trainer/Alpha Loss                            0.397141
expl/num steps total                     242000
expl/num paths total                        242
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.47812
expl/Rewards Std                              1.21809
expl/Rewards Max                              8.06311
expl/Rewards Min                             -0.644925
expl/Returns Mean                          5478.12
expl/Returns Std                              0
expl/Returns Max                           5478.12
expl/Returns Min                           5478.12
expl/Actions Mean                             0.132577
expl/Actions Std                              0.804204
expl/Actions Max                              0.999646
expl/Actions Min                             -0.999297
expl/Num Paths                                1
expl/Average Returns                       5478.12
expl/env_infos/final/reward_run Mean          5.80805
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.80805
expl/env_infos/final/reward_run Min           5.80805
expl/env_infos/initial/reward_run Mean       -0.335271
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.335271
expl/env_infos/initial/reward_run Min        -0.335271
expl/env_infos/reward_run Mean                5.87671
expl/env_infos/reward_run Std                 1.20101
expl/env_infos/reward_run Max                 8.54637
expl/env_infos/reward_run Min                -0.335271
expl/env_infos/final/reward_ctrl Mean        -0.398668
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.398668
expl/env_infos/final/reward_ctrl Min         -0.398668
expl/env_infos/initial/reward_ctrl Mean      -0.309654
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.309654
expl/env_infos/initial/reward_ctrl Min       -0.309654
expl/env_infos/reward_ctrl Mean              -0.398593
expl/env_infos/reward_ctrl Std                0.0897328
expl/env_infos/reward_ctrl Max               -0.0516817
expl/env_infos/reward_ctrl Min               -0.578921
eval/num steps total                          1.205e+06
eval/num paths total                       1205
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.52315
eval/Rewards Std                              1.25842
eval/Rewards Max                              8.14849
eval/Rewards Min                             -0.675145
eval/Returns Mean                          5523.15
eval/Returns Std                             48.7472
eval/Returns Max                           5576.46
eval/Returns Min                           5446.97
eval/Actions Mean                             0.136697
eval/Actions Std                              0.811046
eval/Actions Max                              0.998568
eval/Actions Min                             -0.996989
eval/Num Paths                                5
eval/Average Returns                       5523.15
eval/env_infos/final/reward_run Mean          5.39112
eval/env_infos/final/reward_run Std           0.519785
eval/env_infos/final/reward_run Max           6.37029
eval/env_infos/final/reward_run Min           4.87596
eval/env_infos/initial/reward_run Mean       -0.301463
eval/env_infos/initial/reward_run Std         0.0600726
eval/env_infos/initial/reward_run Max        -0.210761
eval/env_infos/initial/reward_run Min        -0.391448
eval/env_infos/reward_run Mean                5.92904
eval/env_infos/reward_run Std                 1.23489
eval/env_infos/reward_run Max                 8.6071
eval/env_infos/reward_run Min                -0.391448
eval/env_infos/final/reward_ctrl Mean        -0.422481
eval/env_infos/final/reward_ctrl Std          0.0433314
eval/env_infos/final/reward_ctrl Max         -0.35747
eval/env_infos/final/reward_ctrl Min         -0.482953
eval/env_infos/initial/reward_ctrl Mean      -0.284138
eval/env_infos/initial/reward_ctrl Std        0.0330608
eval/env_infos/initial/reward_ctrl Max       -0.240685
eval/env_infos/initial/reward_ctrl Min       -0.34161
eval/env_infos/reward_ctrl Mean              -0.405889
eval/env_infos/reward_ctrl Std                0.0887037
eval/env_infos/reward_ctrl Max               -0.113355
eval/env_infos/reward_ctrl Min               -0.581385
time/data storing (s)                         0.00448819
time/evaluation sampling (s)                  1.98651
time/exploration sampling (s)                 0.533976
time/logging (s)                              0.0136045
time/sac training (s)                         7.35435
time/saving (s)                               0.00375029
time/training (s)                             3.4251e-05
time/epoch (s)                                9.89672
time/total (s)                             2576.92
Epoch                                       240
---------------------------------------  ---------------
2021-11-24 01:12:20.948909 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 241 finished
---------------------------------------  ----------------
epoch                                       241
replay_buffer/size                       243000
trainer/num train calls                  242000
trainer/QF1 Loss                              5.81845
trainer/QF2 Loss                              5.03263
trainer/Policy Loss                        -343.005
trainer/Q1 Predictions Mean                 343.514
trainer/Q1 Predictions Std                  100.105
trainer/Q1 Predictions Max                  424.511
trainer/Q1 Predictions Min                   18.212
trainer/Q2 Predictions Mean                 343.499
trainer/Q2 Predictions Std                  100.132
trainer/Q2 Predictions Max                  422.388
trainer/Q2 Predictions Min                   17.5724
trainer/Q Targets Mean                      343.491
trainer/Q Targets Std                       100.191
trainer/Q Targets Max                       426.377
trainer/Q Targets Min                        17.5467
trainer/Log Pis Mean                          5.87299
trainer/Log Pis Std                           4.68067
trainer/Log Pis Max                          17.0716
trainer/Log Pis Min                          -5.60892
trainer/policy/mean Mean                      0.0900322
trainer/policy/mean Std                       0.771461
trainer/policy/mean Max                       0.997517
trainer/policy/mean Min                      -0.995961
trainer/policy/normal/std Mean                0.446455
trainer/policy/normal/std Std                 0.146756
trainer/policy/normal/std Max                 0.949431
trainer/policy/normal/std Min                 0.0676265
trainer/policy/normal/log_std Mean           -0.877094
trainer/policy/normal/log_std Std             0.413416
trainer/policy/normal/log_std Max            -0.0518925
trainer/policy/normal/log_std Min            -2.69376
trainer/Alpha                                 0.123199
trainer/Alpha Loss                           -0.265963
expl/num steps total                     243000
expl/num paths total                        243
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.37372
expl/Rewards Std                              1.17699
expl/Rewards Max                              7.55845
expl/Rewards Min                             -0.50352
expl/Returns Mean                          5373.72
expl/Returns Std                              0
expl/Returns Max                           5373.72
expl/Returns Min                           5373.72
expl/Actions Mean                             0.104834
expl/Actions Std                              0.80502
expl/Actions Max                              0.999889
expl/Actions Min                             -0.999721
expl/Num Paths                                1
expl/Average Returns                       5373.72
expl/env_infos/final/reward_run Mean          5.56258
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.56258
expl/env_infos/final/reward_run Min           5.56258
expl/env_infos/initial/reward_run Mean       -0.142973
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.142973
expl/env_infos/initial/reward_run Min        -0.142973
expl/env_infos/reward_run Mean                5.76915
expl/env_infos/reward_run Std                 1.16193
expl/env_infos/reward_run Max                 8.06146
expl/env_infos/reward_run Min                -0.250001
expl/env_infos/final/reward_ctrl Mean        -0.409993
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.409993
expl/env_infos/final/reward_ctrl Min         -0.409993
expl/env_infos/initial/reward_ctrl Mean      -0.308539
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.308539
expl/env_infos/initial/reward_ctrl Min       -0.308539
expl/env_infos/reward_ctrl Mean              -0.395428
expl/env_infos/reward_ctrl Std                0.089467
expl/env_infos/reward_ctrl Max               -0.0853816
expl/env_infos/reward_ctrl Min               -0.584056
eval/num steps total                          1.21e+06
eval/num paths total                       1210
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.64831
eval/Rewards Std                              1.26915
eval/Rewards Max                              8.05142
eval/Rewards Min                             -0.877733
eval/Returns Mean                          5648.31
eval/Returns Std                             43.0586
eval/Returns Max                           5707.26
eval/Returns Min                           5580.05
eval/Actions Mean                             0.114664
eval/Actions Std                              0.814523
eval/Actions Max                              0.998137
eval/Actions Min                             -0.99538
eval/Num Paths                                5
eval/Average Returns                       5648.31
eval/env_infos/final/reward_run Mean          6.42879
eval/env_infos/final/reward_run Std           0.849451
eval/env_infos/final/reward_run Max           7.39571
eval/env_infos/final/reward_run Min           5.18475
eval/env_infos/initial/reward_run Mean       -0.375574
eval/env_infos/initial/reward_run Std         0.130588
eval/env_infos/initial/reward_run Max        -0.143119
eval/env_infos/initial/reward_run Min        -0.507768
eval/env_infos/reward_run Mean                6.05427
eval/env_infos/reward_run Std                 1.25249
eval/env_infos/reward_run Max                 8.53438
eval/env_infos/reward_run Min                -0.507768
eval/env_infos/final/reward_ctrl Mean        -0.437693
eval/env_infos/final/reward_ctrl Std          0.0351854
eval/env_infos/final/reward_ctrl Max         -0.390343
eval/env_infos/final/reward_ctrl Min         -0.471941
eval/env_infos/initial/reward_ctrl Mean      -0.326026
eval/env_infos/initial/reward_ctrl Std        0.0600566
eval/env_infos/initial/reward_ctrl Max       -0.241313
eval/env_infos/initial/reward_ctrl Min       -0.401811
eval/env_infos/reward_ctrl Mean              -0.405957
eval/env_infos/reward_ctrl Std                0.0886088
eval/env_infos/reward_ctrl Max               -0.112686
eval/env_infos/reward_ctrl Min               -0.57933
time/data storing (s)                         0.00447825
time/evaluation sampling (s)                  2.00408
time/exploration sampling (s)                 0.533109
time/logging (s)                              0.0137958
time/sac training (s)                         7.44331
time/saving (s)                               0.00374727
time/training (s)                             3.41421e-05
time/epoch (s)                               10.0026
time/total (s)                             2587.2
Epoch                                       241
---------------------------------------  ----------------
2021-11-24 01:12:31.176145 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 242 finished
---------------------------------------  ---------------
epoch                                       242
replay_buffer/size                       244000
trainer/num train calls                  243000
trainer/QF1 Loss                              8.79353
trainer/QF2 Loss                              9.19289
trainer/Policy Loss                        -331.341
trainer/Q1 Predictions Mean                 331.614
trainer/Q1 Predictions Std                  108.944
trainer/Q1 Predictions Max                  419.004
trainer/Q1 Predictions Min                   18.1952
trainer/Q2 Predictions Mean                 331.575
trainer/Q2 Predictions Std                  108.968
trainer/Q2 Predictions Max                  420.142
trainer/Q2 Predictions Min                   18.0929
trainer/Q Targets Mean                      331.388
trainer/Q Targets Std                       109.112
trainer/Q Targets Max                       418.704
trainer/Q Targets Min                        16.4026
trainer/Log Pis Mean                          6.3253
trainer/Log Pis Std                           4.72668
trainer/Log Pis Max                          18.9864
trainer/Log Pis Min                          -5.66233
trainer/policy/mean Mean                      0.0668905
trainer/policy/mean Std                       0.775315
trainer/policy/mean Max                       0.998662
trainer/policy/mean Min                      -0.996618
trainer/policy/normal/std Mean                0.44954
trainer/policy/normal/std Std                 0.150007
trainer/policy/normal/std Max                 0.935158
trainer/policy/normal/std Min                 0.0819994
trainer/policy/normal/log_std Mean           -0.868704
trainer/policy/normal/log_std Std             0.402367
trainer/policy/normal/log_std Max            -0.0670396
trainer/policy/normal/log_std Min            -2.50104
trainer/Alpha                                 0.124133
trainer/Alpha Loss                            0.678701
expl/num steps total                     244000
expl/num paths total                        244
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             4.03207
expl/Rewards Std                              2.29801
expl/Rewards Max                              7.96356
expl/Rewards Min                             -1.58401
expl/Returns Mean                          4032.07
expl/Returns Std                              0
expl/Returns Max                           4032.07
expl/Returns Min                           4032.07
expl/Actions Mean                             0.0539281
expl/Actions Std                              0.770542
expl/Actions Max                              1
expl/Actions Min                             -0.999944
expl/Num Paths                                1
expl/Average Returns                       4032.07
expl/env_infos/final/reward_run Mean          1.33089
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           1.33089
expl/env_infos/final/reward_run Min           1.33089
expl/env_infos/initial/reward_run Mean       -0.292678
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.292678
expl/env_infos/initial/reward_run Min        -0.292678
expl/env_infos/reward_run Mean                4.39005
expl/env_infos/reward_run Std                 2.34541
expl/env_infos/reward_run Max                 8.43612
expl/env_infos/reward_run Min                -1.26481
expl/env_infos/final/reward_ctrl Mean        -0.32968
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.32968
expl/env_infos/final/reward_ctrl Min         -0.32968
expl/env_infos/initial/reward_ctrl Mean      -0.370603
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.370603
expl/env_infos/initial/reward_ctrl Min       -0.370603
expl/env_infos/reward_ctrl Mean              -0.357986
expl/env_infos/reward_ctrl Std                0.107125
expl/env_infos/reward_ctrl Max               -0.0828218
expl/env_infos/reward_ctrl Min               -0.597901
eval/num steps total                          1.215e+06
eval/num paths total                       1215
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.48276
eval/Rewards Std                              1.23578
eval/Rewards Max                              8.17629
eval/Rewards Min                             -0.755331
eval/Returns Mean                          5482.76
eval/Returns Std                             46.4594
eval/Returns Max                           5551.75
eval/Returns Min                           5413.51
eval/Actions Mean                             0.105036
eval/Actions Std                              0.82046
eval/Actions Max                              0.998261
eval/Actions Min                             -0.997321
eval/Num Paths                                5
eval/Average Returns                       5482.76
eval/env_infos/final/reward_run Mean          5.87521
eval/env_infos/final/reward_run Std           0.52184
eval/env_infos/final/reward_run Max           6.8756
eval/env_infos/final/reward_run Min           5.42704
eval/env_infos/initial/reward_run Mean       -0.221014
eval/env_infos/initial/reward_run Std         0.11561
eval/env_infos/initial/reward_run Max        -0.0872255
eval/env_infos/initial/reward_run Min        -0.39928
eval/env_infos/reward_run Mean                5.89327
eval/env_infos/reward_run Std                 1.2208
eval/env_infos/reward_run Max                 8.66438
eval/env_infos/reward_run Min                -0.39928
eval/env_infos/final/reward_ctrl Mean        -0.44218
eval/env_infos/final/reward_ctrl Std          0.0464807
eval/env_infos/final/reward_ctrl Max         -0.388143
eval/env_infos/final/reward_ctrl Min         -0.517643
eval/env_infos/initial/reward_ctrl Mean      -0.335579
eval/env_infos/initial/reward_ctrl Std        0.0548745
eval/env_infos/initial/reward_ctrl Max       -0.23665
eval/env_infos/initial/reward_ctrl Min       -0.398926
eval/env_infos/reward_ctrl Mean              -0.410513
eval/env_infos/reward_ctrl Std                0.0887132
eval/env_infos/reward_ctrl Max               -0.113262
eval/env_infos/reward_ctrl Min               -0.584285
time/data storing (s)                         0.00445711
time/evaluation sampling (s)                  2.01494
time/exploration sampling (s)                 0.527698
time/logging (s)                              0.0142333
time/sac training (s)                         7.37369
time/saving (s)                               0.00377193
time/training (s)                             3.4055e-05
time/epoch (s)                                9.93883
time/total (s)                             2597.41
Epoch                                       242
---------------------------------------  ---------------
2021-11-24 01:12:41.474035 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 243 finished
---------------------------------------  ---------------
epoch                                       243
replay_buffer/size                       245000
trainer/num train calls                  244000
trainer/QF1 Loss                              6.15537
trainer/QF2 Loss                              4.99059
trainer/Policy Loss                        -342.475
trainer/Q1 Predictions Mean                 342.979
trainer/Q1 Predictions Std                  103.352
trainer/Q1 Predictions Max                  424.893
trainer/Q1 Predictions Min                   16.6505
trainer/Q2 Predictions Mean                 343.291
trainer/Q2 Predictions Std                  103.368
trainer/Q2 Predictions Max                  422.034
trainer/Q2 Predictions Min                   15.3764
trainer/Q Targets Mean                      342.702
trainer/Q Targets Std                       103.35
trainer/Q Targets Max                       423.083
trainer/Q Targets Min                        15.6618
trainer/Log Pis Mean                          5.96231
trainer/Log Pis Std                           4.62047
trainer/Log Pis Max                          17.2126
trainer/Log Pis Min                          -4.69935
trainer/policy/mean Mean                      0.0567348
trainer/policy/mean Std                       0.771534
trainer/policy/mean Max                       0.996913
trainer/policy/mean Min                      -0.99754
trainer/policy/normal/std Mean                0.4472
trainer/policy/normal/std Std                 0.149425
trainer/policy/normal/std Max                 1.01425
trainer/policy/normal/std Min                 0.0778464
trainer/policy/normal/log_std Mean           -0.874964
trainer/policy/normal/log_std Std             0.407441
trainer/policy/normal/log_std Max             0.0141473
trainer/policy/normal/log_std Min            -2.55302
trainer/Alpha                                 0.122869
trainer/Alpha Loss                           -0.0790256
expl/num steps total                     245000
expl/num paths total                        245
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.44368
expl/Rewards Std                              1.2519
expl/Rewards Max                              7.63249
expl/Rewards Min                             -0.600599
expl/Returns Mean                          5443.68
expl/Returns Std                              0
expl/Returns Max                           5443.68
expl/Returns Min                           5443.68
expl/Actions Mean                             0.0906301
expl/Actions Std                              0.805574
expl/Actions Max                              0.999598
expl/Actions Min                             -0.999601
expl/Num Paths                                1
expl/Average Returns                       5443.68
expl/env_infos/final/reward_run Mean          5.4793
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.4793
expl/env_infos/final/reward_run Min           5.4793
expl/env_infos/initial/reward_run Mean       -0.141103
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.141103
expl/env_infos/initial/reward_run Min        -0.141103
expl/env_infos/reward_run Mean                5.83798
expl/env_infos/reward_run Std                 1.24423
expl/env_infos/reward_run Max                 8.06026
expl/env_infos/reward_run Min                -0.426986
expl/env_infos/final/reward_ctrl Mean        -0.417172
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.417172
expl/env_infos/final/reward_ctrl Min         -0.417172
expl/env_infos/initial/reward_ctrl Mean      -0.219175
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.219175
expl/env_infos/initial/reward_ctrl Min       -0.219175
expl/env_infos/reward_ctrl Mean              -0.394298
expl/env_infos/reward_ctrl Std                0.0922042
expl/env_infos/reward_ctrl Max               -0.107454
expl/env_infos/reward_ctrl Min               -0.581552
eval/num steps total                          1.22e+06
eval/num paths total                       1220
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.61833
eval/Rewards Std                              1.23678
eval/Rewards Max                              8.09342
eval/Rewards Min                             -0.544395
eval/Returns Mean                          5618.33
eval/Returns Std                             59.6588
eval/Returns Max                           5677.55
eval/Returns Min                           5539.56
eval/Actions Mean                             0.108691
eval/Actions Std                              0.815983
eval/Actions Max                              0.999003
eval/Actions Min                             -0.996502
eval/Num Paths                                5
eval/Average Returns                       5618.33
eval/env_infos/final/reward_run Mean          5.55707
eval/env_infos/final/reward_run Std           0.493976
eval/env_infos/final/reward_run Max           6.31808
eval/env_infos/final/reward_run Min           4.84216
eval/env_infos/initial/reward_run Mean       -0.0529715
eval/env_infos/initial/reward_run Std         0.243277
eval/env_infos/initial/reward_run Max         0.331193
eval/env_infos/initial/reward_run Min        -0.299495
eval/env_infos/reward_run Mean                6.02491
eval/env_infos/reward_run Std                 1.21426
eval/env_infos/reward_run Max                 8.56259
eval/env_infos/reward_run Min                -0.299495
eval/env_infos/final/reward_ctrl Mean        -0.443286
eval/env_infos/final/reward_ctrl Std          0.0288515
eval/env_infos/final/reward_ctrl Max         -0.39526
eval/env_infos/final/reward_ctrl Min         -0.474218
eval/env_infos/initial/reward_ctrl Mean      -0.213777
eval/env_infos/initial/reward_ctrl Std        0.0459968
eval/env_infos/initial/reward_ctrl Max       -0.136856
eval/env_infos/initial/reward_ctrl Min       -0.25961
eval/env_infos/reward_ctrl Mean              -0.406585
eval/env_infos/reward_ctrl Std                0.0936095
eval/env_infos/reward_ctrl Max               -0.128653
eval/env_infos/reward_ctrl Min               -0.581561
time/data storing (s)                         0.00448118
time/evaluation sampling (s)                  2.01325
time/exploration sampling (s)                 0.532039
time/logging (s)                              0.0137405
time/sac training (s)                         7.43919
time/saving (s)                               0.00377962
time/training (s)                             3.4698e-05
time/epoch (s)                               10.0065
time/total (s)                             2607.7
Epoch                                       243
---------------------------------------  ---------------
2021-11-24 01:12:51.702091 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 244 finished
---------------------------------------  ---------------
epoch                                       244
replay_buffer/size                       246000
trainer/num train calls                  245000
trainer/QF1 Loss                              4.31063
trainer/QF2 Loss                              4.8464
trainer/Policy Loss                        -343.527
trainer/Q1 Predictions Mean                 344.187
trainer/Q1 Predictions Std                  104.067
trainer/Q1 Predictions Max                  422.624
trainer/Q1 Predictions Min                   16.6492
trainer/Q2 Predictions Mean                 344.309
trainer/Q2 Predictions Std                  104.039
trainer/Q2 Predictions Max                  422.265
trainer/Q2 Predictions Min                   17.052
trainer/Q Targets Mean                      344.515
trainer/Q Targets Std                       104.256
trainer/Q Targets Max                       424.077
trainer/Q Targets Min                        17.2216
trainer/Log Pis Mean                          6.17127
trainer/Log Pis Std                           4.582
trainer/Log Pis Max                          19.0212
trainer/Log Pis Min                          -5.49281
trainer/policy/mean Mean                      0.0823287
trainer/policy/mean Std                       0.779863
trainer/policy/mean Max                       0.997747
trainer/policy/mean Min                      -0.996138
trainer/policy/normal/std Mean                0.444083
trainer/policy/normal/std Std                 0.149781
trainer/policy/normal/std Max                 1.16145
trainer/policy/normal/std Min                 0.0684321
trainer/policy/normal/log_std Mean           -0.885984
trainer/policy/normal/log_std Std             0.42476
trainer/policy/normal/log_std Max             0.149669
trainer/policy/normal/log_std Min            -2.68191
trainer/Alpha                                 0.124909
trainer/Alpha Loss                            0.356272
expl/num steps total                     246000
expl/num paths total                        246
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.36384
expl/Rewards Std                              1.20278
expl/Rewards Max                              7.65677
expl/Rewards Min                             -0.559246
expl/Returns Mean                          5363.84
expl/Returns Std                              0
expl/Returns Max                           5363.84
expl/Returns Min                           5363.84
expl/Actions Mean                             0.0973664
expl/Actions Std                              0.80182
expl/Actions Max                              0.999614
expl/Actions Min                             -0.999078
expl/Num Paths                                1
expl/Average Returns                       5363.84
expl/env_infos/final/reward_run Mean          5.09314
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.09314
expl/env_infos/final/reward_run Min           5.09314
expl/env_infos/initial/reward_run Mean       -0.315546
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.315546
expl/env_infos/initial/reward_run Min        -0.315546
expl/env_infos/reward_run Mean                5.75528
expl/env_infos/reward_run Std                 1.19757
expl/env_infos/reward_run Max                 8.1468
expl/env_infos/reward_run Min                -0.315546
expl/env_infos/final/reward_ctrl Mean        -0.440668
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.440668
expl/env_infos/final/reward_ctrl Min         -0.440668
expl/env_infos/initial/reward_ctrl Mean      -0.2437
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.2437
expl/env_infos/initial/reward_ctrl Min       -0.2437
expl/env_infos/reward_ctrl Mean              -0.391437
expl/env_infos/reward_ctrl Std                0.0918574
expl/env_infos/reward_ctrl Max               -0.104287
expl/env_infos/reward_ctrl Min               -0.587875
eval/num steps total                          1.225e+06
eval/num paths total                       1225
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.70162
eval/Rewards Std                              1.22989
eval/Rewards Max                              8.07542
eval/Rewards Min                             -0.854023
eval/Returns Mean                          5701.62
eval/Returns Std                             43.3428
eval/Returns Max                           5784.09
eval/Returns Min                           5661.94
eval/Actions Mean                             0.113996
eval/Actions Std                              0.813301
eval/Actions Max                              0.998314
eval/Actions Min                             -0.99717
eval/Num Paths                                5
eval/Average Returns                       5701.62
eval/env_infos/final/reward_run Mean          6.46897
eval/env_infos/final/reward_run Std           0.59296
eval/env_infos/final/reward_run Max           7.57174
eval/env_infos/final/reward_run Min           5.9119
eval/env_infos/initial/reward_run Mean       -0.302448
eval/env_infos/initial/reward_run Std         0.197613
eval/env_infos/initial/reward_run Max        -0.0825515
eval/env_infos/initial/reward_run Min        -0.540681
eval/env_infos/reward_run Mean                6.10629
eval/env_infos/reward_run Std                 1.22013
eval/env_infos/reward_run Max                 8.51062
eval/env_infos/reward_run Min                -0.540681
eval/env_infos/final/reward_ctrl Mean        -0.414835
eval/env_infos/final/reward_ctrl Std          0.044293
eval/env_infos/final/reward_ctrl Max         -0.34306
eval/env_infos/final/reward_ctrl Min         -0.470295
eval/env_infos/initial/reward_ctrl Mean      -0.315957
eval/env_infos/initial/reward_ctrl Std        0.0339661
eval/env_infos/initial/reward_ctrl Max       -0.280475
eval/env_infos/initial/reward_ctrl Min       -0.371463
eval/env_infos/reward_ctrl Mean              -0.404672
eval/env_infos/reward_ctrl Std                0.0860231
eval/env_infos/reward_ctrl Max               -0.126389
eval/env_infos/reward_ctrl Min               -0.582323
time/data storing (s)                         0.00448398
time/evaluation sampling (s)                  1.97248
time/exploration sampling (s)                 0.527249
time/logging (s)                              0.0136329
time/sac training (s)                         7.41749
time/saving (s)                               0.00377066
time/training (s)                             3.4493e-05
time/epoch (s)                                9.93914
time/total (s)                             2617.91
Epoch                                       244
---------------------------------------  ---------------
2021-11-24 01:13:01.878163 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 245 finished
---------------------------------------  ---------------
epoch                                       245
replay_buffer/size                       247000
trainer/num train calls                  246000
trainer/QF1 Loss                              6.79304
trainer/QF2 Loss                              5.19372
trainer/Policy Loss                        -337.877
trainer/Q1 Predictions Mean                 338.956
trainer/Q1 Predictions Std                  114.541
trainer/Q1 Predictions Max                  427.192
trainer/Q1 Predictions Min                   17.1596
trainer/Q2 Predictions Mean                 338.225
trainer/Q2 Predictions Std                  114.502
trainer/Q2 Predictions Max                  426.952
trainer/Q2 Predictions Min                   15.9802
trainer/Q Targets Mean                      338.659
trainer/Q Targets Std                       114.713
trainer/Q Targets Max                       424.032
trainer/Q Targets Min                        17.0125
trainer/Log Pis Mean                          6.16911
trainer/Log Pis Std                           4.76694
trainer/Log Pis Max                          18.7093
trainer/Log Pis Min                          -5.23822
trainer/policy/mean Mean                      0.0687017
trainer/policy/mean Std                       0.781164
trainer/policy/mean Max                       0.99766
trainer/policy/mean Min                      -0.998769
trainer/policy/normal/std Mean                0.458729
trainer/policy/normal/std Std                 0.144003
trainer/policy/normal/std Max                 1.20522
trainer/policy/normal/std Min                 0.0693548
trainer/policy/normal/log_std Mean           -0.843614
trainer/policy/normal/log_std Std             0.393837
trainer/policy/normal/log_std Max             0.186665
trainer/policy/normal/log_std Min            -2.66852
trainer/Alpha                                 0.125345
trainer/Alpha Loss                            0.35119
expl/num steps total                     247000
expl/num paths total                        247
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.40868
expl/Rewards Std                              1.23257
expl/Rewards Max                              7.87312
expl/Rewards Min                             -0.507611
expl/Returns Mean                          5408.68
expl/Returns Std                              0
expl/Returns Max                           5408.68
expl/Returns Min                           5408.68
expl/Actions Mean                             0.0844344
expl/Actions Std                              0.814215
expl/Actions Max                              0.999832
expl/Actions Min                             -0.99952
expl/Num Paths                                1
expl/Average Returns                       5408.68
expl/env_infos/final/reward_run Mean          5.96509
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.96509
expl/env_infos/final/reward_run Min           5.96509
expl/env_infos/initial/reward_run Mean       -0.261715
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.261715
expl/env_infos/initial/reward_run Min        -0.261715
expl/env_infos/reward_run Mean                5.81073
expl/env_infos/reward_run Std                 1.21997
expl/env_infos/reward_run Max                 8.38035
expl/env_infos/reward_run Min                -0.261715
expl/env_infos/final/reward_ctrl Mean        -0.333209
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.333209
expl/env_infos/final/reward_ctrl Min         -0.333209
expl/env_infos/initial/reward_ctrl Mean      -0.235487
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.235487
expl/env_infos/initial/reward_ctrl Min       -0.235487
expl/env_infos/reward_ctrl Mean              -0.402045
expl/env_infos/reward_ctrl Std                0.0883439
expl/env_infos/reward_ctrl Max               -0.0804893
expl/env_infos/reward_ctrl Min               -0.569116
eval/num steps total                          1.23e+06
eval/num paths total                       1230
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.71242
eval/Rewards Std                              1.27886
eval/Rewards Max                              8.15749
eval/Rewards Min                             -0.976818
eval/Returns Mean                          5712.42
eval/Returns Std                             65.9933
eval/Returns Max                           5834.76
eval/Returns Min                           5644.9
eval/Actions Mean                             0.0928516
eval/Actions Std                              0.825867
eval/Actions Max                              0.998416
eval/Actions Min                             -0.997475
eval/Num Paths                                5
eval/Average Returns                       5712.42
eval/env_infos/final/reward_run Mean          6.13688
eval/env_infos/final/reward_run Std           1.2
eval/env_infos/final/reward_run Max           7.55317
eval/env_infos/final/reward_run Min           4.44593
eval/env_infos/initial/reward_run Mean       -0.295472
eval/env_infos/initial/reward_run Std         0.186812
eval/env_infos/initial/reward_run Max        -0.0324964
eval/env_infos/initial/reward_run Min        -0.590874
eval/env_infos/reward_run Mean                6.12683
eval/env_infos/reward_run Std                 1.26046
eval/env_infos/reward_run Max                 8.63609
eval/env_infos/reward_run Min                -0.590874
eval/env_infos/final/reward_ctrl Mean        -0.432305
eval/env_infos/final/reward_ctrl Std          0.0180094
eval/env_infos/final/reward_ctrl Max         -0.414182
eval/env_infos/final/reward_ctrl Min         -0.464825
eval/env_infos/initial/reward_ctrl Mean      -0.274659
eval/env_infos/initial/reward_ctrl Std        0.0661405
eval/env_infos/initial/reward_ctrl Max       -0.202592
eval/env_infos/initial/reward_ctrl Min       -0.385944
eval/env_infos/reward_ctrl Mean              -0.414407
eval/env_infos/reward_ctrl Std                0.0886407
eval/env_infos/reward_ctrl Max               -0.10765
eval/env_infos/reward_ctrl Min               -0.58965
time/data storing (s)                         0.00445981
time/evaluation sampling (s)                  1.9741
time/exploration sampling (s)                 0.525877
time/logging (s)                              0.0136575
time/sac training (s)                         7.36368
time/saving (s)                               0.00517191
time/training (s)                             3.3647e-05
time/epoch (s)                                9.88698
time/total (s)                             2628.07
Epoch                                       245
---------------------------------------  ---------------
2021-11-24 01:13:12.047703 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 246 finished
---------------------------------------  ---------------
epoch                                       246
replay_buffer/size                       248000
trainer/num train calls                  247000
trainer/QF1 Loss                              6.71097
trainer/QF2 Loss                              6.21341
trainer/Policy Loss                        -341.778
trainer/Q1 Predictions Mean                 342.231
trainer/Q1 Predictions Std                  107.108
trainer/Q1 Predictions Max                  424.996
trainer/Q1 Predictions Min                   16.4326
trainer/Q2 Predictions Mean                 342.445
trainer/Q2 Predictions Std                  107.101
trainer/Q2 Predictions Max                  425.973
trainer/Q2 Predictions Min                   17.8981
trainer/Q Targets Mean                      342.227
trainer/Q Targets Std                       107.097
trainer/Q Targets Max                       425.777
trainer/Q Targets Min                        18.4097
trainer/Log Pis Mean                          6.20048
trainer/Log Pis Std                           4.73031
trainer/Log Pis Max                          21.2122
trainer/Log Pis Min                          -5.88548
trainer/policy/mean Mean                      0.0740525
trainer/policy/mean Std                       0.782806
trainer/policy/mean Max                       0.998728
trainer/policy/mean Min                      -0.998627
trainer/policy/normal/std Mean                0.455502
trainer/policy/normal/std Std                 0.151052
trainer/policy/normal/std Max                 1.49943
trainer/policy/normal/std Min                 0.0679419
trainer/policy/normal/log_std Mean           -0.855018
trainer/policy/normal/log_std Std             0.403321
trainer/policy/normal/log_std Max             0.405085
trainer/policy/normal/log_std Min            -2.6891
trainer/Alpha                                 0.125164
trainer/Alpha Loss                            0.41663
expl/num steps total                     248000
expl/num paths total                        248
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33042
expl/Rewards Std                              1.18018
expl/Rewards Max                              7.46922
expl/Rewards Min                             -0.522877
expl/Returns Mean                          5330.42
expl/Returns Std                              0
expl/Returns Max                           5330.42
expl/Returns Min                           5330.42
expl/Actions Mean                             0.0926505
expl/Actions Std                              0.803192
expl/Actions Max                              0.999485
expl/Actions Min                             -0.999104
expl/Num Paths                                1
expl/Average Returns                       5330.42
expl/env_infos/final/reward_run Mean          5.98652
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.98652
expl/env_infos/final/reward_run Min           5.98652
expl/env_infos/initial/reward_run Mean       -0.248629
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.248629
expl/env_infos/initial/reward_run Min        -0.248629
expl/env_infos/reward_run Mean                5.72264
expl/env_infos/reward_run Std                 1.16319
expl/env_infos/reward_run Max                 7.92385
expl/env_infos/reward_run Min                -0.248629
expl/env_infos/final/reward_ctrl Mean        -0.360872
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.360872
expl/env_infos/final/reward_ctrl Min         -0.360872
expl/env_infos/initial/reward_ctrl Mean      -0.274248
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.274248
expl/env_infos/initial/reward_ctrl Min       -0.274248
expl/env_infos/reward_ctrl Mean              -0.392221
expl/env_infos/reward_ctrl Std                0.0921954
expl/env_infos/reward_ctrl Max               -0.0800845
expl/env_infos/reward_ctrl Min               -0.575332
eval/num steps total                          1.235e+06
eval/num paths total                       1235
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.72009
eval/Rewards Std                              1.27357
eval/Rewards Max                              8.42012
eval/Rewards Min                             -0.867342
eval/Returns Mean                          5720.09
eval/Returns Std                             69.3599
eval/Returns Max                           5792.62
eval/Returns Min                           5619.1
eval/Actions Mean                             0.0975269
eval/Actions Std                              0.816761
eval/Actions Max                              0.998193
eval/Actions Min                             -0.997838
eval/Num Paths                                5
eval/Average Returns                       5720.09
eval/env_infos/final/reward_run Mean          6.20452
eval/env_infos/final/reward_run Std           0.847806
eval/env_infos/final/reward_run Max           7.48747
eval/env_infos/final/reward_run Min           4.92703
eval/env_infos/initial/reward_run Mean       -0.340432
eval/env_infos/initial/reward_run Std         0.138706
eval/env_infos/initial/reward_run Max        -0.179643
eval/env_infos/initial/reward_run Min        -0.597642
eval/env_infos/reward_run Mean                6.12606
eval/env_infos/reward_run Std                 1.25609
eval/env_infos/reward_run Max                 8.89036
eval/env_infos/reward_run Min                -0.597642
eval/env_infos/final/reward_ctrl Mean        -0.460215
eval/env_infos/final/reward_ctrl Std          0.0380441
eval/env_infos/final/reward_ctrl Max         -0.414344
eval/env_infos/final/reward_ctrl Min         -0.513802
eval/env_infos/initial/reward_ctrl Mean      -0.322121
eval/env_infos/initial/reward_ctrl Std        0.0444741
eval/env_infos/initial/reward_ctrl Max       -0.2697
eval/env_infos/initial/reward_ctrl Min       -0.4015
eval/env_infos/reward_ctrl Mean              -0.405966
eval/env_infos/reward_ctrl Std                0.091917
eval/env_infos/reward_ctrl Max               -0.107936
eval/env_infos/reward_ctrl Min               -0.582238
time/data storing (s)                         0.00449215
time/evaluation sampling (s)                  1.9809
time/exploration sampling (s)                 0.522314
time/logging (s)                              0.0137271
time/sac training (s)                         7.35563
time/saving (s)                               0.00376629
time/training (s)                             3.4678e-05
time/epoch (s)                                9.88087
time/total (s)                             2638.23
Epoch                                       246
---------------------------------------  ---------------
2021-11-24 01:13:22.228194 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 247 finished
---------------------------------------  ---------------
epoch                                       247
replay_buffer/size                       249000
trainer/num train calls                  248000
trainer/QF1 Loss                              7.34737
trainer/QF2 Loss                              7.37474
trainer/Policy Loss                        -344.347
trainer/Q1 Predictions Mean                 344.922
trainer/Q1 Predictions Std                   96.7058
trainer/Q1 Predictions Max                  420.682
trainer/Q1 Predictions Min                   19.1351
trainer/Q2 Predictions Mean                 344.782
trainer/Q2 Predictions Std                   96.7419
trainer/Q2 Predictions Max                  422.013
trainer/Q2 Predictions Min                   17.7029
trainer/Q Targets Mean                      344.195
trainer/Q Targets Std                        96.5326
trainer/Q Targets Max                       420.932
trainer/Q Targets Min                        18.8573
trainer/Log Pis Mean                          5.76858
trainer/Log Pis Std                           4.15329
trainer/Log Pis Max                          18.0095
trainer/Log Pis Min                          -4.35543
trainer/policy/mean Mean                      0.072153
trainer/policy/mean Std                       0.76926
trainer/policy/mean Max                       0.99866
trainer/policy/mean Min                      -0.996561
trainer/policy/normal/std Mean                0.439514
trainer/policy/normal/std Std                 0.14371
trainer/policy/normal/std Max                 0.898875
trainer/policy/normal/std Min                 0.0676663
trainer/policy/normal/log_std Mean           -0.893187
trainer/policy/normal/log_std Std             0.416505
trainer/policy/normal/log_std Max            -0.106612
trainer/policy/normal/log_std Min            -2.69317
trainer/Alpha                                 0.124002
trainer/Alpha Loss                           -0.483076
expl/num steps total                     249000
expl/num paths total                        249
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.4253
expl/Rewards Std                              1.15987
expl/Rewards Max                              7.57524
expl/Rewards Min                             -0.549051
expl/Returns Mean                          5425.3
expl/Returns Std                              0
expl/Returns Max                           5425.3
expl/Returns Min                           5425.3
expl/Actions Mean                             0.0907774
expl/Actions Std                              0.801819
expl/Actions Max                              0.999206
expl/Actions Min                             -0.999151
expl/Num Paths                                1
expl/Average Returns                       5425.3
expl/env_infos/final/reward_run Mean          6.30745
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.30745
expl/env_infos/final/reward_run Min           6.30745
expl/env_infos/initial/reward_run Mean       -0.249954
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.249954
expl/env_infos/initial/reward_run Min        -0.249954
expl/env_infos/reward_run Mean                5.816
expl/env_infos/reward_run Std                 1.15089
expl/env_infos/reward_run Max                 8.0245
expl/env_infos/reward_run Min                -0.249954
expl/env_infos/final/reward_ctrl Mean        -0.309452
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.309452
expl/env_infos/final/reward_ctrl Min         -0.309452
expl/env_infos/initial/reward_ctrl Mean      -0.299097
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.299097
expl/env_infos/initial/reward_ctrl Min       -0.299097
expl/env_infos/reward_ctrl Mean              -0.390692
expl/env_infos/reward_ctrl Std                0.0936625
expl/env_infos/reward_ctrl Max               -0.0876454
expl/env_infos/reward_ctrl Min               -0.579359
eval/num steps total                          1.24e+06
eval/num paths total                       1240
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.76055
eval/Rewards Std                              1.24166
eval/Rewards Max                              8.21852
eval/Rewards Min                             -0.727699
eval/Returns Mean                          5760.55
eval/Returns Std                             34.7244
eval/Returns Max                           5823.35
eval/Returns Min                           5717.9
eval/Actions Mean                             0.0914712
eval/Actions Std                              0.816489
eval/Actions Max                              0.998259
eval/Actions Min                             -0.99675
eval/Num Paths                                5
eval/Average Returns                       5760.55
eval/env_infos/final/reward_run Mean          6.04642
eval/env_infos/final/reward_run Std           0.753288
eval/env_infos/final/reward_run Max           7.32046
eval/env_infos/final/reward_run Min           5.31064
eval/env_infos/initial/reward_run Mean       -0.286353
eval/env_infos/initial/reward_run Std         0.0738989
eval/env_infos/initial/reward_run Max        -0.180626
eval/env_infos/initial/reward_run Min        -0.365392
eval/env_infos/reward_run Mean                6.16556
eval/env_infos/reward_run Std                 1.2306
eval/env_infos/reward_run Max                 8.68309
eval/env_infos/reward_run Min                -0.365392
eval/env_infos/final/reward_ctrl Mean        -0.377254
eval/env_infos/final/reward_ctrl Std          0.0826491
eval/env_infos/final/reward_ctrl Max         -0.234798
eval/env_infos/final/reward_ctrl Min         -0.481329
eval/env_infos/initial/reward_ctrl Mean      -0.304094
eval/env_infos/initial/reward_ctrl Std        0.0579607
eval/env_infos/initial/reward_ctrl Max       -0.240371
eval/env_infos/initial/reward_ctrl Min       -0.380596
eval/env_infos/reward_ctrl Mean              -0.405012
eval/env_infos/reward_ctrl Std                0.0903436
eval/env_infos/reward_ctrl Max               -0.107259
eval/env_infos/reward_ctrl Min               -0.581354
time/data storing (s)                         0.00450757
time/evaluation sampling (s)                  1.98068
time/exploration sampling (s)                 0.530216
time/logging (s)                              0.013766
time/sac training (s)                         7.35822
time/saving (s)                               0.00375128
time/training (s)                             3.4191e-05
time/epoch (s)                                9.89118
time/total (s)                             2648.4
Epoch                                       247
---------------------------------------  ---------------
2021-11-24 01:13:32.410925 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 248 finished
---------------------------------------  ---------------
epoch                                       248
replay_buffer/size                       250000
trainer/num train calls                  249000
trainer/QF1 Loss                              5.78336
trainer/QF2 Loss                              6.92587
trainer/Policy Loss                        -352.928
trainer/Q1 Predictions Mean                 353.463
trainer/Q1 Predictions Std                   97.9001
trainer/Q1 Predictions Max                  424.671
trainer/Q1 Predictions Min                   17.6052
trainer/Q2 Predictions Mean                 353.332
trainer/Q2 Predictions Std                   97.9753
trainer/Q2 Predictions Max                  423.412
trainer/Q2 Predictions Min                   16.9945
trainer/Q Targets Mean                      353.032
trainer/Q Targets Std                        97.6736
trainer/Q Targets Max                       422.714
trainer/Q Targets Min                        16.522
trainer/Log Pis Mean                          6.15244
trainer/Log Pis Std                           4.52263
trainer/Log Pis Max                          15.1046
trainer/Log Pis Min                          -5.43888
trainer/policy/mean Mean                      0.0621852
trainer/policy/mean Std                       0.784929
trainer/policy/mean Max                       0.999772
trainer/policy/mean Min                      -0.997631
trainer/policy/normal/std Mean                0.442928
trainer/policy/normal/std Std                 0.146771
trainer/policy/normal/std Max                 1.01977
trainer/policy/normal/std Min                 0.0685881
trainer/policy/normal/log_std Mean           -0.884654
trainer/policy/normal/log_std Std             0.409492
trainer/policy/normal/log_std Max             0.0195817
trainer/policy/normal/log_std Min            -2.67964
trainer/Alpha                                 0.124041
trainer/Alpha Loss                            0.318156
expl/num steps total                     250000
expl/num paths total                        250
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.49066
expl/Rewards Std                              1.18915
expl/Rewards Max                              7.89224
expl/Rewards Min                             -0.265862
expl/Returns Mean                          5490.66
expl/Returns Std                              0
expl/Returns Max                           5490.66
expl/Returns Min                           5490.66
expl/Actions Mean                             0.0858365
expl/Actions Std                              0.810516
expl/Actions Max                              0.999625
expl/Actions Min                             -0.99895
expl/Num Paths                                1
expl/Average Returns                       5490.66
expl/env_infos/final/reward_run Mean          6.91586
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.91586
expl/env_infos/final/reward_run Min           6.91586
expl/env_infos/initial/reward_run Mean        0.0157134
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0157134
expl/env_infos/initial/reward_run Min         0.0157134
expl/env_infos/reward_run Mean                5.88925
expl/env_infos/reward_run Std                 1.18192
expl/env_infos/reward_run Max                 8.39951
expl/env_infos/reward_run Min                -0.09227
expl/env_infos/final/reward_ctrl Mean        -0.462374
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.462374
expl/env_infos/final/reward_ctrl Min         -0.462374
expl/env_infos/initial/reward_ctrl Mean      -0.274607
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.274607
expl/env_infos/initial/reward_ctrl Min       -0.274607
expl/env_infos/reward_ctrl Mean              -0.398583
expl/env_infos/reward_ctrl Std                0.0915097
expl/env_infos/reward_ctrl Max               -0.0579101
expl/env_infos/reward_ctrl Min               -0.574584
eval/num steps total                          1.245e+06
eval/num paths total                       1245
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.65787
eval/Rewards Std                              1.23197
eval/Rewards Max                              8.02414
eval/Rewards Min                             -0.677246
eval/Returns Mean                          5657.87
eval/Returns Std                             39.6943
eval/Returns Max                           5706.68
eval/Returns Min                           5599.46
eval/Actions Mean                             0.0990298
eval/Actions Std                              0.819627
eval/Actions Max                              0.998525
eval/Actions Min                             -0.997686
eval/Num Paths                                5
eval/Average Returns                       5657.87
eval/env_infos/final/reward_run Mean          6.04826
eval/env_infos/final/reward_run Std           0.693442
eval/env_infos/final/reward_run Max           7.17998
eval/env_infos/final/reward_run Min           5.09675
eval/env_infos/initial/reward_run Mean       -0.210961
eval/env_infos/initial/reward_run Std         0.130719
eval/env_infos/initial/reward_run Max        -0.0421999
eval/env_infos/initial/reward_run Min        -0.368962
eval/env_infos/reward_run Mean                6.06682
eval/env_infos/reward_run Std                 1.2192
eval/env_infos/reward_run Max                 8.49808
eval/env_infos/reward_run Min                -0.368962
eval/env_infos/final/reward_ctrl Mean        -0.414155
eval/env_infos/final/reward_ctrl Std          0.0332971
eval/env_infos/final/reward_ctrl Max         -0.385219
eval/env_infos/final/reward_ctrl Min         -0.477384
eval/env_infos/initial/reward_ctrl Mean      -0.27527
eval/env_infos/initial/reward_ctrl Std        0.057492
eval/env_infos/initial/reward_ctrl Max       -0.193836
eval/env_infos/initial/reward_ctrl Min       -0.357534
eval/env_infos/reward_ctrl Mean              -0.408958
eval/env_infos/reward_ctrl Std                0.0865939
eval/env_infos/reward_ctrl Max               -0.116384
eval/env_infos/reward_ctrl Min               -0.578946
time/data storing (s)                         0.00450386
time/evaluation sampling (s)                  1.98718
time/exploration sampling (s)                 0.531955
time/logging (s)                              0.0137775
time/sac training (s)                         7.3522
time/saving (s)                               0.00379012
time/training (s)                             3.5083e-05
time/epoch (s)                                9.89344
time/total (s)                             2658.57
Epoch                                       248
---------------------------------------  ---------------
2021-11-24 01:13:42.647958 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 249 finished
---------------------------------------  ---------------
epoch                                       249
replay_buffer/size                       251000
trainer/num train calls                  250000
trainer/QF1 Loss                              5.97319
trainer/QF2 Loss                              5.21486
trainer/Policy Loss                        -341.304
trainer/Q1 Predictions Mean                 341.706
trainer/Q1 Predictions Std                  107.041
trainer/Q1 Predictions Max                  431.232
trainer/Q1 Predictions Min                   15.7594
trainer/Q2 Predictions Mean                 342.045
trainer/Q2 Predictions Std                  107.29
trainer/Q2 Predictions Max                  431.949
trainer/Q2 Predictions Min                   16.1013
trainer/Q Targets Mean                      341.434
trainer/Q Targets Std                       106.964
trainer/Q Targets Max                       431.983
trainer/Q Targets Min                        16.7264
trainer/Log Pis Mean                          6.06888
trainer/Log Pis Std                           4.69943
trainer/Log Pis Max                          16.8572
trainer/Log Pis Min                          -7.03039
trainer/policy/mean Mean                      0.0920155
trainer/policy/mean Std                       0.775416
trainer/policy/mean Max                       0.995308
trainer/policy/mean Min                      -0.999376
trainer/policy/normal/std Mean                0.452261
trainer/policy/normal/std Std                 0.151386
trainer/policy/normal/std Max                 1.25666
trainer/policy/normal/std Min                 0.0789892
trainer/policy/normal/log_std Mean           -0.864323
trainer/policy/normal/log_std Std             0.410496
trainer/policy/normal/log_std Max             0.228456
trainer/policy/normal/log_std Min            -2.53844
trainer/Alpha                                 0.127873
trainer/Alpha Loss                            0.141661
expl/num steps total                     251000
expl/num paths total                        251
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33322
expl/Rewards Std                              1.20028
expl/Rewards Max                              7.50942
expl/Rewards Min                             -0.585679
expl/Returns Mean                          5333.22
expl/Returns Std                              0
expl/Returns Max                           5333.22
expl/Returns Min                           5333.22
expl/Actions Mean                             0.0807954
expl/Actions Std                              0.809645
expl/Actions Max                              0.999416
expl/Actions Min                             -0.999798
expl/Num Paths                                1
expl/Average Returns                       5333.22
expl/env_infos/final/reward_run Mean          6.96112
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.96112
expl/env_infos/final/reward_run Min           6.96112
expl/env_infos/initial/reward_run Mean       -0.338892
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.338892
expl/env_infos/initial/reward_run Min        -0.338892
expl/env_infos/reward_run Mean                5.73045
expl/env_infos/reward_run Std                 1.18435
expl/env_infos/reward_run Max                 7.96838
expl/env_infos/reward_run Min                -0.338892
expl/env_infos/final/reward_ctrl Mean        -0.375931
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.375931
expl/env_infos/final/reward_ctrl Min         -0.375931
expl/env_infos/initial/reward_ctrl Mean      -0.246787
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.246787
expl/env_infos/initial/reward_ctrl Min       -0.246787
expl/env_infos/reward_ctrl Mean              -0.397231
expl/env_infos/reward_ctrl Std                0.0955452
expl/env_infos/reward_ctrl Max               -0.0931204
expl/env_infos/reward_ctrl Min               -0.573244
eval/num steps total                          1.25e+06
eval/num paths total                       1250
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.76555
eval/Rewards Std                              1.27541
eval/Rewards Max                              8.00381
eval/Rewards Min                             -0.744121
eval/Returns Mean                          5765.55
eval/Returns Std                             30.2003
eval/Returns Max                           5803.38
eval/Returns Min                           5724.48
eval/Actions Mean                             0.075735
eval/Actions Std                              0.827628
eval/Actions Max                              0.996963
eval/Actions Min                             -0.998617
eval/Num Paths                                5
eval/Average Returns                       5765.55
eval/env_infos/final/reward_run Mean          5.70349
eval/env_infos/final/reward_run Std           0.397495
eval/env_infos/final/reward_run Max           6.21013
eval/env_infos/final/reward_run Min           5.00708
eval/env_infos/initial/reward_run Mean       -0.255359
eval/env_infos/initial/reward_run Std         0.102005
eval/env_infos/initial/reward_run Max        -0.141723
eval/env_infos/initial/reward_run Min        -0.392496
eval/env_infos/reward_run Mean                6.17997
eval/env_infos/reward_run Std                 1.25362
eval/env_infos/reward_run Max                 8.51436
eval/env_infos/reward_run Min                -0.392496
eval/env_infos/final/reward_ctrl Mean        -0.481601
eval/env_infos/final/reward_ctrl Std          0.0380764
eval/env_infos/final/reward_ctrl Max         -0.43086
eval/env_infos/final/reward_ctrl Min         -0.540668
eval/env_infos/initial/reward_ctrl Mean      -0.314752
eval/env_infos/initial/reward_ctrl Std        0.0335201
eval/env_infos/initial/reward_ctrl Max       -0.274089
eval/env_infos/initial/reward_ctrl Min       -0.351625
eval/env_infos/reward_ctrl Mean              -0.414423
eval/env_infos/reward_ctrl Std                0.0954786
eval/env_infos/reward_ctrl Max               -0.106553
eval/env_infos/reward_ctrl Min               -0.582378
time/data storing (s)                         0.00444872
time/evaluation sampling (s)                  2.01561
time/exploration sampling (s)                 0.520805
time/logging (s)                              0.0138143
time/sac training (s)                         7.38979
time/saving (s)                               0.00375236
time/training (s)                             3.3932e-05
time/epoch (s)                                9.94826
time/total (s)                             2668.79
Epoch                                       249
---------------------------------------  ---------------
2021-11-24 01:13:52.847816 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 250 finished
---------------------------------------  ---------------
epoch                                       250
replay_buffer/size                       252000
trainer/num train calls                  251000
trainer/QF1 Loss                              9.64424
trainer/QF2 Loss                              7.58697
trainer/Policy Loss                        -344.223
trainer/Q1 Predictions Mean                 344.948
trainer/Q1 Predictions Std                  101.241
trainer/Q1 Predictions Max                  423.594
trainer/Q1 Predictions Min                   17.7917
trainer/Q2 Predictions Mean                 344.707
trainer/Q2 Predictions Std                  101.242
trainer/Q2 Predictions Max                  423.816
trainer/Q2 Predictions Min                   16.1236
trainer/Q Targets Mean                      345.187
trainer/Q Targets Std                       101.375
trainer/Q Targets Max                       425.093
trainer/Q Targets Min                        16.1795
trainer/Log Pis Mean                          5.91514
trainer/Log Pis Std                           4.5208
trainer/Log Pis Max                          17.2815
trainer/Log Pis Min                          -5.36445
trainer/policy/mean Mean                      0.0644888
trainer/policy/mean Std                       0.767016
trainer/policy/mean Max                       0.998499
trainer/policy/mean Min                      -0.998733
trainer/policy/normal/std Mean                0.444319
trainer/policy/normal/std Std                 0.149727
trainer/policy/normal/std Max                 0.960978
trainer/policy/normal/std Min                 0.0583051
trainer/policy/normal/log_std Mean           -0.883217
trainer/policy/normal/log_std Std             0.414781
trainer/policy/normal/log_std Max            -0.0398035
trainer/policy/normal/log_std Min            -2.84207
trainer/Alpha                                 0.12536
trainer/Alpha Loss                           -0.17621
expl/num steps total                     252000
expl/num paths total                        252
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.32038
expl/Rewards Std                              1.19673
expl/Rewards Max                              7.78794
expl/Rewards Min                             -0.595159
expl/Returns Mean                          5320.38
expl/Returns Std                              0
expl/Returns Max                           5320.38
expl/Returns Min                           5320.38
expl/Actions Mean                             0.0709734
expl/Actions Std                              0.808199
expl/Actions Max                              0.999732
expl/Actions Min                             -0.99942
expl/Num Paths                                1
expl/Average Returns                       5320.38
expl/env_infos/final/reward_run Mean          6.92281
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.92281
expl/env_infos/final/reward_run Min           6.92281
expl/env_infos/initial/reward_run Mean       -0.26336
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.26336
expl/env_infos/initial/reward_run Min        -0.26336
expl/env_infos/reward_run Mean                5.71531
expl/env_infos/reward_run Std                 1.18447
expl/env_infos/reward_run Max                 8.2307
expl/env_infos/reward_run Min                -0.26336
expl/env_infos/final/reward_ctrl Mean        -0.399444
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.399444
expl/env_infos/final/reward_ctrl Min         -0.399444
expl/env_infos/initial/reward_ctrl Mean      -0.331799
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.331799
expl/env_infos/initial/reward_ctrl Min       -0.331799
expl/env_infos/reward_ctrl Mean              -0.394933
expl/env_infos/reward_ctrl Std                0.091094
expl/env_infos/reward_ctrl Max               -0.103702
expl/env_infos/reward_ctrl Min               -0.576417
eval/num steps total                          1.255e+06
eval/num paths total                       1255
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.75857
eval/Rewards Std                              1.28515
eval/Rewards Max                              8.42505
eval/Rewards Min                             -0.758081
eval/Returns Mean                          5758.57
eval/Returns Std                             88.7902
eval/Returns Max                           5924.89
eval/Returns Min                           5676.43
eval/Actions Mean                             0.0788568
eval/Actions Std                              0.82533
eval/Actions Max                              0.999028
eval/Actions Min                             -0.998698
eval/Num Paths                                5
eval/Average Returns                       5758.57
eval/env_infos/final/reward_run Mean          6.72124
eval/env_infos/final/reward_run Std           0.925728
eval/env_infos/final/reward_run Max           8.31794
eval/env_infos/final/reward_run Min           5.78652
eval/env_infos/initial/reward_run Mean       -0.280008
eval/env_infos/initial/reward_run Std         0.132819
eval/env_infos/initial/reward_run Max        -0.0997106
eval/env_infos/initial/reward_run Min        -0.485287
eval/env_infos/reward_run Mean                6.171
eval/env_infos/reward_run Std                 1.26949
eval/env_infos/reward_run Max                 8.92773
eval/env_infos/reward_run Min                -0.485287
eval/env_infos/final/reward_ctrl Mean        -0.383168
eval/env_infos/final/reward_ctrl Std          0.0573181
eval/env_infos/final/reward_ctrl Max         -0.320016
eval/env_infos/final/reward_ctrl Min         -0.470845
eval/env_infos/initial/reward_ctrl Mean      -0.306984
eval/env_infos/initial/reward_ctrl Std        0.0353785
eval/env_infos/initial/reward_ctrl Max       -0.265356
eval/env_infos/initial/reward_ctrl Min       -0.363203
eval/env_infos/reward_ctrl Mean              -0.412433
eval/env_infos/reward_ctrl Std                0.0937353
eval/env_infos/reward_ctrl Max               -0.101275
eval/env_infos/reward_ctrl Min               -0.58812
time/data storing (s)                         0.00446508
time/evaluation sampling (s)                  2.00355
time/exploration sampling (s)                 0.532986
time/logging (s)                              0.0138005
time/sac training (s)                         7.35131
time/saving (s)                               0.00374774
time/training (s)                             3.405e-05
time/epoch (s)                                9.9099
time/total (s)                             2678.98
Epoch                                       250
---------------------------------------  ---------------
2021-11-24 01:14:03.085675 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 251 finished
---------------------------------------  ---------------
epoch                                       251
replay_buffer/size                       253000
trainer/num train calls                  252000
trainer/QF1 Loss                              7.57025
trainer/QF2 Loss                              6.64045
trainer/Policy Loss                        -335.848
trainer/Q1 Predictions Mean                 335.877
trainer/Q1 Predictions Std                  116.044
trainer/Q1 Predictions Max                  428.877
trainer/Q1 Predictions Min                   18.7301
trainer/Q2 Predictions Mean                 335.746
trainer/Q2 Predictions Std                  116.08
trainer/Q2 Predictions Max                  428.59
trainer/Q2 Predictions Min                   17.7098
trainer/Q Targets Mean                      335.846
trainer/Q Targets Std                       116.211
trainer/Q Targets Max                       430.538
trainer/Q Targets Min                        18.1108
trainer/Log Pis Mean                          6.10056
trainer/Log Pis Std                           4.99342
trainer/Log Pis Max                          21.8273
trainer/Log Pis Min                          -4.32589
trainer/policy/mean Mean                      0.0905244
trainer/policy/mean Std                       0.768103
trainer/policy/mean Max                       0.999279
trainer/policy/mean Min                      -0.997619
trainer/policy/normal/std Mean                0.458645
trainer/policy/normal/std Std                 0.153998
trainer/policy/normal/std Max                 0.912871
trainer/policy/normal/std Min                 0.067756
trainer/policy/normal/log_std Mean           -0.85327
trainer/policy/normal/log_std Std             0.423098
trainer/policy/normal/log_std Max            -0.0911604
trainer/policy/normal/log_std Min            -2.69184
trainer/Alpha                                 0.126664
trainer/Alpha Loss                            0.207775
expl/num steps total                     253000
expl/num paths total                        253
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.48296
expl/Rewards Std                              1.24631
expl/Rewards Max                              7.8801
expl/Rewards Min                             -0.664426
expl/Returns Mean                          5482.96
expl/Returns Std                              0
expl/Returns Max                           5482.96
expl/Returns Min                           5482.96
expl/Actions Mean                             0.0769768
expl/Actions Std                              0.806976
expl/Actions Max                              0.999787
expl/Actions Min                             -0.998798
expl/Num Paths                                1
expl/Average Returns                       5482.96
expl/env_infos/final/reward_run Mean          6.06131
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.06131
expl/env_infos/final/reward_run Min           6.06131
expl/env_infos/initial/reward_run Mean       -0.391656
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.391656
expl/env_infos/initial/reward_run Min        -0.391656
expl/env_infos/reward_run Mean                5.87724
expl/env_infos/reward_run Std                 1.24213
expl/env_infos/reward_run Max                 8.35287
expl/env_infos/reward_run Min                -0.391656
expl/env_infos/final/reward_ctrl Mean        -0.350745
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.350745
expl/env_infos/final/reward_ctrl Min         -0.350745
expl/env_infos/initial/reward_ctrl Mean      -0.27277
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.27277
expl/env_infos/initial/reward_ctrl Min       -0.27277
expl/env_infos/reward_ctrl Mean              -0.394282
expl/env_infos/reward_ctrl Std                0.091265
expl/env_infos/reward_ctrl Max               -0.113878
expl/env_infos/reward_ctrl Min               -0.57297
eval/num steps total                          1.26e+06
eval/num paths total                       1260
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.71043
eval/Rewards Std                              1.25664
eval/Rewards Max                              8.21078
eval/Rewards Min                             -0.745036
eval/Returns Mean                          5710.43
eval/Returns Std                             52.2982
eval/Returns Max                           5784.36
eval/Returns Min                           5626.11
eval/Actions Mean                             0.0905853
eval/Actions Std                              0.824229
eval/Actions Max                              0.997974
eval/Actions Min                             -0.997403
eval/Num Paths                                5
eval/Average Returns                       5710.43
eval/env_infos/final/reward_run Mean          6.1534
eval/env_infos/final/reward_run Std           0.914021
eval/env_infos/final/reward_run Max           7.81002
eval/env_infos/final/reward_run Min           5.05811
eval/env_infos/initial/reward_run Mean       -0.375972
eval/env_infos/initial/reward_run Std         0.0637331
eval/env_infos/initial/reward_run Max        -0.270214
eval/env_infos/initial/reward_run Min        -0.467269
eval/env_infos/reward_run Mean                6.12297
eval/env_infos/reward_run Std                 1.24506
eval/env_infos/reward_run Max                 8.69572
eval/env_infos/reward_run Min                -0.467269
eval/env_infos/final/reward_ctrl Mean        -0.41663
eval/env_infos/final/reward_ctrl Std          0.0438547
eval/env_infos/final/reward_ctrl Max         -0.35492
eval/env_infos/final/reward_ctrl Min         -0.479018
eval/env_infos/initial/reward_ctrl Mean      -0.290808
eval/env_infos/initial/reward_ctrl Std        0.0127014
eval/env_infos/initial/reward_ctrl Max       -0.27749
eval/env_infos/initial/reward_ctrl Min       -0.308009
eval/env_infos/reward_ctrl Mean              -0.412536
eval/env_infos/reward_ctrl Std                0.0876105
eval/env_infos/reward_ctrl Max               -0.103247
eval/env_infos/reward_ctrl Min               -0.584646
time/data storing (s)                         0.00446595
time/evaluation sampling (s)                  1.98759
time/exploration sampling (s)                 0.530905
time/logging (s)                              0.0135494
time/sac training (s)                         7.40666
time/saving (s)                               0.00519294
time/training (s)                             3.4592e-05
time/epoch (s)                                9.9484
time/total (s)                             2689.2
Epoch                                       251
---------------------------------------  ---------------
2021-11-24 01:14:13.683931 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 252 finished
---------------------------------------  ---------------
epoch                                       252
replay_buffer/size                       254000
trainer/num train calls                  253000
trainer/QF1 Loss                              7.91887
trainer/QF2 Loss                              7.70581
trainer/Policy Loss                        -344.174
trainer/Q1 Predictions Mean                 344.824
trainer/Q1 Predictions Std                  109.45
trainer/Q1 Predictions Max                  427.092
trainer/Q1 Predictions Min                   17.0905
trainer/Q2 Predictions Mean                 344.712
trainer/Q2 Predictions Std                  109.57
trainer/Q2 Predictions Max                  426.647
trainer/Q2 Predictions Min                   17.0047
trainer/Q Targets Mean                      344.868
trainer/Q Targets Std                       109.523
trainer/Q Targets Max                       427.758
trainer/Q Targets Min                        16.5605
trainer/Log Pis Mean                          6.60985
trainer/Log Pis Std                           4.81343
trainer/Log Pis Max                          18.0883
trainer/Log Pis Min                          -5.30974
trainer/policy/mean Mean                      0.0856926
trainer/policy/mean Std                       0.783327
trainer/policy/mean Max                       0.999278
trainer/policy/mean Min                      -0.997744
trainer/policy/normal/std Mean                0.451804
trainer/policy/normal/std Std                 0.150869
trainer/policy/normal/std Max                 0.970269
trainer/policy/normal/std Min                 0.0663437
trainer/policy/normal/log_std Mean           -0.868175
trainer/policy/normal/log_std Std             0.422523
trainer/policy/normal/log_std Max            -0.0301823
trainer/policy/normal/log_std Min            -2.71291
trainer/Alpha                                 0.128667
trainer/Alpha Loss                            1.25052
expl/num steps total                     254000
expl/num paths total                        254
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.47303
expl/Rewards Std                              1.24394
expl/Rewards Max                              7.84011
expl/Rewards Min                             -0.799468
expl/Returns Mean                          5473.03
expl/Returns Std                              0
expl/Returns Max                           5473.03
expl/Returns Min                           5473.03
expl/Actions Mean                             0.0900117
expl/Actions Std                              0.816132
expl/Actions Max                              0.999693
expl/Actions Min                             -0.999364
expl/Num Paths                                1
expl/Average Returns                       5473.03
expl/env_infos/final/reward_run Mean          5.27562
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.27562
expl/env_infos/final/reward_run Min           5.27562
expl/env_infos/initial/reward_run Mean       -0.508678
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.508678
expl/env_infos/initial/reward_run Min        -0.508678
expl/env_infos/reward_run Mean                5.87753
expl/env_infos/reward_run Std                 1.23304
expl/env_infos/reward_run Max                 8.32868
expl/env_infos/reward_run Min                -0.508678
expl/env_infos/final/reward_ctrl Mean        -0.551433
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.551433
expl/env_infos/final/reward_ctrl Min         -0.551433
expl/env_infos/initial/reward_ctrl Mean      -0.29079
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.29079
expl/env_infos/initial/reward_ctrl Min       -0.29079
expl/env_infos/reward_ctrl Mean              -0.404504
expl/env_infos/reward_ctrl Std                0.0916135
expl/env_infos/reward_ctrl Max               -0.112026
expl/env_infos/reward_ctrl Min               -0.567102
eval/num steps total                          1.265e+06
eval/num paths total                       1265
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.73545
eval/Rewards Std                              1.29756
eval/Rewards Max                              8.45346
eval/Rewards Min                             -0.885482
eval/Returns Mean                          5735.45
eval/Returns Std                             67.4341
eval/Returns Max                           5831.28
eval/Returns Min                           5634.74
eval/Actions Mean                             0.0993205
eval/Actions Std                              0.827945
eval/Actions Max                              0.997971
eval/Actions Min                             -0.998516
eval/Num Paths                                5
eval/Average Returns                       5735.45
eval/env_infos/final/reward_run Mean          6.62419
eval/env_infos/final/reward_run Std           0.763353
eval/env_infos/final/reward_run Max           7.73885
eval/env_infos/final/reward_run Min           5.80927
eval/env_infos/initial/reward_run Mean       -0.287648
eval/env_infos/initial/reward_run Std         0.148298
eval/env_infos/initial/reward_run Max        -0.0795229
eval/env_infos/initial/reward_run Min        -0.500445
eval/env_infos/reward_run Mean                6.15266
eval/env_infos/reward_run Std                 1.28133
eval/env_infos/reward_run Max                 8.91551
eval/env_infos/reward_run Min                -0.500445
eval/env_infos/final/reward_ctrl Mean        -0.467215
eval/env_infos/final/reward_ctrl Std          0.0454022
eval/env_infos/final/reward_ctrl Max         -0.387849
eval/env_infos/final/reward_ctrl Min         -0.527641
eval/env_infos/initial/reward_ctrl Mean      -0.301638
eval/env_infos/initial/reward_ctrl Std        0.0732411
eval/env_infos/initial/reward_ctrl Max       -0.195221
eval/env_infos/initial/reward_ctrl Min       -0.385037
eval/env_infos/reward_ctrl Mean              -0.417215
eval/env_infos/reward_ctrl Std                0.0886589
eval/env_infos/reward_ctrl Max               -0.0871551
eval/env_infos/reward_ctrl Min               -0.581373
time/data storing (s)                         0.00450884
time/evaluation sampling (s)                  2.06728
time/exploration sampling (s)                 0.535527
time/logging (s)                              0.0136739
time/sac training (s)                         7.65099
time/saving (s)                               0.00375289
time/training (s)                             3.4652e-05
time/epoch (s)                               10.2758
time/total (s)                             2699.79
Epoch                                       252
---------------------------------------  ---------------
2021-11-24 01:14:24.030558 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 253 finished
---------------------------------------  ---------------
epoch                                       253
replay_buffer/size                       255000
trainer/num train calls                  254000
trainer/QF1 Loss                             23.171
trainer/QF2 Loss                             22.7016
trainer/Policy Loss                        -342.402
trainer/Q1 Predictions Mean                 342.428
trainer/Q1 Predictions Std                  102.783
trainer/Q1 Predictions Max                  424.461
trainer/Q1 Predictions Min                   16.7922
trainer/Q2 Predictions Mean                 342.911
trainer/Q2 Predictions Std                  102.954
trainer/Q2 Predictions Max                  425.929
trainer/Q2 Predictions Min                   17.0637
trainer/Q Targets Mean                      343.282
trainer/Q Targets Std                       103.565
trainer/Q Targets Max                       427.217
trainer/Q Targets Min                        17.7817
trainer/Log Pis Mean                          6.34572
trainer/Log Pis Std                           4.80434
trainer/Log Pis Max                          17.6149
trainer/Log Pis Min                          -5.1341
trainer/policy/mean Mean                      0.0930895
trainer/policy/mean Std                       0.783008
trainer/policy/mean Max                       0.997731
trainer/policy/mean Min                      -0.997908
trainer/policy/normal/std Mean                0.451326
trainer/policy/normal/std Std                 0.143773
trainer/policy/normal/std Max                 0.965427
trainer/policy/normal/std Min                 0.0692334
trainer/policy/normal/log_std Mean           -0.861729
trainer/policy/normal/log_std Std             0.398302
trainer/policy/normal/log_std Max            -0.0351846
trainer/policy/normal/log_std Min            -2.67027
trainer/Alpha                                 0.126131
trainer/Alpha Loss                            0.715798
expl/num steps total                     255000
expl/num paths total                        255
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.50643
expl/Rewards Std                              1.19951
expl/Rewards Max                              7.56406
expl/Rewards Min                             -0.394437
expl/Returns Mean                          5506.43
expl/Returns Std                              0
expl/Returns Max                           5506.43
expl/Returns Min                           5506.43
expl/Actions Mean                             0.0993956
expl/Actions Std                              0.817053
expl/Actions Max                              0.999804
expl/Actions Min                             -0.999476
expl/Num Paths                                1
expl/Average Returns                       5506.43
expl/env_infos/final/reward_run Mean          7.39506
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.39506
expl/env_infos/final/reward_run Min           7.39506
expl/env_infos/initial/reward_run Mean       -0.141418
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.141418
expl/env_infos/initial/reward_run Min        -0.141418
expl/env_infos/reward_run Mean                5.9129
expl/env_infos/reward_run Std                 1.19373
expl/env_infos/reward_run Max                 8.05961
expl/env_infos/reward_run Min                -0.141418
expl/env_infos/final/reward_ctrl Mean        -0.452056
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.452056
expl/env_infos/final/reward_ctrl Min         -0.452056
expl/env_infos/initial/reward_ctrl Mean      -0.253018
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.253018
expl/env_infos/initial/reward_ctrl Min       -0.253018
expl/env_infos/reward_ctrl Mean              -0.406473
expl/env_infos/reward_ctrl Std                0.0900806
expl/env_infos/reward_ctrl Max               -0.0854181
expl/env_infos/reward_ctrl Min               -0.585085
eval/num steps total                          1.27e+06
eval/num paths total                       1270
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.61938
eval/Rewards Std                              1.25918
eval/Rewards Max                              7.91875
eval/Rewards Min                             -0.962981
eval/Returns Mean                          5619.38
eval/Returns Std                             54.8686
eval/Returns Max                           5672.51
eval/Returns Min                           5535.7
eval/Actions Mean                             0.118497
eval/Actions Std                              0.827479
eval/Actions Max                              0.998826
eval/Actions Min                             -0.99743
eval/Num Paths                                5
eval/Average Returns                       5619.38
eval/env_infos/final/reward_run Mean          5.74502
eval/env_infos/final/reward_run Std           0.707185
eval/env_infos/final/reward_run Max           7.03378
eval/env_infos/final/reward_run Min           5.09715
eval/env_infos/initial/reward_run Mean       -0.339808
eval/env_infos/initial/reward_run Std         0.145973
eval/env_infos/initial/reward_run Max        -0.161236
eval/env_infos/initial/reward_run Min        -0.573815
eval/env_infos/reward_run Mean                6.03864
eval/env_infos/reward_run Std                 1.25079
eval/env_infos/reward_run Max                 8.41411
eval/env_infos/reward_run Min                -0.573815
eval/env_infos/final/reward_ctrl Mean        -0.400457
eval/env_infos/final/reward_ctrl Std          0.0868691
eval/env_infos/final/reward_ctrl Max         -0.241924
eval/env_infos/final/reward_ctrl Min         -0.502808
eval/env_infos/initial/reward_ctrl Mean      -0.290609
eval/env_infos/initial/reward_ctrl Std        0.077374
eval/env_infos/initial/reward_ctrl Max       -0.198171
eval/env_infos/initial/reward_ctrl Min       -0.389166
eval/env_infos/reward_ctrl Mean              -0.419258
eval/env_infos/reward_ctrl Std                0.0856323
eval/env_infos/reward_ctrl Max               -0.111777
eval/env_infos/reward_ctrl Min               -0.581705
time/data storing (s)                         0.00450999
time/evaluation sampling (s)                  2.01512
time/exploration sampling (s)                 0.530921
time/logging (s)                              0.0136479
time/sac training (s)                         7.48771
time/saving (s)                               0.00375508
time/training (s)                             3.5341e-05
time/epoch (s)                               10.0557
time/total (s)                             2710.12
Epoch                                       253
---------------------------------------  ---------------
2021-11-24 01:14:34.288256 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 254 finished
---------------------------------------  ---------------
epoch                                       254
replay_buffer/size                       256000
trainer/num train calls                  255000
trainer/QF1 Loss                              5.54314
trainer/QF2 Loss                              4.58467
trainer/Policy Loss                        -343.867
trainer/Q1 Predictions Mean                 344.213
trainer/Q1 Predictions Std                  107.162
trainer/Q1 Predictions Max                  427.804
trainer/Q1 Predictions Min                   18.4173
trainer/Q2 Predictions Mean                 344.684
trainer/Q2 Predictions Std                  107.407
trainer/Q2 Predictions Max                  429.611
trainer/Q2 Predictions Min                   17.0683
trainer/Q Targets Mean                      344.704
trainer/Q Targets Std                       107.334
trainer/Q Targets Max                       429.671
trainer/Q Targets Min                        18.7963
trainer/Log Pis Mean                          5.73867
trainer/Log Pis Std                           4.70299
trainer/Log Pis Max                          19.0524
trainer/Log Pis Min                          -4.94227
trainer/policy/mean Mean                      0.0869382
trainer/policy/mean Std                       0.767202
trainer/policy/mean Max                       0.995749
trainer/policy/mean Min                      -0.998452
trainer/policy/normal/std Mean                0.448616
trainer/policy/normal/std Std                 0.151597
trainer/policy/normal/std Max                 1.06674
trainer/policy/normal/std Min                 0.0654391
trainer/policy/normal/log_std Mean           -0.875517
trainer/policy/normal/log_std Std             0.422528
trainer/policy/normal/log_std Max             0.0646044
trainer/policy/normal/log_std Min            -2.72664
trainer/Alpha                                 0.125474
trainer/Alpha Loss                           -0.542426
expl/num steps total                     256000
expl/num paths total                        256
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.37869
expl/Rewards Std                              1.19322
expl/Rewards Max                              7.59621
expl/Rewards Min                             -0.587391
expl/Returns Mean                          5378.69
expl/Returns Std                              0
expl/Returns Max                           5378.69
expl/Returns Min                           5378.69
expl/Actions Mean                             0.0844685
expl/Actions Std                              0.800929
expl/Actions Max                              0.999569
expl/Actions Min                             -0.998917
expl/Num Paths                                1
expl/Average Returns                       5378.69
expl/env_infos/final/reward_run Mean          7.95703
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.95703
expl/env_infos/final/reward_run Min           7.95703
expl/env_infos/initial/reward_run Mean       -0.267349
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.267349
expl/env_infos/initial/reward_run Min        -0.267349
expl/env_infos/reward_run Mean                5.76787
expl/env_infos/reward_run Std                 1.19023
expl/env_infos/reward_run Max                 8.05735
expl/env_infos/reward_run Min                -0.267349
expl/env_infos/final/reward_ctrl Mean        -0.477248
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.477248
expl/env_infos/final/reward_ctrl Min         -0.477248
expl/env_infos/initial/reward_ctrl Mean      -0.194828
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.194828
expl/env_infos/initial/reward_ctrl Min       -0.194828
expl/env_infos/reward_ctrl Mean              -0.389173
expl/env_infos/reward_ctrl Std                0.0921848
expl/env_infos/reward_ctrl Max               -0.05942
expl/env_infos/reward_ctrl Min               -0.585753
eval/num steps total                          1.275e+06
eval/num paths total                       1275
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.7342
eval/Rewards Std                              1.26733
eval/Rewards Max                              8.30669
eval/Rewards Min                             -0.682507
eval/Returns Mean                          5734.2
eval/Returns Std                            102.994
eval/Returns Max                           5887.07
eval/Returns Min                           5597.74
eval/Actions Mean                             0.0911311
eval/Actions Std                              0.822094
eval/Actions Max                              0.996611
eval/Actions Min                             -0.995808
eval/Num Paths                                5
eval/Average Returns                       5734.2
eval/env_infos/final/reward_run Mean          5.77098
eval/env_infos/final/reward_run Std           0.74775
eval/env_infos/final/reward_run Max           6.89925
eval/env_infos/final/reward_run Min           4.74748
eval/env_infos/initial/reward_run Mean       -0.144712
eval/env_infos/initial/reward_run Std         0.13621
eval/env_infos/initial/reward_run Max         0.0333661
eval/env_infos/initial/reward_run Min        -0.36421
eval/env_infos/reward_run Mean                6.14468
eval/env_infos/reward_run Std                 1.25886
eval/env_infos/reward_run Max                 8.82147
eval/env_infos/reward_run Min                -0.36421
eval/env_infos/final/reward_ctrl Mean        -0.457052
eval/env_infos/final/reward_ctrl Std          0.0462231
eval/env_infos/final/reward_ctrl Max         -0.407951
eval/env_infos/final/reward_ctrl Min         -0.535212
eval/env_infos/initial/reward_ctrl Mean      -0.280559
eval/env_infos/initial/reward_ctrl Std        0.0314552
eval/env_infos/initial/reward_ctrl Max       -0.233038
eval/env_infos/initial/reward_ctrl Min       -0.318298
eval/env_infos/reward_ctrl Mean              -0.410486
eval/env_infos/reward_ctrl Std                0.0889809
eval/env_infos/reward_ctrl Max               -0.111416
eval/env_infos/reward_ctrl Min               -0.583605
time/data storing (s)                         0.00447903
time/evaluation sampling (s)                  2.01223
time/exploration sampling (s)                 0.529027
time/logging (s)                              0.0136717
time/sac training (s)                         7.40446
time/saving (s)                               0.00377167
time/training (s)                             3.4205e-05
time/epoch (s)                                9.96768
time/total (s)                             2720.36
Epoch                                       254
---------------------------------------  ---------------
2021-11-24 01:14:44.544675 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 255 finished
---------------------------------------  ---------------
epoch                                       255
replay_buffer/size                       257000
trainer/num train calls                  256000
trainer/QF1 Loss                              7.00544
trainer/QF2 Loss                              5.45153
trainer/Policy Loss                        -342.258
trainer/Q1 Predictions Mean                 342.894
trainer/Q1 Predictions Std                  116.44
trainer/Q1 Predictions Max                  429.938
trainer/Q1 Predictions Min                   17.7477
trainer/Q2 Predictions Mean                 342.848
trainer/Q2 Predictions Std                  116.223
trainer/Q2 Predictions Max                  428.842
trainer/Q2 Predictions Min                   18.0108
trainer/Q Targets Mean                      343.02
trainer/Q Targets Std                       116.602
trainer/Q Targets Max                       431.972
trainer/Q Targets Min                        16.6252
trainer/Log Pis Mean                          5.73129
trainer/Log Pis Std                           4.88427
trainer/Log Pis Max                          16.8609
trainer/Log Pis Min                          -6.10648
trainer/policy/mean Mean                      0.0810141
trainer/policy/mean Std                       0.767161
trainer/policy/mean Max                       0.997655
trainer/policy/mean Min                      -0.996055
trainer/policy/normal/std Mean                0.446196
trainer/policy/normal/std Std                 0.150848
trainer/policy/normal/std Max                 1.08457
trainer/policy/normal/std Min                 0.0695733
trainer/policy/normal/log_std Mean           -0.882515
trainer/policy/normal/log_std Std             0.42994
trainer/policy/normal/log_std Max             0.0811845
trainer/policy/normal/log_std Min            -2.66537
trainer/Alpha                                 0.12399
trainer/Alpha Loss                           -0.560953
expl/num steps total                     257000
expl/num paths total                        257
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.52861
expl/Rewards Std                              1.23766
expl/Rewards Max                              7.69697
expl/Rewards Min                             -0.922644
expl/Returns Mean                          5528.61
expl/Returns Std                              0
expl/Returns Max                           5528.61
expl/Returns Min                           5528.61
expl/Actions Mean                             0.100918
expl/Actions Std                              0.804128
expl/Actions Max                              0.99933
expl/Actions Min                             -0.999359
expl/Num Paths                                1
expl/Average Returns                       5528.61
expl/env_infos/final/reward_run Mean          7.01706
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.01706
expl/env_infos/final/reward_run Min           7.01706
expl/env_infos/initial/reward_run Mean       -0.609288
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.609288
expl/env_infos/initial/reward_run Min        -0.609288
expl/env_infos/reward_run Mean                5.9227
expl/env_infos/reward_run Std                 1.23154
expl/env_infos/reward_run Max                 8.12152
expl/env_infos/reward_run Min                -0.609288
expl/env_infos/final/reward_ctrl Mean        -0.270091
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.270091
expl/env_infos/final/reward_ctrl Min         -0.270091
expl/env_infos/initial/reward_ctrl Mean      -0.313356
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.313356
expl/env_infos/initial/reward_ctrl Min       -0.313356
expl/env_infos/reward_ctrl Mean              -0.394084
expl/env_infos/reward_ctrl Std                0.0937779
expl/env_infos/reward_ctrl Max               -0.0865206
expl/env_infos/reward_ctrl Min               -0.585635
eval/num steps total                          1.28e+06
eval/num paths total                       1280
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.65989
eval/Rewards Std                              1.26886
eval/Rewards Max                              8.04651
eval/Rewards Min                             -0.77946
eval/Returns Mean                          5659.89
eval/Returns Std                             85.5761
eval/Returns Max                           5759.81
eval/Returns Min                           5534.25
eval/Actions Mean                             0.10996
eval/Actions Std                              0.813459
eval/Actions Max                              0.997253
eval/Actions Min                             -0.996805
eval/Num Paths                                5
eval/Average Returns                       5659.89
eval/env_infos/final/reward_run Mean          5.90691
eval/env_infos/final/reward_run Std           0.44477
eval/env_infos/final/reward_run Max           6.4187
eval/env_infos/final/reward_run Min           5.11271
eval/env_infos/initial/reward_run Mean       -0.307052
eval/env_infos/initial/reward_run Std         0.110913
eval/env_infos/initial/reward_run Max        -0.176585
eval/env_infos/initial/reward_run Min        -0.470697
eval/env_infos/reward_run Mean                6.06417
eval/env_infos/reward_run Std                 1.25613
eval/env_infos/reward_run Max                 8.54505
eval/env_infos/reward_run Min                -0.470697
eval/env_infos/final/reward_ctrl Mean        -0.455018
eval/env_infos/final/reward_ctrl Std          0.0514464
eval/env_infos/final/reward_ctrl Max         -0.405733
eval/env_infos/final/reward_ctrl Min         -0.548936
eval/env_infos/initial/reward_ctrl Mean      -0.282834
eval/env_infos/initial/reward_ctrl Std        0.0351496
eval/env_infos/initial/reward_ctrl Max       -0.214198
eval/env_infos/initial/reward_ctrl Min       -0.308763
eval/env_infos/reward_ctrl Mean              -0.404284
eval/env_infos/reward_ctrl Std                0.0909819
eval/env_infos/reward_ctrl Max               -0.105909
eval/env_infos/reward_ctrl Min               -0.58464
time/data storing (s)                         0.00449899
time/evaluation sampling (s)                  2.02361
time/exploration sampling (s)                 0.532108
time/logging (s)                              0.0136426
time/sac training (s)                         7.38905
time/saving (s)                               0.00372571
time/training (s)                             3.4155e-05
time/epoch (s)                                9.96667
time/total (s)                             2730.61
Epoch                                       255
---------------------------------------  ---------------
2021-11-24 01:14:54.779109 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 256 finished
---------------------------------------  ---------------
epoch                                       256
replay_buffer/size                       258000
trainer/num train calls                  257000
trainer/QF1 Loss                              7.31823
trainer/QF2 Loss                              6.82935
trainer/Policy Loss                        -344.252
trainer/Q1 Predictions Mean                 344.739
trainer/Q1 Predictions Std                  111.725
trainer/Q1 Predictions Max                  430.872
trainer/Q1 Predictions Min                   16.1351
trainer/Q2 Predictions Mean                 344.744
trainer/Q2 Predictions Std                  111.747
trainer/Q2 Predictions Max                  429.422
trainer/Q2 Predictions Min                   16.202
trainer/Q Targets Mean                      345.211
trainer/Q Targets Std                       111.883
trainer/Q Targets Max                       429.437
trainer/Q Targets Min                        16.276
trainer/Log Pis Mean                          6.27437
trainer/Log Pis Std                           4.73897
trainer/Log Pis Max                          16.956
trainer/Log Pis Min                          -5.77592
trainer/policy/mean Mean                      0.0955256
trainer/policy/mean Std                       0.779303
trainer/policy/mean Max                       0.998189
trainer/policy/mean Min                      -0.998084
trainer/policy/normal/std Mean                0.454345
trainer/policy/normal/std Std                 0.156912
trainer/policy/normal/std Max                 1.06173
trainer/policy/normal/std Min                 0.065662
trainer/policy/normal/log_std Mean           -0.865243
trainer/policy/normal/log_std Std             0.427477
trainer/policy/normal/log_std Max             0.0598979
trainer/policy/normal/log_std Min            -2.72323
trainer/Alpha                                 0.126177
trainer/Alpha Loss                            0.56796
expl/num steps total                     258000
expl/num paths total                        258
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.3284
expl/Rewards Std                              1.22742
expl/Rewards Max                              7.85223
expl/Rewards Min                             -0.834948
expl/Returns Mean                          5328.4
expl/Returns Std                              0
expl/Returns Max                           5328.4
expl/Returns Min                           5328.4
expl/Actions Mean                             0.116763
expl/Actions Std                              0.803437
expl/Actions Max                              0.99961
expl/Actions Min                             -0.99892
expl/Num Paths                                1
expl/Average Returns                       5328.4
expl/env_infos/final/reward_run Mean          5.96957
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.96957
expl/env_infos/final/reward_run Min           5.96957
expl/env_infos/initial/reward_run Mean       -0.635891
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.635891
expl/env_infos/initial/reward_run Min        -0.635891
expl/env_infos/reward_run Mean                5.72389
expl/env_infos/reward_run Std                 1.2174
expl/env_infos/reward_run Max                 8.39117
expl/env_infos/reward_run Min                -0.635891
expl/env_infos/final/reward_ctrl Mean        -0.492857
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.492857
expl/env_infos/final/reward_ctrl Min         -0.492857
expl/env_infos/initial/reward_ctrl Mean      -0.199057
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.199057
expl/env_infos/initial/reward_ctrl Min       -0.199057
expl/env_infos/reward_ctrl Mean              -0.395487
expl/env_infos/reward_ctrl Std                0.0959501
expl/env_infos/reward_ctrl Max               -0.0800754
expl/env_infos/reward_ctrl Min               -0.582083
eval/num steps total                          1.285e+06
eval/num paths total                       1285
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.63975
eval/Rewards Std                              1.27193
eval/Rewards Max                              8.20586
eval/Rewards Min                             -0.884055
eval/Returns Mean                          5639.75
eval/Returns Std                             44.1228
eval/Returns Max                           5690.82
eval/Returns Min                           5564.25
eval/Actions Mean                             0.126735
eval/Actions Std                              0.817913
eval/Actions Max                              0.998273
eval/Actions Min                             -0.998157
eval/Num Paths                                5
eval/Average Returns                       5639.75
eval/env_infos/final/reward_run Mean          6.1487
eval/env_infos/final/reward_run Std           1.01332
eval/env_infos/final/reward_run Max           8.01258
eval/env_infos/final/reward_run Min           5.14745
eval/env_infos/initial/reward_run Mean       -0.312406
eval/env_infos/initial/reward_run Std         0.106677
eval/env_infos/initial/reward_run Max        -0.138603
eval/env_infos/initial/reward_run Min        -0.436742
eval/env_infos/reward_run Mean                6.05078
eval/env_infos/reward_run Std                 1.25872
eval/env_infos/reward_run Max                 8.68913
eval/env_infos/reward_run Min                -0.464429
eval/env_infos/final/reward_ctrl Mean        -0.470598
eval/env_infos/final/reward_ctrl Std          0.0503375
eval/env_infos/final/reward_ctrl Max         -0.41323
eval/env_infos/final/reward_ctrl Min         -0.546232
eval/env_infos/initial/reward_ctrl Mean      -0.2926
eval/env_infos/initial/reward_ctrl Std        0.0540023
eval/env_infos/initial/reward_ctrl Max       -0.225077
eval/env_infos/initial/reward_ctrl Min       -0.371842
eval/env_infos/reward_ctrl Mean              -0.411026
eval/env_infos/reward_ctrl Std                0.0907604
eval/env_infos/reward_ctrl Max               -0.110802
eval/env_infos/reward_ctrl Min               -0.587386
time/data storing (s)                         0.0044872
time/evaluation sampling (s)                  2.00746
time/exploration sampling (s)                 0.533659
time/logging (s)                              0.0135773
time/sac training (s)                         7.38137
time/saving (s)                               0.00374868
time/training (s)                             3.4397e-05
time/epoch (s)                                9.94433
time/total (s)                             2740.83
Epoch                                       256
---------------------------------------  ---------------
2021-11-24 01:15:05.027164 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 257 finished
---------------------------------------  ---------------
epoch                                       257
replay_buffer/size                       259000
trainer/num train calls                  258000
trainer/QF1 Loss                              6.92026
trainer/QF2 Loss                              5.37366
trainer/Policy Loss                        -346.662
trainer/Q1 Predictions Mean                 347.152
trainer/Q1 Predictions Std                  109.16
trainer/Q1 Predictions Max                  435.225
trainer/Q1 Predictions Min                   16.628
trainer/Q2 Predictions Mean                 347.126
trainer/Q2 Predictions Std                  109.08
trainer/Q2 Predictions Max                  434.717
trainer/Q2 Predictions Min                   16.6969
trainer/Q Targets Mean                      346.64
trainer/Q Targets Std                       108.807
trainer/Q Targets Max                       433.297
trainer/Q Targets Min                        16.6905
trainer/Log Pis Mean                          5.63943
trainer/Log Pis Std                           5.13992
trainer/Log Pis Max                          24.8025
trainer/Log Pis Min                          -5.80444
trainer/policy/mean Mean                      0.060152
trainer/policy/mean Std                       0.764972
trainer/policy/mean Max                       0.999937
trainer/policy/mean Min                      -0.998227
trainer/policy/normal/std Mean                0.449555
trainer/policy/normal/std Std                 0.153457
trainer/policy/normal/std Max                 1.35709
trainer/policy/normal/std Min                 0.0731233
trainer/policy/normal/log_std Mean           -0.871917
trainer/policy/normal/log_std Std             0.413006
trainer/policy/normal/log_std Max             0.305345
trainer/policy/normal/log_std Min            -2.61561
trainer/Alpha                                 0.126384
trainer/Alpha Loss                           -0.745822
expl/num steps total                     259000
expl/num paths total                        259
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.51894
expl/Rewards Std                              1.25153
expl/Rewards Max                              7.92123
expl/Rewards Min                             -1.28894
expl/Returns Mean                          5518.94
expl/Returns Std                              0
expl/Returns Max                           5518.94
expl/Returns Min                           5518.94
expl/Actions Mean                             0.075053
expl/Actions Std                              0.80718
expl/Actions Max                              0.999468
expl/Actions Min                             -0.999907
expl/Num Paths                                1
expl/Average Returns                       5518.94
expl/env_infos/final/reward_run Mean          6.95272
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.95272
expl/env_infos/final/reward_run Min           6.95272
expl/env_infos/initial/reward_run Mean       -0.885288
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.885288
expl/env_infos/initial/reward_run Min        -0.885288
expl/env_infos/reward_run Mean                5.91325
expl/env_infos/reward_run Std                 1.24006
expl/env_infos/reward_run Max                 8.43472
expl/env_infos/reward_run Min                -0.885288
expl/env_infos/final/reward_ctrl Mean        -0.323898
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.323898
expl/env_infos/final/reward_ctrl Min         -0.323898
expl/env_infos/initial/reward_ctrl Mean      -0.403652
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.403652
expl/env_infos/initial/reward_ctrl Min       -0.403652
expl/env_infos/reward_ctrl Mean              -0.394303
expl/env_infos/reward_ctrl Std                0.0966305
expl/env_infos/reward_ctrl Max               -0.0988593
expl/env_infos/reward_ctrl Min               -0.582603
eval/num steps total                          1.29e+06
eval/num paths total                       1290
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.77834
eval/Rewards Std                              1.2721
eval/Rewards Max                              8.12927
eval/Rewards Min                             -1.00697
eval/Returns Mean                          5778.34
eval/Returns Std                             66.2344
eval/Returns Max                           5906.95
eval/Returns Min                           5731.42
eval/Actions Mean                             0.0711355
eval/Actions Std                              0.81976
eval/Actions Max                              0.998386
eval/Actions Min                             -0.99914
eval/Num Paths                                5
eval/Average Returns                       5778.34
eval/env_infos/final/reward_run Mean          5.73015
eval/env_infos/final/reward_run Std           0.896957
eval/env_infos/final/reward_run Max           7.12474
eval/env_infos/final/reward_run Min           4.72505
eval/env_infos/initial/reward_run Mean       -0.312783
eval/env_infos/initial/reward_run Std         0.200004
eval/env_infos/initial/reward_run Max        -0.0634466
eval/env_infos/initial/reward_run Min        -0.658109
eval/env_infos/reward_run Mean                6.18458
eval/env_infos/reward_run Std                 1.25697
eval/env_infos/reward_run Max                 8.60038
eval/env_infos/reward_run Min                -0.658109
eval/env_infos/final/reward_ctrl Mean        -0.474687
eval/env_infos/final/reward_ctrl Std          0.0499381
eval/env_infos/final/reward_ctrl Max         -0.414003
eval/env_infos/final/reward_ctrl Min         -0.545816
eval/env_infos/initial/reward_ctrl Mean      -0.263742
eval/env_infos/initial/reward_ctrl Std        0.0655543
eval/env_infos/initial/reward_ctrl Max       -0.198681
eval/env_infos/initial/reward_ctrl Min       -0.348865
eval/env_infos/reward_ctrl Mean              -0.40624
eval/env_infos/reward_ctrl Std                0.097341
eval/env_infos/reward_ctrl Max               -0.101484
eval/env_infos/reward_ctrl Min               -0.582342
time/data storing (s)                         0.00448353
time/evaluation sampling (s)                  2.00942
time/exploration sampling (s)                 0.53377
time/logging (s)                              0.0136022
time/sac training (s)                         7.39336
time/saving (s)                               0.00376565
time/training (s)                             3.3716e-05
time/epoch (s)                                9.95844
time/total (s)                             2751.06
Epoch                                       257
---------------------------------------  ---------------
2021-11-24 01:15:15.262498 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 258 finished
---------------------------------------  ---------------
epoch                                       258
replay_buffer/size                       260000
trainer/num train calls                  259000
trainer/QF1 Loss                              5.65425
trainer/QF2 Loss                              7.4341
trainer/Policy Loss                        -348.669
trainer/Q1 Predictions Mean                 349.24
trainer/Q1 Predictions Std                  109.061
trainer/Q1 Predictions Max                  430.876
trainer/Q1 Predictions Min                   16.3515
trainer/Q2 Predictions Mean                 348.977
trainer/Q2 Predictions Std                  108.95
trainer/Q2 Predictions Max                  429.34
trainer/Q2 Predictions Min                   16.3217
trainer/Q Targets Mean                      349.785
trainer/Q Targets Std                       109.145
trainer/Q Targets Max                       431.504
trainer/Q Targets Min                        17.0743
trainer/Log Pis Mean                          5.69819
trainer/Log Pis Std                           4.43618
trainer/Log Pis Max                          15.7001
trainer/Log Pis Min                          -6.82184
trainer/policy/mean Mean                      0.040523
trainer/policy/mean Std                       0.770712
trainer/policy/mean Max                       0.99637
trainer/policy/mean Min                      -0.99559
trainer/policy/normal/std Mean                0.45088
trainer/policy/normal/std Std                 0.148819
trainer/policy/normal/std Max                 0.945614
trainer/policy/normal/std Min                 0.0708714
trainer/policy/normal/log_std Mean           -0.866393
trainer/policy/normal/log_std Std             0.409457
trainer/policy/normal/log_std Max            -0.055921
trainer/policy/normal/log_std Min            -2.64689
trainer/Alpha                                 0.126666
trainer/Alpha Loss                           -0.623607
expl/num steps total                     260000
expl/num paths total                        260
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.49881
expl/Rewards Std                              1.33121
expl/Rewards Max                              7.8772
expl/Rewards Min                             -0.767352
expl/Returns Mean                          5498.81
expl/Returns Std                              0
expl/Returns Max                           5498.81
expl/Returns Min                           5498.81
expl/Actions Mean                             0.0654821
expl/Actions Std                              0.809483
expl/Actions Max                              0.999612
expl/Actions Min                             -0.999685
expl/Num Paths                                1
expl/Average Returns                       5498.81
expl/env_infos/final/reward_run Mean          5.13384
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.13384
expl/env_infos/final/reward_run Min           5.13384
expl/env_infos/initial/reward_run Mean       -0.100041
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.100041
expl/env_infos/initial/reward_run Min        -0.100041
expl/env_infos/reward_run Mean                5.89454
expl/env_infos/reward_run Std                 1.32603
expl/env_infos/reward_run Max                 8.30786
expl/env_infos/reward_run Min                -0.301727
expl/env_infos/final/reward_ctrl Mean        -0.549221
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.549221
expl/env_infos/final/reward_ctrl Min         -0.549221
expl/env_infos/initial/reward_ctrl Mean      -0.1215
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.1215
expl/env_infos/initial/reward_ctrl Min       -0.1215
expl/env_infos/reward_ctrl Mean              -0.39573
expl/env_infos/reward_ctrl Std                0.0967575
expl/env_infos/reward_ctrl Max               -0.0358851
expl/env_infos/reward_ctrl Min               -0.580711
eval/num steps total                          1.295e+06
eval/num paths total                       1295
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.81758
eval/Rewards Std                              1.27202
eval/Rewards Max                              8.19273
eval/Rewards Min                             -0.980982
eval/Returns Mean                          5817.58
eval/Returns Std                             45.9406
eval/Returns Max                           5876.56
eval/Returns Min                           5774.87
eval/Actions Mean                             0.0711763
eval/Actions Std                              0.822896
eval/Actions Max                              0.998422
eval/Actions Min                             -0.997518
eval/Num Paths                                5
eval/Average Returns                       5817.58
eval/env_infos/final/reward_run Mean          7.05676
eval/env_infos/final/reward_run Std           0.909557
eval/env_infos/final/reward_run Max           8.31834
eval/env_infos/final/reward_run Min           5.96405
eval/env_infos/initial/reward_run Mean       -0.405686
eval/env_infos/initial/reward_run Std         0.17307
eval/env_infos/initial/reward_run Max        -0.148442
eval/env_infos/initial/reward_run Min        -0.599611
eval/env_infos/reward_run Mean                6.22692
eval/env_infos/reward_run Std                 1.25717
eval/env_infos/reward_run Max                 8.69244
eval/env_infos/reward_run Min                -0.599611
eval/env_infos/final/reward_ctrl Mean        -0.419635
eval/env_infos/final/reward_ctrl Std          0.0688959
eval/env_infos/final/reward_ctrl Max         -0.352014
eval/env_infos/final/reward_ctrl Min         -0.507019
eval/env_infos/initial/reward_ctrl Mean      -0.331865
eval/env_infos/initial/reward_ctrl Std        0.0833453
eval/env_infos/initial/reward_ctrl Max       -0.181775
eval/env_infos/initial/reward_ctrl Min       -0.429385
eval/env_infos/reward_ctrl Mean              -0.409334
eval/env_infos/reward_ctrl Std                0.0920557
eval/env_infos/reward_ctrl Max               -0.116235
eval/env_infos/reward_ctrl Min               -0.586198
time/data storing (s)                         0.00454413
time/evaluation sampling (s)                  2.01196
time/exploration sampling (s)                 0.534807
time/logging (s)                              0.0135969
time/sac training (s)                         7.37591
time/saving (s)                               0.00374068
time/training (s)                             3.431e-05
time/epoch (s)                                9.94459
time/total (s)                             2761.28
Epoch                                       258
---------------------------------------  ---------------
2021-11-24 01:15:25.483721 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 259 finished
---------------------------------------  ---------------
epoch                                       259
replay_buffer/size                       261000
trainer/num train calls                  260000
trainer/QF1 Loss                              7.07666
trainer/QF2 Loss                              5.73998
trainer/Policy Loss                        -359.154
trainer/Q1 Predictions Mean                 359.705
trainer/Q1 Predictions Std                   91.8222
trainer/Q1 Predictions Max                  433.467
trainer/Q1 Predictions Min                   17.4984
trainer/Q2 Predictions Mean                 359.813
trainer/Q2 Predictions Std                   91.8788
trainer/Q2 Predictions Max                  435.319
trainer/Q2 Predictions Min                   15.6218
trainer/Q Targets Mean                      359.977
trainer/Q Targets Std                        92.0285
trainer/Q Targets Max                       435.544
trainer/Q Targets Min                        13.9228
trainer/Log Pis Mean                          6.26516
trainer/Log Pis Std                           4.75427
trainer/Log Pis Max                          20.9715
trainer/Log Pis Min                          -4.93076
trainer/policy/mean Mean                      0.0736675
trainer/policy/mean Std                       0.787198
trainer/policy/mean Max                       0.997775
trainer/policy/mean Min                      -0.998173
trainer/policy/normal/std Mean                0.4518
trainer/policy/normal/std Std                 0.145555
trainer/policy/normal/std Max                 1.22644
trainer/policy/normal/std Min                 0.0625939
trainer/policy/normal/log_std Mean           -0.859789
trainer/policy/normal/log_std Std             0.3946
trainer/policy/normal/log_std Max             0.20412
trainer/policy/normal/log_std Min            -2.77109
trainer/Alpha                                 0.126544
trainer/Alpha Loss                            0.548126
expl/num steps total                     261000
expl/num paths total                        261
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.41459
expl/Rewards Std                              1.15909
expl/Rewards Max                              7.63424
expl/Rewards Min                             -0.214408
expl/Returns Mean                          5414.59
expl/Returns Std                              0
expl/Returns Max                           5414.59
expl/Returns Min                           5414.59
expl/Actions Mean                             0.078846
expl/Actions Std                              0.801522
expl/Actions Max                              0.999622
expl/Actions Min                             -0.999735
expl/Num Paths                                1
expl/Average Returns                       5414.59
expl/env_infos/final/reward_run Mean          7.08688
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.08688
expl/env_infos/final/reward_run Min           7.08688
expl/env_infos/initial/reward_run Mean        0.0819224
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0819224
expl/env_infos/initial/reward_run Min         0.0819224
expl/env_infos/reward_run Mean                5.80378
expl/env_infos/reward_run Std                 1.14814
expl/env_infos/reward_run Max                 8.11261
expl/env_infos/reward_run Min                 0.0819224
expl/env_infos/final/reward_ctrl Mean        -0.398077
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.398077
expl/env_infos/final/reward_ctrl Min         -0.398077
expl/env_infos/initial/reward_ctrl Mean      -0.29633
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.29633
expl/env_infos/initial/reward_ctrl Min       -0.29633
expl/env_infos/reward_ctrl Mean              -0.389193
expl/env_infos/reward_ctrl Std                0.0963565
expl/env_infos/reward_ctrl Max               -0.0830563
expl/env_infos/reward_ctrl Min               -0.581617
eval/num steps total                          1.3e+06
eval/num paths total                       1300
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.71552
eval/Rewards Std                              1.27196
eval/Rewards Max                              8.30396
eval/Rewards Min                             -0.867465
eval/Returns Mean                          5715.52
eval/Returns Std                             78.3265
eval/Returns Max                           5866.93
eval/Returns Min                           5649.14
eval/Actions Mean                             0.102688
eval/Actions Std                              0.816496
eval/Actions Max                              0.99917
eval/Actions Min                             -0.996543
eval/Num Paths                                5
eval/Average Returns                       5715.52
eval/env_infos/final/reward_run Mean          6.51166
eval/env_infos/final/reward_run Std           0.791063
eval/env_infos/final/reward_run Max           7.92939
eval/env_infos/final/reward_run Min           5.6546
eval/env_infos/initial/reward_run Mean       -0.275789
eval/env_infos/initial/reward_run Std         0.161508
eval/env_infos/initial/reward_run Max        -0.0713661
eval/env_infos/initial/reward_run Min        -0.494016
eval/env_infos/reward_run Mean                6.12185
eval/env_infos/reward_run Std                 1.25597
eval/env_infos/reward_run Max                 8.79117
eval/env_infos/reward_run Min                -0.494016
eval/env_infos/final/reward_ctrl Mean        -0.446392
eval/env_infos/final/reward_ctrl Std          0.0829961
eval/env_infos/final/reward_ctrl Max         -0.284156
eval/env_infos/final/reward_ctrl Min         -0.519155
eval/env_infos/initial/reward_ctrl Mean      -0.321012
eval/env_infos/initial/reward_ctrl Std        0.0520096
eval/env_infos/initial/reward_ctrl Max       -0.227159
eval/env_infos/initial/reward_ctrl Min       -0.373449
eval/env_infos/reward_ctrl Mean              -0.406326
eval/env_infos/reward_ctrl Std                0.0926083
eval/env_infos/reward_ctrl Max               -0.102031
eval/env_infos/reward_ctrl Min               -0.584617
time/data storing (s)                         0.00446733
time/evaluation sampling (s)                  2.00693
time/exploration sampling (s)                 0.534905
time/logging (s)                              0.0135811
time/sac training (s)                         7.3677
time/saving (s)                               0.00374437
time/training (s)                             3.4253e-05
time/epoch (s)                                9.93137
time/total (s)                             2771.49
Epoch                                       259
---------------------------------------  ---------------
2021-11-24 01:15:35.747317 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 260 finished
---------------------------------------  ---------------
epoch                                       260
replay_buffer/size                       262000
trainer/num train calls                  261000
trainer/QF1 Loss                              8.47632
trainer/QF2 Loss                              6.72759
trainer/Policy Loss                        -352.002
trainer/Q1 Predictions Mean                 352.605
trainer/Q1 Predictions Std                   97.5375
trainer/Q1 Predictions Max                  430.439
trainer/Q1 Predictions Min                   18.2559
trainer/Q2 Predictions Mean                 352.736
trainer/Q2 Predictions Std                   97.7192
trainer/Q2 Predictions Max                  432.008
trainer/Q2 Predictions Min                   18.152
trainer/Q Targets Mean                      352.708
trainer/Q Targets Std                        97.699
trainer/Q Targets Max                       432.864
trainer/Q Targets Min                        17.8819
trainer/Log Pis Mean                          5.84612
trainer/Log Pis Std                           4.88933
trainer/Log Pis Max                          20.4808
trainer/Log Pis Min                          -7.97882
trainer/policy/mean Mean                      0.0981522
trainer/policy/mean Std                       0.778365
trainer/policy/mean Max                       0.997951
trainer/policy/mean Min                      -0.995887
trainer/policy/normal/std Mean                0.45377
trainer/policy/normal/std Std                 0.142328
trainer/policy/normal/std Max                 1.00535
trainer/policy/normal/std Min                 0.0627143
trainer/policy/normal/log_std Mean           -0.854129
trainer/policy/normal/log_std Std             0.392382
trainer/policy/normal/log_std Max             0.0053368
trainer/policy/normal/log_std Min            -2.76917
trainer/Alpha                                 0.130726
trainer/Alpha Loss                           -0.313094
expl/num steps total                     262000
expl/num paths total                        262
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.4968
expl/Rewards Std                              1.21984
expl/Rewards Max                              7.88232
expl/Rewards Min                             -0.67966
expl/Returns Mean                          5496.8
expl/Returns Std                              0
expl/Returns Max                           5496.8
expl/Returns Min                           5496.8
expl/Actions Mean                             0.0801313
expl/Actions Std                              0.809511
expl/Actions Max                              0.999775
expl/Actions Min                             -0.999196
expl/Num Paths                                1
expl/Average Returns                       5496.8
expl/env_infos/final/reward_run Mean          4.99937
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.99937
expl/env_infos/final/reward_run Min           4.99937
expl/env_infos/initial/reward_run Mean       -0.342757
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.342757
expl/env_infos/initial/reward_run Min        -0.342757
expl/env_infos/reward_run Mean                5.89383
expl/env_infos/reward_run Std                 1.21163
expl/env_infos/reward_run Max                 8.36821
expl/env_infos/reward_run Min                -0.342757
expl/env_infos/final/reward_ctrl Mean        -0.213678
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.213678
expl/env_infos/final/reward_ctrl Min         -0.213678
expl/env_infos/initial/reward_ctrl Mean      -0.336903
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.336903
expl/env_infos/initial/reward_ctrl Min       -0.336903
expl/env_infos/reward_ctrl Mean              -0.397037
expl/env_infos/reward_ctrl Std                0.0979195
expl/env_infos/reward_ctrl Max               -0.102899
expl/env_infos/reward_ctrl Min               -0.592615
eval/num steps total                          1.305e+06
eval/num paths total                       1305
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.77116
eval/Rewards Std                              1.2532
eval/Rewards Max                              8.06603
eval/Rewards Min                             -1.14826
eval/Returns Mean                          5771.16
eval/Returns Std                             41.2729
eval/Returns Max                           5819.65
eval/Returns Min                           5708.12
eval/Actions Mean                             0.0913218
eval/Actions Std                              0.821416
eval/Actions Max                              0.998981
eval/Actions Min                             -0.996188
eval/Num Paths                                5
eval/Average Returns                       5771.16
eval/env_infos/final/reward_run Mean          5.65435
eval/env_infos/final/reward_run Std           0.765255
eval/env_infos/final/reward_run Max           6.82413
eval/env_infos/final/reward_run Min           4.77445
eval/env_infos/initial/reward_run Mean       -0.405008
eval/env_infos/initial/reward_run Std         0.251781
eval/env_infos/initial/reward_run Max        -0.0184232
eval/env_infos/initial/reward_run Min        -0.745923
eval/env_infos/reward_run Mean                6.181
eval/env_infos/reward_run Std                 1.24153
eval/env_infos/reward_run Max                 8.56007
eval/env_infos/reward_run Min                -0.745923
eval/env_infos/final/reward_ctrl Mean        -0.442842
eval/env_infos/final/reward_ctrl Std          0.0426553
eval/env_infos/final/reward_ctrl Max         -0.40052
eval/env_infos/final/reward_ctrl Min         -0.513073
eval/env_infos/initial/reward_ctrl Mean      -0.293234
eval/env_infos/initial/reward_ctrl Std        0.0727952
eval/env_infos/initial/reward_ctrl Max       -0.228062
eval/env_infos/initial/reward_ctrl Min       -0.402339
eval/env_infos/reward_ctrl Mean              -0.409838
eval/env_infos/reward_ctrl Std                0.0959708
eval/env_infos/reward_ctrl Max               -0.100554
eval/env_infos/reward_ctrl Min               -0.580759
time/data storing (s)                         0.00448762
time/evaluation sampling (s)                  2.00939
time/exploration sampling (s)                 0.534947
time/logging (s)                              0.0136086
time/sac training (s)                         7.40898
time/saving (s)                               0.00375028
time/training (s)                             3.3861e-05
time/epoch (s)                                9.9752
time/total (s)                             2781.74
Epoch                                       260
---------------------------------------  ---------------
2021-11-24 01:15:46.069325 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 261 finished
---------------------------------------  ---------------
epoch                                       261
replay_buffer/size                       263000
trainer/num train calls                  262000
trainer/QF1 Loss                              7.99974
trainer/QF2 Loss                              6.82914
trainer/Policy Loss                        -355.412
trainer/Q1 Predictions Mean                 356.145
trainer/Q1 Predictions Std                  102.109
trainer/Q1 Predictions Max                  432.14
trainer/Q1 Predictions Min                   15.9816
trainer/Q2 Predictions Mean                 355.877
trainer/Q2 Predictions Std                  102.041
trainer/Q2 Predictions Max                  430.067
trainer/Q2 Predictions Min                   15.3629
trainer/Q Targets Mean                      356.031
trainer/Q Targets Std                       101.85
trainer/Q Targets Max                       429.711
trainer/Q Targets Min                        18.1625
trainer/Log Pis Mean                          6.27767
trainer/Log Pis Std                           4.2215
trainer/Log Pis Max                          15.618
trainer/Log Pis Min                          -4.82849
trainer/policy/mean Mean                      0.0802152
trainer/policy/mean Std                       0.773735
trainer/policy/mean Max                       0.998134
trainer/policy/mean Min                      -0.999492
trainer/policy/normal/std Mean                0.428132
trainer/policy/normal/std Std                 0.141617
trainer/policy/normal/std Max                 1.08134
trainer/policy/normal/std Min                 0.0718607
trainer/policy/normal/log_std Mean           -0.92136
trainer/policy/normal/log_std Std             0.421832
trainer/policy/normal/log_std Max             0.0782046
trainer/policy/normal/log_std Min            -2.63303
trainer/Alpha                                 0.12802
trainer/Alpha Loss                            0.570769
expl/num steps total                     263000
expl/num paths total                        263
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.54115
expl/Rewards Std                              1.19207
expl/Rewards Max                              7.85713
expl/Rewards Min                             -0.63798
expl/Returns Mean                          5541.15
expl/Returns Std                              0
expl/Returns Max                           5541.15
expl/Returns Min                           5541.15
expl/Actions Mean                             0.0949743
expl/Actions Std                              0.801943
expl/Actions Max                              0.99968
expl/Actions Min                             -0.999133
expl/Num Paths                                1
expl/Average Returns                       5541.15
expl/env_infos/final/reward_run Mean          6.528
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.528
expl/env_infos/final/reward_run Min           6.528
expl/env_infos/initial/reward_run Mean       -0.263323
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.263323
expl/env_infos/initial/reward_run Min        -0.263323
expl/env_infos/reward_run Mean                5.93243
expl/env_infos/reward_run Std                 1.18879
expl/env_infos/reward_run Max                 8.31508
expl/env_infos/reward_run Min                -0.263323
expl/env_infos/final/reward_ctrl Mean        -0.45092
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.45092
expl/env_infos/final/reward_ctrl Min         -0.45092
expl/env_infos/initial/reward_ctrl Mean      -0.374656
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.374656
expl/env_infos/initial/reward_ctrl Min       -0.374656
expl/env_infos/reward_ctrl Mean              -0.39128
expl/env_infos/reward_ctrl Std                0.0882819
expl/env_infos/reward_ctrl Max               -0.0624541
expl/env_infos/reward_ctrl Min               -0.57757
eval/num steps total                          1.31e+06
eval/num paths total                       1310
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.768
eval/Rewards Std                              1.26566
eval/Rewards Max                              8.31066
eval/Rewards Min                             -0.866936
eval/Returns Mean                          5768
eval/Returns Std                             67.5484
eval/Returns Max                           5856.87
eval/Returns Min                           5654.08
eval/Actions Mean                             0.102294
eval/Actions Std                              0.818605
eval/Actions Max                              0.998129
eval/Actions Min                             -0.994135
eval/Num Paths                                5
eval/Average Returns                       5768
eval/env_infos/final/reward_run Mean          6.25939
eval/env_infos/final/reward_run Std           0.733566
eval/env_infos/final/reward_run Max           7.17127
eval/env_infos/final/reward_run Min           5.31451
eval/env_infos/initial/reward_run Mean       -0.329497
eval/env_infos/initial/reward_run Std         0.1171
eval/env_infos/initial/reward_run Max        -0.199533
eval/env_infos/initial/reward_run Min        -0.506215
eval/env_infos/reward_run Mean                6.17635
eval/env_infos/reward_run Std                 1.26293
eval/env_infos/reward_run Max                 8.81379
eval/env_infos/reward_run Min                -0.506215
eval/env_infos/final/reward_ctrl Mean        -0.395822
eval/env_infos/final/reward_ctrl Std          0.0628927
eval/env_infos/final/reward_ctrl Max         -0.293523
eval/env_infos/final/reward_ctrl Min         -0.457996
eval/env_infos/initial/reward_ctrl Mean      -0.345882
eval/env_infos/initial/reward_ctrl Std        0.0515238
eval/env_infos/initial/reward_ctrl Max       -0.245298
eval/env_infos/initial/reward_ctrl Min       -0.388165
eval/env_infos/reward_ctrl Mean              -0.408347
eval/env_infos/reward_ctrl Std                0.0862284
eval/env_infos/reward_ctrl Max               -0.101996
eval/env_infos/reward_ctrl Min               -0.582592
time/data storing (s)                         0.00448087
time/evaluation sampling (s)                  2.0112
time/exploration sampling (s)                 0.531266
time/logging (s)                              0.0136392
time/sac training (s)                         7.46333
time/saving (s)                               0.00377309
time/training (s)                             3.4039e-05
time/epoch (s)                               10.0277
time/total (s)                             2792.05
Epoch                                       261
---------------------------------------  ---------------
2021-11-24 01:15:56.341273 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 262 finished
---------------------------------------  ---------------
epoch                                       262
replay_buffer/size                       264000
trainer/num train calls                  263000
trainer/QF1 Loss                              6.41165
trainer/QF2 Loss                              7.12067
trainer/Policy Loss                        -347.999
trainer/Q1 Predictions Mean                 348.197
trainer/Q1 Predictions Std                  108.021
trainer/Q1 Predictions Max                  436.241
trainer/Q1 Predictions Min                   16.7353
trainer/Q2 Predictions Mean                 348.281
trainer/Q2 Predictions Std                  108.138
trainer/Q2 Predictions Max                  435.656
trainer/Q2 Predictions Min                   17.0645
trainer/Q Targets Mean                      348.74
trainer/Q Targets Std                       108.12
trainer/Q Targets Max                       437.539
trainer/Q Targets Min                        16.5703
trainer/Log Pis Mean                          5.90067
trainer/Log Pis Std                           4.86119
trainer/Log Pis Max                          23.5764
trainer/Log Pis Min                          -7.18063
trainer/policy/mean Mean                      0.0705776
trainer/policy/mean Std                       0.781763
trainer/policy/mean Max                       0.999981
trainer/policy/mean Min                      -0.997571
trainer/policy/normal/std Mean                0.455718
trainer/policy/normal/std Std                 0.150446
trainer/policy/normal/std Max                 1.71448
trainer/policy/normal/std Min                 0.0675106
trainer/policy/normal/log_std Mean           -0.854221
trainer/policy/normal/log_std Std             0.404227
trainer/policy/normal/log_std Max             0.539111
trainer/policy/normal/log_std Min            -2.69547
trainer/Alpha                                 0.128923
trainer/Alpha Loss                           -0.203475
expl/num steps total                     264000
expl/num paths total                        264
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.3927
expl/Rewards Std                              1.20814
expl/Rewards Max                              7.6764
expl/Rewards Min                             -0.692782
expl/Returns Mean                          5392.7
expl/Returns Std                              0
expl/Returns Max                           5392.7
expl/Returns Min                           5392.7
expl/Actions Mean                             0.0916595
expl/Actions Std                              0.801278
expl/Actions Max                              0.99959
expl/Actions Min                             -0.999046
expl/Num Paths                                1
expl/Average Returns                       5392.7
expl/env_infos/final/reward_run Mean          6.06157
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.06157
expl/env_infos/final/reward_run Min           6.06157
expl/env_infos/initial/reward_run Mean       -0.133905
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.133905
expl/env_infos/initial/reward_run Min        -0.133905
expl/env_infos/reward_run Mean                5.78297
expl/env_infos/reward_run Std                 1.20001
expl/env_infos/reward_run Max                 8.10815
expl/env_infos/reward_run Min                -0.16945
expl/env_infos/final/reward_ctrl Mean        -0.461509
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.461509
expl/env_infos/final/reward_ctrl Min         -0.461509
expl/env_infos/initial/reward_ctrl Mean      -0.310928
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.310928
expl/env_infos/initial/reward_ctrl Min       -0.310928
expl/env_infos/reward_ctrl Mean              -0.390269
expl/env_infos/reward_ctrl Std                0.0969491
expl/env_infos/reward_ctrl Max               -0.0795222
expl/env_infos/reward_ctrl Min               -0.578327
eval/num steps total                          1.315e+06
eval/num paths total                       1315
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.81874
eval/Rewards Std                              1.25574
eval/Rewards Max                              8.18388
eval/Rewards Min                             -0.633468
eval/Returns Mean                          5818.74
eval/Returns Std                             30.234
eval/Returns Max                           5849.63
eval/Returns Min                           5766.87
eval/Actions Mean                             0.0952675
eval/Actions Std                              0.81593
eval/Actions Max                              0.99717
eval/Actions Min                             -0.996043
eval/Num Paths                                5
eval/Average Returns                       5818.74
eval/env_infos/final/reward_run Mean          6.10758
eval/env_infos/final/reward_run Std           0.428352
eval/env_infos/final/reward_run Max           6.78955
eval/env_infos/final/reward_run Min           5.59762
eval/env_infos/initial/reward_run Mean       -0.254664
eval/env_infos/initial/reward_run Std         0.0662928
eval/env_infos/initial/reward_run Max        -0.175323
eval/env_infos/initial/reward_run Min        -0.33831
eval/env_infos/reward_run Mean                6.22363
eval/env_infos/reward_run Std                 1.23967
eval/env_infos/reward_run Max                 8.68062
eval/env_infos/reward_run Min                -0.33831
eval/env_infos/final/reward_ctrl Mean        -0.405144
eval/env_infos/final/reward_ctrl Std          0.058617
eval/env_infos/final/reward_ctrl Max         -0.291275
eval/env_infos/final/reward_ctrl Min         -0.447125
eval/env_infos/initial/reward_ctrl Mean      -0.297931
eval/env_infos/initial/reward_ctrl Std        0.0125245
eval/env_infos/initial/reward_ctrl Max       -0.282366
eval/env_infos/initial/reward_ctrl Min       -0.320521
eval/env_infos/reward_ctrl Mean              -0.40489
eval/env_infos/reward_ctrl Std                0.0974581
eval/env_infos/reward_ctrl Max               -0.086223
eval/env_infos/reward_ctrl Min               -0.58742
time/data storing (s)                         0.00454759
time/evaluation sampling (s)                  2.00719
time/exploration sampling (s)                 0.526681
time/logging (s)                              0.0136359
time/sac training (s)                         7.42058
time/saving (s)                               0.00376236
time/training (s)                             3.4742e-05
time/epoch (s)                                9.97643
time/total (s)                             2802.31
Epoch                                       262
---------------------------------------  ---------------
2021-11-24 01:16:06.643364 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 263 finished
---------------------------------------  ---------------
epoch                                       263
replay_buffer/size                       265000
trainer/num train calls                  264000
trainer/QF1 Loss                              5.36776
trainer/QF2 Loss                              6.2448
trainer/Policy Loss                        -357.987
trainer/Q1 Predictions Mean                 358.443
trainer/Q1 Predictions Std                  100.365
trainer/Q1 Predictions Max                  439.15
trainer/Q1 Predictions Min                   15.4432
trainer/Q2 Predictions Mean                 358.592
trainer/Q2 Predictions Std                  100.443
trainer/Q2 Predictions Max                  440.312
trainer/Q2 Predictions Min                   14.964
trainer/Q Targets Mean                      357.895
trainer/Q Targets Std                       100.289
trainer/Q Targets Max                       440.598
trainer/Q Targets Min                        15.7847
trainer/Log Pis Mean                          6.23668
trainer/Log Pis Std                           4.50281
trainer/Log Pis Max                          17.8118
trainer/Log Pis Min                          -4.39739
trainer/policy/mean Mean                      0.0999152
trainer/policy/mean Std                       0.770521
trainer/policy/mean Max                       0.998214
trainer/policy/mean Min                      -0.99601
trainer/policy/normal/std Mean                0.435027
trainer/policy/normal/std Std                 0.143078
trainer/policy/normal/std Max                 0.865355
trainer/policy/normal/std Min                 0.0761652
trainer/policy/normal/log_std Mean           -0.904639
trainer/policy/normal/log_std Std             0.41813
trainer/policy/normal/log_std Max            -0.144616
trainer/policy/normal/log_std Min            -2.57485
trainer/Alpha                                 0.128056
trainer/Alpha Loss                            0.486444
expl/num steps total                     265000
expl/num paths total                        265
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.50604
expl/Rewards Std                              1.23153
expl/Rewards Max                              7.61345
expl/Rewards Min                             -0.4061
expl/Returns Mean                          5506.04
expl/Returns Std                              0
expl/Returns Max                           5506.04
expl/Returns Min                           5506.04
expl/Actions Mean                             0.109878
expl/Actions Std                              0.803727
expl/Actions Max                              0.999714
expl/Actions Min                             -0.999346
expl/Num Paths                                1
expl/Average Returns                       5506.04
expl/env_infos/final/reward_run Mean          5.74893
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.74893
expl/env_infos/final/reward_run Min           5.74893
expl/env_infos/initial/reward_run Mean       -0.00671942
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.00671942
expl/env_infos/initial/reward_run Min        -0.00671942
expl/env_infos/reward_run Mean                5.90087
expl/env_infos/reward_run Std                 1.21693
expl/env_infos/reward_run Max                 8.11352
expl/env_infos/reward_run Min                -0.00671942
expl/env_infos/final/reward_ctrl Mean        -0.523711
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.523711
expl/env_infos/final/reward_ctrl Min         -0.523711
expl/env_infos/initial/reward_ctrl Mean      -0.399381
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.399381
expl/env_infos/initial/reward_ctrl Min       -0.399381
expl/env_infos/reward_ctrl Mean              -0.394831
expl/env_infos/reward_ctrl Std                0.0953326
expl/env_infos/reward_ctrl Max               -0.0704469
expl/env_infos/reward_ctrl Min               -0.578612
eval/num steps total                          1.32e+06
eval/num paths total                       1320
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.73294
eval/Rewards Std                              1.25767
eval/Rewards Max                              8.14085
eval/Rewards Min                             -0.547508
eval/Returns Mean                          5732.94
eval/Returns Std                             47.7306
eval/Returns Max                           5802.57
eval/Returns Min                           5664.88
eval/Actions Mean                             0.119052
eval/Actions Std                              0.813192
eval/Actions Max                              0.997983
eval/Actions Min                             -0.996546
eval/Num Paths                                5
eval/Average Returns                       5732.94
eval/env_infos/final/reward_run Mean          6.27749
eval/env_infos/final/reward_run Std           0.475612
eval/env_infos/final/reward_run Max           7.12974
eval/env_infos/final/reward_run Min           5.65811
eval/env_infos/initial/reward_run Mean       -0.196215
eval/env_infos/initial/reward_run Std         0.0419408
eval/env_infos/initial/reward_run Max        -0.142824
eval/env_infos/initial/reward_run Min        -0.258932
eval/env_infos/reward_run Mean                6.13822
eval/env_infos/reward_run Std                 1.24005
eval/env_infos/reward_run Max                 8.62087
eval/env_infos/reward_run Min                -0.258932
eval/env_infos/final/reward_ctrl Mean        -0.407895
eval/env_infos/final/reward_ctrl Std          0.0552822
eval/env_infos/final/reward_ctrl Max         -0.315207
eval/env_infos/final/reward_ctrl Min         -0.464128
eval/env_infos/initial/reward_ctrl Mean      -0.248725
eval/env_infos/initial/reward_ctrl Std        0.0276899
eval/env_infos/initial/reward_ctrl Max       -0.216077
eval/env_infos/initial/reward_ctrl Min       -0.288576
eval/env_infos/reward_ctrl Mean              -0.405273
eval/env_infos/reward_ctrl Std                0.0935054
eval/env_infos/reward_ctrl Max               -0.103498
eval/env_infos/reward_ctrl Min               -0.580899
time/data storing (s)                         0.00447959
time/evaluation sampling (s)                  2.01531
time/exploration sampling (s)                 0.536717
time/logging (s)                              0.0135796
time/sac training (s)                         7.4345
time/saving (s)                               0.0037583
time/training (s)                             3.4448e-05
time/epoch (s)                               10.0084
time/total (s)                             2812.6
Epoch                                       263
---------------------------------------  ---------------
2021-11-24 01:16:16.894847 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 264 finished
---------------------------------------  ---------------
epoch                                       264
replay_buffer/size                       266000
trainer/num train calls                  265000
trainer/QF1 Loss                              6.91206
trainer/QF2 Loss                              6.26562
trainer/Policy Loss                        -361.927
trainer/Q1 Predictions Mean                 362.125
trainer/Q1 Predictions Std                   89.8694
trainer/Q1 Predictions Max                  435.237
trainer/Q1 Predictions Min                   16.4701
trainer/Q2 Predictions Mean                 362.238
trainer/Q2 Predictions Std                   90.0673
trainer/Q2 Predictions Max                  435.479
trainer/Q2 Predictions Min                   17.2221
trainer/Q Targets Mean                      361.946
trainer/Q Targets Std                        90.1244
trainer/Q Targets Max                       436.814
trainer/Q Targets Min                        16.2849
trainer/Log Pis Mean                          5.73845
trainer/Log Pis Std                           4.5847
trainer/Log Pis Max                          18.7002
trainer/Log Pis Min                          -7.9848
trainer/policy/mean Mean                      0.0800511
trainer/policy/mean Std                       0.767823
trainer/policy/mean Max                       0.999193
trainer/policy/mean Min                      -0.998477
trainer/policy/normal/std Mean                0.439551
trainer/policy/normal/std Std                 0.145008
trainer/policy/normal/std Max                 0.892229
trainer/policy/normal/std Min                 0.0705139
trainer/policy/normal/log_std Mean           -0.892959
trainer/policy/normal/log_std Std             0.412469
trainer/policy/normal/log_std Max            -0.114032
trainer/policy/normal/log_std Min            -2.65195
trainer/Alpha                                 0.128089
trainer/Alpha Loss                           -0.53749
expl/num steps total                     266000
expl/num paths total                        266
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.3758
expl/Rewards Std                              1.17519
expl/Rewards Max                              8.09872
expl/Rewards Min                             -0.680866
expl/Returns Mean                          5375.8
expl/Returns Std                              0
expl/Returns Max                           5375.8
expl/Returns Min                           5375.8
expl/Actions Mean                             0.0917177
expl/Actions Std                              0.797008
expl/Actions Max                              0.999922
expl/Actions Min                             -0.999815
expl/Num Paths                                1
expl/Average Returns                       5375.8
expl/env_infos/final/reward_run Mean          5.08495
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.08495
expl/env_infos/final/reward_run Min           5.08495
expl/env_infos/initial/reward_run Mean        0.212031
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.212031
expl/env_infos/initial/reward_run Min         0.212031
expl/env_infos/reward_run Mean                5.76198
expl/env_infos/reward_run Std                 1.17189
expl/env_infos/reward_run Max                 8.58731
expl/env_infos/reward_run Min                -0.448384
expl/env_infos/final/reward_ctrl Mean        -0.312931
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.312931
expl/env_infos/final/reward_ctrl Min         -0.312931
expl/env_infos/initial/reward_ctrl Mean      -0.295361
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.295361
expl/env_infos/initial/reward_ctrl Min       -0.295361
expl/env_infos/reward_ctrl Mean              -0.38618
expl/env_infos/reward_ctrl Std                0.0958152
expl/env_infos/reward_ctrl Max               -0.0912567
expl/env_infos/reward_ctrl Min               -0.581191
eval/num steps total                          1.325e+06
eval/num paths total                       1325
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.77365
eval/Rewards Std                              1.2639
eval/Rewards Max                              8.50781
eval/Rewards Min                             -0.768487
eval/Returns Mean                          5773.65
eval/Returns Std                             36.9922
eval/Returns Max                           5846.53
eval/Returns Min                           5745.5
eval/Actions Mean                             0.0968051
eval/Actions Std                              0.819349
eval/Actions Max                              0.997223
eval/Actions Min                             -0.997526
eval/Num Paths                                5
eval/Average Returns                       5773.65
eval/env_infos/final/reward_run Mean          6.85735
eval/env_infos/final/reward_run Std           0.944274
eval/env_infos/final/reward_run Max           7.83511
eval/env_infos/final/reward_run Min           5.51816
eval/env_infos/initial/reward_run Mean       -0.309379
eval/env_infos/initial/reward_run Std         0.0937947
eval/env_infos/initial/reward_run Max        -0.184594
eval/env_infos/initial/reward_run Min        -0.465552
eval/env_infos/reward_run Mean                6.18207
eval/env_infos/reward_run Std                 1.26176
eval/env_infos/reward_run Max                 9.00881
eval/env_infos/reward_run Min                -0.465552
eval/env_infos/final/reward_ctrl Mean        -0.452053
eval/env_infos/final/reward_ctrl Std          0.0335375
eval/env_infos/final/reward_ctrl Max         -0.413739
eval/env_infos/final/reward_ctrl Min         -0.498498
eval/env_infos/initial/reward_ctrl Mean      -0.270357
eval/env_infos/initial/reward_ctrl Std        0.0481341
eval/env_infos/initial/reward_ctrl Max       -0.214715
eval/env_infos/initial/reward_ctrl Min       -0.340802
eval/env_infos/reward_ctrl Mean              -0.408422
eval/env_infos/reward_ctrl Std                0.0900541
eval/env_infos/reward_ctrl Max               -0.0836385
eval/env_infos/reward_ctrl Min               -0.574604
time/data storing (s)                         0.00452465
time/evaluation sampling (s)                  2.00595
time/exploration sampling (s)                 0.529131
time/logging (s)                              0.0136366
time/sac training (s)                         7.40145
time/saving (s)                               0.00375106
time/training (s)                             3.3801e-05
time/epoch (s)                                9.95847
time/total (s)                             2822.84
Epoch                                       264
---------------------------------------  ---------------
2021-11-24 01:16:27.149823 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 265 finished
---------------------------------------  ---------------
epoch                                       265
replay_buffer/size                       267000
trainer/num train calls                  266000
trainer/QF1 Loss                              8.17765
trainer/QF2 Loss                              6.73711
trainer/Policy Loss                        -360.342
trainer/Q1 Predictions Mean                 360.765
trainer/Q1 Predictions Std                   94.4767
trainer/Q1 Predictions Max                  444.107
trainer/Q1 Predictions Min                   17.9905
trainer/Q2 Predictions Mean                 361.159
trainer/Q2 Predictions Std                   94.6031
trainer/Q2 Predictions Max                  442.654
trainer/Q2 Predictions Min                   18.3731
trainer/Q Targets Mean                      361.053
trainer/Q Targets Std                        94.629
trainer/Q Targets Max                       441.451
trainer/Q Targets Min                        18.0751
trainer/Log Pis Mean                          6.18999
trainer/Log Pis Std                           4.2083
trainer/Log Pis Max                          14.9983
trainer/Log Pis Min                          -5.21042
trainer/policy/mean Mean                      0.0760193
trainer/policy/mean Std                       0.77754
trainer/policy/mean Max                       0.998528
trainer/policy/mean Min                      -0.996869
trainer/policy/normal/std Mean                0.437287
trainer/policy/normal/std Std                 0.143104
trainer/policy/normal/std Max                 0.945918
trainer/policy/normal/std Min                 0.0700525
trainer/policy/normal/log_std Mean           -0.897556
trainer/policy/normal/log_std Std             0.412909
trainer/policy/normal/log_std Max            -0.0555994
trainer/policy/normal/log_std Min            -2.65851
trainer/Alpha                                 0.129537
trainer/Alpha Loss                            0.388292
expl/num steps total                     267000
expl/num paths total                        267
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.46691
expl/Rewards Std                              1.20656
expl/Rewards Max                              7.57585
expl/Rewards Min                             -0.496359
expl/Returns Mean                          5466.91
expl/Returns Std                              0
expl/Returns Max                           5466.91
expl/Returns Min                           5466.91
expl/Actions Mean                             0.0900024
expl/Actions Std                              0.8044
expl/Actions Max                              0.999458
expl/Actions Min                             -0.999047
expl/Num Paths                                1
expl/Average Returns                       5466.91
expl/env_infos/final/reward_run Mean          4.4787
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.4787
expl/env_infos/final/reward_run Min           4.4787
expl/env_infos/initial/reward_run Mean       -0.27888
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.27888
expl/env_infos/initial/reward_run Min        -0.27888
expl/env_infos/reward_run Mean                5.86
expl/env_infos/reward_run Std                 1.19128
expl/env_infos/reward_run Max                 8.0651
expl/env_infos/reward_run Min                -0.27888
expl/env_infos/final/reward_ctrl Mean        -0.479783
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.479783
expl/env_infos/final/reward_ctrl Min         -0.479783
expl/env_infos/initial/reward_ctrl Mean      -0.217479
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.217479
expl/env_infos/initial/reward_ctrl Min       -0.217479
expl/env_infos/reward_ctrl Mean              -0.393096
expl/env_infos/reward_ctrl Std                0.0909685
expl/env_infos/reward_ctrl Max               -0.0653434
expl/env_infos/reward_ctrl Min               -0.576288
eval/num steps total                          1.33e+06
eval/num paths total                       1330
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.67748
eval/Rewards Std                              1.26002
eval/Rewards Max                              8.61198
eval/Rewards Min                             -0.673479
eval/Returns Mean                          5677.48
eval/Returns Std                             53.4367
eval/Returns Max                           5750.68
eval/Returns Min                           5586.18
eval/Actions Mean                             0.10517
eval/Actions Std                              0.813365
eval/Actions Max                              0.99699
eval/Actions Min                             -0.994835
eval/Num Paths                                5
eval/Average Returns                       5677.48
eval/env_infos/final/reward_run Mean          6.53671
eval/env_infos/final/reward_run Std           0.834503
eval/env_infos/final/reward_run Max           7.57228
eval/env_infos/final/reward_run Min           5.33158
eval/env_infos/initial/reward_run Mean       -0.265859
eval/env_infos/initial/reward_run Std         0.078597
eval/env_infos/initial/reward_run Max        -0.168487
eval/env_infos/initial/reward_run Min        -0.390478
eval/env_infos/reward_run Mean                6.08105
eval/env_infos/reward_run Std                 1.238
eval/env_infos/reward_run Max                 9.10759
eval/env_infos/reward_run Min                -0.390478
eval/env_infos/final/reward_ctrl Mean        -0.451478
eval/env_infos/final/reward_ctrl Std          0.0255595
eval/env_infos/final/reward_ctrl Max         -0.406664
eval/env_infos/final/reward_ctrl Min         -0.474392
eval/env_infos/initial/reward_ctrl Mean      -0.291023
eval/env_infos/initial/reward_ctrl Std        0.060359
eval/env_infos/initial/reward_ctrl Max       -0.184954
eval/env_infos/initial/reward_ctrl Min       -0.35316
eval/env_infos/reward_ctrl Mean              -0.403574
eval/env_infos/reward_ctrl Std                0.091419
eval/env_infos/reward_ctrl Max               -0.120209
eval/env_infos/reward_ctrl Min               -0.583245
time/data storing (s)                         0.00453225
time/evaluation sampling (s)                  2.00665
time/exploration sampling (s)                 0.530706
time/logging (s)                              0.0136098
time/sac training (s)                         7.40327
time/saving (s)                               0.00378072
time/training (s)                             3.6266e-05
time/epoch (s)                                9.96258
time/total (s)                             2833.08
Epoch                                       265
---------------------------------------  ---------------
2021-11-24 01:16:37.412637 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 266 finished
---------------------------------------  ---------------
epoch                                       266
replay_buffer/size                       268000
trainer/num train calls                  267000
trainer/QF1 Loss                              5.66731
trainer/QF2 Loss                              5.34942
trainer/Policy Loss                        -348.295
trainer/Q1 Predictions Mean                 348.649
trainer/Q1 Predictions Std                  111.353
trainer/Q1 Predictions Max                  434.077
trainer/Q1 Predictions Min                   18.0026
trainer/Q2 Predictions Mean                 348.686
trainer/Q2 Predictions Std                  111.392
trainer/Q2 Predictions Max                  434.741
trainer/Q2 Predictions Min                   18.5929
trainer/Q Targets Mean                      348.208
trainer/Q Targets Std                       111.31
trainer/Q Targets Max                       434.506
trainer/Q Targets Min                        17.9442
trainer/Log Pis Mean                          5.87761
trainer/Log Pis Std                           4.9335
trainer/Log Pis Max                          17.6247
trainer/Log Pis Min                          -5.53386
trainer/policy/mean Mean                      0.0960071
trainer/policy/mean Std                       0.773202
trainer/policy/mean Max                       0.996983
trainer/policy/mean Min                      -0.996033
trainer/policy/normal/std Mean                0.44791
trainer/policy/normal/std Std                 0.147099
trainer/policy/normal/std Max                 0.995713
trainer/policy/normal/std Min                 0.0671594
trainer/policy/normal/log_std Mean           -0.87441
trainer/policy/normal/log_std Std             0.416042
trainer/policy/normal/log_std Max            -0.00429598
trainer/policy/normal/log_std Min            -2.70069
trainer/Alpha                                 0.129509
trainer/Alpha Loss                           -0.250172
expl/num steps total                     268000
expl/num paths total                        268
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.33878
expl/Rewards Std                              1.18097
expl/Rewards Max                              7.65872
expl/Rewards Min                             -0.495888
expl/Returns Mean                          5338.78
expl/Returns Std                              0
expl/Returns Max                           5338.78
expl/Returns Min                           5338.78
expl/Actions Mean                             0.0935719
expl/Actions Std                              0.803974
expl/Actions Max                              0.999829
expl/Actions Min                             -0.99932
expl/Num Paths                                1
expl/Average Returns                       5338.78
expl/env_infos/final/reward_run Mean          7.28016
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.28016
expl/env_infos/final/reward_run Min           7.28016
expl/env_infos/initial/reward_run Mean       -0.184534
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.184534
expl/env_infos/initial/reward_run Min        -0.184534
expl/env_infos/reward_run Mean                5.73186
expl/env_infos/reward_run Std                 1.17151
expl/env_infos/reward_run Max                 8.07879
expl/env_infos/reward_run Min                -0.202117
expl/env_infos/final/reward_ctrl Mean        -0.407577
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.407577
expl/env_infos/final/reward_ctrl Min         -0.407577
expl/env_infos/initial/reward_ctrl Mean      -0.311355
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.311355
expl/env_infos/initial/reward_ctrl Min       -0.311355
expl/env_infos/reward_ctrl Mean              -0.393078
expl/env_infos/reward_ctrl Std                0.0908888
expl/env_infos/reward_ctrl Max               -0.0599781
expl/env_infos/reward_ctrl Min               -0.587321
eval/num steps total                          1.335e+06
eval/num paths total                       1335
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.6987
eval/Rewards Std                              1.25259
eval/Rewards Max                              8.26901
eval/Rewards Min                             -0.656695
eval/Returns Mean                          5698.7
eval/Returns Std                             15.8644
eval/Returns Max                           5724.52
eval/Returns Min                           5674.85
eval/Actions Mean                             0.115038
eval/Actions Std                              0.818599
eval/Actions Max                              0.998206
eval/Actions Min                             -0.996437
eval/Num Paths                                5
eval/Average Returns                       5698.7
eval/env_infos/final/reward_run Mean          5.73692
eval/env_infos/final/reward_run Std           0.24179
eval/env_infos/final/reward_run Max           6.02778
eval/env_infos/final/reward_run Min           5.45504
eval/env_infos/initial/reward_run Mean       -0.22168
eval/env_infos/initial/reward_run Std         0.104681
eval/env_infos/initial/reward_run Max        -0.0630895
eval/env_infos/initial/reward_run Min        -0.338395
eval/env_infos/reward_run Mean                6.1087
eval/env_infos/reward_run Std                 1.24059
eval/env_infos/reward_run Max                 8.72823
eval/env_infos/reward_run Min                -0.338395
eval/env_infos/final/reward_ctrl Mean        -0.433792
eval/env_infos/final/reward_ctrl Std          0.0120206
eval/env_infos/final/reward_ctrl Max         -0.411801
eval/env_infos/final/reward_ctrl Min         -0.445626
eval/env_infos/initial/reward_ctrl Mean      -0.25372
eval/env_infos/initial/reward_ctrl Std        0.0465943
eval/env_infos/initial/reward_ctrl Max       -0.194149
eval/env_infos/initial/reward_ctrl Min       -0.336311
eval/env_infos/reward_ctrl Mean              -0.410002
eval/env_infos/reward_ctrl Std                0.0886739
eval/env_infos/reward_ctrl Max               -0.117324
eval/env_infos/reward_ctrl Min               -0.588247
time/data storing (s)                         0.00453574
time/evaluation sampling (s)                  2.01018
time/exploration sampling (s)                 0.530934
time/logging (s)                              0.0135767
time/sac training (s)                         7.40746
time/saving (s)                               0.00378742
time/training (s)                             3.539e-05
time/epoch (s)                                9.97051
time/total (s)                             2843.33
Epoch                                       266
---------------------------------------  ---------------
2021-11-24 01:16:47.691419 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 267 finished
---------------------------------------  ---------------
epoch                                       267
replay_buffer/size                       269000
trainer/num train calls                  268000
trainer/QF1 Loss                              6.68481
trainer/QF2 Loss                              5.25999
trainer/Policy Loss                        -355.54
trainer/Q1 Predictions Mean                 355.974
trainer/Q1 Predictions Std                  105.29
trainer/Q1 Predictions Max                  439.547
trainer/Q1 Predictions Min                   17.247
trainer/Q2 Predictions Mean                 356.161
trainer/Q2 Predictions Std                  105.199
trainer/Q2 Predictions Max                  441.079
trainer/Q2 Predictions Min                   17.9595
trainer/Q Targets Mean                      356.365
trainer/Q Targets Std                       105.371
trainer/Q Targets Max                       443.008
trainer/Q Targets Min                        17.2991
trainer/Log Pis Mean                          6.39058
trainer/Log Pis Std                           4.7483
trainer/Log Pis Max                          16.3904
trainer/Log Pis Min                          -8.02511
trainer/policy/mean Mean                      0.0803916
trainer/policy/mean Std                       0.782829
trainer/policy/mean Max                       0.997822
trainer/policy/mean Min                      -0.997353
trainer/policy/normal/std Mean                0.442089
trainer/policy/normal/std Std                 0.14559
trainer/policy/normal/std Max                 1.30087
trainer/policy/normal/std Min                 0.0747164
trainer/policy/normal/log_std Mean           -0.884276
trainer/policy/normal/log_std Std             0.400081
trainer/policy/normal/log_std Max             0.263037
trainer/policy/normal/log_std Min            -2.59406
trainer/Alpha                                 0.128708
trainer/Alpha Loss                            0.800774
expl/num steps total                     269000
expl/num paths total                        269
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.49353
expl/Rewards Std                              1.21964
expl/Rewards Max                              7.90276
expl/Rewards Min                             -0.631201
expl/Returns Mean                          5493.53
expl/Returns Std                              0
expl/Returns Max                           5493.53
expl/Returns Min                           5493.53
expl/Actions Mean                             0.0977272
expl/Actions Std                              0.809542
expl/Actions Max                              0.99956
expl/Actions Min                             -0.999908
expl/Num Paths                                1
expl/Average Returns                       5493.53
expl/env_infos/final/reward_run Mean          5.3414
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.3414
expl/env_infos/final/reward_run Min           5.3414
expl/env_infos/initial/reward_run Mean       -0.327689
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.327689
expl/env_infos/initial/reward_run Min        -0.327689
expl/env_infos/reward_run Mean                5.89248
expl/env_infos/reward_run Std                 1.2096
expl/env_infos/reward_run Max                 8.37946
expl/env_infos/reward_run Min                -0.327689
expl/env_infos/final/reward_ctrl Mean        -0.416842
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.416842
expl/env_infos/final/reward_ctrl Min         -0.416842
expl/env_infos/initial/reward_ctrl Mean      -0.303512
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.303512
expl/env_infos/initial/reward_ctrl Min       -0.303512
expl/env_infos/reward_ctrl Mean              -0.398945
expl/env_infos/reward_ctrl Std                0.0935698
expl/env_infos/reward_ctrl Max               -0.0968263
expl/env_infos/reward_ctrl Min               -0.589889
eval/num steps total                          1.34e+06
eval/num paths total                       1340
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.87598
eval/Rewards Std                              1.30595
eval/Rewards Max                              8.55444
eval/Rewards Min                             -0.737513
eval/Returns Mean                          5875.98
eval/Returns Std                            115.718
eval/Returns Max                           6084.34
eval/Returns Min                           5739.29
eval/Actions Mean                             0.119588
eval/Actions Std                              0.824683
eval/Actions Max                              0.997207
eval/Actions Min                             -0.998488
eval/Num Paths                                5
eval/Average Returns                       5875.98
eval/env_infos/final/reward_run Mean          6.69681
eval/env_infos/final/reward_run Std           0.22814
eval/env_infos/final/reward_run Max           6.95668
eval/env_infos/final/reward_run Min           6.36213
eval/env_infos/initial/reward_run Mean       -0.327123
eval/env_infos/initial/reward_run Std         0.0643439
eval/env_infos/initial/reward_run Max        -0.263813
eval/env_infos/initial/reward_run Min        -0.44009
eval/env_infos/reward_run Mean                6.29263
eval/env_infos/reward_run Std                 1.29555
eval/env_infos/reward_run Max                 9.05342
eval/env_infos/reward_run Min                -0.44009
eval/env_infos/final/reward_ctrl Mean        -0.387902
eval/env_infos/final/reward_ctrl Std          0.0615775
eval/env_infos/final/reward_ctrl Max         -0.290531
eval/env_infos/final/reward_ctrl Min         -0.482108
eval/env_infos/initial/reward_ctrl Mean      -0.260381
eval/env_infos/initial/reward_ctrl Std        0.0473576
eval/env_infos/initial/reward_ctrl Max       -0.199597
eval/env_infos/initial/reward_ctrl Min       -0.310587
eval/env_infos/reward_ctrl Mean              -0.416642
eval/env_infos/reward_ctrl Std                0.0884778
eval/env_infos/reward_ctrl Max               -0.0979361
eval/env_infos/reward_ctrl Min               -0.586914
time/data storing (s)                         0.00446725
time/evaluation sampling (s)                  2.01089
time/exploration sampling (s)                 0.534079
time/logging (s)                              0.0135955
time/sac training (s)                         7.41943
time/saving (s)                               0.00374079
time/training (s)                             3.446e-05
time/epoch (s)                                9.98624
time/total (s)                             2853.59
Epoch                                       267
---------------------------------------  ---------------
2021-11-24 01:16:57.927676 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 268 finished
---------------------------------------  ---------------
epoch                                       268
replay_buffer/size                       270000
trainer/num train calls                  269000
trainer/QF1 Loss                             12.2046
trainer/QF2 Loss                              8.29692
trainer/Policy Loss                        -356.393
trainer/Q1 Predictions Mean                 356.842
trainer/Q1 Predictions Std                   97.5061
trainer/Q1 Predictions Max                  434.361
trainer/Q1 Predictions Min                   17.4772
trainer/Q2 Predictions Mean                 357.19
trainer/Q2 Predictions Std                   97.6017
trainer/Q2 Predictions Max                  433.798
trainer/Q2 Predictions Min                   18.2986
trainer/Q Targets Mean                      357.584
trainer/Q Targets Std                        97.6545
trainer/Q Targets Max                       434.724
trainer/Q Targets Min                        17.4173
trainer/Log Pis Mean                          6.2857
trainer/Log Pis Std                           4.96129
trainer/Log Pis Max                          19.785
trainer/Log Pis Min                          -6.8913
trainer/policy/mean Mean                      0.0674498
trainer/policy/mean Std                       0.780908
trainer/policy/mean Max                       0.998655
trainer/policy/mean Min                      -0.996746
trainer/policy/normal/std Mean                0.438987
trainer/policy/normal/std Std                 0.14387
trainer/policy/normal/std Max                 0.860148
trainer/policy/normal/std Min                 0.0644912
trainer/policy/normal/log_std Mean           -0.892443
trainer/policy/normal/log_std Std             0.405755
trainer/policy/normal/log_std Max            -0.150651
trainer/policy/normal/log_std Min            -2.74123
trainer/Alpha                                 0.129401
trainer/Alpha Loss                            0.58421
expl/num steps total                     270000
expl/num paths total                        270
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.54656
expl/Rewards Std                              1.27666
expl/Rewards Max                              7.81677
expl/Rewards Min                             -0.773631
expl/Returns Mean                          5546.56
expl/Returns Std                              0
expl/Returns Max                           5546.56
expl/Returns Min                           5546.56
expl/Actions Mean                             0.0856849
expl/Actions Std                              0.814827
expl/Actions Max                              0.999303
expl/Actions Min                             -0.999676
expl/Num Paths                                1
expl/Average Returns                       5546.56
expl/env_infos/final/reward_run Mean          5.80088
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.80088
expl/env_infos/final/reward_run Min           5.80088
expl/env_infos/initial/reward_run Mean       -0.516276
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.516276
expl/env_infos/initial/reward_run Min        -0.516276
expl/env_infos/reward_run Mean                5.94933
expl/env_infos/reward_run Std                 1.25659
expl/env_infos/reward_run Max                 8.30647
expl/env_infos/reward_run Min                -0.516276
expl/env_infos/final/reward_ctrl Mean        -0.438606
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.438606
expl/env_infos/final/reward_ctrl Min         -0.438606
expl/env_infos/initial/reward_ctrl Mean      -0.257355
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.257355
expl/env_infos/initial/reward_ctrl Min       -0.257355
expl/env_infos/reward_ctrl Mean              -0.402771
expl/env_infos/reward_ctrl Std                0.0915146
expl/env_infos/reward_ctrl Max               -0.103988
expl/env_infos/reward_ctrl Min               -0.580412
eval/num steps total                          1.345e+06
eval/num paths total                       1345
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.8289
eval/Rewards Std                              1.28604
eval/Rewards Max                              8.21083
eval/Rewards Min                             -0.846063
eval/Returns Mean                          5828.9
eval/Returns Std                             81.8995
eval/Returns Max                           5911.04
eval/Returns Min                           5716.12
eval/Actions Mean                             0.0955831
eval/Actions Std                              0.824622
eval/Actions Max                              0.997644
eval/Actions Min                             -0.996921
eval/Num Paths                                5
eval/Average Returns                       5828.9
eval/env_infos/final/reward_run Mean          7.13921
eval/env_infos/final/reward_run Std           0.90831
eval/env_infos/final/reward_run Max           8.17566
eval/env_infos/final/reward_run Min           5.479
eval/env_infos/initial/reward_run Mean       -0.16133
eval/env_infos/initial/reward_run Std         0.0673485
eval/env_infos/initial/reward_run Max        -0.0395357
eval/env_infos/initial/reward_run Min        -0.234072
eval/env_infos/reward_run Mean                6.24238
eval/env_infos/reward_run Std                 1.2633
eval/env_infos/reward_run Max                 8.68963
eval/env_infos/reward_run Min                -0.316498
eval/env_infos/final/reward_ctrl Mean        -0.343554
eval/env_infos/final/reward_ctrl Std          0.0701535
eval/env_infos/final/reward_ctrl Max         -0.248427
eval/env_infos/final/reward_ctrl Min         -0.439619
eval/env_infos/initial/reward_ctrl Mean      -0.255647
eval/env_infos/initial/reward_ctrl Std        0.0395124
eval/env_infos/initial/reward_ctrl Max       -0.201254
eval/env_infos/initial/reward_ctrl Min       -0.30538
eval/env_infos/reward_ctrl Mean              -0.413482
eval/env_infos/reward_ctrl Std                0.0950271
eval/env_infos/reward_ctrl Max               -0.117436
eval/env_infos/reward_ctrl Min               -0.588246
time/data storing (s)                         0.00448098
time/evaluation sampling (s)                  2.01184
time/exploration sampling (s)                 0.531369
time/logging (s)                              0.0135701
time/sac training (s)                         7.37752
time/saving (s)                               0.00374766
time/training (s)                             3.9654e-05
time/epoch (s)                                9.94257
time/total (s)                             2863.82
Epoch                                       268
---------------------------------------  ---------------
2021-11-24 01:17:08.155193 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 269 finished
---------------------------------------  ---------------
epoch                                       269
replay_buffer/size                       271000
trainer/num train calls                  270000
trainer/QF1 Loss                              7.41495
trainer/QF2 Loss                              6.62476
trainer/Policy Loss                        -350.738
trainer/Q1 Predictions Mean                 350.989
trainer/Q1 Predictions Std                  111.742
trainer/Q1 Predictions Max                  439.542
trainer/Q1 Predictions Min                   16.6687
trainer/Q2 Predictions Mean                 351.213
trainer/Q2 Predictions Std                  111.884
trainer/Q2 Predictions Max                  439.605
trainer/Q2 Predictions Min                   16.8252
trainer/Q Targets Mean                      351.467
trainer/Q Targets Std                       111.96
trainer/Q Targets Max                       440
trainer/Q Targets Min                        16.7613
trainer/Log Pis Mean                          6.00635
trainer/Log Pis Std                           4.84826
trainer/Log Pis Max                          18.6291
trainer/Log Pis Min                          -6.9627
trainer/policy/mean Mean                      0.0611518
trainer/policy/mean Std                       0.774149
trainer/policy/mean Max                       0.999128
trainer/policy/mean Min                      -0.999424
trainer/policy/normal/std Mean                0.456763
trainer/policy/normal/std Std                 0.152106
trainer/policy/normal/std Max                 1.05083
trainer/policy/normal/std Min                 0.0745432
trainer/policy/normal/log_std Mean           -0.853357
trainer/policy/normal/log_std Std             0.40661
trainer/policy/normal/log_std Max             0.0495778
trainer/policy/normal/log_std Min            -2.59638
trainer/Alpha                                 0.128944
trainer/Alpha Loss                            0.0130163
expl/num steps total                     271000
expl/num paths total                        271
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.49493
expl/Rewards Std                              1.21772
expl/Rewards Max                              7.81762
expl/Rewards Min                             -0.763499
expl/Returns Mean                          5494.93
expl/Returns Std                              0
expl/Returns Max                           5494.93
expl/Returns Min                           5494.93
expl/Actions Mean                             0.0788099
expl/Actions Std                              0.810388
expl/Actions Max                              0.999826
expl/Actions Min                             -0.999106
expl/Num Paths                                1
expl/Average Returns                       5494.93
expl/env_infos/final/reward_run Mean          4.97454
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.97454
expl/env_infos/final/reward_run Min           4.97454
expl/env_infos/initial/reward_run Mean       -0.436775
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.436775
expl/env_infos/initial/reward_run Min        -0.436775
expl/env_infos/reward_run Mean                5.89269
expl/env_infos/reward_run Std                 1.20299
expl/env_infos/reward_run Max                 8.28317
expl/env_infos/reward_run Min                -0.436775
expl/env_infos/final/reward_ctrl Mean        -0.299829
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.299829
expl/env_infos/final/reward_ctrl Min         -0.299829
expl/env_infos/initial/reward_ctrl Mean      -0.326724
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.326724
expl/env_infos/initial/reward_ctrl Min       -0.326724
expl/env_infos/reward_ctrl Mean              -0.397764
expl/env_infos/reward_ctrl Std                0.0938967
expl/env_infos/reward_ctrl Max               -0.120302
expl/env_infos/reward_ctrl Min               -0.574794
eval/num steps total                          1.35e+06
eval/num paths total                       1350
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.77089
eval/Rewards Std                              1.28489
eval/Rewards Max                              8.37497
eval/Rewards Min                             -1.13018
eval/Returns Mean                          5770.89
eval/Returns Std                             61.4821
eval/Returns Max                           5874.35
eval/Returns Min                           5690.86
eval/Actions Mean                             0.0852796
eval/Actions Std                              0.822096
eval/Actions Max                              0.998572
eval/Actions Min                             -0.997854
eval/Num Paths                                5
eval/Average Returns                       5770.89
eval/env_infos/final/reward_run Mean          7.26254
eval/env_infos/final/reward_run Std           0.915586
eval/env_infos/final/reward_run Max           8.2725
eval/env_infos/final/reward_run Min           5.59639
eval/env_infos/initial/reward_run Mean       -0.094978
eval/env_infos/initial/reward_run Std         0.124321
eval/env_infos/initial/reward_run Max         0.0867945
eval/env_infos/initial/reward_run Min        -0.247898
eval/env_infos/reward_run Mean                6.18076
eval/env_infos/reward_run Std                 1.26042
eval/env_infos/reward_run Max                 8.86763
eval/env_infos/reward_run Min                -0.596131
eval/env_infos/final/reward_ctrl Mean        -0.403776
eval/env_infos/final/reward_ctrl Std          0.0606924
eval/env_infos/final/reward_ctrl Max         -0.332728
eval/env_infos/final/reward_ctrl Min         -0.512954
eval/env_infos/initial/reward_ctrl Mean      -0.240927
eval/env_infos/initial/reward_ctrl Std        0.064005
eval/env_infos/initial/reward_ctrl Max       -0.181865
eval/env_infos/initial/reward_ctrl Min       -0.36319
eval/env_infos/reward_ctrl Mean              -0.409869
eval/env_infos/reward_ctrl Std                0.0929819
eval/env_infos/reward_ctrl Max               -0.0975891
eval/env_infos/reward_ctrl Min               -0.585805
time/data storing (s)                         0.00452601
time/evaluation sampling (s)                  2.00274
time/exploration sampling (s)                 0.524074
time/logging (s)                              0.0135869
time/sac training (s)                         7.38643
time/saving (s)                               0.00374959
time/training (s)                             3.3982e-05
time/epoch (s)                                9.93514
time/total (s)                             2874.03
Epoch                                       269
---------------------------------------  ---------------
2021-11-24 01:17:18.369175 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 270 finished
---------------------------------------  ---------------
epoch                                       270
replay_buffer/size                       272000
trainer/num train calls                  271000
trainer/QF1 Loss                              6.42566
trainer/QF2 Loss                              5.40686
trainer/Policy Loss                        -359.92
trainer/Q1 Predictions Mean                 360.231
trainer/Q1 Predictions Std                   97.593
trainer/Q1 Predictions Max                  434.519
trainer/Q1 Predictions Min                   17.5168
trainer/Q2 Predictions Mean                 360.21
trainer/Q2 Predictions Std                   97.4594
trainer/Q2 Predictions Max                  434.646
trainer/Q2 Predictions Min                   16.7158
trainer/Q Targets Mean                      360.336
trainer/Q Targets Std                        97.4884
trainer/Q Targets Max                       436.077
trainer/Q Targets Min                        16.5839
trainer/Log Pis Mean                          5.9416
trainer/Log Pis Std                           4.36826
trainer/Log Pis Max                          16.469
trainer/Log Pis Min                          -5.69535
trainer/policy/mean Mean                      0.0606473
trainer/policy/mean Std                       0.772669
trainer/policy/mean Max                       0.999005
trainer/policy/mean Min                      -0.998835
trainer/policy/normal/std Mean                0.436787
trainer/policy/normal/std Std                 0.145586
trainer/policy/normal/std Max                 0.997201
trainer/policy/normal/std Min                 0.0627696
trainer/policy/normal/log_std Mean           -0.901248
trainer/policy/normal/log_std Std             0.420704
trainer/policy/normal/log_std Max            -0.00280296
trainer/policy/normal/log_std Min            -2.76829
trainer/Alpha                                 0.131393
trainer/Alpha Loss                           -0.118524
expl/num steps total                     272000
expl/num paths total                        272
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.49533
expl/Rewards Std                              1.24497
expl/Rewards Max                              7.66787
expl/Rewards Min                             -0.454306
expl/Returns Mean                          5495.33
expl/Returns Std                              0
expl/Returns Max                           5495.33
expl/Returns Min                           5495.33
expl/Actions Mean                             0.108283
expl/Actions Std                              0.796366
expl/Actions Max                              0.999338
expl/Actions Min                             -0.998967
expl/Num Paths                                1
expl/Average Returns                       5495.33
expl/env_infos/final/reward_run Mean          4.73991
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.73991
expl/env_infos/final/reward_run Min           4.73991
expl/env_infos/initial/reward_run Mean       -0.0976971
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0976971
expl/env_infos/initial/reward_run Min        -0.0976971
expl/env_infos/reward_run Mean                5.88288
expl/env_infos/reward_run Std                 1.2335
expl/env_infos/reward_run Max                 8.15886
expl/env_infos/reward_run Min                -0.0976971
expl/env_infos/final/reward_ctrl Mean        -0.351949
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.351949
expl/env_infos/final/reward_ctrl Min         -0.351949
expl/env_infos/initial/reward_ctrl Mean      -0.356609
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.356609
expl/env_infos/initial/reward_ctrl Min       -0.356609
expl/env_infos/reward_ctrl Mean              -0.387554
expl/env_infos/reward_ctrl Std                0.0906575
expl/env_infos/reward_ctrl Max               -0.123108
expl/env_infos/reward_ctrl Min               -0.575644
eval/num steps total                          1.355e+06
eval/num paths total                       1355
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.65
eval/Rewards Std                              1.25346
eval/Rewards Max                              8.35895
eval/Rewards Min                             -0.664886
eval/Returns Mean                          5650
eval/Returns Std                             27.8179
eval/Returns Max                           5688.47
eval/Returns Min                           5614.11
eval/Actions Mean                             0.115906
eval/Actions Std                              0.808142
eval/Actions Max                              0.997366
eval/Actions Min                             -0.994933
eval/Num Paths                                5
eval/Average Returns                       5650
eval/env_infos/final/reward_run Mean          6.66425
eval/env_infos/final/reward_run Std           0.806985
eval/env_infos/final/reward_run Max           7.55746
eval/env_infos/final/reward_run Min           5.48509
eval/env_infos/initial/reward_run Mean       -0.170045
eval/env_infos/initial/reward_run Std         0.109194
eval/env_infos/initial/reward_run Max        -0.0593537
eval/env_infos/initial/reward_run Min        -0.341947
eval/env_infos/reward_run Mean                6.04992
eval/env_infos/reward_run Std                 1.24068
eval/env_infos/reward_run Max                 8.86061
eval/env_infos/reward_run Min                -0.341947
eval/env_infos/final/reward_ctrl Mean        -0.418654
eval/env_infos/final/reward_ctrl Std          0.0302206
eval/env_infos/final/reward_ctrl Max         -0.364493
eval/env_infos/final/reward_ctrl Min         -0.449294
eval/env_infos/initial/reward_ctrl Mean      -0.327158
eval/env_infos/initial/reward_ctrl Std        0.0518089
eval/env_infos/initial/reward_ctrl Max       -0.262455
eval/env_infos/initial/reward_ctrl Min       -0.40219
eval/env_infos/reward_ctrl Mean              -0.399917
eval/env_infos/reward_ctrl Std                0.0907059
eval/env_infos/reward_ctrl Max               -0.0942709
eval/env_infos/reward_ctrl Min               -0.58268
time/data storing (s)                         0.0045273
time/evaluation sampling (s)                  2.00517
time/exploration sampling (s)                 0.53137
time/logging (s)                              0.0135972
time/sac training (s)                         7.36282
time/saving (s)                               0.00376774
time/training (s)                             3.4993e-05
time/epoch (s)                                9.92129
time/total (s)                             2884.23
Epoch                                       270
---------------------------------------  ---------------
2021-11-24 01:17:28.625057 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 271 finished
---------------------------------------  ---------------
epoch                                       271
replay_buffer/size                       273000
trainer/num train calls                  272000
trainer/QF1 Loss                              7.1277
trainer/QF2 Loss                              9.11003
trainer/Policy Loss                        -357.188
trainer/Q1 Predictions Mean                 357.762
trainer/Q1 Predictions Std                  103.647
trainer/Q1 Predictions Max                  441.541
trainer/Q1 Predictions Min                   17.5785
trainer/Q2 Predictions Mean                 357.621
trainer/Q2 Predictions Std                  103.754
trainer/Q2 Predictions Max                  440.769
trainer/Q2 Predictions Min                   17.4592
trainer/Q Targets Mean                      357.604
trainer/Q Targets Std                       103.656
trainer/Q Targets Max                       442.329
trainer/Q Targets Min                        16.8228
trainer/Log Pis Mean                          5.8393
trainer/Log Pis Std                           4.56631
trainer/Log Pis Max                          19.6839
trainer/Log Pis Min                          -3.98073
trainer/policy/mean Mean                      0.100101
trainer/policy/mean Std                       0.768465
trainer/policy/mean Max                       0.99682
trainer/policy/mean Min                      -0.999855
trainer/policy/normal/std Mean                0.440805
trainer/policy/normal/std Std                 0.146969
trainer/policy/normal/std Max                 0.914222
trainer/policy/normal/std Min                 0.0723025
trainer/policy/normal/log_std Mean           -0.891478
trainer/policy/normal/log_std Std             0.417683
trainer/policy/normal/log_std Max            -0.0896817
trainer/policy/normal/log_std Min            -2.6269
trainer/Alpha                                 0.128887
trainer/Alpha Loss                           -0.329244
expl/num steps total                     273000
expl/num paths total                        273
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.58298
expl/Rewards Std                              1.21628
expl/Rewards Max                              7.55155
expl/Rewards Min                             -0.584331
expl/Returns Mean                          5582.98
expl/Returns Std                              0
expl/Returns Max                           5582.98
expl/Returns Min                           5582.98
expl/Actions Mean                             0.105872
expl/Actions Std                              0.802874
expl/Actions Max                              0.999751
expl/Actions Min                             -0.999539
expl/Num Paths                                1
expl/Average Returns                       5582.98
expl/env_infos/final/reward_run Mean          7.30255
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.30255
expl/env_infos/final/reward_run Min           7.30255
expl/env_infos/initial/reward_run Mean       -0.290732
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.290732
expl/env_infos/initial/reward_run Min        -0.290732
expl/env_infos/reward_run Mean                5.97647
expl/env_infos/reward_run Std                 1.20905
expl/env_infos/reward_run Max                 8.07439
expl/env_infos/reward_run Min                -0.290732
expl/env_infos/final/reward_ctrl Mean        -0.405203
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.405203
expl/env_infos/final/reward_ctrl Min         -0.405203
expl/env_infos/initial/reward_ctrl Mean      -0.293599
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.293599
expl/env_infos/initial/reward_ctrl Min       -0.293599
expl/env_infos/reward_ctrl Mean              -0.39349
expl/env_infos/reward_ctrl Std                0.0913054
expl/env_infos/reward_ctrl Max               -0.0962599
expl/env_infos/reward_ctrl Min               -0.583565
eval/num steps total                          1.36e+06
eval/num paths total                       1360
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.83182
eval/Rewards Std                              1.2468
eval/Rewards Max                              8.24736
eval/Rewards Min                             -0.719612
eval/Returns Mean                          5831.82
eval/Returns Std                             60.5311
eval/Returns Max                           5926.02
eval/Returns Min                           5772.51
eval/Actions Mean                             0.106043
eval/Actions Std                              0.815866
eval/Actions Max                              0.998036
eval/Actions Min                             -0.993704
eval/Num Paths                                5
eval/Average Returns                       5831.82
eval/env_infos/final/reward_run Mean          6.67102
eval/env_infos/final/reward_run Std           0.70866
eval/env_infos/final/reward_run Max           7.61019
eval/env_infos/final/reward_run Min           5.96471
eval/env_infos/initial/reward_run Mean       -0.117617
eval/env_infos/initial/reward_run Std         0.172432
eval/env_infos/initial/reward_run Max         0.0358248
eval/env_infos/initial/reward_run Min        -0.424833
eval/env_infos/reward_run Mean                6.23795
eval/env_infos/reward_run Std                 1.23971
eval/env_infos/reward_run Max                 8.75182
eval/env_infos/reward_run Min                -0.424833
eval/env_infos/final/reward_ctrl Mean        -0.437245
eval/env_infos/final/reward_ctrl Std          0.0137169
eval/env_infos/final/reward_ctrl Max         -0.41314
eval/env_infos/final/reward_ctrl Min         -0.449254
eval/env_infos/initial/reward_ctrl Mean      -0.2459
eval/env_infos/initial/reward_ctrl Std        0.032228
eval/env_infos/initial/reward_ctrl Max       -0.21233
eval/env_infos/initial/reward_ctrl Min       -0.29478
eval/env_infos/reward_ctrl Mean              -0.406129
eval/env_infos/reward_ctrl Std                0.0944893
eval/env_infos/reward_ctrl Max               -0.0829135
eval/env_infos/reward_ctrl Min               -0.585361
time/data storing (s)                         0.00450381
time/evaluation sampling (s)                  2.01367
time/exploration sampling (s)                 0.543904
time/logging (s)                              0.0135905
time/sac training (s)                         7.38422
time/saving (s)                               0.00378141
time/training (s)                             3.3637e-05
time/epoch (s)                                9.96371
time/total (s)                             2894.47
Epoch                                       271
---------------------------------------  ---------------
2021-11-24 01:17:38.884112 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 272 finished
---------------------------------------  ----------------
epoch                                       272
replay_buffer/size                       274000
trainer/num train calls                  273000
trainer/QF1 Loss                              8.22649
trainer/QF2 Loss                              6.9307
trainer/Policy Loss                        -352.277
trainer/Q1 Predictions Mean                 352.409
trainer/Q1 Predictions Std                  108.285
trainer/Q1 Predictions Max                  432.767
trainer/Q1 Predictions Min                   17.9848
trainer/Q2 Predictions Mean                 352.696
trainer/Q2 Predictions Std                  108.452
trainer/Q2 Predictions Max                  434.121
trainer/Q2 Predictions Min                   17.7002
trainer/Q Targets Mean                      352.871
trainer/Q Targets Std                       108.508
trainer/Q Targets Max                       436.877
trainer/Q Targets Min                        16.7184
trainer/Log Pis Mean                          5.88186
trainer/Log Pis Std                           4.79277
trainer/Log Pis Max                          17.9915
trainer/Log Pis Min                          -6.79065
trainer/policy/mean Mean                      0.0729295
trainer/policy/mean Std                       0.770239
trainer/policy/mean Max                       0.999113
trainer/policy/mean Min                      -0.99738
trainer/policy/normal/std Mean                0.453468
trainer/policy/normal/std Std                 0.149099
trainer/policy/normal/std Max                 0.999083
trainer/policy/normal/std Min                 0.0757205
trainer/policy/normal/log_std Mean           -0.856292
trainer/policy/normal/log_std Std             0.389574
trainer/policy/normal/log_std Max            -0.000917856
trainer/policy/normal/log_std Min            -2.58071
trainer/Alpha                                 0.12929
trainer/Alpha Loss                           -0.241681
expl/num steps total                     274000
expl/num paths total                        274
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.66151
expl/Rewards Std                              1.18873
expl/Rewards Max                              7.95411
expl/Rewards Min                             -0.660018
expl/Returns Mean                          5661.51
expl/Returns Std                              0
expl/Returns Max                           5661.51
expl/Returns Min                           5661.51
expl/Actions Mean                             0.101504
expl/Actions Std                              0.811111
expl/Actions Max                              0.999633
expl/Actions Min                             -0.999613
expl/Num Paths                                1
expl/Average Returns                       5661.51
expl/env_infos/final/reward_run Mean          6.2659
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.2659
expl/env_infos/final/reward_run Min           6.2659
expl/env_infos/initial/reward_run Mean       -0.28446
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.28446
expl/env_infos/initial/reward_run Min        -0.28446
expl/env_infos/reward_run Mean                6.06243
expl/env_infos/reward_run Std                 1.18094
expl/env_infos/reward_run Max                 8.47562
expl/env_infos/reward_run Min                -0.28446
expl/env_infos/final/reward_ctrl Mean        -0.458764
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.458764
expl/env_infos/final/reward_ctrl Min         -0.458764
expl/env_infos/initial/reward_ctrl Mean      -0.375558
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.375558
expl/env_infos/initial/reward_ctrl Min       -0.375558
expl/env_infos/reward_ctrl Mean              -0.400922
expl/env_infos/reward_ctrl Std                0.0897567
expl/env_infos/reward_ctrl Max               -0.11557
expl/env_infos/reward_ctrl Min               -0.5828
eval/num steps total                          1.365e+06
eval/num paths total                       1365
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.77139
eval/Rewards Std                              1.26162
eval/Rewards Max                              8.3425
eval/Rewards Min                             -0.784384
eval/Returns Mean                          5771.39
eval/Returns Std                             63.4528
eval/Returns Max                           5837.51
eval/Returns Min                           5668.28
eval/Actions Mean                             0.0960856
eval/Actions Std                              0.817848
eval/Actions Max                              0.996862
eval/Actions Min                             -0.997478
eval/Num Paths                                5
eval/Average Returns                       5771.39
eval/env_infos/final/reward_run Mean          7.35612
eval/env_infos/final/reward_run Std           0.583507
eval/env_infos/final/reward_run Max           7.75183
eval/env_infos/final/reward_run Min           6.20572
eval/env_infos/initial/reward_run Mean       -0.192284
eval/env_infos/initial/reward_run Std         0.0912805
eval/env_infos/initial/reward_run Max        -0.0204191
eval/env_infos/initial/reward_run Min        -0.282597
eval/env_infos/reward_run Mean                6.17825
eval/env_infos/reward_run Std                 1.24755
eval/env_infos/reward_run Max                 8.81477
eval/env_infos/reward_run Min                -0.396724
eval/env_infos/final/reward_ctrl Mean        -0.434709
eval/env_infos/final/reward_ctrl Std          0.027971
eval/env_infos/final/reward_ctrl Max         -0.39133
eval/env_infos/final/reward_ctrl Min         -0.460603
eval/env_infos/initial/reward_ctrl Mean      -0.268428
eval/env_infos/initial/reward_ctrl Std        0.0374301
eval/env_infos/initial/reward_ctrl Max       -0.224775
eval/env_infos/initial/reward_ctrl Min       -0.338093
eval/env_infos/reward_ctrl Mean              -0.406865
eval/env_infos/reward_ctrl Std                0.0882893
eval/env_infos/reward_ctrl Max               -0.102076
eval/env_infos/reward_ctrl Min               -0.582953
time/data storing (s)                         0.00455211
time/evaluation sampling (s)                  2.00582
time/exploration sampling (s)                 0.537084
time/logging (s)                              0.0135863
time/sac training (s)                         7.4013
time/saving (s)                               0.00377529
time/training (s)                             3.3964e-05
time/epoch (s)                                9.96616
time/total (s)                             2904.72
Epoch                                       272
---------------------------------------  ----------------
2021-11-24 01:17:49.103386 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 273 finished
---------------------------------------  ---------------
epoch                                       273
replay_buffer/size                       275000
trainer/num train calls                  274000
trainer/QF1 Loss                              8.5452
trainer/QF2 Loss                             10.4418
trainer/Policy Loss                        -356.503
trainer/Q1 Predictions Mean                 356.582
trainer/Q1 Predictions Std                  105.959
trainer/Q1 Predictions Max                  439.057
trainer/Q1 Predictions Min                   17.1157
trainer/Q2 Predictions Mean                 357.026
trainer/Q2 Predictions Std                  106.184
trainer/Q2 Predictions Max                  438.741
trainer/Q2 Predictions Min                   16.5117
trainer/Q Targets Mean                      357.134
trainer/Q Targets Std                       106.182
trainer/Q Targets Max                       439.071
trainer/Q Targets Min                        16.7687
trainer/Log Pis Mean                          6.08175
trainer/Log Pis Std                           4.69478
trainer/Log Pis Max                          18.3803
trainer/Log Pis Min                          -7.77357
trainer/policy/mean Mean                      0.106643
trainer/policy/mean Std                       0.779101
trainer/policy/mean Max                       0.998394
trainer/policy/mean Min                      -0.997261
trainer/policy/normal/std Mean                0.449089
trainer/policy/normal/std Std                 0.143431
trainer/policy/normal/std Max                 0.822597
trainer/policy/normal/std Min                 0.0737612
trainer/policy/normal/log_std Mean           -0.869109
trainer/policy/normal/log_std Std             0.409092
trainer/policy/normal/log_std Max            -0.195288
trainer/policy/normal/log_std Min            -2.60692
trainer/Alpha                                 0.130146
trainer/Alpha Loss                            0.166702
expl/num steps total                     275000
expl/num paths total                        275
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.43371
expl/Rewards Std                              1.22126
expl/Rewards Max                              7.85858
expl/Rewards Min                             -0.538041
expl/Returns Mean                          5433.71
expl/Returns Std                              0
expl/Returns Max                           5433.71
expl/Returns Min                           5433.71
expl/Actions Mean                             0.115011
expl/Actions Std                              0.80428
expl/Actions Max                              0.999739
expl/Actions Min                             -0.998889
expl/Num Paths                                1
expl/Average Returns                       5433.71
expl/env_infos/final/reward_run Mean          5.28521
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.28521
expl/env_infos/final/reward_run Min           5.28521
expl/env_infos/initial/reward_run Mean       -0.163223
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.163223
expl/env_infos/initial/reward_run Min        -0.163223
expl/env_infos/reward_run Mean                5.82977
expl/env_infos/reward_run Std                 1.214
expl/env_infos/reward_run Max                 8.33733
expl/env_infos/reward_run Min                -0.163223
expl/env_infos/final/reward_ctrl Mean        -0.564286
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.564286
expl/env_infos/final/reward_ctrl Min         -0.564286
expl/env_infos/initial/reward_ctrl Mean      -0.374818
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.374818
expl/env_infos/initial/reward_ctrl Min       -0.374818
expl/env_infos/reward_ctrl Mean              -0.396057
expl/env_infos/reward_ctrl Std                0.0918413
expl/env_infos/reward_ctrl Max               -0.0853552
expl/env_infos/reward_ctrl Min               -0.57484
eval/num steps total                          1.37e+06
eval/num paths total                       1370
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.76606
eval/Rewards Std                              1.23255
eval/Rewards Max                              8.12872
eval/Rewards Min                             -0.458241
eval/Returns Mean                          5766.06
eval/Returns Std                             24.8557
eval/Returns Max                           5808.96
eval/Returns Min                           5741.09
eval/Actions Mean                             0.12051
eval/Actions Std                              0.817555
eval/Actions Max                              0.998759
eval/Actions Min                             -0.995126
eval/Num Paths                                5
eval/Average Returns                       5766.06
eval/env_infos/final/reward_run Mean          6.47219
eval/env_infos/final/reward_run Std           1.22463
eval/env_infos/final/reward_run Max           8.32181
eval/env_infos/final/reward_run Min           4.77488
eval/env_infos/initial/reward_run Mean        0.161423
eval/env_infos/initial/reward_run Std         0.257818
eval/env_infos/initial/reward_run Max         0.627902
eval/env_infos/initial/reward_run Min        -0.124754
eval/env_infos/reward_run Mean                6.17581
eval/env_infos/reward_run Std                 1.22077
eval/env_infos/reward_run Max                 8.6294
eval/env_infos/reward_run Min                -0.233201
eval/env_infos/final/reward_ctrl Mean        -0.482938
eval/env_infos/final/reward_ctrl Std          0.0243322
eval/env_infos/final/reward_ctrl Max         -0.451629
eval/env_infos/final/reward_ctrl Min         -0.513372
eval/env_infos/initial/reward_ctrl Mean      -0.205585
eval/env_infos/initial/reward_ctrl Std        0.0665751
eval/env_infos/initial/reward_ctrl Max       -0.0837094
eval/env_infos/initial/reward_ctrl Min       -0.281312
eval/env_infos/reward_ctrl Mean              -0.409751
eval/env_infos/reward_ctrl Std                0.0922604
eval/env_infos/reward_ctrl Max               -0.0837094
eval/env_infos/reward_ctrl Min               -0.58104
time/data storing (s)                         0.00452845
time/evaluation sampling (s)                  2.00967
time/exploration sampling (s)                 0.528315
time/logging (s)                              0.0135391
time/sac training (s)                         7.36605
time/saving (s)                               0.00515406
time/training (s)                             3.4499e-05
time/epoch (s)                                9.92729
time/total (s)                             2914.92
Epoch                                       273
---------------------------------------  ---------------
2021-11-24 01:17:59.369973 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 274 finished
---------------------------------------  ---------------
epoch                                       274
replay_buffer/size                       276000
trainer/num train calls                  275000
trainer/QF1 Loss                              8.14465
trainer/QF2 Loss                              7.71708
trainer/Policy Loss                        -365.04
trainer/Q1 Predictions Mean                 365.43
trainer/Q1 Predictions Std                   91.2106
trainer/Q1 Predictions Max                  440.469
trainer/Q1 Predictions Min                   17.6936
trainer/Q2 Predictions Mean                 365.586
trainer/Q2 Predictions Std                   91.2155
trainer/Q2 Predictions Max                  439.6
trainer/Q2 Predictions Min                   17.3147
trainer/Q Targets Mean                      365.659
trainer/Q Targets Std                        91.2731
trainer/Q Targets Max                       439.489
trainer/Q Targets Min                        17.1407
trainer/Log Pis Mean                          6.09446
trainer/Log Pis Std                           4.4715
trainer/Log Pis Max                          22.9513
trainer/Log Pis Min                          -5.5248
trainer/policy/mean Mean                      0.0580608
trainer/policy/mean Std                       0.772367
trainer/policy/mean Max                       0.995603
trainer/policy/mean Min                      -0.998796
trainer/policy/normal/std Mean                0.44151
trainer/policy/normal/std Std                 0.143001
trainer/policy/normal/std Max                 0.913476
trainer/policy/normal/std Min                 0.0583408
trainer/policy/normal/log_std Mean           -0.886552
trainer/policy/normal/log_std Std             0.408685
trainer/policy/normal/log_std Max            -0.0904979
trainer/policy/normal/log_std Min            -2.84145
trainer/Alpha                                 0.129217
trainer/Alpha Loss                            0.193288
expl/num steps total                     276000
expl/num paths total                        276
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.57425
expl/Rewards Std                              1.23125
expl/Rewards Max                              7.9005
expl/Rewards Min                             -0.653966
expl/Returns Mean                          5574.25
expl/Returns Std                              0
expl/Returns Max                           5574.25
expl/Returns Min                           5574.25
expl/Actions Mean                             0.0887982
expl/Actions Std                              0.802581
expl/Actions Max                              0.999671
expl/Actions Min                             -0.999225
expl/Num Paths                                1
expl/Average Returns                       5574.25
expl/env_infos/final/reward_run Mean          6.50676
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.50676
expl/env_infos/final/reward_run Min           6.50676
expl/env_infos/initial/reward_run Mean       -0.362736
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.362736
expl/env_infos/initial/reward_run Min        -0.362736
expl/env_infos/reward_run Mean                5.96547
expl/env_infos/reward_run Std                 1.22068
expl/env_infos/reward_run Max                 8.25852
expl/env_infos/reward_run Min                -0.362736
expl/env_infos/final/reward_ctrl Mean        -0.337969
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.337969
expl/env_infos/final/reward_ctrl Min         -0.337969
expl/env_infos/initial/reward_ctrl Mean      -0.29123
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.29123
expl/env_infos/initial/reward_ctrl Min       -0.29123
expl/env_infos/reward_ctrl Mean              -0.391213
expl/env_infos/reward_ctrl Std                0.0918623
expl/env_infos/reward_ctrl Max               -0.0832512
expl/env_infos/reward_ctrl Min               -0.582027
eval/num steps total                          1.375e+06
eval/num paths total                       1375
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.79688
eval/Rewards Std                              1.24764
eval/Rewards Max                              8.47235
eval/Rewards Min                             -0.643047
eval/Returns Mean                          5796.88
eval/Returns Std                             49.6201
eval/Returns Max                           5885.9
eval/Returns Min                           5746.14
eval/Actions Mean                             0.0957597
eval/Actions Std                              0.816649
eval/Actions Max                              0.997329
eval/Actions Min                             -0.994132
eval/Num Paths                                5
eval/Average Returns                       5796.88
eval/env_infos/final/reward_run Mean          7.52929
eval/env_infos/final/reward_run Std           0.41145
eval/env_infos/final/reward_run Max           7.96192
eval/env_infos/final/reward_run Min           6.7572
eval/env_infos/initial/reward_run Mean       -0.170735
eval/env_infos/initial/reward_run Std         0.168967
eval/env_infos/initial/reward_run Max         0.113394
eval/env_infos/initial/reward_run Min        -0.369172
eval/env_infos/reward_run Mean                6.20254
eval/env_infos/reward_run Std                 1.23397
eval/env_infos/reward_run Max                 8.95527
eval/env_infos/reward_run Min                -0.369172
eval/env_infos/final/reward_ctrl Mean        -0.432236
eval/env_infos/final/reward_ctrl Std          0.071513
eval/env_infos/final/reward_ctrl Max         -0.293886
eval/env_infos/final/reward_ctrl Min         -0.499282
eval/env_infos/initial/reward_ctrl Mean      -0.229527
eval/env_infos/initial/reward_ctrl Std        0.0259696
eval/env_infos/initial/reward_ctrl Max       -0.198381
eval/env_infos/initial/reward_ctrl Min       -0.273875
eval/env_infos/reward_ctrl Mean              -0.405651
eval/env_infos/reward_ctrl Std                0.0906784
eval/env_infos/reward_ctrl Max               -0.0956555
eval/env_infos/reward_ctrl Min               -0.583123
time/data storing (s)                         0.00452352
time/evaluation sampling (s)                  2.00307
time/exploration sampling (s)                 0.526974
time/logging (s)                              0.0135924
time/sac training (s)                         7.42209
time/saving (s)                               0.00377267
time/training (s)                             3.4464e-05
time/epoch (s)                                9.97406
time/total (s)                             2925.18
Epoch                                       274
---------------------------------------  ---------------
2021-11-24 01:18:09.594800 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 275 finished
---------------------------------------  ---------------
epoch                                       275
replay_buffer/size                       277000
trainer/num train calls                  276000
trainer/QF1 Loss                              8.01849
trainer/QF2 Loss                             13.0849
trainer/Policy Loss                        -359.481
trainer/Q1 Predictions Mean                 359.909
trainer/Q1 Predictions Std                  103.188
trainer/Q1 Predictions Max                  439.237
trainer/Q1 Predictions Min                   18.3369
trainer/Q2 Predictions Mean                 359.995
trainer/Q2 Predictions Std                  103.311
trainer/Q2 Predictions Max                  442.303
trainer/Q2 Predictions Min                   18.3115
trainer/Q Targets Mean                      359.486
trainer/Q Targets Std                       103.118
trainer/Q Targets Max                       441.747
trainer/Q Targets Min                        17.083
trainer/Log Pis Mean                          5.99929
trainer/Log Pis Std                           5.05452
trainer/Log Pis Max                          19.4482
trainer/Log Pis Min                          -7.02397
trainer/policy/mean Mean                      0.0582834
trainer/policy/mean Std                       0.779606
trainer/policy/mean Max                       0.998429
trainer/policy/mean Min                      -0.999881
trainer/policy/normal/std Mean                0.443683
trainer/policy/normal/std Std                 0.141241
trainer/policy/normal/std Max                 0.983934
trainer/policy/normal/std Min                 0.0712454
trainer/policy/normal/log_std Mean           -0.879989
trainer/policy/normal/log_std Std             0.404579
trainer/policy/normal/log_std Max            -0.0161962
trainer/policy/normal/log_std Min            -2.64162
trainer/Alpha                                 0.130266
trainer/Alpha Loss                           -0.00144202
expl/num steps total                     277000
expl/num paths total                        277
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.43591
expl/Rewards Std                              1.23715
expl/Rewards Max                              7.93129
expl/Rewards Min                             -0.438711
expl/Returns Mean                          5435.91
expl/Returns Std                              0
expl/Returns Max                           5435.91
expl/Returns Min                           5435.91
expl/Actions Mean                             0.0842319
expl/Actions Std                              0.801291
expl/Actions Max                              0.999429
expl/Actions Min                             -0.999674
expl/Num Paths                                1
expl/Average Returns                       5435.91
expl/env_infos/final/reward_run Mean          6.29333
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.29333
expl/env_infos/final/reward_run Min           6.29333
expl/env_infos/initial/reward_run Mean       -0.160712
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.160712
expl/env_infos/initial/reward_run Min        -0.160712
expl/env_infos/reward_run Mean                5.82541
expl/env_infos/reward_run Std                 1.23473
expl/env_infos/reward_run Max                 8.42002
expl/env_infos/reward_run Min                -0.160712
expl/env_infos/final/reward_ctrl Mean        -0.256201
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.256201
expl/env_infos/final/reward_ctrl Min         -0.256201
expl/env_infos/initial/reward_ctrl Mean      -0.278
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.278
expl/env_infos/initial/reward_ctrl Min       -0.278
expl/env_infos/reward_ctrl Mean              -0.389497
expl/env_infos/reward_ctrl Std                0.0929931
expl/env_infos/reward_ctrl Max               -0.11099
expl/env_infos/reward_ctrl Min               -0.586817
eval/num steps total                          1.38e+06
eval/num paths total                       1380
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.80968
eval/Rewards Std                              1.24251
eval/Rewards Max                              8.40287
eval/Rewards Min                             -0.640765
eval/Returns Mean                          5809.68
eval/Returns Std                             67.3799
eval/Returns Max                           5910.66
eval/Returns Min                           5704.77
eval/Actions Mean                             0.0814276
eval/Actions Std                              0.81787
eval/Actions Max                              0.996189
eval/Actions Min                             -0.997302
eval/Num Paths                                5
eval/Average Returns                       5809.68
eval/env_infos/final/reward_run Mean          6.56376
eval/env_infos/final/reward_run Std           0.733272
eval/env_infos/final/reward_run Max           7.75046
eval/env_infos/final/reward_run Min           5.70034
eval/env_infos/initial/reward_run Mean       -0.171272
eval/env_infos/initial/reward_run Std         0.156083
eval/env_infos/initial/reward_run Max         0.0947827
eval/env_infos/initial/reward_run Min        -0.344558
eval/env_infos/reward_run Mean                6.21501
eval/env_infos/reward_run Std                 1.23186
eval/env_infos/reward_run Max                 8.91825
eval/env_infos/reward_run Min                -0.344558
eval/env_infos/final/reward_ctrl Mean        -0.454005
eval/env_infos/final/reward_ctrl Std          0.0821644
eval/env_infos/final/reward_ctrl Max         -0.293504
eval/env_infos/final/reward_ctrl Min         -0.516408
eval/env_infos/initial/reward_ctrl Mean      -0.304704
eval/env_infos/initial/reward_ctrl Std        0.0334148
eval/env_infos/initial/reward_ctrl Max       -0.25179
eval/env_infos/initial/reward_ctrl Min       -0.345271
eval/env_infos/reward_ctrl Mean              -0.405325
eval/env_infos/reward_ctrl Std                0.0913291
eval/env_infos/reward_ctrl Max               -0.0954165
eval/env_infos/reward_ctrl Min               -0.583419
time/data storing (s)                         0.00451593
time/evaluation sampling (s)                  1.99486
time/exploration sampling (s)                 0.535209
time/logging (s)                              0.0135173
time/sac training (s)                         7.37895
time/saving (s)                               0.0037871
time/training (s)                             3.4349e-05
time/epoch (s)                                9.93087
time/total (s)                             2935.39
Epoch                                       275
---------------------------------------  ---------------
2021-11-24 01:18:19.819239 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 276 finished
---------------------------------------  ---------------
epoch                                       276
replay_buffer/size                       278000
trainer/num train calls                  277000
trainer/QF1 Loss                              5.76297
trainer/QF2 Loss                              5.47897
trainer/Policy Loss                        -360.938
trainer/Q1 Predictions Mean                 361.392
trainer/Q1 Predictions Std                  101.397
trainer/Q1 Predictions Max                  437.672
trainer/Q1 Predictions Min                   15.8039
trainer/Q2 Predictions Mean                 361.558
trainer/Q2 Predictions Std                  101.488
trainer/Q2 Predictions Max                  437.572
trainer/Q2 Predictions Min                   16.0198
trainer/Q Targets Mean                      362.066
trainer/Q Targets Std                       101.684
trainer/Q Targets Max                       438.31
trainer/Q Targets Min                        15.7926
trainer/Log Pis Mean                          5.86172
trainer/Log Pis Std                           4.67182
trainer/Log Pis Max                          18.2886
trainer/Log Pis Min                          -4.92326
trainer/policy/mean Mean                      0.0841312
trainer/policy/mean Std                       0.771391
trainer/policy/mean Max                       0.997311
trainer/policy/mean Min                      -0.995281
trainer/policy/normal/std Mean                0.442504
trainer/policy/normal/std Std                 0.146448
trainer/policy/normal/std Max                 0.85765
trainer/policy/normal/std Min                 0.0720666
trainer/policy/normal/log_std Mean           -0.887629
trainer/policy/normal/log_std Std             0.418589
trainer/policy/normal/log_std Max            -0.153559
trainer/policy/normal/log_std Min            -2.63016
trainer/Alpha                                 0.131556
trainer/Alpha Loss                           -0.280486
expl/num steps total                     278000
expl/num paths total                        278
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.69466
expl/Rewards Std                              1.24078
expl/Rewards Max                              8.1757
expl/Rewards Min                             -0.492646
expl/Returns Mean                          5694.66
expl/Returns Std                              0
expl/Returns Max                           5694.66
expl/Returns Min                           5694.66
expl/Actions Mean                             0.0973604
expl/Actions Std                              0.804333
expl/Actions Max                              0.999251
expl/Actions Min                             -0.999067
expl/Num Paths                                1
expl/Average Returns                       5694.66
expl/env_infos/final/reward_run Mean          5.77037
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.77037
expl/env_infos/final/reward_run Min           5.77037
expl/env_infos/initial/reward_run Mean       -0.0842108
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0842108
expl/env_infos/initial/reward_run Min        -0.0842108
expl/env_infos/reward_run Mean                6.08852
expl/env_infos/reward_run Std                 1.23185
expl/env_infos/reward_run Max                 8.66945
expl/env_infos/reward_run Min                -0.0842108
expl/env_infos/final/reward_ctrl Mean        -0.515763
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.515763
expl/env_infos/final/reward_ctrl Min         -0.515763
expl/env_infos/initial/reward_ctrl Mean      -0.408435
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.408435
expl/env_infos/initial/reward_ctrl Min       -0.408435
expl/env_infos/reward_ctrl Mean              -0.393859
expl/env_infos/reward_ctrl Std                0.0924874
expl/env_infos/reward_ctrl Max               -0.106947
expl/env_infos/reward_ctrl Min               -0.578204
eval/num steps total                          1.385e+06
eval/num paths total                       1385
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.72665
eval/Rewards Std                              1.2483
eval/Rewards Max                              8.11834
eval/Rewards Min                             -0.805401
eval/Returns Mean                          5726.65
eval/Returns Std                             33.6918
eval/Returns Max                           5787.58
eval/Returns Min                           5690.05
eval/Actions Mean                             0.122603
eval/Actions Std                              0.817032
eval/Actions Max                              0.997589
eval/Actions Min                             -0.996855
eval/Num Paths                                5
eval/Average Returns                       5726.65
eval/env_infos/final/reward_run Mean          6.53577
eval/env_infos/final/reward_run Std           0.834456
eval/env_infos/final/reward_run Max           7.39214
eval/env_infos/final/reward_run Min           5.40268
eval/env_infos/initial/reward_run Mean       -0.084571
eval/env_infos/initial/reward_run Std         0.26825
eval/env_infos/initial/reward_run Max         0.211365
eval/env_infos/initial/reward_run Min        -0.506306
eval/env_infos/reward_run Mean                6.1362
eval/env_infos/reward_run Std                 1.23447
eval/env_infos/reward_run Max                 8.61096
eval/env_infos/reward_run Min                -0.506306
eval/env_infos/final/reward_ctrl Mean        -0.410674
eval/env_infos/final/reward_ctrl Std          0.0364027
eval/env_infos/final/reward_ctrl Max         -0.343434
eval/env_infos/final/reward_ctrl Min         -0.451167
eval/env_infos/initial/reward_ctrl Mean      -0.210432
eval/env_infos/initial/reward_ctrl Std        0.0700286
eval/env_infos/initial/reward_ctrl Max       -0.125639
eval/env_infos/initial/reward_ctrl Min       -0.299095
eval/env_infos/reward_ctrl Mean              -0.409544
eval/env_infos/reward_ctrl Std                0.0903063
eval/env_infos/reward_ctrl Max               -0.0780112
eval/env_infos/reward_ctrl Min               -0.582579
time/data storing (s)                         0.00444513
time/evaluation sampling (s)                  2.00625
time/exploration sampling (s)                 0.531997
time/logging (s)                              0.0136329
time/sac training (s)                         7.37126
time/saving (s)                               0.00376096
time/training (s)                             3.3515e-05
time/epoch (s)                                9.93139
time/total (s)                             2945.6
Epoch                                       276
---------------------------------------  ---------------
2021-11-24 01:18:30.057154 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 277 finished
---------------------------------------  ---------------
epoch                                       277
replay_buffer/size                       279000
trainer/num train calls                  278000
trainer/QF1 Loss                              6.05501
trainer/QF2 Loss                              6.65983
trainer/Policy Loss                        -367.596
trainer/Q1 Predictions Mean                 368.226
trainer/Q1 Predictions Std                   96.2653
trainer/Q1 Predictions Max                  444.305
trainer/Q1 Predictions Min                   17.1487
trainer/Q2 Predictions Mean                 368.398
trainer/Q2 Predictions Std                   96.1439
trainer/Q2 Predictions Max                  445.44
trainer/Q2 Predictions Min                   17.1254
trainer/Q Targets Mean                      368.778
trainer/Q Targets Std                        96.2965
trainer/Q Targets Max                       444.806
trainer/Q Targets Min                        16.5618
trainer/Log Pis Mean                          5.95079
trainer/Log Pis Std                           4.33597
trainer/Log Pis Max                          18.3562
trainer/Log Pis Min                          -5.47439
trainer/policy/mean Mean                      0.0931536
trainer/policy/mean Std                       0.779548
trainer/policy/mean Max                       0.996718
trainer/policy/mean Min                      -0.999831
trainer/policy/normal/std Mean                0.435749
trainer/policy/normal/std Std                 0.14243
trainer/policy/normal/std Max                 1.32025
trainer/policy/normal/std Min                 0.0641628
trainer/policy/normal/log_std Mean           -0.90317
trainer/policy/normal/log_std Std             0.421422
trainer/policy/normal/log_std Max             0.277818
trainer/policy/normal/log_std Min            -2.74633
trainer/Alpha                                 0.131878
trainer/Alpha Loss                           -0.0996995
expl/num steps total                     279000
expl/num paths total                        279
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.48987
expl/Rewards Std                              1.23413
expl/Rewards Max                              7.76307
expl/Rewards Min                             -0.606078
expl/Returns Mean                          5489.87
expl/Returns Std                              0
expl/Returns Max                           5489.87
expl/Returns Min                           5489.87
expl/Actions Mean                             0.100319
expl/Actions Std                              0.801992
expl/Actions Max                              0.999252
expl/Actions Min                             -0.998823
expl/Num Paths                                1
expl/Average Returns                       5489.87
expl/env_infos/final/reward_run Mean          5.62773
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.62773
expl/env_infos/final/reward_run Min           5.62773
expl/env_infos/initial/reward_run Mean       -0.28071
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.28071
expl/env_infos/initial/reward_run Min        -0.28071
expl/env_infos/reward_run Mean                5.88182
expl/env_infos/reward_run Std                 1.22862
expl/env_infos/reward_run Max                 8.24482
expl/env_infos/reward_run Min                -0.28071
expl/env_infos/final/reward_ctrl Mean        -0.365915
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.365915
expl/env_infos/final/reward_ctrl Min         -0.365915
expl/env_infos/initial/reward_ctrl Mean      -0.325368
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.325368
expl/env_infos/initial/reward_ctrl Min       -0.325368
expl/env_infos/reward_ctrl Mean              -0.391953
expl/env_infos/reward_ctrl Std                0.0897337
expl/env_infos/reward_ctrl Max               -0.0879751
expl/env_infos/reward_ctrl Min               -0.590291
eval/num steps total                          1.39e+06
eval/num paths total                       1390
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.88605
eval/Rewards Std                              1.26018
eval/Rewards Max                              8.54895
eval/Rewards Min                             -0.694054
eval/Returns Mean                          5886.05
eval/Returns Std                             39.8383
eval/Returns Max                           5935.05
eval/Returns Min                           5816.54
eval/Actions Mean                             0.0912277
eval/Actions Std                              0.818589
eval/Actions Max                              0.997379
eval/Actions Min                             -0.995592
eval/Num Paths                                5
eval/Average Returns                       5886.05
eval/env_infos/final/reward_run Mean          6.57248
eval/env_infos/final/reward_run Std           0.97445
eval/env_infos/final/reward_run Max           8.0134
eval/env_infos/final/reward_run Min           5.52982
eval/env_infos/initial/reward_run Mean       -0.221558
eval/env_infos/initial/reward_run Std         0.117024
eval/env_infos/initial/reward_run Max        -0.0412007
eval/env_infos/initial/reward_run Min        -0.378943
eval/env_infos/reward_run Mean                6.2931
eval/env_infos/reward_run Std                 1.25221
eval/env_infos/reward_run Max                 9.02991
eval/env_infos/reward_run Min                -0.378943
eval/env_infos/final/reward_ctrl Mean        -0.452349
eval/env_infos/final/reward_ctrl Std          0.0332304
eval/env_infos/final/reward_ctrl Max         -0.390333
eval/env_infos/final/reward_ctrl Min         -0.48341
eval/env_infos/initial/reward_ctrl Mean      -0.271995
eval/env_infos/initial/reward_ctrl Std        0.0459982
eval/env_infos/initial/reward_ctrl Max       -0.196364
eval/env_infos/initial/reward_ctrl Min       -0.320491
eval/env_infos/reward_ctrl Mean              -0.407046
eval/env_infos/reward_ctrl Std                0.0897684
eval/env_infos/reward_ctrl Max               -0.0986539
eval/env_infos/reward_ctrl Min               -0.584768
time/data storing (s)                         0.00447519
time/evaluation sampling (s)                  2.00751
time/exploration sampling (s)                 0.536396
time/logging (s)                              0.0136168
time/sac training (s)                         7.3784
time/saving (s)                               0.00377201
time/training (s)                             3.3881e-05
time/epoch (s)                                9.9442
time/total (s)                             2955.83
Epoch                                       277
---------------------------------------  ---------------
2021-11-24 01:18:40.279892 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 278 finished
---------------------------------------  ---------------
epoch                                       278
replay_buffer/size                       280000
trainer/num train calls                  279000
trainer/QF1 Loss                              7.38563
trainer/QF2 Loss                              6.99078
trainer/Policy Loss                        -357.521
trainer/Q1 Predictions Mean                 358.195
trainer/Q1 Predictions Std                  105.095
trainer/Q1 Predictions Max                  443.805
trainer/Q1 Predictions Min                   16.1397
trainer/Q2 Predictions Mean                 357.542
trainer/Q2 Predictions Std                  104.917
trainer/Q2 Predictions Max                  441.512
trainer/Q2 Predictions Min                   16.0883
trainer/Q Targets Mean                      357.845
trainer/Q Targets Std                       105.155
trainer/Q Targets Max                       442.941
trainer/Q Targets Min                        16.6197
trainer/Log Pis Mean                          6.26129
trainer/Log Pis Std                           4.6917
trainer/Log Pis Max                          15.637
trainer/Log Pis Min                          -7.08513
trainer/policy/mean Mean                      0.0557709
trainer/policy/mean Std                       0.78083
trainer/policy/mean Max                       0.998849
trainer/policy/mean Min                      -0.998374
trainer/policy/normal/std Mean                0.446228
trainer/policy/normal/std Std                 0.145271
trainer/policy/normal/std Max                 0.964206
trainer/policy/normal/std Min                 0.0714314
trainer/policy/normal/log_std Mean           -0.877764
trainer/policy/normal/log_std Std             0.416712
trainer/policy/normal/log_std Max            -0.03645
trainer/policy/normal/log_std Min            -2.63902
trainer/Alpha                                 0.132097
trainer/Alpha Loss                            0.528909
expl/num steps total                     280000
expl/num paths total                        280
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.6141
expl/Rewards Std                              1.19326
expl/Rewards Max                              7.85352
expl/Rewards Min                             -0.420797
expl/Returns Mean                          5614.1
expl/Returns Std                              0
expl/Returns Max                           5614.1
expl/Returns Min                           5614.1
expl/Actions Mean                             0.0690218
expl/Actions Std                              0.808782
expl/Actions Max                              0.999574
expl/Actions Min                             -0.99911
expl/Num Paths                                1
expl/Average Returns                       5614.1
expl/env_infos/final/reward_run Mean          6.77252
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.77252
expl/env_infos/final/reward_run Min           6.77252
expl/env_infos/initial/reward_run Mean       -0.13727
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.13727
expl/env_infos/initial/reward_run Min        -0.13727
expl/env_infos/reward_run Mean                6.00943
expl/env_infos/reward_run Std                 1.18733
expl/env_infos/reward_run Max                 8.37488
expl/env_infos/reward_run Min                -0.13727
expl/env_infos/final/reward_ctrl Mean        -0.380687
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.380687
expl/env_infos/final/reward_ctrl Min         -0.380687
expl/env_infos/initial/reward_ctrl Mean      -0.283527
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.283527
expl/env_infos/initial/reward_ctrl Min       -0.283527
expl/env_infos/reward_ctrl Mean              -0.395335
expl/env_infos/reward_ctrl Std                0.0943112
expl/env_infos/reward_ctrl Max               -0.0255395
expl/env_infos/reward_ctrl Min               -0.58804
eval/num steps total                          1.395e+06
eval/num paths total                       1395
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.81809
eval/Rewards Std                              1.26429
eval/Rewards Max                              8.41988
eval/Rewards Min                             -0.656465
eval/Returns Mean                          5818.09
eval/Returns Std                             50.7505
eval/Returns Max                           5868.69
eval/Returns Min                           5752.65
eval/Actions Mean                             0.071785
eval/Actions Std                              0.825897
eval/Actions Max                              0.996483
eval/Actions Min                             -0.996953
eval/Num Paths                                5
eval/Average Returns                       5818.09
eval/env_infos/final/reward_run Mean          6.03021
eval/env_infos/final/reward_run Std           0.614821
eval/env_infos/final/reward_run Max           7.08612
eval/env_infos/final/reward_run Min           5.38605
eval/env_infos/initial/reward_run Mean       -0.237159
eval/env_infos/initial/reward_run Std         0.0989952
eval/env_infos/initial/reward_run Max        -0.12213
eval/env_infos/initial/reward_run Min        -0.389436
eval/env_infos/reward_run Mean                6.23045
eval/env_infos/reward_run Std                 1.25471
eval/env_infos/reward_run Max                 8.92053
eval/env_infos/reward_run Min                -0.389436
eval/env_infos/final/reward_ctrl Mean        -0.412907
eval/env_infos/final/reward_ctrl Std          0.0642804
eval/env_infos/final/reward_ctrl Max         -0.33182
eval/env_infos/final/reward_ctrl Min         -0.506109
eval/env_infos/initial/reward_ctrl Mean      -0.265421
eval/env_infos/initial/reward_ctrl Std        0.0411786
eval/env_infos/initial/reward_ctrl Max       -0.210974
eval/env_infos/initial/reward_ctrl Min       -0.327003
eval/env_infos/reward_ctrl Mean              -0.412356
eval/env_infos/reward_ctrl Std                0.0942377
eval/env_infos/reward_ctrl Max               -0.0994407
eval/env_infos/reward_ctrl Min               -0.584736
time/data storing (s)                         0.00447761
time/evaluation sampling (s)                  2.00897
time/exploration sampling (s)                 0.526144
time/logging (s)                              0.0135207
time/sac training (s)                         7.37248
time/saving (s)                               0.00375518
time/training (s)                             3.4204e-05
time/epoch (s)                                9.92938
time/total (s)                             2966.03
Epoch                                       278
---------------------------------------  ---------------
2021-11-24 01:18:50.542005 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 279 finished
---------------------------------------  ---------------
epoch                                       279
replay_buffer/size                       281000
trainer/num train calls                  280000
trainer/QF1 Loss                              8.50042
trainer/QF2 Loss                             10.6938
trainer/Policy Loss                        -370.243
trainer/Q1 Predictions Mean                 370.922
trainer/Q1 Predictions Std                   85.6765
trainer/Q1 Predictions Max                  439.317
trainer/Q1 Predictions Min                   16.7367
trainer/Q2 Predictions Mean                 370.723
trainer/Q2 Predictions Std                   85.7133
trainer/Q2 Predictions Max                  439.61
trainer/Q2 Predictions Min                   16.16
trainer/Q Targets Mean                      371.158
trainer/Q Targets Std                        86.0232
trainer/Q Targets Max                       441.688
trainer/Q Targets Min                        16.3008
trainer/Log Pis Mean                          6.56974
trainer/Log Pis Std                           4.32547
trainer/Log Pis Max                          18.0712
trainer/Log Pis Min                          -7.03376
trainer/policy/mean Mean                      0.0706855
trainer/policy/mean Std                       0.793928
trainer/policy/mean Max                       0.998847
trainer/policy/mean Min                      -0.998606
trainer/policy/normal/std Mean                0.441709
trainer/policy/normal/std Std                 0.136196
trainer/policy/normal/std Max                 1.07546
trainer/policy/normal/std Min                 0.0686368
trainer/policy/normal/log_std Mean           -0.879431
trainer/policy/normal/log_std Std             0.387977
trainer/policy/normal/log_std Max             0.0727468
trainer/policy/normal/log_std Min            -2.67893
trainer/Alpha                                 0.130611
trainer/Alpha Loss                            1.15972
expl/num steps total                     281000
expl/num paths total                        281
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.68111
expl/Rewards Std                              1.25059
expl/Rewards Max                              7.8936
expl/Rewards Min                             -0.48835
expl/Returns Mean                          5681.11
expl/Returns Std                              0
expl/Returns Max                           5681.11
expl/Returns Min                           5681.11
expl/Actions Mean                             0.0936814
expl/Actions Std                              0.809397
expl/Actions Max                              0.999798
expl/Actions Min                             -0.998945
expl/Num Paths                                1
expl/Average Returns                       5681.11
expl/env_infos/final/reward_run Mean          7.79745
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.79745
expl/env_infos/final/reward_run Min           7.79745
expl/env_infos/initial/reward_run Mean       -0.197373
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.197373
expl/env_infos/initial/reward_run Min        -0.197373
expl/env_infos/reward_run Mean                6.07945
expl/env_infos/reward_run Std                 1.24202
expl/env_infos/reward_run Max                 8.41534
expl/env_infos/reward_run Min                -0.197373
expl/env_infos/final/reward_ctrl Mean        -0.383208
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.383208
expl/env_infos/final/reward_ctrl Min         -0.383208
expl/env_infos/initial/reward_ctrl Mean      -0.290977
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.290977
expl/env_infos/initial/reward_ctrl Min       -0.290977
expl/env_infos/reward_ctrl Mean              -0.398339
expl/env_infos/reward_ctrl Std                0.0923872
expl/env_infos/reward_ctrl Max               -0.0927593
expl/env_infos/reward_ctrl Min               -0.587936
eval/num steps total                          1.4e+06
eval/num paths total                       1400
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.89039
eval/Rewards Std                              1.2711
eval/Rewards Max                              8.55467
eval/Rewards Min                             -0.784234
eval/Returns Mean                          5890.39
eval/Returns Std                             84.4081
eval/Returns Max                           5983.95
eval/Returns Min                           5756.33
eval/Actions Mean                             0.0997962
eval/Actions Std                              0.82422
eval/Actions Max                              0.997483
eval/Actions Min                             -0.997772
eval/Num Paths                                5
eval/Average Returns                       5890.39
eval/env_infos/final/reward_run Mean          6.64853
eval/env_infos/final/reward_run Std           0.846965
eval/env_infos/final/reward_run Max           7.97076
eval/env_infos/final/reward_run Min           5.61013
eval/env_infos/initial/reward_run Mean       -0.291764
eval/env_infos/initial/reward_run Std         0.123557
eval/env_infos/initial/reward_run Max        -0.109497
eval/env_infos/initial/reward_run Min        -0.449749
eval/env_infos/reward_run Mean                6.30396
eval/env_infos/reward_run Std                 1.26267
eval/env_infos/reward_run Max                 9.07827
eval/env_infos/reward_run Min                -0.449749
eval/env_infos/final/reward_ctrl Mean        -0.443622
eval/env_infos/final/reward_ctrl Std          0.0418755
eval/env_infos/final/reward_ctrl Max         -0.363405
eval/env_infos/final/reward_ctrl Min         -0.47173
eval/env_infos/initial/reward_ctrl Mean      -0.283438
eval/env_infos/initial/reward_ctrl Std        0.053612
eval/env_infos/initial/reward_ctrl Max       -0.217838
eval/env_infos/initial/reward_ctrl Min       -0.375565
eval/env_infos/reward_ctrl Mean              -0.413579
eval/env_infos/reward_ctrl Std                0.0891858
eval/env_infos/reward_ctrl Max               -0.105878
eval/env_infos/reward_ctrl Min               -0.587396
time/data storing (s)                         0.00449705
time/evaluation sampling (s)                  2.01718
time/exploration sampling (s)                 0.534954
time/logging (s)                              0.0137155
time/sac training (s)                         7.39494
time/saving (s)                               0.00377376
time/training (s)                             3.4907e-05
time/epoch (s)                                9.96909
time/total (s)                             2976.28
Epoch                                       279
---------------------------------------  ---------------
2021-11-24 01:19:00.744362 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 280 finished
---------------------------------------  ---------------
epoch                                       280
replay_buffer/size                       282000
trainer/num train calls                  281000
trainer/QF1 Loss                              6.66742
trainer/QF2 Loss                              5.96843
trainer/Policy Loss                        -369.243
trainer/Q1 Predictions Mean                 369.984
trainer/Q1 Predictions Std                   91.0299
trainer/Q1 Predictions Max                  445.799
trainer/Q1 Predictions Min                   18.2284
trainer/Q2 Predictions Mean                 369.675
trainer/Q2 Predictions Std                   90.9344
trainer/Q2 Predictions Max                  445.383
trainer/Q2 Predictions Min                   18.8583
trainer/Q Targets Mean                      369.928
trainer/Q Targets Std                        91.0805
trainer/Q Targets Max                       443.596
trainer/Q Targets Min                        17.8249
trainer/Log Pis Mean                          6.01889
trainer/Log Pis Std                           4.28178
trainer/Log Pis Max                          16.4437
trainer/Log Pis Min                          -4.72953
trainer/policy/mean Mean                      0.058477
trainer/policy/mean Std                       0.777968
trainer/policy/mean Max                       0.994055
trainer/policy/mean Min                      -0.998071
trainer/policy/normal/std Mean                0.434896
trainer/policy/normal/std Std                 0.133221
trainer/policy/normal/std Max                 0.82107
trainer/policy/normal/std Min                 0.0684268
trainer/policy/normal/log_std Mean           -0.892685
trainer/policy/normal/log_std Std             0.377165
trainer/policy/normal/log_std Max            -0.197147
trainer/policy/normal/log_std Min            -2.68199
trainer/Alpha                                 0.131464
trainer/Alpha Loss                            0.0383376
expl/num steps total                     282000
expl/num paths total                        282
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.66821
expl/Rewards Std                              1.21108
expl/Rewards Max                              8.17189
expl/Rewards Min                             -0.507364
expl/Returns Mean                          5668.21
expl/Returns Std                              0
expl/Returns Max                           5668.21
expl/Returns Min                           5668.21
expl/Actions Mean                             0.0831432
expl/Actions Std                              0.805957
expl/Actions Max                              0.999697
expl/Actions Min                             -0.999127
expl/Num Paths                                1
expl/Average Returns                       5668.21
expl/env_infos/final/reward_run Mean          5.8472
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.8472
expl/env_infos/final/reward_run Min           5.8472
expl/env_infos/initial/reward_run Mean       -0.204638
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.204638
expl/env_infos/initial/reward_run Min        -0.204638
expl/env_infos/reward_run Mean                6.0621
expl/env_infos/reward_run Std                 1.20482
expl/env_infos/reward_run Max                 8.68031
expl/env_infos/reward_run Min                -0.204638
expl/env_infos/final/reward_ctrl Mean        -0.483812
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.483812
expl/env_infos/final/reward_ctrl Min         -0.483812
expl/env_infos/initial/reward_ctrl Mean      -0.302726
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.302726
expl/env_infos/initial/reward_ctrl Min       -0.302726
expl/env_infos/reward_ctrl Mean              -0.393887
expl/env_infos/reward_ctrl Std                0.0902798
expl/env_infos/reward_ctrl Max               -0.119475
expl/env_infos/reward_ctrl Min               -0.581339
eval/num steps total                          1.405e+06
eval/num paths total                       1405
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.8346
eval/Rewards Std                              1.24699
eval/Rewards Max                              8.47898
eval/Rewards Min                             -0.599045
eval/Returns Mean                          5834.6
eval/Returns Std                             64.3421
eval/Returns Max                           5919.11
eval/Returns Min                           5734.22
eval/Actions Mean                             0.0783004
eval/Actions Std                              0.820423
eval/Actions Max                              0.997778
eval/Actions Min                             -0.996527
eval/Num Paths                                5
eval/Average Returns                       5834.6
eval/env_infos/final/reward_run Mean          6.52144
eval/env_infos/final/reward_run Std           0.880203
eval/env_infos/final/reward_run Max           7.60412
eval/env_infos/final/reward_run Min           5.576
eval/env_infos/initial/reward_run Mean       -0.187127
eval/env_infos/initial/reward_run Std         0.088872
eval/env_infos/initial/reward_run Max        -0.0435714
eval/env_infos/initial/reward_run Min        -0.300131
eval/env_infos/reward_run Mean                6.24213
eval/env_infos/reward_run Std                 1.2395
eval/env_infos/reward_run Max                 8.96721
eval/env_infos/reward_run Min                -0.300131
eval/env_infos/final/reward_ctrl Mean        -0.414118
eval/env_infos/final/reward_ctrl Std          0.0714518
eval/env_infos/final/reward_ctrl Max         -0.321406
eval/env_infos/final/reward_ctrl Min         -0.499525
eval/env_infos/initial/reward_ctrl Mean      -0.294963
eval/env_infos/initial/reward_ctrl Std        0.0495125
eval/env_infos/initial/reward_ctrl Max       -0.222733
eval/env_infos/initial/reward_ctrl Min       -0.363339
eval/env_infos/reward_ctrl Mean              -0.407535
eval/env_infos/reward_ctrl Std                0.0876555
eval/env_infos/reward_ctrl Max               -0.0976056
eval/env_infos/reward_ctrl Min               -0.581848
time/data storing (s)                         0.00452539
time/evaluation sampling (s)                  2.00375
time/exploration sampling (s)                 0.52065
time/logging (s)                              0.0136454
time/sac training (s)                         7.36418
time/saving (s)                               0.00374578
time/training (s)                             3.4014e-05
time/epoch (s)                                9.91054
time/total (s)                             2986.47
Epoch                                       280
---------------------------------------  ---------------
2021-11-24 01:19:10.987613 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 281 finished
---------------------------------------  ---------------
epoch                                       281
replay_buffer/size                       283000
trainer/num train calls                  282000
trainer/QF1 Loss                              5.30173
trainer/QF2 Loss                              4.804
trainer/Policy Loss                        -369.465
trainer/Q1 Predictions Mean                 370
trainer/Q1 Predictions Std                   92.9589
trainer/Q1 Predictions Max                  442.003
trainer/Q1 Predictions Min                   16.8695
trainer/Q2 Predictions Mean                 370.126
trainer/Q2 Predictions Std                   93.0112
trainer/Q2 Predictions Max                  441.707
trainer/Q2 Predictions Min                   17.3794
trainer/Q Targets Mean                      370.234
trainer/Q Targets Std                        93.2347
trainer/Q Targets Max                       442.735
trainer/Q Targets Min                        16.8438
trainer/Log Pis Mean                          6.19629
trainer/Log Pis Std                           4.4535
trainer/Log Pis Max                          17.5602
trainer/Log Pis Min                          -4.30239
trainer/policy/mean Mean                      0.0892258
trainer/policy/mean Std                       0.772845
trainer/policy/mean Max                       0.999408
trainer/policy/mean Min                      -0.999339
trainer/policy/normal/std Mean                0.43043
trainer/policy/normal/std Std                 0.145063
trainer/policy/normal/std Max                 1.17402
trainer/policy/normal/std Min                 0.075452
trainer/policy/normal/log_std Mean           -0.915635
trainer/policy/normal/log_std Std             0.41633
trainer/policy/normal/log_std Max             0.160431
trainer/policy/normal/log_std Min            -2.58426
trainer/Alpha                                 0.13073
trainer/Alpha Loss                            0.399379
expl/num steps total                     283000
expl/num paths total                        283
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.40629
expl/Rewards Std                              1.1891
expl/Rewards Max                              7.50762
expl/Rewards Min                             -0.475304
expl/Returns Mean                          5406.29
expl/Returns Std                              0
expl/Returns Max                           5406.29
expl/Returns Min                           5406.29
expl/Actions Mean                             0.0833336
expl/Actions Std                              0.797115
expl/Actions Max                              0.999167
expl/Actions Min                             -0.999359
expl/Num Paths                                1
expl/Average Returns                       5406.29
expl/env_infos/final/reward_run Mean          6.13068
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.13068
expl/env_infos/final/reward_run Min           6.13068
expl/env_infos/initial/reward_run Mean       -0.157811
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.157811
expl/env_infos/initial/reward_run Min        -0.157811
expl/env_infos/reward_run Mean                5.79169
expl/env_infos/reward_run Std                 1.18315
expl/env_infos/reward_run Max                 7.97988
expl/env_infos/reward_run Min                -0.157811
expl/env_infos/final/reward_ctrl Mean        -0.125581
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.125581
expl/env_infos/final/reward_ctrl Min         -0.125581
expl/env_infos/initial/reward_ctrl Mean      -0.317493
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.317493
expl/env_infos/initial/reward_ctrl Min       -0.317493
expl/env_infos/reward_ctrl Mean              -0.385402
expl/env_infos/reward_ctrl Std                0.091614
expl/env_infos/reward_ctrl Max               -0.0438552
expl/env_infos/reward_ctrl Min               -0.565104
eval/num steps total                          1.41e+06
eval/num paths total                       1410
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.77159
eval/Rewards Std                              1.25855
eval/Rewards Max                              8.18997
eval/Rewards Min                             -0.766916
eval/Returns Mean                          5771.59
eval/Returns Std                             30.5337
eval/Returns Max                           5804.78
eval/Returns Min                           5729.68
eval/Actions Mean                             0.0708452
eval/Actions Std                              0.817102
eval/Actions Max                              0.998783
eval/Actions Min                             -0.998262
eval/Num Paths                                5
eval/Average Returns                       5771.59
eval/env_infos/final/reward_run Mean          6.69257
eval/env_infos/final/reward_run Std           0.373786
eval/env_infos/final/reward_run Max           7.41503
eval/env_infos/final/reward_run Min           6.33619
eval/env_infos/initial/reward_run Mean       -0.19263
eval/env_infos/initial/reward_run Std         0.0974176
eval/env_infos/initial/reward_run Max        -0.00687954
eval/env_infos/initial/reward_run Min        -0.277208
eval/env_infos/reward_run Mean                6.1752
eval/env_infos/reward_run Std                 1.25758
eval/env_infos/reward_run Max                 8.67471
eval/env_infos/reward_run Min                -0.454014
eval/env_infos/final/reward_ctrl Mean        -0.449164
eval/env_infos/final/reward_ctrl Std          0.035283
eval/env_infos/final/reward_ctrl Max         -0.403754
eval/env_infos/final/reward_ctrl Min         -0.497902
eval/env_infos/initial/reward_ctrl Mean      -0.216923
eval/env_infos/initial/reward_ctrl Std        0.071654
eval/env_infos/initial/reward_ctrl Max       -0.105132
eval/env_infos/initial/reward_ctrl Min       -0.330416
eval/env_infos/reward_ctrl Mean              -0.403605
eval/env_infos/reward_ctrl Std                0.0875213
eval/env_infos/reward_ctrl Max               -0.08882
eval/env_infos/reward_ctrl Min               -0.583442
time/data storing (s)                         0.00443139
time/evaluation sampling (s)                  1.99719
time/exploration sampling (s)                 0.553183
time/logging (s)                              0.0139572
time/sac training (s)                         7.378
time/saving (s)                               0.00375412
time/training (s)                             3.3978e-05
time/epoch (s)                                9.95055
time/total (s)                             2996.7
Epoch                                       281
---------------------------------------  ---------------
2021-11-24 01:19:21.330385 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 282 finished
---------------------------------------  ---------------
epoch                                       282
replay_buffer/size                       284000
trainer/num train calls                  283000
trainer/QF1 Loss                              5.08228
trainer/QF2 Loss                              4.44593
trainer/Policy Loss                        -368.767
trainer/Q1 Predictions Mean                 369.239
trainer/Q1 Predictions Std                   97.1491
trainer/Q1 Predictions Max                  437.658
trainer/Q1 Predictions Min                   17.4022
trainer/Q2 Predictions Mean                 369.603
trainer/Q2 Predictions Std                   97.2155
trainer/Q2 Predictions Max                  438.423
trainer/Q2 Predictions Min                   17.8092
trainer/Q Targets Mean                      369.933
trainer/Q Targets Std                        97.2466
trainer/Q Targets Max                       439.05
trainer/Q Targets Min                        17.7796
trainer/Log Pis Mean                          5.97899
trainer/Log Pis Std                           4.58214
trainer/Log Pis Max                          20.7059
trainer/Log Pis Min                          -6.51454
trainer/policy/mean Mean                      0.0944493
trainer/policy/mean Std                       0.778127
trainer/policy/mean Max                       0.995068
trainer/policy/mean Min                      -0.997942
trainer/policy/normal/std Mean                0.445265
trainer/policy/normal/std Std                 0.149453
trainer/policy/normal/std Max                 0.99701
trainer/policy/normal/std Min                 0.0668262
trainer/policy/normal/log_std Mean           -0.881577
trainer/policy/normal/log_std Std             0.416543
trainer/policy/normal/log_std Max            -0.00299431
trainer/policy/normal/log_std Min            -2.70566
trainer/Alpha                                 0.130685
trainer/Alpha Loss                           -0.0427584
expl/num steps total                     284000
expl/num paths total                        284
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.52646
expl/Rewards Std                              1.25997
expl/Rewards Max                              8.15724
expl/Rewards Min                             -0.621503
expl/Returns Mean                          5526.46
expl/Returns Std                              0
expl/Returns Max                           5526.46
expl/Returns Min                           5526.46
expl/Actions Mean                             0.117976
expl/Actions Std                              0.80483
expl/Actions Max                              0.999609
expl/Actions Min                             -0.999591
expl/Num Paths                                1
expl/Average Returns                       5526.46
expl/env_infos/final/reward_run Mean          5.8246
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.8246
expl/env_infos/final/reward_run Min           5.8246
expl/env_infos/initial/reward_run Mean       -0.236718
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.236718
expl/env_infos/initial/reward_run Min        -0.236718
expl/env_infos/reward_run Mean                5.92346
expl/env_infos/reward_run Std                 1.24503
expl/env_infos/reward_run Max                 8.62124
expl/env_infos/reward_run Min                -0.236718
expl/env_infos/final/reward_ctrl Mean        -0.411133
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.411133
expl/env_infos/final/reward_ctrl Min         -0.411133
expl/env_infos/initial/reward_ctrl Mean      -0.384786
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.384786
expl/env_infos/initial/reward_ctrl Min       -0.384786
expl/env_infos/reward_ctrl Mean              -0.397002
expl/env_infos/reward_ctrl Std                0.0971929
expl/env_infos/reward_ctrl Max               -0.028806
expl/env_infos/reward_ctrl Min               -0.583731
eval/num steps total                          1.415e+06
eval/num paths total                       1415
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.78243
eval/Rewards Std                              1.27511
eval/Rewards Max                              8.21195
eval/Rewards Min                             -0.554591
eval/Returns Mean                          5782.43
eval/Returns Std                             73.443
eval/Returns Max                           5885.85
eval/Returns Min                           5670.66
eval/Actions Mean                             0.13021
eval/Actions Std                              0.81725
eval/Actions Max                              0.997584
eval/Actions Min                             -0.997775
eval/Num Paths                                5
eval/Average Returns                       5782.43
eval/env_infos/final/reward_run Mean          6.99721
eval/env_infos/final/reward_run Std           0.830189
eval/env_infos/final/reward_run Max           8.10815
eval/env_infos/final/reward_run Min           6.02525
eval/env_infos/initial/reward_run Mean       -0.207885
eval/env_infos/initial/reward_run Std         0.0969052
eval/env_infos/initial/reward_run Max        -0.0900363
eval/env_infos/initial/reward_run Min        -0.322477
eval/env_infos/reward_run Mean                6.19334
eval/env_infos/reward_run Std                 1.25527
eval/env_infos/reward_run Max                 8.75125
eval/env_infos/reward_run Min                -0.322477
eval/env_infos/final/reward_ctrl Mean        -0.391749
eval/env_infos/final/reward_ctrl Std          0.0586696
eval/env_infos/final/reward_ctrl Max         -0.292753
eval/env_infos/final/reward_ctrl Min         -0.475597
eval/env_infos/initial/reward_ctrl Mean      -0.24734
eval/env_infos/initial/reward_ctrl Std        0.0182888
eval/env_infos/initial/reward_ctrl Max       -0.217761
eval/env_infos/initial/reward_ctrl Min       -0.270219
eval/env_infos/reward_ctrl Mean              -0.410911
eval/env_infos/reward_ctrl Std                0.0930444
eval/env_infos/reward_ctrl Max               -0.0941866
eval/env_infos/reward_ctrl Min               -0.584922
time/data storing (s)                         0.0045054
time/evaluation sampling (s)                  2.01569
time/exploration sampling (s)                 0.534009
time/logging (s)                              0.0135537
time/sac training (s)                         7.47743
time/saving (s)                               0.00374116
time/training (s)                             4.0984e-05
time/epoch (s)                               10.049
time/total (s)                             3007.03
Epoch                                       282
---------------------------------------  ---------------
2021-11-24 01:19:31.559062 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 283 finished
---------------------------------------  ---------------
epoch                                       283
replay_buffer/size                       285000
trainer/num train calls                  284000
trainer/QF1 Loss                              7.43263
trainer/QF2 Loss                              7.40651
trainer/Policy Loss                        -371.558
trainer/Q1 Predictions Mean                 372.086
trainer/Q1 Predictions Std                   86.0743
trainer/Q1 Predictions Max                  439.088
trainer/Q1 Predictions Min                   18.0438
trainer/Q2 Predictions Mean                 371.83
trainer/Q2 Predictions Std                   86.2806
trainer/Q2 Predictions Max                  438.412
trainer/Q2 Predictions Min                   18.0279
trainer/Q Targets Mean                      372.82
trainer/Q Targets Std                        86.4263
trainer/Q Targets Max                       442.197
trainer/Q Targets Min                        17.9509
trainer/Log Pis Mean                          6.08266
trainer/Log Pis Std                           4.14327
trainer/Log Pis Max                          17.0204
trainer/Log Pis Min                          -5.87879
trainer/policy/mean Mean                      0.0754261
trainer/policy/mean Std                       0.775861
trainer/policy/mean Max                       0.994423
trainer/policy/mean Min                      -0.997494
trainer/policy/normal/std Mean                0.42432
trainer/policy/normal/std Std                 0.143208
trainer/policy/normal/std Max                 1.07345
trainer/policy/normal/std Min                 0.0769071
trainer/policy/normal/log_std Mean           -0.931838
trainer/policy/normal/log_std Std             0.423751
trainer/policy/normal/log_std Max             0.070876
trainer/policy/normal/log_std Min            -2.56516
trainer/Alpha                                 0.130239
trainer/Alpha Loss                            0.168499
expl/num steps total                     285000
expl/num paths total                        285
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.62161
expl/Rewards Std                              1.20446
expl/Rewards Max                              7.78364
expl/Rewards Min                             -0.439416
expl/Returns Mean                          5621.61
expl/Returns Std                              0
expl/Returns Max                           5621.61
expl/Returns Min                           5621.61
expl/Actions Mean                             0.0868035
expl/Actions Std                              0.803742
expl/Actions Max                              0.999336
expl/Actions Min                             -0.998715
expl/Num Paths                                1
expl/Average Returns                       5621.61
expl/env_infos/final/reward_run Mean          6.25665
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.25665
expl/env_infos/final/reward_run Min           6.25665
expl/env_infos/initial/reward_run Mean        0.0930394
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0930394
expl/env_infos/initial/reward_run Min         0.0930394
expl/env_infos/reward_run Mean                6.01373
expl/env_infos/reward_run Std                 1.20227
expl/env_infos/reward_run Max                 8.26152
expl/env_infos/reward_run Min                 0.0633357
expl/env_infos/final/reward_ctrl Mean        -0.329694
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.329694
expl/env_infos/final/reward_ctrl Min         -0.329694
expl/env_infos/initial/reward_ctrl Mean      -0.355798
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.355798
expl/env_infos/initial/reward_ctrl Min       -0.355798
expl/env_infos/reward_ctrl Mean              -0.392122
expl/env_infos/reward_ctrl Std                0.0907641
expl/env_infos/reward_ctrl Max               -0.068919
expl/env_infos/reward_ctrl Min               -0.577133
eval/num steps total                          1.42e+06
eval/num paths total                       1420
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.84805
eval/Rewards Std                              1.24164
eval/Rewards Max                              8.54296
eval/Rewards Min                             -0.655745
eval/Returns Mean                          5848.05
eval/Returns Std                             55.3782
eval/Returns Max                           5905.57
eval/Returns Min                           5751.87
eval/Actions Mean                             0.0911554
eval/Actions Std                              0.816109
eval/Actions Max                              0.996343
eval/Actions Min                             -0.995907
eval/Num Paths                                5
eval/Average Returns                       5848.05
eval/env_infos/final/reward_run Mean          6.75249
eval/env_infos/final/reward_run Std           0.826605
eval/env_infos/final/reward_run Max           7.61573
eval/env_infos/final/reward_run Min           5.71875
eval/env_infos/initial/reward_run Mean       -0.122877
eval/env_infos/initial/reward_run Std         0.0580731
eval/env_infos/initial/reward_run Max        -0.0509196
eval/env_infos/initial/reward_run Min        -0.223933
eval/env_infos/reward_run Mean                6.25265
eval/env_infos/reward_run Std                 1.23766
eval/env_infos/reward_run Max                 9.04285
eval/env_infos/reward_run Min                -0.238479
eval/env_infos/final/reward_ctrl Mean        -0.446398
eval/env_infos/final/reward_ctrl Std          0.0349558
eval/env_infos/final/reward_ctrl Max         -0.400788
eval/env_infos/final/reward_ctrl Min         -0.49748
eval/env_infos/initial/reward_ctrl Mean      -0.287701
eval/env_infos/initial/reward_ctrl Std        0.068763
eval/env_infos/initial/reward_ctrl Max       -0.233197
eval/env_infos/initial/reward_ctrl Min       -0.420942
eval/env_infos/reward_ctrl Mean              -0.404606
eval/env_infos/reward_ctrl Std                0.0894363
eval/env_infos/reward_ctrl Max               -0.105548
eval/env_infos/reward_ctrl Min               -0.580274
time/data storing (s)                         0.00445608
time/evaluation sampling (s)                  2.00443
time/exploration sampling (s)                 0.530789
time/logging (s)                              0.0135949
time/sac training (s)                         7.37927
time/saving (s)                               0.00370896
time/training (s)                             3.5194e-05
time/epoch (s)                                9.93628
time/total (s)                             3017.25
Epoch                                       283
---------------------------------------  ---------------
2021-11-24 01:19:41.795226 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 284 finished
---------------------------------------  ---------------
epoch                                       284
replay_buffer/size                       286000
trainer/num train calls                  285000
trainer/QF1 Loss                              6.73248
trainer/QF2 Loss                              5.53922
trainer/Policy Loss                        -370.655
trainer/Q1 Predictions Mean                 370.979
trainer/Q1 Predictions Std                   93.7997
trainer/Q1 Predictions Max                  448.049
trainer/Q1 Predictions Min                   18.2146
trainer/Q2 Predictions Mean                 371.396
trainer/Q2 Predictions Std                   93.8521
trainer/Q2 Predictions Max                  445.411
trainer/Q2 Predictions Min                   18.3809
trainer/Q Targets Mean                      371.535
trainer/Q Targets Std                        93.9792
trainer/Q Targets Max                       447.56
trainer/Q Targets Min                        18.7483
trainer/Log Pis Mean                          5.83206
trainer/Log Pis Std                           4.58603
trainer/Log Pis Max                          20.1619
trainer/Log Pis Min                          -6.16341
trainer/policy/mean Mean                      0.103045
trainer/policy/mean Std                       0.770288
trainer/policy/mean Max                       0.99578
trainer/policy/mean Min                      -0.997568
trainer/policy/normal/std Mean                0.443634
trainer/policy/normal/std Std                 0.143273
trainer/policy/normal/std Max                 0.941286
trainer/policy/normal/std Min                 0.0765411
trainer/policy/normal/log_std Mean           -0.879268
trainer/policy/normal/log_std Std             0.396552
trainer/policy/normal/log_std Max            -0.0605084
trainer/policy/normal/log_std Min            -2.56993
trainer/Alpha                                 0.132956
trainer/Alpha Loss                           -0.33885
expl/num steps total                     286000
expl/num paths total                        286
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.67324
expl/Rewards Std                              1.25795
expl/Rewards Max                              7.98345
expl/Rewards Min                             -0.388516
expl/Returns Mean                          5673.24
expl/Returns Std                              0
expl/Returns Max                           5673.24
expl/Returns Min                           5673.24
expl/Actions Mean                             0.101111
expl/Actions Std                              0.806099
expl/Actions Max                              0.999573
expl/Actions Min                             -0.999328
expl/Num Paths                                1
expl/Average Returns                       5673.24
expl/env_infos/final/reward_run Mean          5.15803
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.15803
expl/env_infos/final/reward_run Min           5.15803
expl/env_infos/initial/reward_run Mean        0.168738
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.168738
expl/env_infos/initial/reward_run Min         0.168738
expl/env_infos/reward_run Mean                6.06925
expl/env_infos/reward_run Std                 1.25741
expl/env_infos/reward_run Max                 8.47695
expl/env_infos/reward_run Min                 0.0507826
expl/env_infos/final/reward_ctrl Mean        -0.492208
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.492208
expl/env_infos/final/reward_ctrl Min         -0.492208
expl/env_infos/initial/reward_ctrl Mean      -0.0917716
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0917716
expl/env_infos/initial/reward_ctrl Min       -0.0917716
expl/env_infos/reward_ctrl Mean              -0.396011
expl/env_infos/reward_ctrl Std                0.0916641
expl/env_infos/reward_ctrl Max               -0.0917716
expl/env_infos/reward_ctrl Min               -0.576577
eval/num steps total                          1.425e+06
eval/num paths total                       1425
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.86261
eval/Rewards Std                              1.26354
eval/Rewards Max                              8.52349
eval/Rewards Min                             -0.5912
eval/Returns Mean                          5862.61
eval/Returns Std                             49.6108
eval/Returns Max                           5956.14
eval/Returns Min                           5824.06
eval/Actions Mean                             0.109328
eval/Actions Std                              0.821663
eval/Actions Max                              0.996571
eval/Actions Min                             -0.997128
eval/Num Paths                                5
eval/Average Returns                       5862.61
eval/env_infos/final/reward_run Mean          7.14527
eval/env_infos/final/reward_run Std           1.01833
eval/env_infos/final/reward_run Max           8.859
eval/env_infos/final/reward_run Min           5.87926
eval/env_infos/initial/reward_run Mean       -0.157917
eval/env_infos/initial/reward_run Std         0.140757
eval/env_infos/initial/reward_run Max         0.00623149
eval/env_infos/initial/reward_run Min        -0.326592
eval/env_infos/reward_run Mean                6.27486
eval/env_infos/reward_run Std                 1.25917
eval/env_infos/reward_run Max                 9.0032
eval/env_infos/reward_run Min                -0.326592
eval/env_infos/final/reward_ctrl Mean        -0.47163
eval/env_infos/final/reward_ctrl Std          0.0528814
eval/env_infos/final/reward_ctrl Max         -0.409455
eval/env_infos/final/reward_ctrl Min         -0.562893
eval/env_infos/initial/reward_ctrl Mean      -0.225455
eval/env_infos/initial/reward_ctrl Std        0.0341747
eval/env_infos/initial/reward_ctrl Max       -0.194456
eval/env_infos/initial/reward_ctrl Min       -0.269727
eval/env_infos/reward_ctrl Mean              -0.41225
eval/env_infos/reward_ctrl Std                0.0932713
eval/env_infos/reward_ctrl Max               -0.0949842
eval/env_infos/reward_ctrl Min               -0.580058
time/data storing (s)                         0.00449825
time/evaluation sampling (s)                  1.99209
time/exploration sampling (s)                 0.5372
time/logging (s)                              0.0135884
time/sac training (s)                         7.39083
time/saving (s)                               0.00372707
time/training (s)                             3.4788e-05
time/epoch (s)                                9.94196
time/total (s)                             3027.47
Epoch                                       284
---------------------------------------  ---------------
2021-11-24 01:19:52.020157 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 285 finished
---------------------------------------  ---------------
epoch                                       285
replay_buffer/size                       287000
trainer/num train calls                  286000
trainer/QF1 Loss                              5.32037
trainer/QF2 Loss                              5.47321
trainer/Policy Loss                        -365.182
trainer/Q1 Predictions Mean                 365.817
trainer/Q1 Predictions Std                  109.136
trainer/Q1 Predictions Max                  450.441
trainer/Q1 Predictions Min                   16.9491
trainer/Q2 Predictions Mean                 365.792
trainer/Q2 Predictions Std                  109.192
trainer/Q2 Predictions Max                  450.027
trainer/Q2 Predictions Min                   16.7986
trainer/Q Targets Mean                      365.523
trainer/Q Targets Std                       109.215
trainer/Q Targets Max                       451.02
trainer/Q Targets Min                        16.7355
trainer/Log Pis Mean                          5.91764
trainer/Log Pis Std                           4.89038
trainer/Log Pis Max                          18.5343
trainer/Log Pis Min                          -6.51667
trainer/policy/mean Mean                      0.0824116
trainer/policy/mean Std                       0.776637
trainer/policy/mean Max                       0.994254
trainer/policy/mean Min                      -0.998102
trainer/policy/normal/std Mean                0.448412
trainer/policy/normal/std Std                 0.149184
trainer/policy/normal/std Max                 0.89751
trainer/policy/normal/std Min                 0.0702781
trainer/policy/normal/log_std Mean           -0.872907
trainer/policy/normal/log_std Std             0.410584
trainer/policy/normal/log_std Max            -0.108131
trainer/policy/normal/log_std Min            -2.6553
trainer/Alpha                                 0.133919
trainer/Alpha Loss                           -0.165585
expl/num steps total                     287000
expl/num paths total                        287
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.48181
expl/Rewards Std                              1.2172
expl/Rewards Max                              7.7495
expl/Rewards Min                             -0.661527
expl/Returns Mean                          5481.81
expl/Returns Std                              0
expl/Returns Max                           5481.81
expl/Returns Min                           5481.81
expl/Actions Mean                             0.0934655
expl/Actions Std                              0.799305
expl/Actions Max                              0.999278
expl/Actions Min                             -0.999701
expl/Num Paths                                1
expl/Average Returns                       5481.81
expl/env_infos/final/reward_run Mean          6.56041
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.56041
expl/env_infos/final/reward_run Min           6.56041
expl/env_infos/initial/reward_run Mean       -0.361744
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.361744
expl/env_infos/initial/reward_run Min        -0.361744
expl/env_infos/reward_run Mean                5.87038
expl/env_infos/reward_run Std                 1.21224
expl/env_infos/reward_run Max                 8.19266
expl/env_infos/reward_run Min                -0.361744
expl/env_infos/final/reward_ctrl Mean        -0.378259
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.378259
expl/env_infos/final/reward_ctrl Min         -0.378259
expl/env_infos/initial/reward_ctrl Mean      -0.299783
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.299783
expl/env_infos/initial/reward_ctrl Min       -0.299783
expl/env_infos/reward_ctrl Mean              -0.388575
expl/env_infos/reward_ctrl Std                0.0961248
expl/env_infos/reward_ctrl Max               -0.0697797
expl/env_infos/reward_ctrl Min               -0.587126
eval/num steps total                          1.43e+06
eval/num paths total                       1430
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.8588
eval/Rewards Std                              1.27432
eval/Rewards Max                              8.35439
eval/Rewards Min                             -0.686552
eval/Returns Mean                          5858.8
eval/Returns Std                             77
eval/Returns Max                           5949.76
eval/Returns Min                           5717.81
eval/Actions Mean                             0.102854
eval/Actions Std                              0.818415
eval/Actions Max                              0.996564
eval/Actions Min                             -0.993043
eval/Num Paths                                5
eval/Average Returns                       5858.8
eval/env_infos/final/reward_run Mean          6.0741
eval/env_infos/final/reward_run Std           0.156242
eval/env_infos/final/reward_run Max           6.27406
eval/env_infos/final/reward_run Min           5.85804
eval/env_infos/initial/reward_run Mean       -0.268248
eval/env_infos/initial/reward_run Std         0.0965729
eval/env_infos/initial/reward_run Max        -0.165364
eval/env_infos/initial/reward_run Min        -0.424377
eval/env_infos/reward_run Mean                6.26703
eval/env_infos/reward_run Std                 1.26805
eval/env_infos/reward_run Max                 8.85565
eval/env_infos/reward_run Min                -0.424377
eval/env_infos/final/reward_ctrl Mean        -0.397753
eval/env_infos/final/reward_ctrl Std          0.0718854
eval/env_infos/final/reward_ctrl Max         -0.294367
eval/env_infos/final/reward_ctrl Min         -0.512931
eval/env_infos/initial/reward_ctrl Mean      -0.313138
eval/env_infos/initial/reward_ctrl Std        0.0591132
eval/env_infos/initial/reward_ctrl Max       -0.202427
eval/env_infos/initial/reward_ctrl Min       -0.366435
eval/env_infos/reward_ctrl Mean              -0.408229
eval/env_infos/reward_ctrl Std                0.0935815
eval/env_infos/reward_ctrl Max               -0.0941356
eval/env_infos/reward_ctrl Min               -0.583111
time/data storing (s)                         0.00454476
time/evaluation sampling (s)                  1.98238
time/exploration sampling (s)                 0.535073
time/logging (s)                              0.0135466
time/sac training (s)                         7.39244
time/saving (s)                               0.0037563
time/training (s)                             3.3818e-05
time/epoch (s)                                9.93178
time/total (s)                             3037.68
Epoch                                       285
---------------------------------------  ---------------
2021-11-24 01:20:02.256159 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 286 finished
---------------------------------------  ----------------
epoch                                       286
replay_buffer/size                       288000
trainer/num train calls                  287000
trainer/QF1 Loss                              6.64552
trainer/QF2 Loss                              6.16171
trainer/Policy Loss                        -373.946
trainer/Q1 Predictions Mean                 374.383
trainer/Q1 Predictions Std                   81.4704
trainer/Q1 Predictions Max                  441.174
trainer/Q1 Predictions Min                   16.1523
trainer/Q2 Predictions Mean                 374.26
trainer/Q2 Predictions Std                   81.408
trainer/Q2 Predictions Max                  440.987
trainer/Q2 Predictions Min                   15.6509
trainer/Q Targets Mean                      374.357
trainer/Q Targets Std                        81.4943
trainer/Q Targets Max                       440.883
trainer/Q Targets Min                        15.4903
trainer/Log Pis Mean                          5.69145
trainer/Log Pis Std                           4.40642
trainer/Log Pis Max                          18.2103
trainer/Log Pis Min                          -8.23874
trainer/policy/mean Mean                      0.0912014
trainer/policy/mean Std                       0.760037
trainer/policy/mean Max                       0.998676
trainer/policy/mean Min                      -0.998984
trainer/policy/normal/std Mean                0.431515
trainer/policy/normal/std Std                 0.141128
trainer/policy/normal/std Max                 1.06279
trainer/policy/normal/std Min                 0.066823
trainer/policy/normal/log_std Mean           -0.908797
trainer/policy/normal/log_std Std             0.402231
trainer/policy/normal/log_std Max             0.0608979
trainer/policy/normal/log_std Min            -2.70571
trainer/Alpha                                 0.13024
trainer/Alpha Loss                           -0.628949
expl/num steps total                     288000
expl/num paths total                        288
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.57132
expl/Rewards Std                              1.2274
expl/Rewards Max                              8.00971
expl/Rewards Min                             -0.290162
expl/Returns Mean                          5571.32
expl/Returns Std                              0
expl/Returns Max                           5571.32
expl/Returns Min                           5571.32
expl/Actions Mean                             0.101835
expl/Actions Std                              0.808032
expl/Actions Max                              0.999582
expl/Actions Min                             -0.999718
expl/Num Paths                                1
expl/Average Returns                       5571.32
expl/env_infos/final/reward_run Mean          7.04499
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.04499
expl/env_infos/final/reward_run Min           7.04499
expl/env_infos/initial/reward_run Mean       -0.0984045
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0984045
expl/env_infos/initial/reward_run Min        -0.0984045
expl/env_infos/reward_run Mean                5.96929
expl/env_infos/reward_run Std                 1.22118
expl/env_infos/reward_run Max                 8.47478
expl/env_infos/reward_run Min                -0.0984045
expl/env_infos/final/reward_ctrl Mean        -0.370992
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.370992
expl/env_infos/final/reward_ctrl Min         -0.370992
expl/env_infos/initial/reward_ctrl Mean      -0.191758
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.191758
expl/env_infos/initial/reward_ctrl Min       -0.191758
expl/env_infos/reward_ctrl Mean              -0.397971
expl/env_infos/reward_ctrl Std                0.0913799
expl/env_infos/reward_ctrl Max               -0.111244
expl/env_infos/reward_ctrl Min               -0.575245
eval/num steps total                          1.435e+06
eval/num paths total                       1435
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.92252
eval/Rewards Std                              1.27398
eval/Rewards Max                              8.37073
eval/Rewards Min                             -0.730649
eval/Returns Mean                          5922.52
eval/Returns Std                             60.9774
eval/Returns Max                           6035.5
eval/Returns Min                           5852.07
eval/Actions Mean                             0.111083
eval/Actions Std                              0.823882
eval/Actions Max                              0.998075
eval/Actions Min                             -0.998089
eval/Num Paths                                5
eval/Average Returns                       5922.52
eval/env_infos/final/reward_run Mean          6.35032
eval/env_infos/final/reward_run Std           0.470415
eval/env_infos/final/reward_run Max           7.03763
eval/env_infos/final/reward_run Min           5.77653
eval/env_infos/initial/reward_run Mean       -0.094686
eval/env_infos/initial/reward_run Std         0.138838
eval/env_infos/initial/reward_run Max         0.000242304
eval/env_infos/initial/reward_run Min        -0.366766
eval/env_infos/reward_run Mean                6.3372
eval/env_infos/reward_run Std                 1.26295
eval/env_infos/reward_run Max                 8.89885
eval/env_infos/reward_run Min                -0.439567
eval/env_infos/final/reward_ctrl Mean        -0.43616
eval/env_infos/final/reward_ctrl Std          0.066676
eval/env_infos/final/reward_ctrl Max         -0.351141
eval/env_infos/final/reward_ctrl Min         -0.522069
eval/env_infos/initial/reward_ctrl Mean      -0.25065
eval/env_infos/initial/reward_ctrl Std        0.0387606
eval/env_infos/initial/reward_ctrl Max       -0.197956
eval/env_infos/initial/reward_ctrl Min       -0.315947
eval/env_infos/reward_ctrl Mean              -0.414672
eval/env_infos/reward_ctrl Std                0.0903913
eval/env_infos/reward_ctrl Max               -0.110206
eval/env_infos/reward_ctrl Min               -0.586753
time/data storing (s)                         0.00446659
time/evaluation sampling (s)                  1.9792
time/exploration sampling (s)                 0.530716
time/logging (s)                              0.0135622
time/sac training (s)                         7.41097
time/saving (s)                               0.00375772
time/training (s)                             3.3817e-05
time/epoch (s)                                9.94271
time/total (s)                             3047.9
Epoch                                       286
---------------------------------------  ----------------
2021-11-24 01:20:12.475058 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 287 finished
---------------------------------------  ---------------
epoch                                       287
replay_buffer/size                       289000
trainer/num train calls                  288000
trainer/QF1 Loss                              5.77008
trainer/QF2 Loss                              5.31996
trainer/Policy Loss                        -365.958
trainer/Q1 Predictions Mean                 366.402
trainer/Q1 Predictions Std                  100.106
trainer/Q1 Predictions Max                  441.66
trainer/Q1 Predictions Min                   17.8482
trainer/Q2 Predictions Mean                 366.298
trainer/Q2 Predictions Std                  100.224
trainer/Q2 Predictions Max                  441.713
trainer/Q2 Predictions Min                   16.9857
trainer/Q Targets Mean                      366.83
trainer/Q Targets Std                       100.398
trainer/Q Targets Max                       442.395
trainer/Q Targets Min                        17.1735
trainer/Log Pis Mean                          5.91587
trainer/Log Pis Std                           4.36667
trainer/Log Pis Max                          17.2477
trainer/Log Pis Min                          -5.52809
trainer/policy/mean Mean                      0.0478542
trainer/policy/mean Std                       0.775855
trainer/policy/mean Max                       0.998529
trainer/policy/mean Min                      -0.997555
trainer/policy/normal/std Mean                0.438811
trainer/policy/normal/std Std                 0.145796
trainer/policy/normal/std Max                 1.00651
trainer/policy/normal/std Min                 0.0721345
trainer/policy/normal/log_std Mean           -0.896941
trainer/policy/normal/log_std Std             0.42172
trainer/policy/normal/log_std Max             0.00649224
trainer/policy/normal/log_std Min            -2.62922
trainer/Alpha                                 0.128526
trainer/Alpha Loss                           -0.172603
expl/num steps total                     289000
expl/num paths total                        289
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.64396
expl/Rewards Std                              1.24509
expl/Rewards Max                              7.9257
expl/Rewards Min                             -0.680682
expl/Returns Mean                          5643.96
expl/Returns Std                              0
expl/Returns Max                           5643.96
expl/Returns Min                           5643.96
expl/Actions Mean                             0.067378
expl/Actions Std                              0.807286
expl/Actions Max                              0.999405
expl/Actions Min                             -0.999687
expl/Num Paths                                1
expl/Average Returns                       5643.96
expl/env_infos/final/reward_run Mean          6.64428
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.64428
expl/env_infos/final/reward_run Min           6.64428
expl/env_infos/initial/reward_run Mean       -0.405704
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.405704
expl/env_infos/initial/reward_run Min        -0.405704
expl/env_infos/reward_run Mean                6.03772
expl/env_infos/reward_run Std                 1.23504
expl/env_infos/reward_run Max                 8.43968
expl/env_infos/reward_run Min                -0.405704
expl/env_infos/final/reward_ctrl Mean        -0.252417
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.252417
expl/env_infos/final/reward_ctrl Min         -0.252417
expl/env_infos/initial/reward_ctrl Mean      -0.274978
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.274978
expl/env_infos/initial/reward_ctrl Min       -0.274978
expl/env_infos/reward_ctrl Mean              -0.39375
expl/env_infos/reward_ctrl Std                0.097129
expl/env_infos/reward_ctrl Max               -0.0895913
expl/env_infos/reward_ctrl Min               -0.582943
eval/num steps total                          1.44e+06
eval/num paths total                       1440
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.84434
eval/Rewards Std                              1.27756
eval/Rewards Max                              8.33728
eval/Rewards Min                             -0.891868
eval/Returns Mean                          5844.34
eval/Returns Std                             39.9727
eval/Returns Max                           5896.21
eval/Returns Min                           5778.65
eval/Actions Mean                             0.0723437
eval/Actions Std                              0.822981
eval/Actions Max                              0.997287
eval/Actions Min                             -0.997263
eval/Num Paths                                5
eval/Average Returns                       5844.34
eval/env_infos/final/reward_run Mean          6.56403
eval/env_infos/final/reward_run Std           0.633569
eval/env_infos/final/reward_run Max           7.54783
eval/env_infos/final/reward_run Min           5.9124
eval/env_infos/initial/reward_run Mean       -0.354747
eval/env_infos/initial/reward_run Std         0.147101
eval/env_infos/initial/reward_run Max        -0.203688
eval/env_infos/initial/reward_run Min        -0.573911
eval/env_infos/reward_run Mean                6.25386
eval/env_infos/reward_run Std                 1.26898
eval/env_infos/reward_run Max                 8.85153
eval/env_infos/reward_run Min                -0.573911
eval/env_infos/final/reward_ctrl Mean        -0.349586
eval/env_infos/final/reward_ctrl Std          0.0870738
eval/env_infos/final/reward_ctrl Max         -0.227306
eval/env_infos/final/reward_ctrl Min         -0.461048
eval/env_infos/initial/reward_ctrl Mean      -0.288282
eval/env_infos/initial/reward_ctrl Std        0.0452761
eval/env_infos/initial/reward_ctrl Max       -0.206837
eval/env_infos/initial/reward_ctrl Min       -0.340584
eval/env_infos/reward_ctrl Mean              -0.409519
eval/env_infos/reward_ctrl Std                0.0954914
eval/env_infos/reward_ctrl Max               -0.0851241
eval/env_infos/reward_ctrl Min               -0.587292
time/data storing (s)                         0.00449615
time/evaluation sampling (s)                  1.99823
time/exploration sampling (s)                 0.523308
time/logging (s)                              0.0135398
time/sac training (s)                         7.38309
time/saving (s)                               0.00374782
time/training (s)                             3.4626e-05
time/epoch (s)                                9.92644
time/total (s)                             3058.11
Epoch                                       287
---------------------------------------  ---------------
2021-11-24 01:20:22.682261 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 288 finished
---------------------------------------  ---------------
epoch                                       288
replay_buffer/size                       290000
trainer/num train calls                  289000
trainer/QF1 Loss                             33.876
trainer/QF2 Loss                             33.857
trainer/Policy Loss                        -361.528
trainer/Q1 Predictions Mean                 361.708
trainer/Q1 Predictions Std                  105.709
trainer/Q1 Predictions Max                  444.379
trainer/Q1 Predictions Min                   16.296
trainer/Q2 Predictions Mean                 361.862
trainer/Q2 Predictions Std                  105.706
trainer/Q2 Predictions Max                  445.535
trainer/Q2 Predictions Min                   16.8004
trainer/Q Targets Mean                      361.504
trainer/Q Targets Std                       106.294
trainer/Q Targets Max                       445.572
trainer/Q Targets Min                        15.7365
trainer/Log Pis Mean                          5.56227
trainer/Log Pis Std                           4.61833
trainer/Log Pis Max                          15.5465
trainer/Log Pis Min                          -5.72814
trainer/policy/mean Mean                      0.0740949
trainer/policy/mean Std                       0.760208
trainer/policy/mean Max                       0.99578
trainer/policy/mean Min                      -0.997685
trainer/policy/normal/std Mean                0.439158
trainer/policy/normal/std Std                 0.15093
trainer/policy/normal/std Max                 0.994579
trainer/policy/normal/std Min                 0.067249
trainer/policy/normal/log_std Mean           -0.900619
trainer/policy/normal/log_std Std             0.434052
trainer/policy/normal/log_std Max            -0.00543621
trainer/policy/normal/log_std Min            -2.69935
trainer/Alpha                                 0.132488
trainer/Alpha Loss                           -0.884759
expl/num steps total                     290000
expl/num paths total                        290
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.60761
expl/Rewards Std                              1.29105
expl/Rewards Max                              8.26918
expl/Rewards Min                             -0.86456
expl/Returns Mean                          5607.61
expl/Returns Std                              0
expl/Returns Max                           5607.61
expl/Returns Min                           5607.61
expl/Actions Mean                             0.0933539
expl/Actions Std                              0.812455
expl/Actions Max                              0.999617
expl/Actions Min                             -0.998925
expl/Num Paths                                1
expl/Average Returns                       5607.61
expl/env_infos/final/reward_run Mean          7.13473
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.13473
expl/env_infos/final/reward_run Min           7.13473
expl/env_infos/initial/reward_run Mean       -0.465954
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.465954
expl/env_infos/initial/reward_run Min        -0.465954
expl/env_infos/reward_run Mean                6.00889
expl/env_infos/reward_run Std                 1.2831
expl/env_infos/reward_run Max                 8.7612
expl/env_infos/reward_run Min                -0.514869
expl/env_infos/final/reward_ctrl Mean        -0.428479
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.428479
expl/env_infos/final/reward_ctrl Min         -0.428479
expl/env_infos/initial/reward_ctrl Mean      -0.249449
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.249449
expl/env_infos/initial/reward_ctrl Min       -0.249449
expl/env_infos/reward_ctrl Mean              -0.401279
expl/env_infos/reward_ctrl Std                0.0853504
expl/env_infos/reward_ctrl Max               -0.118645
expl/env_infos/reward_ctrl Min               -0.577189
eval/num steps total                          1.445e+06
eval/num paths total                       1445
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.80085
eval/Rewards Std                              1.27812
eval/Rewards Max                              8.53424
eval/Rewards Min                             -0.752906
eval/Returns Mean                          5800.85
eval/Returns Std                             69.6759
eval/Returns Max                           5904.39
eval/Returns Min                           5686.28
eval/Actions Mean                             0.10228
eval/Actions Std                              0.822976
eval/Actions Max                              0.997407
eval/Actions Min                             -0.995403
eval/Num Paths                                5
eval/Average Returns                       5800.85
eval/env_infos/final/reward_run Mean          6.23267
eval/env_infos/final/reward_run Std           0.871437
eval/env_infos/final/reward_run Max           7.90386
eval/env_infos/final/reward_run Min           5.5371
eval/env_infos/initial/reward_run Mean       -0.274107
eval/env_infos/initial/reward_run Std         0.12794
eval/env_infos/initial/reward_run Max        -0.133554
eval/env_infos/initial/reward_run Min        -0.475502
eval/env_infos/reward_run Mean                6.2135
eval/env_infos/reward_run Std                 1.26342
eval/env_infos/reward_run Max                 9.02776
eval/env_infos/reward_run Min                -0.475502
eval/env_infos/final/reward_ctrl Mean        -0.44861
eval/env_infos/final/reward_ctrl Std          0.0593164
eval/env_infos/final/reward_ctrl Max         -0.353369
eval/env_infos/final/reward_ctrl Min         -0.528566
eval/env_infos/initial/reward_ctrl Mean      -0.28642
eval/env_infos/initial/reward_ctrl Std        0.0449128
eval/env_infos/initial/reward_ctrl Max       -0.209463
eval/env_infos/initial/reward_ctrl Min       -0.34356
eval/env_infos/reward_ctrl Mean              -0.412651
eval/env_infos/reward_ctrl Std                0.0893203
eval/env_infos/reward_ctrl Max               -0.107523
eval/env_infos/reward_ctrl Min               -0.586383
time/data storing (s)                         0.0044713
time/evaluation sampling (s)                  1.99945
time/exploration sampling (s)                 0.526833
time/logging (s)                              0.0136111
time/sac training (s)                         7.36587
time/saving (s)                               0.00512035
time/training (s)                             3.41e-05
time/epoch (s)                                9.91539
time/total (s)                             3068.3
Epoch                                       288
---------------------------------------  ---------------
2021-11-24 01:20:32.862738 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 289 finished
---------------------------------------  ---------------
epoch                                       289
replay_buffer/size                       291000
trainer/num train calls                  290000
trainer/QF1 Loss                              6.64864
trainer/QF2 Loss                              6.19723
trainer/Policy Loss                        -367.977
trainer/Q1 Predictions Mean                 368.042
trainer/Q1 Predictions Std                   98.3468
trainer/Q1 Predictions Max                  445.61
trainer/Q1 Predictions Min                   16.6765
trainer/Q2 Predictions Mean                 368.647
trainer/Q2 Predictions Std                   98.3347
trainer/Q2 Predictions Max                  445.855
trainer/Q2 Predictions Min                   15.6938
trainer/Q Targets Mean                      368.137
trainer/Q Targets Std                        98.2982
trainer/Q Targets Max                       447.67
trainer/Q Targets Min                        16.8086
trainer/Log Pis Mean                          5.69143
trainer/Log Pis Std                           4.6618
trainer/Log Pis Max                          29.3465
trainer/Log Pis Min                          -6.94416
trainer/policy/mean Mean                      0.0994427
trainer/policy/mean Std                       0.762128
trainer/policy/mean Max                       0.999541
trainer/policy/mean Min                      -0.998883
trainer/policy/normal/std Mean                0.439898
trainer/policy/normal/std Std                 0.147109
trainer/policy/normal/std Max                 0.975453
trainer/policy/normal/std Min                 0.0765609
trainer/policy/normal/log_std Mean           -0.893398
trainer/policy/normal/log_std Std             0.415797
trainer/policy/normal/log_std Max            -0.0248537
trainer/policy/normal/log_std Min            -2.56967
trainer/Alpha                                 0.133323
trainer/Alpha Loss                           -0.621768
expl/num steps total                     291000
expl/num paths total                        291
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.57149
expl/Rewards Std                              1.23641
expl/Rewards Max                              7.73084
expl/Rewards Min                             -0.61131
expl/Returns Mean                          5571.49
expl/Returns Std                              0
expl/Returns Max                           5571.49
expl/Returns Min                           5571.49
expl/Actions Mean                             0.108278
expl/Actions Std                              0.800453
expl/Actions Max                              0.999733
expl/Actions Min                             -0.999501
expl/Num Paths                                1
expl/Average Returns                       5571.49
expl/env_infos/final/reward_run Mean          5.5324
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.5324
expl/env_infos/final/reward_run Min           5.5324
expl/env_infos/initial/reward_run Mean       -0.280362
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.280362
expl/env_infos/initial/reward_run Min        -0.280362
expl/env_infos/reward_run Mean                5.96296
expl/env_infos/reward_run Std                 1.23183
expl/env_infos/reward_run Max                 8.20702
expl/env_infos/reward_run Min                -0.280362
expl/env_infos/final/reward_ctrl Mean        -0.346158
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.346158
expl/env_infos/final/reward_ctrl Min         -0.346158
expl/env_infos/initial/reward_ctrl Mean      -0.330948
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.330948
expl/env_infos/initial/reward_ctrl Min       -0.330948
expl/env_infos/reward_ctrl Mean              -0.39147
expl/env_infos/reward_ctrl Std                0.0928862
expl/env_infos/reward_ctrl Max               -0.0488175
expl/env_infos/reward_ctrl Min               -0.5716
eval/num steps total                          1.45e+06
eval/num paths total                       1450
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.86324
eval/Rewards Std                              1.28216
eval/Rewards Max                              8.35923
eval/Rewards Min                             -0.674902
eval/Returns Mean                          5863.24
eval/Returns Std                             48.9436
eval/Returns Max                           5944.76
eval/Returns Min                           5812.84
eval/Actions Mean                             0.122558
eval/Actions Std                              0.817403
eval/Actions Max                              0.997873
eval/Actions Min                             -0.996462
eval/Num Paths                                5
eval/Average Returns                       5863.24
eval/env_infos/final/reward_run Mean          6.91553
eval/env_infos/final/reward_run Std           0.95845
eval/env_infos/final/reward_run Max           8.13625
eval/env_infos/final/reward_run Min           5.56922
eval/env_infos/initial/reward_run Mean       -0.173539
eval/env_infos/initial/reward_run Std         0.119729
eval/env_infos/initial/reward_run Max        -0.0455374
eval/env_infos/initial/reward_run Min        -0.391456
eval/env_infos/reward_run Mean                6.27314
eval/env_infos/reward_run Std                 1.27466
eval/env_infos/reward_run Max                 8.86846
eval/env_infos/reward_run Min                -0.391456
eval/env_infos/final/reward_ctrl Mean        -0.451171
eval/env_infos/final/reward_ctrl Std          0.0572923
eval/env_infos/final/reward_ctrl Max         -0.384936
eval/env_infos/final/reward_ctrl Min         -0.526635
eval/env_infos/initial/reward_ctrl Mean      -0.21676
eval/env_infos/initial/reward_ctrl Std        0.0453656
eval/env_infos/initial/reward_ctrl Max       -0.142498
eval/env_infos/initial/reward_ctrl Min       -0.283446
eval/env_infos/reward_ctrl Mean              -0.409901
eval/env_infos/reward_ctrl Std                0.0933912
eval/env_infos/reward_ctrl Max               -0.0869291
eval/env_infos/reward_ctrl Min               -0.586201
time/data storing (s)                         0.00455477
time/evaluation sampling (s)                  1.97134
time/exploration sampling (s)                 0.515013
time/logging (s)                              0.0135428
time/sac training (s)                         7.37943
time/saving (s)                               0.00376736
time/training (s)                             3.4902e-05
time/epoch (s)                                9.88769
time/total (s)                             3078.47
Epoch                                       289
---------------------------------------  ---------------
2021-11-24 01:20:43.130596 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 290 finished
---------------------------------------  ---------------
epoch                                       290
replay_buffer/size                       292000
trainer/num train calls                  291000
trainer/QF1 Loss                             10.9728
trainer/QF2 Loss                              8.39861
trainer/Policy Loss                        -370.293
trainer/Q1 Predictions Mean                 370.45
trainer/Q1 Predictions Std                   95.9711
trainer/Q1 Predictions Max                  446.396
trainer/Q1 Predictions Min                   17.2612
trainer/Q2 Predictions Mean                 370.754
trainer/Q2 Predictions Std                   95.8455
trainer/Q2 Predictions Max                  447.257
trainer/Q2 Predictions Min                   16.1068
trainer/Q Targets Mean                      370.854
trainer/Q Targets Std                        95.689
trainer/Q Targets Max                       447.239
trainer/Q Targets Min                        18.7663
trainer/Log Pis Mean                          6.17933
trainer/Log Pis Std                           4.47237
trainer/Log Pis Max                          15.549
trainer/Log Pis Min                          -5.01814
trainer/policy/mean Mean                      0.099996
trainer/policy/mean Std                       0.775387
trainer/policy/mean Max                       0.995701
trainer/policy/mean Min                      -0.997579
trainer/policy/normal/std Mean                0.437939
trainer/policy/normal/std Std                 0.14576
trainer/policy/normal/std Max                 0.915144
trainer/policy/normal/std Min                 0.0616083
trainer/policy/normal/log_std Mean           -0.899027
trainer/policy/normal/log_std Std             0.422549
trainer/policy/normal/log_std Max            -0.0886738
trainer/policy/normal/log_std Min            -2.78696
trainer/Alpha                                 0.133795
trainer/Alpha Loss                            0.360703
expl/num steps total                     292000
expl/num paths total                        292
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.58942
expl/Rewards Std                              1.29603
expl/Rewards Max                              8.09167
expl/Rewards Min                             -0.580994
expl/Returns Mean                          5589.42
expl/Returns Std                              0
expl/Returns Max                           5589.42
expl/Returns Min                           5589.42
expl/Actions Mean                             0.0973827
expl/Actions Std                              0.806481
expl/Actions Max                              0.999134
expl/Actions Min                             -0.999582
expl/Num Paths                                1
expl/Average Returns                       5589.42
expl/env_infos/final/reward_run Mean          6.53841
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.53841
expl/env_infos/final/reward_run Min           6.53841
expl/env_infos/initial/reward_run Mean       -0.279897
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.279897
expl/env_infos/initial/reward_run Min        -0.279897
expl/env_infos/reward_run Mean                5.98535
expl/env_infos/reward_run Std                 1.28691
expl/env_infos/reward_run Max                 8.57621
expl/env_infos/reward_run Min                -0.279897
expl/env_infos/final/reward_ctrl Mean        -0.453793
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.453793
expl/env_infos/final/reward_ctrl Min         -0.453793
expl/env_infos/initial/reward_ctrl Mean      -0.301097
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.301097
expl/env_infos/initial/reward_ctrl Min       -0.301097
expl/env_infos/reward_ctrl Mean              -0.395937
expl/env_infos/reward_ctrl Std                0.091581
expl/env_infos/reward_ctrl Max               -0.116572
expl/env_infos/reward_ctrl Min               -0.589215
eval/num steps total                          1.455e+06
eval/num paths total                       1455
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.76634
eval/Rewards Std                              1.29069
eval/Rewards Max                              8.22408
eval/Rewards Min                             -0.822272
eval/Returns Mean                          5766.34
eval/Returns Std                             48.5497
eval/Returns Max                           5849.15
eval/Returns Min                           5698.41
eval/Actions Mean                             0.10395
eval/Actions Std                              0.817641
eval/Actions Max                              0.99713
eval/Actions Min                             -0.998652
eval/Num Paths                                5
eval/Average Returns                       5766.34
eval/env_infos/final/reward_run Mean          7.09888
eval/env_infos/final/reward_run Std           1.15543
eval/env_infos/final/reward_run Max           8.36372
eval/env_infos/final/reward_run Min           5.57488
eval/env_infos/initial/reward_run Mean       -0.280179
eval/env_infos/initial/reward_run Std         0.141371
eval/env_infos/initial/reward_run Max        -0.154098
eval/env_infos/initial/reward_run Min        -0.552337
eval/env_infos/reward_run Mean                6.17395
eval/env_infos/reward_run Std                 1.27292
eval/env_infos/reward_run Max                 8.71167
eval/env_infos/reward_run Min                -0.552337
eval/env_infos/final/reward_ctrl Mean        -0.437835
eval/env_infos/final/reward_ctrl Std          0.0655313
eval/env_infos/final/reward_ctrl Max         -0.333093
eval/env_infos/final/reward_ctrl Min         -0.498885
eval/env_infos/initial/reward_ctrl Mean      -0.283595
eval/env_infos/initial/reward_ctrl Std        0.0482668
eval/env_infos/initial/reward_ctrl Max       -0.236733
eval/env_infos/initial/reward_ctrl Min       -0.372833
eval/env_infos/reward_ctrl Mean              -0.407606
eval/env_infos/reward_ctrl Std                0.092283
eval/env_infos/reward_ctrl Max               -0.107063
eval/env_infos/reward_ctrl Min               -0.584647
time/data storing (s)                         0.00445156
time/evaluation sampling (s)                  1.99982
time/exploration sampling (s)                 0.517647
time/logging (s)                              0.0135228
time/sac training (s)                         7.4344
time/saving (s)                               0.00375412
time/training (s)                             3.5286e-05
time/epoch (s)                                9.97363
time/total (s)                             3088.72
Epoch                                       290
---------------------------------------  ---------------
2021-11-24 01:20:53.384631 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 291 finished
---------------------------------------  ---------------
epoch                                       291
replay_buffer/size                       293000
trainer/num train calls                  292000
trainer/QF1 Loss                              6.75303
trainer/QF2 Loss                              6.42838
trainer/Policy Loss                        -362.9
trainer/Q1 Predictions Mean                 363.356
trainer/Q1 Predictions Std                  109.548
trainer/Q1 Predictions Max                  447.125
trainer/Q1 Predictions Min                   17.7253
trainer/Q2 Predictions Mean                 363.055
trainer/Q2 Predictions Std                  109.456
trainer/Q2 Predictions Max                  448.922
trainer/Q2 Predictions Min                   17.496
trainer/Q Targets Mean                      362.967
trainer/Q Targets Std                       109.43
trainer/Q Targets Max                       447.537
trainer/Q Targets Min                        16.5747
trainer/Log Pis Mean                          5.8914
trainer/Log Pis Std                           4.85016
trainer/Log Pis Max                          17.2107
trainer/Log Pis Min                          -5.21005
trainer/policy/mean Mean                      0.107631
trainer/policy/mean Std                       0.766753
trainer/policy/mean Max                       0.998816
trainer/policy/mean Min                      -0.998461
trainer/policy/normal/std Mean                0.450957
trainer/policy/normal/std Std                 0.150188
trainer/policy/normal/std Max                 1.0717
trainer/policy/normal/std Min                 0.0826222
trainer/policy/normal/log_std Mean           -0.867902
trainer/policy/normal/log_std Std             0.413751
trainer/policy/normal/log_std Max             0.0692484
trainer/policy/normal/log_std Min            -2.49348
trainer/Alpha                                 0.133459
trainer/Alpha Loss                           -0.218714
expl/num steps total                     293000
expl/num paths total                        293
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.68339
expl/Rewards Std                              1.24012
expl/Rewards Max                              7.70793
expl/Rewards Min                             -0.411509
expl/Returns Mean                          5683.39
expl/Returns Std                              0
expl/Returns Max                           5683.39
expl/Returns Min                           5683.39
expl/Actions Mean                             0.119971
expl/Actions Std                              0.798427
expl/Actions Max                              0.999495
expl/Actions Min                             -0.999484
expl/Num Paths                                1
expl/Average Returns                       5683.39
expl/env_infos/final/reward_run Mean          7.42117
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.42117
expl/env_infos/final/reward_run Min           7.42117
expl/env_infos/initial/reward_run Mean        0.0155976
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0155976
expl/env_infos/initial/reward_run Min         0.0155976
expl/env_infos/reward_run Mean                6.07452
expl/env_infos/reward_run Std                 1.23027
expl/env_infos/reward_run Max                 8.24369
expl/env_infos/reward_run Min                -0.00549147
expl/env_infos/final/reward_ctrl Mean        -0.462136
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.462136
expl/env_infos/final/reward_ctrl Min         -0.462136
expl/env_infos/initial/reward_ctrl Mean      -0.34879
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.34879
expl/env_infos/initial/reward_ctrl Min       -0.34879
expl/env_infos/reward_ctrl Mean              -0.391127
expl/env_infos/reward_ctrl Std                0.0951192
expl/env_infos/reward_ctrl Max               -0.0431899
expl/env_infos/reward_ctrl Min               -0.580283
eval/num steps total                          1.46e+06
eval/num paths total                       1460
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.88106
eval/Rewards Std                              1.27565
eval/Rewards Max                              8.5578
eval/Rewards Min                             -0.764469
eval/Returns Mean                          5881.06
eval/Returns Std                            104.989
eval/Returns Max                           6028.31
eval/Returns Min                           5729.6
eval/Actions Mean                             0.122423
eval/Actions Std                              0.814576
eval/Actions Max                              0.998114
eval/Actions Min                             -0.996391
eval/Num Paths                                5
eval/Average Returns                       5881.06
eval/env_infos/final/reward_run Mean          6.49224
eval/env_infos/final/reward_run Std           0.934248
eval/env_infos/final/reward_run Max           7.73151
eval/env_infos/final/reward_run Min           5.52463
eval/env_infos/initial/reward_run Mean       -0.205001
eval/env_infos/initial/reward_run Std         0.151544
eval/env_infos/initial/reward_run Max        -0.0198406
eval/env_infos/initial/reward_run Min        -0.408949
eval/env_infos/reward_run Mean                6.28817
eval/env_infos/reward_run Std                 1.26547
eval/env_infos/reward_run Max                 9.06177
eval/env_infos/reward_run Min                -0.408949
eval/env_infos/final/reward_ctrl Mean        -0.413577
eval/env_infos/final/reward_ctrl Std          0.0432436
eval/env_infos/final/reward_ctrl Max         -0.377458
eval/env_infos/final/reward_ctrl Min         -0.497446
eval/env_infos/initial/reward_ctrl Mean      -0.287288
eval/env_infos/initial/reward_ctrl Std        0.0492953
eval/env_infos/initial/reward_ctrl Max       -0.232403
eval/env_infos/initial/reward_ctrl Min       -0.355521
eval/env_infos/reward_ctrl Mean              -0.407113
eval/env_infos/reward_ctrl Std                0.0919085
eval/env_infos/reward_ctrl Max               -0.0744286
eval/env_infos/reward_ctrl Min               -0.581867
time/data storing (s)                         0.00449046
time/evaluation sampling (s)                  2.02085
time/exploration sampling (s)                 0.527405
time/logging (s)                              0.0136447
time/sac training (s)                         7.38923
time/saving (s)                               0.00376993
time/training (s)                             3.3895e-05
time/epoch (s)                                9.95943
time/total (s)                             3098.96
Epoch                                       291
---------------------------------------  ---------------
2021-11-24 01:21:03.610283 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 292 finished
---------------------------------------  ---------------
epoch                                       292
replay_buffer/size                       294000
trainer/num train calls                  293000
trainer/QF1 Loss                              7.76843
trainer/QF2 Loss                              5.86423
trainer/Policy Loss                        -369.801
trainer/Q1 Predictions Mean                 370.32
trainer/Q1 Predictions Std                  103.027
trainer/Q1 Predictions Max                  444.663
trainer/Q1 Predictions Min                   17.6722
trainer/Q2 Predictions Mean                 370.296
trainer/Q2 Predictions Std                  103.003
trainer/Q2 Predictions Max                  444.513
trainer/Q2 Predictions Min                   17.2716
trainer/Q Targets Mean                      370.573
trainer/Q Targets Std                       102.991
trainer/Q Targets Max                       446.762
trainer/Q Targets Min                        17.6418
trainer/Log Pis Mean                          5.5626
trainer/Log Pis Std                           4.57151
trainer/Log Pis Max                          16.8895
trainer/Log Pis Min                          -5.04838
trainer/policy/mean Mean                      0.0643981
trainer/policy/mean Std                       0.771119
trainer/policy/mean Max                       0.998017
trainer/policy/mean Min                      -0.998883
trainer/policy/normal/std Mean                0.442458
trainer/policy/normal/std Std                 0.144721
trainer/policy/normal/std Max                 0.874048
trainer/policy/normal/std Min                 0.0729843
trainer/policy/normal/log_std Mean           -0.886969
trainer/policy/normal/log_std Std             0.417499
trainer/policy/normal/log_std Max            -0.13462
trainer/policy/normal/log_std Min            -2.61751
trainer/Alpha                                 0.134945
trainer/Alpha Loss                           -0.876063
expl/num steps total                     294000
expl/num paths total                        294
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.65946
expl/Rewards Std                              1.28269
expl/Rewards Max                              8.36525
expl/Rewards Min                             -0.826372
expl/Returns Mean                          5659.46
expl/Returns Std                              0
expl/Returns Max                           5659.46
expl/Returns Min                           5659.46
expl/Actions Mean                             0.105831
expl/Actions Std                              0.808154
expl/Actions Max                              0.999642
expl/Actions Min                             -0.999781
expl/Num Paths                                1
expl/Average Returns                       5659.46
expl/env_infos/final/reward_run Mean          6.94059
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.94059
expl/env_infos/final/reward_run Min           6.94059
expl/env_infos/initial/reward_run Mean       -0.161844
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.161844
expl/env_infos/initial/reward_run Min        -0.161844
expl/env_infos/reward_run Mean                6.05804
expl/env_infos/reward_run Std                 1.27156
expl/env_infos/reward_run Max                 8.8886
expl/env_infos/reward_run Min                -0.399719
expl/env_infos/final/reward_ctrl Mean        -0.449202
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.449202
expl/env_infos/final/reward_ctrl Min         -0.449202
expl/env_infos/initial/reward_ctrl Mean      -0.302319
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.302319
expl/env_infos/initial/reward_ctrl Min       -0.302319
expl/env_infos/reward_ctrl Mean              -0.398588
expl/env_infos/reward_ctrl Std                0.0937708
expl/env_infos/reward_ctrl Max               -0.0849067
expl/env_infos/reward_ctrl Min               -0.577367
eval/num steps total                          1.465e+06
eval/num paths total                       1465
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.90339
eval/Rewards Std                              1.28002
eval/Rewards Max                              8.3132
eval/Rewards Min                             -0.667276
eval/Returns Mean                          5903.39
eval/Returns Std                             67.0515
eval/Returns Max                           5993.17
eval/Returns Min                           5785.22
eval/Actions Mean                             0.111878
eval/Actions Std                              0.821656
eval/Actions Max                              0.995181
eval/Actions Min                             -0.99583
eval/Num Paths                                5
eval/Average Returns                       5903.39
eval/env_infos/final/reward_run Mean          6.23914
eval/env_infos/final/reward_run Std           0.551981
eval/env_infos/final/reward_run Max           7.20133
eval/env_infos/final/reward_run Min           5.67013
eval/env_infos/initial/reward_run Mean       -0.160824
eval/env_infos/initial/reward_run Std         0.112376
eval/env_infos/initial/reward_run Max         0.00142341
eval/env_infos/initial/reward_run Min        -0.290545
eval/env_infos/reward_run Mean                6.31597
eval/env_infos/reward_run Std                 1.26609
eval/env_infos/reward_run Max                 8.82515
eval/env_infos/reward_run Min                -0.290545
eval/env_infos/final/reward_ctrl Mean        -0.441347
eval/env_infos/final/reward_ctrl Std          0.0246712
eval/env_infos/final/reward_ctrl Max         -0.405574
eval/env_infos/final/reward_ctrl Min         -0.475211
eval/env_infos/initial/reward_ctrl Mean      -0.309392
eval/env_infos/initial/reward_ctrl Std        0.0625921
eval/env_infos/initial/reward_ctrl Max       -0.223947
eval/env_infos/initial/reward_ctrl Min       -0.376731
eval/env_infos/reward_ctrl Mean              -0.412581
eval/env_infos/reward_ctrl Std                0.0944733
eval/env_infos/reward_ctrl Max               -0.0996885
eval/env_infos/reward_ctrl Min               -0.586186
time/data storing (s)                         0.00451629
time/evaluation sampling (s)                  2.00485
time/exploration sampling (s)                 0.531591
time/logging (s)                              0.013599
time/sac training (s)                         7.37281
time/saving (s)                               0.00517356
time/training (s)                             3.4578e-05
time/epoch (s)                                9.93257
time/total (s)                             3109.18
Epoch                                       292
---------------------------------------  ---------------
2021-11-24 01:21:13.824133 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 293 finished
---------------------------------------  ----------------
epoch                                       293
replay_buffer/size                       295000
trainer/num train calls                  294000
trainer/QF1 Loss                              4.91111
trainer/QF2 Loss                              5.65343
trainer/Policy Loss                        -367.093
trainer/Q1 Predictions Mean                 367.493
trainer/Q1 Predictions Std                  107.022
trainer/Q1 Predictions Max                  447.564
trainer/Q1 Predictions Min                   17.2358
trainer/Q2 Predictions Mean                 367.607
trainer/Q2 Predictions Std                  107.072
trainer/Q2 Predictions Max                  447.976
trainer/Q2 Predictions Min                   16.5014
trainer/Q Targets Mean                      367.445
trainer/Q Targets Std                       107.104
trainer/Q Targets Max                       447.414
trainer/Q Targets Min                        15.8841
trainer/Log Pis Mean                          5.78199
trainer/Log Pis Std                           4.50619
trainer/Log Pis Max                          16.1564
trainer/Log Pis Min                          -6.6665
trainer/policy/mean Mean                      0.113939
trainer/policy/mean Std                       0.768175
trainer/policy/mean Max                       0.995087
trainer/policy/mean Min                      -0.997427
trainer/policy/normal/std Mean                0.44848
trainer/policy/normal/std Std                 0.144763
trainer/policy/normal/std Max                 1.01464
trainer/policy/normal/std Min                 0.0573015
trainer/policy/normal/log_std Mean           -0.869864
trainer/policy/normal/log_std Std             0.404048
trainer/policy/normal/log_std Max             0.0145323
trainer/policy/normal/log_std Min            -2.85943
trainer/Alpha                                 0.133782
trainer/Alpha Loss                           -0.438536
expl/num steps total                     295000
expl/num paths total                        295
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.60218
expl/Rewards Std                              1.26633
expl/Rewards Max                              8.13797
expl/Rewards Min                             -0.645072
expl/Returns Mean                          5602.18
expl/Returns Std                              0
expl/Returns Max                           5602.18
expl/Returns Min                           5602.18
expl/Actions Mean                             0.116671
expl/Actions Std                              0.797336
expl/Actions Max                              0.999484
expl/Actions Min                             -0.999101
expl/Num Paths                                1
expl/Average Returns                       5602.18
expl/env_infos/final/reward_run Mean          8.12904
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.12904
expl/env_infos/final/reward_run Min           8.12904
expl/env_infos/initial/reward_run Mean       -0.326382
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.326382
expl/env_infos/initial/reward_run Min        -0.326382
expl/env_infos/reward_run Mean                5.9918
expl/env_infos/reward_run Std                 1.26052
expl/env_infos/reward_run Max                 8.59745
expl/env_infos/reward_run Min                -0.326382
expl/env_infos/final/reward_ctrl Mean        -0.526669
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.526669
expl/env_infos/final/reward_ctrl Min         -0.526669
expl/env_infos/initial/reward_ctrl Mean      -0.31869
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.31869
expl/env_infos/initial/reward_ctrl Min       -0.31869
expl/env_infos/reward_ctrl Mean              -0.389614
expl/env_infos/reward_ctrl Std                0.0953929
expl/env_infos/reward_ctrl Max               -0.0960831
expl/env_infos/reward_ctrl Min               -0.582881
eval/num steps total                          1.47e+06
eval/num paths total                       1470
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.8748
eval/Rewards Std                              1.29585
eval/Rewards Max                              8.46598
eval/Rewards Min                             -0.739219
eval/Returns Mean                          5874.8
eval/Returns Std                             88.8815
eval/Returns Max                           5982.45
eval/Returns Min                           5730.64
eval/Actions Mean                             0.126587
eval/Actions Std                              0.814186
eval/Actions Max                              0.997686
eval/Actions Min                             -0.996057
eval/Num Paths                                5
eval/Average Returns                       5874.8
eval/env_infos/final/reward_run Mean          7.03699
eval/env_infos/final/reward_run Std           0.775845
eval/env_infos/final/reward_run Max           7.91859
eval/env_infos/final/reward_run Min           5.76967
eval/env_infos/initial/reward_run Mean       -0.157063
eval/env_infos/initial/reward_run Std         0.159634
eval/env_infos/initial/reward_run Max         0.0251066
eval/env_infos/initial/reward_run Min        -0.380935
eval/env_infos/reward_run Mean                6.28216
eval/env_infos/reward_run Std                 1.28592
eval/env_infos/reward_run Max                 8.92471
eval/env_infos/reward_run Min                -0.380935
eval/env_infos/final/reward_ctrl Mean        -0.452268
eval/env_infos/final/reward_ctrl Std          0.0265051
eval/env_infos/final/reward_ctrl Max         -0.420888
eval/env_infos/final/reward_ctrl Min         -0.492464
eval/env_infos/initial/reward_ctrl Mean      -0.254355
eval/env_infos/initial/reward_ctrl Std        0.0630865
eval/env_infos/initial/reward_ctrl Max       -0.16285
eval/env_infos/initial/reward_ctrl Min       -0.358285
eval/env_infos/reward_ctrl Mean              -0.407354
eval/env_infos/reward_ctrl Std                0.090779
eval/env_infos/reward_ctrl Max               -0.0945428
eval/env_infos/reward_ctrl Min               -0.582296
time/data storing (s)                         0.00446969
time/evaluation sampling (s)                  1.98736
time/exploration sampling (s)                 0.529592
time/logging (s)                              0.0135669
time/sac training (s)                         7.38058
time/saving (s)                               0.00377377
time/training (s)                             3.46701e-05
time/epoch (s)                                9.91938
time/total (s)                             3119.38
Epoch                                       293
---------------------------------------  ----------------
2021-11-24 01:21:24.057195 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 294 finished
---------------------------------------  ---------------
epoch                                       294
replay_buffer/size                       296000
trainer/num train calls                  295000
trainer/QF1 Loss                              5.14175
trainer/QF2 Loss                              4.46466
trainer/Policy Loss                        -368.885
trainer/Q1 Predictions Mean                 369.471
trainer/Q1 Predictions Std                  102.432
trainer/Q1 Predictions Max                  442.591
trainer/Q1 Predictions Min                   17.9
trainer/Q2 Predictions Mean                 369.146
trainer/Q2 Predictions Std                  102.22
trainer/Q2 Predictions Max                  442.812
trainer/Q2 Predictions Min                   18.7511
trainer/Q Targets Mean                      369.379
trainer/Q Targets Std                       102.37
trainer/Q Targets Max                       444.973
trainer/Q Targets Min                        18.5113
trainer/Log Pis Mean                          5.60002
trainer/Log Pis Std                           4.13465
trainer/Log Pis Max                          15.9255
trainer/Log Pis Min                          -4.18909
trainer/policy/mean Mean                      0.115507
trainer/policy/mean Std                       0.762078
trainer/policy/mean Max                       0.997792
trainer/policy/mean Min                      -0.99599
trainer/policy/normal/std Mean                0.447765
trainer/policy/normal/std Std                 0.140052
trainer/policy/normal/std Max                 0.888883
trainer/policy/normal/std Min                 0.072799
trainer/policy/normal/log_std Mean           -0.867588
trainer/policy/normal/log_std Std             0.393115
trainer/policy/normal/log_std Max            -0.11779
trainer/policy/normal/log_std Min            -2.62005
trainer/Alpha                                 0.13141
trainer/Alpha Loss                           -0.811727
expl/num steps total                     296000
expl/num paths total                        296
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.59804
expl/Rewards Std                              1.29366
expl/Rewards Max                              8.21068
expl/Rewards Min                             -0.53755
expl/Returns Mean                          5598.04
expl/Returns Std                              0
expl/Returns Max                           5598.04
expl/Returns Min                           5598.04
expl/Actions Mean                             0.117377
expl/Actions Std                              0.799663
expl/Actions Max                              0.999521
expl/Actions Min                             -0.999595
expl/Num Paths                                1
expl/Average Returns                       5598.04
expl/env_infos/final/reward_run Mean          5.93045
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.93045
expl/env_infos/final/reward_run Min           5.93045
expl/env_infos/initial/reward_run Mean       -0.104839
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.104839
expl/env_infos/initial/reward_run Min        -0.104839
expl/env_infos/reward_run Mean                5.98998
expl/env_infos/reward_run Std                 1.28321
expl/env_infos/reward_run Max                 8.68287
expl/env_infos/reward_run Min                -0.166017
expl/env_infos/final/reward_ctrl Mean        -0.486071
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.486071
expl/env_infos/final/reward_ctrl Min         -0.486071
expl/env_infos/initial/reward_ctrl Mean      -0.198185
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.198185
expl/env_infos/initial/reward_ctrl Min       -0.198185
expl/env_infos/reward_ctrl Mean              -0.391943
expl/env_infos/reward_ctrl Std                0.0974278
expl/env_infos/reward_ctrl Max               -0.0550222
expl/env_infos/reward_ctrl Min               -0.575406
eval/num steps total                          1.475e+06
eval/num paths total                       1475
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.85137
eval/Rewards Std                              1.28919
eval/Rewards Max                              8.36699
eval/Rewards Min                             -0.719896
eval/Returns Mean                          5851.37
eval/Returns Std                             26.1453
eval/Returns Max                           5882.4
eval/Returns Min                           5811.04
eval/Actions Mean                             0.125497
eval/Actions Std                              0.815144
eval/Actions Max                              0.996779
eval/Actions Min                             -0.996255
eval/Num Paths                                5
eval/Average Returns                       5851.37
eval/env_infos/final/reward_run Mean          6.63579
eval/env_infos/final/reward_run Std           0.967478
eval/env_infos/final/reward_run Max           7.86221
eval/env_infos/final/reward_run Min           5.30017
eval/env_infos/initial/reward_run Mean       -0.0398658
eval/env_infos/initial/reward_run Std         0.271289
eval/env_infos/initial/reward_run Max         0.350694
eval/env_infos/initial/reward_run Min        -0.501348
eval/env_infos/reward_run Mean                6.25949
eval/env_infos/reward_run Std                 1.27607
eval/env_infos/reward_run Max                 8.84867
eval/env_infos/reward_run Min                -0.501348
eval/env_infos/final/reward_ctrl Mean        -0.489394
eval/env_infos/final/reward_ctrl Std          0.0569146
eval/env_infos/final/reward_ctrl Max         -0.383079
eval/env_infos/final/reward_ctrl Min         -0.540865
eval/env_infos/initial/reward_ctrl Mean      -0.193907
eval/env_infos/initial/reward_ctrl Std        0.0638176
eval/env_infos/initial/reward_ctrl Max       -0.0712008
eval/env_infos/initial/reward_ctrl Min       -0.255833
eval/env_infos/reward_ctrl Mean              -0.408125
eval/env_infos/reward_ctrl Std                0.0966664
eval/env_infos/reward_ctrl Max               -0.0712008
eval/env_infos/reward_ctrl Min               -0.580926
time/data storing (s)                         0.00446316
time/evaluation sampling (s)                  2.01198
time/exploration sampling (s)                 0.532421
time/logging (s)                              0.0136537
time/sac training (s)                         7.37394
time/saving (s)                               0.00378654
time/training (s)                             3.4057e-05
time/epoch (s)                                9.94028
time/total (s)                             3129.6
Epoch                                       294
---------------------------------------  ---------------
2021-11-24 01:21:34.346287 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 295 finished
---------------------------------------  ---------------
epoch                                       295
replay_buffer/size                       297000
trainer/num train calls                  296000
trainer/QF1 Loss                              8.88811
trainer/QF2 Loss                              8.12153
trainer/Policy Loss                        -367.604
trainer/Q1 Predictions Mean                 368.005
trainer/Q1 Predictions Std                  104.302
trainer/Q1 Predictions Max                  453.899
trainer/Q1 Predictions Min                   16.9435
trainer/Q2 Predictions Mean                 368.298
trainer/Q2 Predictions Std                  104.377
trainer/Q2 Predictions Max                  452.445
trainer/Q2 Predictions Min                   17.069
trainer/Q Targets Mean                      368.617
trainer/Q Targets Std                       104.526
trainer/Q Targets Max                       453.834
trainer/Q Targets Min                        17.2989
trainer/Log Pis Mean                          5.96
trainer/Log Pis Std                           4.66254
trainer/Log Pis Max                          17.6157
trainer/Log Pis Min                          -9.04606
trainer/policy/mean Mean                      0.0584583
trainer/policy/mean Std                       0.7775
trainer/policy/mean Max                       0.999642
trainer/policy/mean Min                      -0.995679
trainer/policy/normal/std Mean                0.449069
trainer/policy/normal/std Std                 0.148184
trainer/policy/normal/std Max                 1.02841
trainer/policy/normal/std Min                 0.075661
trainer/policy/normal/log_std Mean           -0.871569
trainer/policy/normal/log_std Std             0.413789
trainer/policy/normal/log_std Max             0.0280176
trainer/policy/normal/log_std Min            -2.58149
trainer/Alpha                                 0.133403
trainer/Alpha Loss                           -0.0805657
expl/num steps total                     297000
expl/num paths total                        297
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.67589
expl/Rewards Std                              1.24107
expl/Rewards Max                              7.91197
expl/Rewards Min                             -0.448896
expl/Returns Mean                          5675.89
expl/Returns Std                              0
expl/Returns Max                           5675.89
expl/Returns Min                           5675.89
expl/Actions Mean                             0.0789893
expl/Actions Std                              0.809747
expl/Actions Max                              0.999441
expl/Actions Min                             -0.999237
expl/Num Paths                                1
expl/Average Returns                       5675.89
expl/env_infos/final/reward_run Mean          7.06761
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.06761
expl/env_infos/final/reward_run Min           7.06761
expl/env_infos/initial/reward_run Mean       -0.103015
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.103015
expl/env_infos/initial/reward_run Min        -0.103015
expl/env_infos/reward_run Mean                6.07304
expl/env_infos/reward_run Std                 1.23095
expl/env_infos/reward_run Max                 8.45907
expl/env_infos/reward_run Min                -0.103015
expl/env_infos/final/reward_ctrl Mean        -0.431561
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.431561
expl/env_infos/final/reward_ctrl Min         -0.431561
expl/env_infos/initial/reward_ctrl Mean      -0.345881
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.345881
expl/env_infos/initial/reward_ctrl Min       -0.345881
expl/env_infos/reward_ctrl Mean              -0.397158
expl/env_infos/reward_ctrl Std                0.0958777
expl/env_infos/reward_ctrl Max               -0.0918005
expl/env_infos/reward_ctrl Min               -0.572933
eval/num steps total                          1.48e+06
eval/num paths total                       1480
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.86799
eval/Rewards Std                              1.26997
eval/Rewards Max                              8.34394
eval/Rewards Min                             -0.774312
eval/Returns Mean                          5867.99
eval/Returns Std                             57.5753
eval/Returns Max                           5952.68
eval/Returns Min                           5792.66
eval/Actions Mean                             0.0877563
eval/Actions Std                              0.821087
eval/Actions Max                              0.996842
eval/Actions Min                             -0.995478
eval/Num Paths                                5
eval/Average Returns                       5867.99
eval/env_infos/final/reward_run Mean          6.88025
eval/env_infos/final/reward_run Std           0.564639
eval/env_infos/final/reward_run Max           7.58295
eval/env_infos/final/reward_run Min           6.17442
eval/env_infos/initial/reward_run Mean       -0.22468
eval/env_infos/initial/reward_run Std         0.11456
eval/env_infos/initial/reward_run Max        -0.0780346
eval/env_infos/initial/reward_run Min        -0.399639
eval/env_infos/reward_run Mean                6.27712
eval/env_infos/reward_run Std                 1.25585
eval/env_infos/reward_run Max                 8.83705
eval/env_infos/reward_run Min                -0.399639
eval/env_infos/final/reward_ctrl Mean        -0.404641
eval/env_infos/final/reward_ctrl Std          0.0826451
eval/env_infos/final/reward_ctrl Max         -0.244141
eval/env_infos/final/reward_ctrl Min         -0.468056
eval/env_infos/initial/reward_ctrl Mean      -0.306913
eval/env_infos/initial/reward_ctrl Std        0.0591054
eval/env_infos/initial/reward_ctrl Max       -0.230889
eval/env_infos/initial/reward_ctrl Min       -0.378328
eval/env_infos/reward_ctrl Mean              -0.409131
eval/env_infos/reward_ctrl Std                0.0975364
eval/env_infos/reward_ctrl Max               -0.0930069
eval/env_infos/reward_ctrl Min               -0.584551
time/data storing (s)                         0.00451405
time/evaluation sampling (s)                  2.01592
time/exploration sampling (s)                 0.532378
time/logging (s)                              0.0136309
time/sac training (s)                         7.42208
time/saving (s)                               0.00376906
time/training (s)                             3.4289e-05
time/epoch (s)                                9.99233
time/total (s)                             3139.87
Epoch                                       295
---------------------------------------  ---------------
2021-11-24 01:21:44.582660 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 296 finished
---------------------------------------  ---------------
epoch                                       296
replay_buffer/size                       298000
trainer/num train calls                  297000
trainer/QF1 Loss                              7.12185
trainer/QF2 Loss                              7.30851
trainer/Policy Loss                        -380.865
trainer/Q1 Predictions Mean                 381.688
trainer/Q1 Predictions Std                   92.5055
trainer/Q1 Predictions Max                  454.081
trainer/Q1 Predictions Min                   18.3045
trainer/Q2 Predictions Mean                 381.471
trainer/Q2 Predictions Std                   92.4036
trainer/Q2 Predictions Max                  453.551
trainer/Q2 Predictions Min                   18.7748
trainer/Q Targets Mean                      381
trainer/Q Targets Std                        92.6298
trainer/Q Targets Max                       450.334
trainer/Q Targets Min                        19.2291
trainer/Log Pis Mean                          6.41405
trainer/Log Pis Std                           4.54594
trainer/Log Pis Max                          16.5628
trainer/Log Pis Min                          -6.11792
trainer/policy/mean Mean                      0.0638295
trainer/policy/mean Std                       0.78832
trainer/policy/mean Max                       0.996896
trainer/policy/mean Min                      -0.997673
trainer/policy/normal/std Mean                0.424821
trainer/policy/normal/std Std                 0.145732
trainer/policy/normal/std Max                 0.988662
trainer/policy/normal/std Min                 0.067045
trainer/policy/normal/log_std Mean           -0.931723
trainer/policy/normal/log_std Std             0.426473
trainer/policy/normal/log_std Max            -0.0114028
trainer/policy/normal/log_std Min            -2.70239
trainer/Alpha                                 0.13254
trainer/Alpha Loss                            0.836741
expl/num steps total                     298000
expl/num paths total                        298
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.6825
expl/Rewards Std                              1.21479
expl/Rewards Max                              7.99769
expl/Rewards Min                             -0.759998
expl/Returns Mean                          5682.5
expl/Returns Std                              0
expl/Returns Max                           5682.5
expl/Returns Min                           5682.5
expl/Actions Mean                             0.0932734
expl/Actions Std                              0.807086
expl/Actions Max                              0.999602
expl/Actions Min                             -0.998149
expl/Num Paths                                1
expl/Average Returns                       5682.5
expl/env_infos/final/reward_run Mean          5.62203
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.62203
expl/env_infos/final/reward_run Min           5.62203
expl/env_infos/initial/reward_run Mean       -0.469496
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.469496
expl/env_infos/initial/reward_run Min        -0.469496
expl/env_infos/reward_run Mean                6.07856
expl/env_infos/reward_run Std                 1.20511
expl/env_infos/reward_run Max                 8.45612
expl/env_infos/reward_run Min                -0.469496
expl/env_infos/final/reward_ctrl Mean        -0.378405
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.378405
expl/env_infos/final/reward_ctrl Min         -0.378405
expl/env_infos/initial/reward_ctrl Mean      -0.290502
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.290502
expl/env_infos/initial/reward_ctrl Min       -0.290502
expl/env_infos/reward_ctrl Mean              -0.396053
expl/env_infos/reward_ctrl Std                0.0947926
expl/env_infos/reward_ctrl Max               -0.107366
expl/env_infos/reward_ctrl Min               -0.581696
eval/num steps total                          1.485e+06
eval/num paths total                       1485
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.84153
eval/Rewards Std                              1.25009
eval/Rewards Max                              8.37066
eval/Rewards Min                             -0.904346
eval/Returns Mean                          5841.53
eval/Returns Std                            110.061
eval/Returns Max                           5990.85
eval/Returns Min                           5719.84
eval/Actions Mean                             0.0930173
eval/Actions Std                              0.819538
eval/Actions Max                              0.995978
eval/Actions Min                             -0.995213
eval/Num Paths                                5
eval/Average Returns                       5841.53
eval/env_infos/final/reward_run Mean          7.08862
eval/env_infos/final/reward_run Std           0.947127
eval/env_infos/final/reward_run Max           8.25852
eval/env_infos/final/reward_run Min           5.85037
eval/env_infos/initial/reward_run Mean       -0.394951
eval/env_infos/initial/reward_run Std         0.128613
eval/env_infos/initial/reward_run Max        -0.187006
eval/env_infos/initial/reward_run Min        -0.550569
eval/env_infos/reward_run Mean                6.2497
eval/env_infos/reward_run Std                 1.24046
eval/env_infos/reward_run Max                 8.84521
eval/env_infos/reward_run Min                -0.550569
eval/env_infos/final/reward_ctrl Mean        -0.458544
eval/env_infos/final/reward_ctrl Std          0.0397865
eval/env_infos/final/reward_ctrl Max         -0.406313
eval/env_infos/final/reward_ctrl Min         -0.513484
eval/env_infos/initial/reward_ctrl Mean      -0.304413
eval/env_infos/initial/reward_ctrl Std        0.0321028
eval/env_infos/initial/reward_ctrl Max       -0.264063
eval/env_infos/initial/reward_ctrl Min       -0.353776
eval/env_infos/reward_ctrl Mean              -0.408177
eval/env_infos/reward_ctrl Std                0.0936538
eval/env_infos/reward_ctrl Max               -0.0894491
eval/env_infos/reward_ctrl Min               -0.578127
time/data storing (s)                         0.00450851
time/evaluation sampling (s)                  2.00122
time/exploration sampling (s)                 0.535525
time/logging (s)                              0.0135929
time/sac training (s)                         7.38295
time/saving (s)                               0.00376325
time/training (s)                             3.456e-05
time/epoch (s)                                9.94159
time/total (s)                             3150.09
Epoch                                       296
---------------------------------------  ---------------
2021-11-24 01:21:54.986122 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 297 finished
---------------------------------------  ---------------
epoch                                       297
replay_buffer/size                       299000
trainer/num train calls                  298000
trainer/QF1 Loss                              5.90096
trainer/QF2 Loss                              5.56291
trainer/Policy Loss                        -374.828
trainer/Q1 Predictions Mean                 375.246
trainer/Q1 Predictions Std                   95.3447
trainer/Q1 Predictions Max                  454.933
trainer/Q1 Predictions Min                   18.1993
trainer/Q2 Predictions Mean                 375.334
trainer/Q2 Predictions Std                   95.436
trainer/Q2 Predictions Max                  452.482
trainer/Q2 Predictions Min                   18.4827
trainer/Q Targets Mean                      375.325
trainer/Q Targets Std                        95.5476
trainer/Q Targets Max                       452.922
trainer/Q Targets Min                        18.1891
trainer/Log Pis Mean                          5.88114
trainer/Log Pis Std                           4.43131
trainer/Log Pis Max                          14.832
trainer/Log Pis Min                          -4.82767
trainer/policy/mean Mean                      0.0748294
trainer/policy/mean Std                       0.763621
trainer/policy/mean Max                       0.997344
trainer/policy/mean Min                      -0.995317
trainer/policy/normal/std Mean                0.431114
trainer/policy/normal/std Std                 0.145319
trainer/policy/normal/std Max                 0.836078
trainer/policy/normal/std Min                 0.0668695
trainer/policy/normal/log_std Mean           -0.917222
trainer/policy/normal/log_std Std             0.428875
trainer/policy/normal/log_std Max            -0.179034
trainer/policy/normal/log_std Min            -2.70501
trainer/Alpha                                 0.13355
trainer/Alpha Loss                           -0.23929
expl/num steps total                     299000
expl/num paths total                        299
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.59485
expl/Rewards Std                              1.20311
expl/Rewards Max                              7.8711
expl/Rewards Min                             -0.696473
expl/Returns Mean                          5594.85
expl/Returns Std                              0
expl/Returns Max                           5594.85
expl/Returns Min                           5594.85
expl/Actions Mean                             0.103512
expl/Actions Std                              0.802976
expl/Actions Max                              0.999336
expl/Actions Min                             -0.999437
expl/Num Paths                                1
expl/Average Returns                       5594.85
expl/env_infos/final/reward_run Mean          7.20765
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.20765
expl/env_infos/final/reward_run Min           7.20765
expl/env_infos/initial/reward_run Mean       -0.351451
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.351451
expl/env_infos/initial/reward_run Min        -0.351451
expl/env_infos/reward_run Mean                5.98814
expl/env_infos/reward_run Std                 1.19646
expl/env_infos/reward_run Max                 8.3397
expl/env_infos/reward_run Min                -0.351451
expl/env_infos/final/reward_ctrl Mean        -0.483124
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.483124
expl/env_infos/final/reward_ctrl Min         -0.483124
expl/env_infos/initial/reward_ctrl Mean      -0.345022
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.345022
expl/env_infos/initial/reward_ctrl Min       -0.345022
expl/env_infos/reward_ctrl Mean              -0.393291
expl/env_infos/reward_ctrl Std                0.0944293
expl/env_infos/reward_ctrl Max               -0.0539908
expl/env_infos/reward_ctrl Min               -0.579743
eval/num steps total                          1.49e+06
eval/num paths total                       1490
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.87216
eval/Rewards Std                              1.26565
eval/Rewards Max                              8.41284
eval/Rewards Min                             -0.580699
eval/Returns Mean                          5872.16
eval/Returns Std                             83.059
eval/Returns Max                           6002.12
eval/Returns Min                           5745.87
eval/Actions Mean                             0.102491
eval/Actions Std                              0.819059
eval/Actions Max                              0.996473
eval/Actions Min                             -0.994906
eval/Num Paths                                5
eval/Average Returns                       5872.16
eval/env_infos/final/reward_run Mean          6.72799
eval/env_infos/final/reward_run Std           0.880539
eval/env_infos/final/reward_run Max           8.07564
eval/env_infos/final/reward_run Min           5.7354
eval/env_infos/initial/reward_run Mean       -0.101047
eval/env_infos/initial/reward_run Std         0.124202
eval/env_infos/initial/reward_run Max         0.0646222
eval/env_infos/initial/reward_run Min        -0.252419
eval/env_infos/reward_run Mean                6.28098
eval/env_infos/reward_run Std                 1.26178
eval/env_infos/reward_run Max                 8.91251
eval/env_infos/reward_run Min                -0.252419
eval/env_infos/final/reward_ctrl Mean        -0.418264
eval/env_infos/final/reward_ctrl Std          0.0363888
eval/env_infos/final/reward_ctrl Max         -0.387367
eval/env_infos/final/reward_ctrl Min         -0.482186
eval/env_infos/initial/reward_ctrl Mean      -0.226225
eval/env_infos/initial/reward_ctrl Std        0.0615713
eval/env_infos/initial/reward_ctrl Max       -0.138238
eval/env_infos/initial/reward_ctrl Min       -0.324965
eval/env_infos/reward_ctrl Mean              -0.408817
eval/env_infos/reward_ctrl Std                0.0923571
eval/env_infos/reward_ctrl Max               -0.0896167
eval/env_infos/reward_ctrl Min               -0.580066
time/data storing (s)                         0.00448628
time/evaluation sampling (s)                  2.01139
time/exploration sampling (s)                 0.533642
time/logging (s)                              0.0137536
time/sac training (s)                         7.5355
time/saving (s)                               0.00386194
time/training (s)                             4.5945e-05
time/epoch (s)                               10.1027
time/total (s)                             3160.48
Epoch                                       297
---------------------------------------  ---------------
2021-11-24 01:22:05.606642 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 298 finished
---------------------------------------  ---------------
epoch                                       298
replay_buffer/size                       300000
trainer/num train calls                  299000
trainer/QF1 Loss                              8.59469
trainer/QF2 Loss                              6.75339
trainer/Policy Loss                        -366.844
trainer/Q1 Predictions Mean                 366.953
trainer/Q1 Predictions Std                  107.516
trainer/Q1 Predictions Max                  450.205
trainer/Q1 Predictions Min                   16.1225
trainer/Q2 Predictions Mean                 367.105
trainer/Q2 Predictions Std                  107.338
trainer/Q2 Predictions Max                  446.996
trainer/Q2 Predictions Min                   14.8935
trainer/Q Targets Mean                      367.408
trainer/Q Targets Std                       107.51
trainer/Q Targets Max                       452.198
trainer/Q Targets Min                        14.5502
trainer/Log Pis Mean                          5.43929
trainer/Log Pis Std                           4.51569
trainer/Log Pis Max                          17.7527
trainer/Log Pis Min                          -6.42522
trainer/policy/mean Mean                      0.0784921
trainer/policy/mean Std                       0.767921
trainer/policy/mean Max                       0.996592
trainer/policy/mean Min                      -0.999419
trainer/policy/normal/std Mean                0.454729
trainer/policy/normal/std Std                 0.154984
trainer/policy/normal/std Max                 1.25962
trainer/policy/normal/std Min                 0.0746837
trainer/policy/normal/log_std Mean           -0.860767
trainer/policy/normal/log_std Std             0.414549
trainer/policy/normal/log_std Max             0.23081
trainer/policy/normal/log_std Min            -2.59449
trainer/Alpha                                 0.134907
trainer/Alpha Loss                           -1.12319
expl/num steps total                     300000
expl/num paths total                        300
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.75805
expl/Rewards Std                              1.25718
expl/Rewards Max                              7.98641
expl/Rewards Min                             -0.471233
expl/Returns Mean                          5758.05
expl/Returns Std                              0
expl/Returns Max                           5758.05
expl/Returns Min                           5758.05
expl/Actions Mean                             0.094618
expl/Actions Std                              0.805454
expl/Actions Max                              0.999767
expl/Actions Min                             -0.999963
expl/Num Paths                                1
expl/Average Returns                       5758.05
expl/env_infos/final/reward_run Mean          5.82736
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.82736
expl/env_infos/final/reward_run Min           5.82736
expl/env_infos/initial/reward_run Mean       -0.169716
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.169716
expl/env_infos/initial/reward_run Min        -0.169716
expl/env_infos/reward_run Mean                6.15267
expl/env_infos/reward_run Std                 1.25269
expl/env_infos/reward_run Max                 8.53072
expl/env_infos/reward_run Min                -0.169716
expl/env_infos/final/reward_ctrl Mean        -0.389422
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.389422
expl/env_infos/final/reward_ctrl Min         -0.389422
expl/env_infos/initial/reward_ctrl Mean      -0.301516
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.301516
expl/env_infos/initial/reward_ctrl Min       -0.301516
expl/env_infos/reward_ctrl Mean              -0.394625
expl/env_infos/reward_ctrl Std                0.0939
expl/env_infos/reward_ctrl Max               -0.0778002
expl/env_infos/reward_ctrl Min               -0.589073
eval/num steps total                          1.495e+06
eval/num paths total                       1495
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.8953
eval/Rewards Std                              1.27769
eval/Rewards Max                              8.30191
eval/Rewards Min                             -0.744906
eval/Returns Mean                          5895.3
eval/Returns Std                             57.4642
eval/Returns Max                           5937.13
eval/Returns Min                           5785.7
eval/Actions Mean                             0.102043
eval/Actions Std                              0.819826
eval/Actions Max                              0.998027
eval/Actions Min                             -0.997468
eval/Num Paths                                5
eval/Average Returns                       5895.3
eval/env_infos/final/reward_run Mean          7.13714
eval/env_infos/final/reward_run Std           0.461297
eval/env_infos/final/reward_run Max           7.76302
eval/env_infos/final/reward_run Min           6.36946
eval/env_infos/initial/reward_run Mean       -0.273134
eval/env_infos/initial/reward_run Std         0.167461
eval/env_infos/initial/reward_run Max        -0.0103384
eval/env_infos/initial/reward_run Min        -0.533915
eval/env_infos/reward_run Mean                6.30481
eval/env_infos/reward_run Std                 1.26898
eval/env_infos/reward_run Max                 8.82241
eval/env_infos/reward_run Min                -0.533915
eval/env_infos/final/reward_ctrl Mean        -0.407813
eval/env_infos/final/reward_ctrl Std          0.100297
eval/env_infos/final/reward_ctrl Max         -0.228436
eval/env_infos/final/reward_ctrl Min         -0.527794
eval/env_infos/initial/reward_ctrl Mean      -0.236264
eval/env_infos/initial/reward_ctrl Std        0.0327774
eval/env_infos/initial/reward_ctrl Max       -0.210991
eval/env_infos/initial/reward_ctrl Min       -0.29962
eval/env_infos/reward_ctrl Mean              -0.409516
eval/env_infos/reward_ctrl Std                0.0930539
eval/env_infos/reward_ctrl Max               -0.0853913
eval/env_infos/reward_ctrl Min               -0.586354
time/data storing (s)                         0.00454622
time/evaluation sampling (s)                  2.02645
time/exploration sampling (s)                 0.548718
time/logging (s)                              0.0137512
time/sac training (s)                         7.71677
time/saving (s)                               0.00383689
time/training (s)                             3.5364e-05
time/epoch (s)                               10.3141
time/total (s)                             3171.09
Epoch                                       298
---------------------------------------  ---------------
2021-11-24 01:22:16.259233 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 299 finished
---------------------------------------  ---------------
epoch                                       299
replay_buffer/size                       301000
trainer/num train calls                  300000
trainer/QF1 Loss                              6.86223
trainer/QF2 Loss                              7.19772
trainer/Policy Loss                        -363.221
trainer/Q1 Predictions Mean                 363.43
trainer/Q1 Predictions Std                  109.988
trainer/Q1 Predictions Max                  444.325
trainer/Q1 Predictions Min                   17.1701
trainer/Q2 Predictions Mean                 363.595
trainer/Q2 Predictions Std                  110.059
trainer/Q2 Predictions Max                  444.255
trainer/Q2 Predictions Min                   18.0505
trainer/Q Targets Mean                      363.8
trainer/Q Targets Std                       109.983
trainer/Q Targets Max                       445.368
trainer/Q Targets Min                        17.7249
trainer/Log Pis Mean                          5.50685
trainer/Log Pis Std                           4.32142
trainer/Log Pis Max                          18.413
trainer/Log Pis Min                          -6.35879
trainer/policy/mean Mean                      0.0641107
trainer/policy/mean Std                       0.768965
trainer/policy/mean Max                       0.999957
trainer/policy/mean Min                      -0.996136
trainer/policy/normal/std Mean                0.445649
trainer/policy/normal/std Std                 0.154452
trainer/policy/normal/std Max                 1.59979
trainer/policy/normal/std Min                 0.0770334
trainer/policy/normal/log_std Mean           -0.880251
trainer/policy/normal/log_std Std             0.409708
trainer/policy/normal/log_std Max             0.469875
trainer/policy/normal/log_std Min            -2.56352
trainer/Alpha                                 0.133303
trainer/Alpha Loss                           -0.99377
expl/num steps total                     301000
expl/num paths total                        301
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.41555
expl/Rewards Std                              1.14987
expl/Rewards Max                              7.56707
expl/Rewards Min                             -0.673422
expl/Returns Mean                          5415.55
expl/Returns Std                              0
expl/Returns Max                           5415.55
expl/Returns Min                           5415.55
expl/Actions Mean                             0.0825216
expl/Actions Std                              0.806641
expl/Actions Max                              0.998694
expl/Actions Min                             -0.99929
expl/Num Paths                                1
expl/Average Returns                       5415.55
expl/env_infos/final/reward_run Mean          4.82332
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.82332
expl/env_infos/final/reward_run Min           4.82332
expl/env_infos/initial/reward_run Mean       -0.318348
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.318348
expl/env_infos/initial/reward_run Min        -0.318348
expl/env_infos/reward_run Mean                5.81003
expl/env_infos/reward_run Std                 1.13918
expl/env_infos/reward_run Max                 8.0701
expl/env_infos/reward_run Min                -0.360677
expl/env_infos/final/reward_ctrl Mean        -0.413847
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.413847
expl/env_infos/final/reward_ctrl Min         -0.413847
expl/env_infos/initial/reward_ctrl Mean      -0.208088
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.208088
expl/env_infos/initial/reward_ctrl Min       -0.208088
expl/env_infos/reward_ctrl Mean              -0.394488
expl/env_infos/reward_ctrl Std                0.0921547
expl/env_infos/reward_ctrl Max               -0.0731567
expl/env_infos/reward_ctrl Min               -0.574083
eval/num steps total                          1.5e+06
eval/num paths total                       1500
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.84516
eval/Rewards Std                              1.25486
eval/Rewards Max                              8.35155
eval/Rewards Min                             -0.840216
eval/Returns Mean                          5845.16
eval/Returns Std                             30.4775
eval/Returns Max                           5887.63
eval/Returns Min                           5818.53
eval/Actions Mean                             0.0937032
eval/Actions Std                              0.825009
eval/Actions Max                              0.997266
eval/Actions Min                             -0.995871
eval/Num Paths                                5
eval/Average Returns                       5845.16
eval/env_infos/final/reward_run Mean          6.7289
eval/env_infos/final/reward_run Std           0.332447
eval/env_infos/final/reward_run Max           7.25514
eval/env_infos/final/reward_run Min           6.3133
eval/env_infos/initial/reward_run Mean       -0.239437
eval/env_infos/initial/reward_run Std         0.175806
eval/env_infos/initial/reward_run Max        -0.0109645
eval/env_infos/initial/reward_run Min        -0.498113
eval/env_infos/reward_run Mean                6.25881
eval/env_infos/reward_run Std                 1.2463
eval/env_infos/reward_run Max                 8.85314
eval/env_infos/reward_run Min                -0.498113
eval/env_infos/final/reward_ctrl Mean        -0.45782
eval/env_infos/final/reward_ctrl Std          0.0341215
eval/env_infos/final/reward_ctrl Max         -0.401619
eval/env_infos/final/reward_ctrl Min         -0.505565
eval/env_infos/initial/reward_ctrl Mean      -0.265155
eval/env_infos/initial/reward_ctrl Std        0.0452157
eval/env_infos/initial/reward_ctrl Max       -0.215305
eval/env_infos/initial/reward_ctrl Min       -0.342103
eval/env_infos/reward_ctrl Mean              -0.413652
eval/env_infos/reward_ctrl Std                0.0886383
eval/env_infos/reward_ctrl Max               -0.102416
eval/env_infos/reward_ctrl Min               -0.583206
time/data storing (s)                         0.00449601
time/evaluation sampling (s)                  2.12332
time/exploration sampling (s)                 0.53888
time/logging (s)                              0.0138292
time/sac training (s)                         7.66294
time/saving (s)                               0.0038322
time/training (s)                             3.5797e-05
time/epoch (s)                               10.3473
time/total (s)                             3181.73
Epoch                                       299
---------------------------------------  ---------------
2021-11-24 01:22:26.956857 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 300 finished
---------------------------------------  ---------------
epoch                                       300
replay_buffer/size                       302000
trainer/num train calls                  301000
trainer/QF1 Loss                              8.81004
trainer/QF2 Loss                              5.81503
trainer/Policy Loss                        -374.311
trainer/Q1 Predictions Mean                 374.786
trainer/Q1 Predictions Std                  101.202
trainer/Q1 Predictions Max                  456.725
trainer/Q1 Predictions Min                   18.3214
trainer/Q2 Predictions Mean                 375.315
trainer/Q2 Predictions Std                  101.138
trainer/Q2 Predictions Max                  456.848
trainer/Q2 Predictions Min                   17.9834
trainer/Q Targets Mean                      374.286
trainer/Q Targets Std                       100.935
trainer/Q Targets Max                       457.474
trainer/Q Targets Min                        17.8996
trainer/Log Pis Mean                          6.04376
trainer/Log Pis Std                           4.46699
trainer/Log Pis Max                          21.359
trainer/Log Pis Min                          -7.3397
trainer/policy/mean Mean                      0.0770412
trainer/policy/mean Std                       0.782741
trainer/policy/mean Max                       0.999011
trainer/policy/mean Min                      -0.997869
trainer/policy/normal/std Mean                0.439166
trainer/policy/normal/std Std                 0.145452
trainer/policy/normal/std Max                 1.09484
trainer/policy/normal/std Min                 0.0693152
trainer/policy/normal/log_std Mean           -0.893824
trainer/policy/normal/log_std Std             0.413261
trainer/policy/normal/log_std Max             0.090609
trainer/policy/normal/log_std Min            -2.66909
trainer/Alpha                                 0.132645
trainer/Alpha Loss                            0.0883978
expl/num steps total                     302000
expl/num paths total                        302
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.70203
expl/Rewards Std                              1.21457
expl/Rewards Max                              7.85269
expl/Rewards Min                             -0.623777
expl/Returns Mean                          5702.03
expl/Returns Std                              0
expl/Returns Max                           5702.03
expl/Returns Min                           5702.03
expl/Actions Mean                             0.0924816
expl/Actions Std                              0.804531
expl/Actions Max                              0.999389
expl/Actions Min                             -0.998827
expl/Num Paths                                1
expl/Average Returns                       5702.03
expl/env_infos/final/reward_run Mean          6.71063
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.71063
expl/env_infos/final/reward_run Min           6.71063
expl/env_infos/initial/reward_run Mean       -0.355955
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.355955
expl/env_infos/initial/reward_run Min        -0.355955
expl/env_infos/reward_run Mean                6.09552
expl/env_infos/reward_run Std                 1.20386
expl/env_infos/reward_run Max                 8.30089
expl/env_infos/reward_run Min                -0.355955
expl/env_infos/final/reward_ctrl Mean        -0.51874
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.51874
expl/env_infos/final/reward_ctrl Min         -0.51874
expl/env_infos/initial/reward_ctrl Mean      -0.267822
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.267822
expl/env_infos/initial/reward_ctrl Min       -0.267822
expl/env_infos/reward_ctrl Mean              -0.393494
expl/env_infos/reward_ctrl Std                0.0937423
expl/env_infos/reward_ctrl Max               -0.0899643
expl/env_infos/reward_ctrl Min               -0.58588
eval/num steps total                          1.505e+06
eval/num paths total                       1505
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.88798
eval/Rewards Std                              1.26116
eval/Rewards Max                              8.34294
eval/Rewards Min                             -0.651115
eval/Returns Mean                          5887.98
eval/Returns Std                             40.3768
eval/Returns Max                           5937.09
eval/Returns Min                           5827.21
eval/Actions Mean                             0.0970687
eval/Actions Std                              0.818357
eval/Actions Max                              0.996913
eval/Actions Min                             -0.995835
eval/Num Paths                                5
eval/Average Returns                       5887.98
eval/env_infos/final/reward_run Mean          6.35179
eval/env_infos/final/reward_run Std           0.376965
eval/env_infos/final/reward_run Max           6.90589
eval/env_infos/final/reward_run Min           5.79051
eval/env_infos/initial/reward_run Mean       -0.241079
eval/env_infos/initial/reward_run Std         0.122557
eval/env_infos/initial/reward_run Max        -0.011858
eval/env_infos/initial/reward_run Min        -0.35979
eval/env_infos/reward_run Mean                6.29546
eval/env_infos/reward_run Std                 1.25298
eval/env_infos/reward_run Max                 8.8483
eval/env_infos/reward_run Min                -0.35979
eval/env_infos/final/reward_ctrl Mean        -0.45521
eval/env_infos/final/reward_ctrl Std          0.0576866
eval/env_infos/final/reward_ctrl Max         -0.344666
eval/env_infos/final/reward_ctrl Min         -0.503791
eval/env_infos/initial/reward_ctrl Mean      -0.286391
eval/env_infos/initial/reward_ctrl Std        0.0296488
eval/env_infos/initial/reward_ctrl Max       -0.247467
eval/env_infos/initial/reward_ctrl Min       -0.334417
eval/env_infos/reward_ctrl Mean              -0.407479
eval/env_infos/reward_ctrl Std                0.0921732
eval/env_infos/reward_ctrl Max               -0.0984027
eval/env_infos/reward_ctrl Min               -0.583614
time/data storing (s)                         0.00459346
time/evaluation sampling (s)                  2.06503
time/exploration sampling (s)                 0.55075
time/logging (s)                              0.0194686
time/sac training (s)                         7.7478
time/saving (s)                               0.00480675
time/training (s)                             4.2943e-05
time/epoch (s)                               10.3925
time/total (s)                             3192.42
Epoch                                       300
---------------------------------------  ---------------
2021-11-24 01:22:37.535468 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 301 finished
---------------------------------------  ---------------
epoch                                       301
replay_buffer/size                       303000
trainer/num train calls                  302000
trainer/QF1 Loss                              5.88049
trainer/QF2 Loss                              5.46314
trainer/Policy Loss                        -363.881
trainer/Q1 Predictions Mean                 364.474
trainer/Q1 Predictions Std                  111.735
trainer/Q1 Predictions Max                  448.776
trainer/Q1 Predictions Min                   18.3964
trainer/Q2 Predictions Mean                 364.264
trainer/Q2 Predictions Std                  111.68
trainer/Q2 Predictions Max                  448.377
trainer/Q2 Predictions Min                   18.1314
trainer/Q Targets Mean                      364.14
trainer/Q Targets Std                       111.672
trainer/Q Targets Max                       448.342
trainer/Q Targets Min                        18.0091
trainer/Log Pis Mean                          5.57771
trainer/Log Pis Std                           4.33729
trainer/Log Pis Max                          16.6369
trainer/Log Pis Min                          -5.22853
trainer/policy/mean Mean                      0.0915551
trainer/policy/mean Std                       0.764344
trainer/policy/mean Max                       0.996699
trainer/policy/mean Min                      -0.996554
trainer/policy/normal/std Mean                0.441147
trainer/policy/normal/std Std                 0.142536
trainer/policy/normal/std Max                 0.855205
trainer/policy/normal/std Min                 0.081662
trainer/policy/normal/log_std Mean           -0.884839
trainer/policy/normal/log_std Std             0.397057
trainer/policy/normal/log_std Max            -0.156414
trainer/policy/normal/log_std Min            -2.50517
trainer/Alpha                                 0.13522
trainer/Alpha Loss                           -0.844934
expl/num steps total                     303000
expl/num paths total                        303
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.52846
expl/Rewards Std                              1.18982
expl/Rewards Max                              7.80242
expl/Rewards Min                             -0.602999
expl/Returns Mean                          5528.46
expl/Returns Std                              0
expl/Returns Max                           5528.46
expl/Returns Min                           5528.46
expl/Actions Mean                             0.120554
expl/Actions Std                              0.789226
expl/Actions Max                              0.999573
expl/Actions Min                             -0.99979
expl/Num Paths                                1
expl/Average Returns                       5528.46
expl/env_infos/final/reward_run Mean          6.80653
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.80653
expl/env_infos/final/reward_run Min           6.80653
expl/env_infos/initial/reward_run Mean       -0.118516
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.118516
expl/env_infos/initial/reward_run Min        -0.118516
expl/env_infos/reward_run Mean                5.9109
expl/env_infos/reward_run Std                 1.18233
expl/env_infos/reward_run Max                 8.30878
expl/env_infos/reward_run Min                -0.183178
expl/env_infos/final/reward_ctrl Mean        -0.442164
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.442164
expl/env_infos/final/reward_ctrl Min         -0.442164
expl/env_infos/initial/reward_ctrl Mean      -0.385911
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.385911
expl/env_infos/initial/reward_ctrl Min       -0.385911
expl/env_infos/reward_ctrl Mean              -0.382446
expl/env_infos/reward_ctrl Std                0.0907566
expl/env_infos/reward_ctrl Max               -0.108943
expl/env_infos/reward_ctrl Min               -0.576504
eval/num steps total                          1.51e+06
eval/num paths total                       1510
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.84775
eval/Rewards Std                              1.26881
eval/Rewards Max                              8.25507
eval/Rewards Min                             -0.599448
eval/Returns Mean                          5847.75
eval/Returns Std                             57.4398
eval/Returns Max                           5910.5
eval/Returns Min                           5749.32
eval/Actions Mean                             0.116435
eval/Actions Std                              0.806639
eval/Actions Max                              0.996599
eval/Actions Min                             -0.994432
eval/Num Paths                                5
eval/Average Returns                       5847.75
eval/env_infos/final/reward_run Mean          6.24381
eval/env_infos/final/reward_run Std           0.893696
eval/env_infos/final/reward_run Max           7.25295
eval/env_infos/final/reward_run Min           4.98348
eval/env_infos/initial/reward_run Mean       -0.254925
eval/env_infos/initial/reward_run Std         0.0765134
eval/env_infos/initial/reward_run Max        -0.188883
eval/env_infos/initial/reward_run Min        -0.364553
eval/env_infos/reward_run Mean                6.24629
eval/env_infos/reward_run Std                 1.26384
eval/env_infos/reward_run Max                 8.76409
eval/env_infos/reward_run Min                -0.364553
eval/env_infos/final/reward_ctrl Mean        -0.455437
eval/env_infos/final/reward_ctrl Std          0.0371074
eval/env_infos/final/reward_ctrl Max         -0.393613
eval/env_infos/final/reward_ctrl Min         -0.500624
eval/env_infos/initial/reward_ctrl Mean      -0.223292
eval/env_infos/initial/reward_ctrl Std        0.0185828
eval/env_infos/initial/reward_ctrl Max       -0.204031
eval/env_infos/initial/reward_ctrl Min       -0.253734
eval/env_infos/reward_ctrl Mean              -0.398534
eval/env_infos/reward_ctrl Std                0.0917509
eval/env_infos/reward_ctrl Max               -0.101493
eval/env_infos/reward_ctrl Min               -0.579053
time/data storing (s)                         0.00450388
time/evaluation sampling (s)                  2.10783
time/exploration sampling (s)                 0.535971
time/logging (s)                              0.0136842
time/sac training (s)                         7.60437
time/saving (s)                               0.00379865
time/training (s)                             3.4581e-05
time/epoch (s)                               10.2702
time/total (s)                             3202.98
Epoch                                       301
---------------------------------------  ---------------
2021-11-24 01:22:48.124683 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 302 finished
---------------------------------------  ---------------
epoch                                       302
replay_buffer/size                       304000
trainer/num train calls                  303000
trainer/QF1 Loss                              6.91603
trainer/QF2 Loss                              7.7746
trainer/Policy Loss                        -365.033
trainer/Q1 Predictions Mean                 365.481
trainer/Q1 Predictions Std                  111.886
trainer/Q1 Predictions Max                  446.759
trainer/Q1 Predictions Min                   17.1872
trainer/Q2 Predictions Mean                 365.805
trainer/Q2 Predictions Std                  112.206
trainer/Q2 Predictions Max                  445.168
trainer/Q2 Predictions Min                   17.6509
trainer/Q Targets Mean                      365.505
trainer/Q Targets Std                       111.969
trainer/Q Targets Max                       444.112
trainer/Q Targets Min                        17.6842
trainer/Log Pis Mean                          5.93543
trainer/Log Pis Std                           4.63576
trainer/Log Pis Max                          16.4514
trainer/Log Pis Min                          -4.75833
trainer/policy/mean Mean                      0.0746675
trainer/policy/mean Std                       0.767644
trainer/policy/mean Max                       0.998677
trainer/policy/mean Min                      -0.998039
trainer/policy/normal/std Mean                0.450729
trainer/policy/normal/std Std                 0.14927
trainer/policy/normal/std Max                 1.25504
trainer/policy/normal/std Min                 0.0723569
trainer/policy/normal/log_std Mean           -0.866615
trainer/policy/normal/log_std Std             0.407862
trainer/policy/normal/log_std Max             0.227165
trainer/policy/normal/log_std Min            -2.62614
trainer/Alpha                                 0.134423
trainer/Alpha Loss                           -0.12958
expl/num steps total                     304000
expl/num paths total                        304
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.50717
expl/Rewards Std                              1.23536
expl/Rewards Max                              7.77232
expl/Rewards Min                             -0.360299
expl/Returns Mean                          5507.17
expl/Returns Std                              0
expl/Returns Max                           5507.17
expl/Returns Min                           5507.17
expl/Actions Mean                             0.100616
expl/Actions Std                              0.803268
expl/Actions Max                              0.999656
expl/Actions Min                             -0.999506
expl/Num Paths                                1
expl/Average Returns                       5507.17
expl/env_infos/final/reward_run Mean          6.37795
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.37795
expl/env_infos/final/reward_run Min           6.37795
expl/env_infos/initial/reward_run Mean       -0.170694
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.170694
expl/env_infos/initial/reward_run Min        -0.170694
expl/env_infos/reward_run Mean                5.90039
expl/env_infos/reward_run Std                 1.22833
expl/env_infos/reward_run Max                 8.28228
expl/env_infos/reward_run Min                -0.170694
expl/env_infos/final/reward_ctrl Mean        -0.454066
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.454066
expl/env_infos/final/reward_ctrl Min         -0.454066
expl/env_infos/initial/reward_ctrl Mean      -0.189605
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.189605
expl/env_infos/initial/reward_ctrl Min       -0.189605
expl/env_infos/reward_ctrl Mean              -0.393218
expl/env_infos/reward_ctrl Std                0.093286
expl/env_infos/reward_ctrl Max               -0.0236808
expl/env_infos/reward_ctrl Min               -0.590305
eval/num steps total                          1.515e+06
eval/num paths total                       1515
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.85022
eval/Rewards Std                              1.29807
eval/Rewards Max                              8.60897
eval/Rewards Min                             -0.701801
eval/Returns Mean                          5850.22
eval/Returns Std                             64.7501
eval/Returns Max                           5916.54
eval/Returns Min                           5771.06
eval/Actions Mean                             0.0996794
eval/Actions Std                              0.821513
eval/Actions Max                              0.996759
eval/Actions Min                             -0.996549
eval/Num Paths                                5
eval/Average Returns                       5850.22
eval/env_infos/final/reward_run Mean          7.2262
eval/env_infos/final/reward_run Std           0.657534
eval/env_infos/final/reward_run Max           8.01834
eval/env_infos/final/reward_run Min           6.3335
eval/env_infos/initial/reward_run Mean       -0.219935
eval/env_infos/initial/reward_run Std         0.129418
eval/env_infos/initial/reward_run Max        -0.00853065
eval/env_infos/initial/reward_run Min        -0.37624
eval/env_infos/reward_run Mean                6.26111
eval/env_infos/reward_run Std                 1.29056
eval/env_infos/reward_run Max                 9.10394
eval/env_infos/reward_run Min                -0.37624
eval/env_infos/final/reward_ctrl Mean        -0.399094
eval/env_infos/final/reward_ctrl Std          0.0508232
eval/env_infos/final/reward_ctrl Max         -0.307368
eval/env_infos/final/reward_ctrl Min         -0.462989
eval/env_infos/initial/reward_ctrl Mean      -0.283187
eval/env_infos/initial/reward_ctrl Std        0.0241185
eval/env_infos/initial/reward_ctrl Max       -0.255061
eval/env_infos/initial/reward_ctrl Min       -0.325561
eval/env_infos/reward_ctrl Mean              -0.410892
eval/env_infos/reward_ctrl Std                0.0889256
eval/env_infos/reward_ctrl Max               -0.0685068
eval/env_infos/reward_ctrl Min               -0.583994
time/data storing (s)                         0.00448586
time/evaluation sampling (s)                  2.06303
time/exploration sampling (s)                 0.517701
time/logging (s)                              0.0137003
time/sac training (s)                         7.67926
time/saving (s)                               0.00381107
time/training (s)                             3.4497e-05
time/epoch (s)                               10.282
time/total (s)                             3213.55
Epoch                                       302
---------------------------------------  ---------------
2021-11-24 01:22:58.620500 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 303 finished
---------------------------------------  ----------------
epoch                                       303
replay_buffer/size                       305000
trainer/num train calls                  304000
trainer/QF1 Loss                              8.34018
trainer/QF2 Loss                             10.8658
trainer/Policy Loss                        -379.94
trainer/Q1 Predictions Mean                 380.564
trainer/Q1 Predictions Std                   96.466
trainer/Q1 Predictions Max                  451.502
trainer/Q1 Predictions Min                   18.9529
trainer/Q2 Predictions Mean                 380.871
trainer/Q2 Predictions Std                   96.5967
trainer/Q2 Predictions Max                  451.413
trainer/Q2 Predictions Min                   18.2453
trainer/Q Targets Mean                      380.544
trainer/Q Targets Std                        96.3161
trainer/Q Targets Max                       448.862
trainer/Q Targets Min                        18.3051
trainer/Log Pis Mean                          6.09385
trainer/Log Pis Std                           4.46377
trainer/Log Pis Max                          15.1481
trainer/Log Pis Min                          -7.13019
trainer/policy/mean Mean                      0.0740458
trainer/policy/mean Std                       0.780525
trainer/policy/mean Max                       0.995147
trainer/policy/mean Min                      -0.998575
trainer/policy/normal/std Mean                0.441547
trainer/policy/normal/std Std                 0.142991
trainer/policy/normal/std Max                 1.01366
trainer/policy/normal/std Min                 0.0705819
trainer/policy/normal/log_std Mean           -0.887686
trainer/policy/normal/log_std Std             0.413598
trainer/policy/normal/log_std Max             0.013569
trainer/policy/normal/log_std Min            -2.65098
trainer/Alpha                                 0.13673
trainer/Alpha Loss                            0.186736
expl/num steps total                     305000
expl/num paths total                        305
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.58166
expl/Rewards Std                              1.19183
expl/Rewards Max                              7.8924
expl/Rewards Min                             -0.276226
expl/Returns Mean                          5581.66
expl/Returns Std                              0
expl/Returns Max                           5581.66
expl/Returns Min                           5581.66
expl/Actions Mean                             0.0907557
expl/Actions Std                              0.806802
expl/Actions Max                              0.999764
expl/Actions Min                             -0.998717
expl/Num Paths                                1
expl/Average Returns                       5581.66
expl/env_infos/final/reward_run Mean          7.73995
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.73995
expl/env_infos/final/reward_run Min           7.73995
expl/env_infos/initial/reward_run Mean        0.000834672
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.000834672
expl/env_infos/initial/reward_run Min         0.000834672
expl/env_infos/reward_run Mean                5.97716
expl/env_infos/reward_run Std                 1.18093
expl/env_infos/reward_run Max                 8.40605
expl/env_infos/reward_run Min                 0.000834672
expl/env_infos/final/reward_ctrl Mean        -0.507932
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.507932
expl/env_infos/final/reward_ctrl Min         -0.507932
expl/env_infos/initial/reward_ctrl Mean      -0.277061
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.277061
expl/env_infos/initial/reward_ctrl Min       -0.277061
expl/env_infos/reward_ctrl Mean              -0.3955
expl/env_infos/reward_ctrl Std                0.0910926
expl/env_infos/reward_ctrl Max               -0.0804394
expl/env_infos/reward_ctrl Min               -0.573991
eval/num steps total                          1.52e+06
eval/num paths total                       1520
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.85031
eval/Rewards Std                              1.29865
eval/Rewards Max                              8.38971
eval/Rewards Min                             -0.732484
eval/Returns Mean                          5850.31
eval/Returns Std                             34.2759
eval/Returns Max                           5887.81
eval/Returns Min                           5789.61
eval/Actions Mean                             0.0867687
eval/Actions Std                              0.82273
eval/Actions Max                              0.996841
eval/Actions Min                             -0.998648
eval/Num Paths                                5
eval/Average Returns                       5850.31
eval/env_infos/final/reward_run Mean          6.83189
eval/env_infos/final/reward_run Std           1.14127
eval/env_infos/final/reward_run Max           7.86849
eval/env_infos/final/reward_run Min           4.86552
eval/env_infos/initial/reward_run Mean       -0.232688
eval/env_infos/initial/reward_run Std         0.128926
eval/env_infos/initial/reward_run Max        -0.0844384
eval/env_infos/initial/reward_run Min        -0.424551
eval/env_infos/reward_run Mean                6.26096
eval/env_infos/reward_run Std                 1.28831
eval/env_infos/reward_run Max                 8.89908
eval/env_infos/reward_run Min                -0.424551
eval/env_infos/final/reward_ctrl Mean        -0.47653
eval/env_infos/final/reward_ctrl Std          0.0488564
eval/env_infos/final/reward_ctrl Max         -0.426663
eval/env_infos/final/reward_ctrl Min         -0.541695
eval/env_infos/initial/reward_ctrl Mean      -0.253285
eval/env_infos/initial/reward_ctrl Std        0.0372424
eval/env_infos/initial/reward_ctrl Max       -0.209082
eval/env_infos/initial/reward_ctrl Min       -0.307933
eval/env_infos/reward_ctrl Mean              -0.410648
eval/env_infos/reward_ctrl Std                0.0892908
eval/env_infos/reward_ctrl Max               -0.105628
eval/env_infos/reward_ctrl Min               -0.584475
time/data storing (s)                         0.00447269
time/evaluation sampling (s)                  2.03256
time/exploration sampling (s)                 0.534244
time/logging (s)                              0.0136076
time/sac training (s)                         7.60526
time/saving (s)                               0.00378075
time/training (s)                             3.5728e-05
time/epoch (s)                               10.194
time/total (s)                             3224.03
Epoch                                       303
---------------------------------------  ----------------
2021-11-24 01:23:09.117716 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 304 finished
---------------------------------------  ---------------
epoch                                       304
replay_buffer/size                       306000
trainer/num train calls                  305000
trainer/QF1 Loss                              9.26839
trainer/QF2 Loss                              6.68603
trainer/Policy Loss                        -371.987
trainer/Q1 Predictions Mean                 372.899
trainer/Q1 Predictions Std                  106.455
trainer/Q1 Predictions Max                  456.477
trainer/Q1 Predictions Min                   -3.01362
trainer/Q2 Predictions Mean                 372.44
trainer/Q2 Predictions Std                  106.221
trainer/Q2 Predictions Max                  457.488
trainer/Q2 Predictions Min                    2.40414
trainer/Q Targets Mean                      372.127
trainer/Q Targets Std                       106.048
trainer/Q Targets Max                       457.083
trainer/Q Targets Min                        14.8044
trainer/Log Pis Mean                          5.93104
trainer/Log Pis Std                           4.68966
trainer/Log Pis Max                          34.2318
trainer/Log Pis Min                          -7.44469
trainer/policy/mean Mean                      0.075562
trainer/policy/mean Std                       0.778318
trainer/policy/mean Max                       1
trainer/policy/mean Min                      -0.998814
trainer/policy/normal/std Mean                0.447099
trainer/policy/normal/std Std                 0.145244
trainer/policy/normal/std Max                 0.917985
trainer/policy/normal/std Min                 0.0778667
trainer/policy/normal/log_std Mean           -0.874949
trainer/policy/normal/log_std Std             0.411344
trainer/policy/normal/log_std Max            -0.0855745
trainer/policy/normal/log_std Min            -2.55276
trainer/Alpha                                 0.136503
trainer/Alpha Loss                           -0.13733
expl/num steps total                     306000
expl/num paths total                        306
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.81355
expl/Rewards Std                              1.23447
expl/Rewards Max                              8.36201
expl/Rewards Min                             -0.685273
expl/Returns Mean                          5813.55
expl/Returns Std                              0
expl/Returns Max                           5813.55
expl/Returns Min                           5813.55
expl/Actions Mean                             0.0998445
expl/Actions Std                              0.805762
expl/Actions Max                              0.999511
expl/Actions Min                             -0.999293
expl/Num Paths                                1
expl/Average Returns                       5813.55
expl/env_infos/final/reward_run Mean          8.0639
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.0639
expl/env_infos/final/reward_run Min           8.0639
expl/env_infos/initial/reward_run Mean       -0.275573
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.275573
expl/env_infos/initial/reward_run Min        -0.275573
expl/env_infos/reward_run Mean                6.20909
expl/env_infos/reward_run Std                 1.22638
expl/env_infos/reward_run Max                 8.86078
expl/env_infos/reward_run Min                -0.275573
expl/env_infos/final/reward_ctrl Mean        -0.34094
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.34094
expl/env_infos/final/reward_ctrl Min         -0.34094
expl/env_infos/initial/reward_ctrl Mean      -0.4097
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.4097
expl/env_infos/initial/reward_ctrl Min       -0.4097
expl/env_infos/reward_ctrl Mean              -0.395533
expl/env_infos/reward_ctrl Std                0.0975716
expl/env_infos/reward_ctrl Max               -0.0880911
expl/env_infos/reward_ctrl Min               -0.594284
eval/num steps total                          1.525e+06
eval/num paths total                       1525
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.97755
eval/Rewards Std                              1.28623
eval/Rewards Max                              8.55756
eval/Rewards Min                             -0.654417
eval/Returns Mean                          5977.55
eval/Returns Std                             90.0931
eval/Returns Max                           6109.74
eval/Returns Min                           5852.19
eval/Actions Mean                             0.0932599
eval/Actions Std                              0.818333
eval/Actions Max                              0.996259
eval/Actions Min                             -0.998587
eval/Num Paths                                5
eval/Average Returns                       5977.55
eval/env_infos/final/reward_run Mean          7.17856
eval/env_infos/final/reward_run Std           0.586888
eval/env_infos/final/reward_run Max           7.83411
eval/env_infos/final/reward_run Min           6.139
eval/env_infos/initial/reward_run Mean       -0.181462
eval/env_infos/initial/reward_run Std         0.134481
eval/env_infos/initial/reward_run Max        -0.0213536
eval/env_infos/initial/reward_run Min        -0.353178
eval/env_infos/reward_run Mean                6.38457
eval/env_infos/reward_run Std                 1.27705
eval/env_infos/reward_run Max                 9.06157
eval/env_infos/reward_run Min                -0.353178
eval/env_infos/final/reward_ctrl Mean        -0.409688
eval/env_infos/final/reward_ctrl Std          0.0710521
eval/env_infos/final/reward_ctrl Max         -0.309228
eval/env_infos/final/reward_ctrl Min         -0.47979
eval/env_infos/initial/reward_ctrl Mean      -0.248066
eval/env_infos/initial/reward_ctrl Std        0.0311573
eval/env_infos/initial/reward_ctrl Max       -0.209082
eval/env_infos/initial/reward_ctrl Min       -0.301239
eval/env_infos/reward_ctrl Mean              -0.40702
eval/env_infos/reward_ctrl Std                0.0976411
eval/env_infos/reward_ctrl Max               -0.0594457
eval/env_infos/reward_ctrl Min               -0.586261
time/data storing (s)                         0.00456709
time/evaluation sampling (s)                  2.06316
time/exploration sampling (s)                 0.556425
time/logging (s)                              0.0136534
time/sac training (s)                         7.55513
time/saving (s)                               0.00380836
time/training (s)                             3.489e-05
time/epoch (s)                               10.1968
time/total (s)                             3234.52
Epoch                                       304
---------------------------------------  ---------------
2021-11-24 01:23:19.565027 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 305 finished
---------------------------------------  ----------------
epoch                                       305
replay_buffer/size                       307000
trainer/num train calls                  306000
trainer/QF1 Loss                              8.94556
trainer/QF2 Loss                              7.2795
trainer/Policy Loss                        -371.88
trainer/Q1 Predictions Mean                 372.457
trainer/Q1 Predictions Std                  103.261
trainer/Q1 Predictions Max                  462.911
trainer/Q1 Predictions Min                   18.2868
trainer/Q2 Predictions Mean                 372.215
trainer/Q2 Predictions Std                  103.047
trainer/Q2 Predictions Max                  462.345
trainer/Q2 Predictions Min                   19.0205
trainer/Q Targets Mean                      373.038
trainer/Q Targets Std                       103.171
trainer/Q Targets Max                       455.712
trainer/Q Targets Min                        17.4947
trainer/Log Pis Mean                          5.74345
trainer/Log Pis Std                           4.55168
trainer/Log Pis Max                          15.0196
trainer/Log Pis Min                          -7.85861
trainer/policy/mean Mean                      0.0920307
trainer/policy/mean Std                       0.770142
trainer/policy/mean Max                       0.999632
trainer/policy/mean Min                      -0.999044
trainer/policy/normal/std Mean                0.449281
trainer/policy/normal/std Std                 0.144987
trainer/policy/normal/std Max                 0.862699
trainer/policy/normal/std Min                 0.0777074
trainer/policy/normal/log_std Mean           -0.869362
trainer/policy/normal/log_std Std             0.408912
trainer/policy/normal/log_std Max            -0.14769
trainer/policy/normal/log_std Min            -2.5548
trainer/Alpha                                 0.138803
trainer/Alpha Loss                           -0.506601
expl/num steps total                     307000
expl/num paths total                        307
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.6423
expl/Rewards Std                              1.20153
expl/Rewards Max                              7.74442
expl/Rewards Min                             -0.308221
expl/Returns Mean                          5642.3
expl/Returns Std                              0
expl/Returns Max                           5642.3
expl/Returns Min                           5642.3
expl/Actions Mean                             0.0873785
expl/Actions Std                              0.804105
expl/Actions Max                              0.999565
expl/Actions Min                             -0.99877
expl/Num Paths                                1
expl/Average Returns                       5642.3
expl/env_infos/final/reward_run Mean          6.51864
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.51864
expl/env_infos/final/reward_run Min           6.51864
expl/env_infos/initial/reward_run Mean        0.12651
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.12651
expl/env_infos/initial/reward_run Min         0.12651
expl/env_infos/reward_run Mean                6.03483
expl/env_infos/reward_run Std                 1.20003
expl/env_infos/reward_run Max                 8.23351
expl/env_infos/reward_run Min                 0.12651
expl/env_infos/final/reward_ctrl Mean        -0.153753
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.153753
expl/env_infos/final/reward_ctrl Min         -0.153753
expl/env_infos/initial/reward_ctrl Mean      -0.279175
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.279175
expl/env_infos/initial/reward_ctrl Min       -0.279175
expl/env_infos/reward_ctrl Mean              -0.392532
expl/env_infos/reward_ctrl Std                0.0965495
expl/env_infos/reward_ctrl Max               -0.0461218
expl/env_infos/reward_ctrl Min               -0.577364
eval/num steps total                          1.53e+06
eval/num paths total                       1530
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.90137
eval/Rewards Std                              1.27074
eval/Rewards Max                              8.41645
eval/Rewards Min                             -0.81178
eval/Returns Mean                          5901.37
eval/Returns Std                             57.8096
eval/Returns Max                           5994.85
eval/Returns Min                           5821.8
eval/Actions Mean                             0.0965832
eval/Actions Std                              0.824951
eval/Actions Max                              0.997869
eval/Actions Min                             -0.994633
eval/Num Paths                                5
eval/Average Returns                       5901.37
eval/env_infos/final/reward_run Mean          7.13919
eval/env_infos/final/reward_run Std           0.681649
eval/env_infos/final/reward_run Max           8.05601
eval/env_infos/final/reward_run Min           6.36111
eval/env_infos/initial/reward_run Mean       -0.324692
eval/env_infos/initial/reward_run Std         0.189784
eval/env_infos/initial/reward_run Max        -0.0671275
eval/env_infos/initial/reward_run Min        -0.595709
eval/env_infos/reward_run Mean                6.3153
eval/env_infos/reward_run Std                 1.26647
eval/env_infos/reward_run Max                 8.91685
eval/env_infos/reward_run Min                -0.595709
eval/env_infos/final/reward_ctrl Mean        -0.456479
eval/env_infos/final/reward_ctrl Std          0.0386265
eval/env_infos/final/reward_ctrl Max         -0.398338
eval/env_infos/final/reward_ctrl Min         -0.506344
eval/env_infos/initial/reward_ctrl Mean      -0.247376
eval/env_infos/initial/reward_ctrl Std        0.0326186
eval/env_infos/initial/reward_ctrl Max       -0.216071
eval/env_infos/initial/reward_ctrl Min       -0.306419
eval/env_infos/reward_ctrl Mean              -0.413923
eval/env_infos/reward_ctrl Std                0.0930653
eval/env_infos/reward_ctrl Max               -0.093837
eval/env_infos/reward_ctrl Min               -0.585155
time/data storing (s)                         0.00447932
time/evaluation sampling (s)                  2.04168
time/exploration sampling (s)                 0.536813
time/logging (s)                              0.013717
time/sac training (s)                         7.54875
time/saving (s)                               0.00378926
time/training (s)                             4.04679e-05
time/epoch (s)                               10.1493
time/total (s)                             3244.95
Epoch                                       305
---------------------------------------  ----------------
2021-11-24 01:23:30.046188 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 306 finished
---------------------------------------  ---------------
epoch                                       306
replay_buffer/size                       308000
trainer/num train calls                  307000
trainer/QF1 Loss                              6.68629
trainer/QF2 Loss                              6.18734
trainer/Policy Loss                        -374.892
trainer/Q1 Predictions Mean                 375.578
trainer/Q1 Predictions Std                  101.187
trainer/Q1 Predictions Max                  449.36
trainer/Q1 Predictions Min                   18.1989
trainer/Q2 Predictions Mean                 375.567
trainer/Q2 Predictions Std                  101.195
trainer/Q2 Predictions Max                  450.178
trainer/Q2 Predictions Min                   18.672
trainer/Q Targets Mean                      375.496
trainer/Q Targets Std                       101.484
trainer/Q Targets Max                       451.389
trainer/Q Targets Min                        17.5202
trainer/Log Pis Mean                          5.95767
trainer/Log Pis Std                           4.60266
trainer/Log Pis Max                          20.9374
trainer/Log Pis Min                          -8.28563
trainer/policy/mean Mean                      0.0850888
trainer/policy/mean Std                       0.775863
trainer/policy/mean Max                       0.999008
trainer/policy/mean Min                      -0.995155
trainer/policy/normal/std Mean                0.449344
trainer/policy/normal/std Std                 0.143757
trainer/policy/normal/std Max                 1.01898
trainer/policy/normal/std Min                 0.0784932
trainer/policy/normal/log_std Mean           -0.867142
trainer/policy/normal/log_std Std             0.401961
trainer/policy/normal/log_std Max             0.0188034
trainer/policy/normal/log_std Min            -2.54474
trainer/Alpha                                 0.139074
trainer/Alpha Loss                           -0.0835064
expl/num steps total                     308000
expl/num paths total                        308
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.61064
expl/Rewards Std                              1.24406
expl/Rewards Max                              7.79617
expl/Rewards Min                             -0.587931
expl/Returns Mean                          5610.64
expl/Returns Std                              0
expl/Returns Max                           5610.64
expl/Returns Min                           5610.64
expl/Actions Mean                             0.101272
expl/Actions Std                              0.798552
expl/Actions Max                              0.999541
expl/Actions Min                             -0.999333
expl/Num Paths                                1
expl/Average Returns                       5610.64
expl/env_infos/final/reward_run Mean          7.43962
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.43962
expl/env_infos/final/reward_run Min           7.43962
expl/env_infos/initial/reward_run Mean       -0.225109
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.225109
expl/env_infos/initial/reward_run Min        -0.225109
expl/env_infos/reward_run Mean                5.9994
expl/env_infos/reward_run Std                 1.23373
expl/env_infos/reward_run Max                 8.33838
expl/env_infos/reward_run Min                -0.225109
expl/env_infos/final/reward_ctrl Mean        -0.198579
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.198579
expl/env_infos/final/reward_ctrl Min         -0.198579
expl/env_infos/initial/reward_ctrl Mean      -0.362822
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.362822
expl/env_infos/initial/reward_ctrl Min       -0.362822
expl/env_infos/reward_ctrl Mean              -0.388765
expl/env_infos/reward_ctrl Std                0.0930689
expl/env_infos/reward_ctrl Max               -0.0845493
expl/env_infos/reward_ctrl Min               -0.57726
eval/num steps total                          1.535e+06
eval/num paths total                       1535
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.85223
eval/Rewards Std                              1.29574
eval/Rewards Max                              8.57529
eval/Rewards Min                             -0.83244
eval/Returns Mean                          5852.23
eval/Returns Std                            111.1
eval/Returns Max                           6021.01
eval/Returns Min                           5739.13
eval/Actions Mean                             0.0950328
eval/Actions Std                              0.815836
eval/Actions Max                              0.999789
eval/Actions Min                             -0.997577
eval/Num Paths                                5
eval/Average Returns                       5852.23
eval/env_infos/final/reward_run Mean          6.3912
eval/env_infos/final/reward_run Std           1.19786
eval/env_infos/final/reward_run Max           7.90864
eval/env_infos/final/reward_run Min           4.77579
eval/env_infos/initial/reward_run Mean       -0.368888
eval/env_infos/initial/reward_run Std         0.105311
eval/env_infos/initial/reward_run Max        -0.230382
eval/env_infos/initial/reward_run Min        -0.529343
eval/env_infos/reward_run Mean                6.257
eval/env_infos/reward_run Std                 1.29042
eval/env_infos/reward_run Max                 9.08596
eval/env_infos/reward_run Min                -0.529343
eval/env_infos/final/reward_ctrl Mean        -0.464872
eval/env_infos/final/reward_ctrl Std          0.0514781
eval/env_infos/final/reward_ctrl Max         -0.370846
eval/env_infos/final/reward_ctrl Min         -0.515147
eval/env_infos/initial/reward_ctrl Mean      -0.232867
eval/env_infos/initial/reward_ctrl Std        0.0407841
eval/env_infos/initial/reward_ctrl Max       -0.179122
eval/env_infos/initial/reward_ctrl Min       -0.303097
eval/env_infos/reward_ctrl Mean              -0.404772
eval/env_infos/reward_ctrl Std                0.0874966
eval/env_infos/reward_ctrl Max               -0.102987
eval/env_infos/reward_ctrl Min               -0.58424
time/data storing (s)                         0.00455114
time/evaluation sampling (s)                  2.02838
time/exploration sampling (s)                 0.53961
time/logging (s)                              0.0136645
time/sac training (s)                         7.5895
time/saving (s)                               0.00380929
time/training (s)                             3.5014e-05
time/epoch (s)                               10.1796
time/total (s)                             3255.42
Epoch                                       306
---------------------------------------  ---------------
2021-11-24 01:23:40.654923 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 307 finished
---------------------------------------  ---------------
epoch                                       307
replay_buffer/size                       309000
trainer/num train calls                  308000
trainer/QF1 Loss                              5.48406
trainer/QF2 Loss                              5.54352
trainer/Policy Loss                        -385.522
trainer/Q1 Predictions Mean                 386.124
trainer/Q1 Predictions Std                   82.1144
trainer/Q1 Predictions Max                  452.228
trainer/Q1 Predictions Min                   18.0218
trainer/Q2 Predictions Mean                 385.879
trainer/Q2 Predictions Std                   82.0776
trainer/Q2 Predictions Max                  452.826
trainer/Q2 Predictions Min                   18.9758
trainer/Q Targets Mean                      385.822
trainer/Q Targets Std                        81.98
trainer/Q Targets Max                       450.889
trainer/Q Targets Min                        17.9689
trainer/Log Pis Mean                          6.41736
trainer/Log Pis Std                           4.51514
trainer/Log Pis Max                          18.2114
trainer/Log Pis Min                          -4.86395
trainer/policy/mean Mean                      0.073081
trainer/policy/mean Std                       0.786396
trainer/policy/mean Max                       0.995828
trainer/policy/mean Min                      -0.994926
trainer/policy/normal/std Mean                0.434706
trainer/policy/normal/std Std                 0.133994
trainer/policy/normal/std Max                 0.851786
trainer/policy/normal/std Min                 0.0532429
trainer/policy/normal/log_std Mean           -0.900126
trainer/policy/normal/log_std Std             0.409825
trainer/policy/normal/log_std Max            -0.16042
trainer/policy/normal/log_std Min            -2.93289
trainer/Alpha                                 0.136477
trainer/Alpha Loss                            0.831212
expl/num steps total                     309000
expl/num paths total                        309
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.66691
expl/Rewards Std                              1.2601
expl/Rewards Max                              8.14859
expl/Rewards Min                             -0.81162
expl/Returns Mean                          5666.91
expl/Returns Std                              0
expl/Returns Max                           5666.91
expl/Returns Min                           5666.91
expl/Actions Mean                             0.106563
expl/Actions Std                              0.811788
expl/Actions Max                              0.999581
expl/Actions Min                             -0.998817
expl/Num Paths                                1
expl/Average Returns                       5666.91
expl/env_infos/final/reward_run Mean          7.15877
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.15877
expl/env_infos/final/reward_run Min           7.15877
expl/env_infos/initial/reward_run Mean       -0.583658
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.583658
expl/env_infos/initial/reward_run Min        -0.583658
expl/env_infos/reward_run Mean                6.06912
expl/env_infos/reward_run Std                 1.25023
expl/env_infos/reward_run Max                 8.65403
expl/env_infos/reward_run Min                -0.583658
expl/env_infos/final/reward_ctrl Mean        -0.379944
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.379944
expl/env_infos/final/reward_ctrl Min         -0.379944
expl/env_infos/initial/reward_ctrl Mean      -0.227961
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.227961
expl/env_infos/initial/reward_ctrl Min       -0.227961
expl/env_infos/reward_ctrl Mean              -0.402213
expl/env_infos/reward_ctrl Std                0.0930363
expl/env_infos/reward_ctrl Max               -0.0884227
expl/env_infos/reward_ctrl Min               -0.585519
eval/num steps total                          1.54e+06
eval/num paths total                       1540
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.90444
eval/Rewards Std                              1.3088
eval/Rewards Max                              8.49013
eval/Rewards Min                             -0.729553
eval/Returns Mean                          5904.44
eval/Returns Std                             43.6037
eval/Returns Max                           5967.89
eval/Returns Min                           5833.96
eval/Actions Mean                             0.107377
eval/Actions Std                              0.826659
eval/Actions Max                              0.998345
eval/Actions Min                             -0.997576
eval/Num Paths                                5
eval/Average Returns                       5904.44
eval/env_infos/final/reward_run Mean          6.77468
eval/env_infos/final/reward_run Std           1.09761
eval/env_infos/final/reward_run Max           8.14506
eval/env_infos/final/reward_run Min           5.13985
eval/env_infos/initial/reward_run Mean       -0.267233
eval/env_infos/initial/reward_run Std         0.115742
eval/env_infos/initial/reward_run Max        -0.130194
eval/env_infos/initial/reward_run Min        -0.429494
eval/env_infos/reward_run Mean                6.32138
eval/env_infos/reward_run Std                 1.29504
eval/env_infos/reward_run Max                 8.98935
eval/env_infos/reward_run Min                -0.429494
eval/env_infos/final/reward_ctrl Mean        -0.423451
eval/env_infos/final/reward_ctrl Std          0.0813003
eval/env_infos/final/reward_ctrl Max         -0.275978
eval/env_infos/final/reward_ctrl Min         -0.508835
eval/env_infos/initial/reward_ctrl Mean      -0.233637
eval/env_infos/initial/reward_ctrl Std        0.0461343
eval/env_infos/initial/reward_ctrl Max       -0.180594
eval/env_infos/initial/reward_ctrl Min       -0.313103
eval/env_infos/reward_ctrl Mean              -0.416937
eval/env_infos/reward_ctrl Std                0.0925579
eval/env_infos/reward_ctrl Max               -0.101639
eval/env_infos/reward_ctrl Min               -0.585391
time/data storing (s)                         0.00489204
time/evaluation sampling (s)                  2.01721
time/exploration sampling (s)                 0.672551
time/logging (s)                              0.0135916
time/sac training (s)                         7.59253
time/saving (s)                               0.00378532
time/training (s)                             3.4917e-05
time/epoch (s)                               10.3046
time/total (s)                             3266.01
Epoch                                       307
---------------------------------------  ---------------
2021-11-24 01:23:51.082724 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 308 finished
---------------------------------------  ---------------
epoch                                       308
replay_buffer/size                       310000
trainer/num train calls                  309000
trainer/QF1 Loss                              6.94303
trainer/QF2 Loss                              7.8649
trainer/Policy Loss                        -370.729
trainer/Q1 Predictions Mean                 371.531
trainer/Q1 Predictions Std                  106.139
trainer/Q1 Predictions Max                  459.944
trainer/Q1 Predictions Min                   17.4852
trainer/Q2 Predictions Mean                 371.125
trainer/Q2 Predictions Std                  105.891
trainer/Q2 Predictions Max                  459.076
trainer/Q2 Predictions Min                   17.1608
trainer/Q Targets Mean                      370.844
trainer/Q Targets Std                       106.07
trainer/Q Targets Max                       461.909
trainer/Q Targets Min                        17.1525
trainer/Log Pis Mean                          6.16666
trainer/Log Pis Std                           4.65317
trainer/Log Pis Max                          17.0141
trainer/Log Pis Min                          -4.79649
trainer/policy/mean Mean                      0.0968524
trainer/policy/mean Std                       0.776603
trainer/policy/mean Max                       0.998489
trainer/policy/mean Min                      -0.997873
trainer/policy/normal/std Mean                0.443756
trainer/policy/normal/std Std                 0.140966
trainer/policy/normal/std Max                 1.12723
trainer/policy/normal/std Min                 0.0778572
trainer/policy/normal/log_std Mean           -0.877434
trainer/policy/normal/log_std Std             0.394226
trainer/policy/normal/log_std Max             0.119765
trainer/policy/normal/log_std Min            -2.55288
trainer/Alpha                                 0.137065
trainer/Alpha Loss                            0.331205
expl/num steps total                     310000
expl/num paths total                        310
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.57735
expl/Rewards Std                              1.27562
expl/Rewards Max                              7.85646
expl/Rewards Min                             -0.645312
expl/Returns Mean                          5577.35
expl/Returns Std                              0
expl/Returns Max                           5577.35
expl/Returns Min                           5577.35
expl/Actions Mean                             0.0972944
expl/Actions Std                              0.80576
expl/Actions Max                              0.999695
expl/Actions Min                             -0.999258
expl/Num Paths                                1
expl/Average Returns                       5577.35
expl/env_infos/final/reward_run Mean          5.55081
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.55081
expl/env_infos/final/reward_run Min           5.55081
expl/env_infos/initial/reward_run Mean       -0.44608
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.44608
expl/env_infos/initial/reward_run Min        -0.44608
expl/env_infos/reward_run Mean                5.97258
expl/env_infos/reward_run Std                 1.27201
expl/env_infos/reward_run Max                 8.34467
expl/env_infos/reward_run Min                -0.44608
expl/env_infos/final/reward_ctrl Mean        -0.409343
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.409343
expl/env_infos/final/reward_ctrl Min         -0.409343
expl/env_infos/initial/reward_ctrl Mean      -0.199232
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.199232
expl/env_infos/initial/reward_ctrl Min       -0.199232
expl/env_infos/reward_ctrl Mean              -0.395229
expl/env_infos/reward_ctrl Std                0.0922956
expl/env_infos/reward_ctrl Max               -0.0638773
expl/env_infos/reward_ctrl Min               -0.582393
eval/num steps total                          1.545e+06
eval/num paths total                       1545
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.95261
eval/Rewards Std                              1.30371
eval/Rewards Max                              8.41147
eval/Rewards Min                             -0.718096
eval/Returns Mean                          5952.61
eval/Returns Std                             54.9812
eval/Returns Max                           6016.57
eval/Returns Min                           5871.17
eval/Actions Mean                             0.105352
eval/Actions Std                              0.822086
eval/Actions Max                              0.99639
eval/Actions Min                             -0.994358
eval/Num Paths                                5
eval/Average Returns                       5952.61
eval/env_infos/final/reward_run Mean          7.1047
eval/env_infos/final/reward_run Std           0.762776
eval/env_infos/final/reward_run Max           7.97899
eval/env_infos/final/reward_run Min           6.06226
eval/env_infos/initial/reward_run Mean       -0.21163
eval/env_infos/initial/reward_run Std         0.0944687
eval/env_infos/initial/reward_run Max        -0.0997346
eval/env_infos/initial/reward_run Min        -0.355836
eval/env_infos/reward_run Mean                6.36476
eval/env_infos/reward_run Std                 1.29506
eval/env_infos/reward_run Max                 8.92993
eval/env_infos/reward_run Min                -0.355836
eval/env_infos/final/reward_ctrl Mean        -0.462097
eval/env_infos/final/reward_ctrl Std          0.0592313
eval/env_infos/final/reward_ctrl Max         -0.351222
eval/env_infos/final/reward_ctrl Min         -0.516919
eval/env_infos/initial/reward_ctrl Mean      -0.253854
eval/env_infos/initial/reward_ctrl Std        0.0745378
eval/env_infos/initial/reward_ctrl Max       -0.16298
eval/env_infos/initial/reward_ctrl Min       -0.38433
eval/env_infos/reward_ctrl Mean              -0.412155
eval/env_infos/reward_ctrl Std                0.0905065
eval/env_infos/reward_ctrl Max               -0.0933569
eval/env_infos/reward_ctrl Min               -0.580498
time/data storing (s)                         0.00449263
time/evaluation sampling (s)                  2.03187
time/exploration sampling (s)                 0.525124
time/logging (s)                              0.0137233
time/sac training (s)                         7.54937
time/saving (s)                               0.00383841
time/training (s)                             3.5721e-05
time/epoch (s)                               10.1284
time/total (s)                             3276.42
Epoch                                       308
---------------------------------------  ---------------
2021-11-24 01:24:01.593763 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 309 finished
---------------------------------------  ---------------
epoch                                       309
replay_buffer/size                       311000
trainer/num train calls                  310000
trainer/QF1 Loss                              4.70519
trainer/QF2 Loss                              5.03278
trainer/Policy Loss                        -371.341
trainer/Q1 Predictions Mean                 371.545
trainer/Q1 Predictions Std                  112.341
trainer/Q1 Predictions Max                  453.454
trainer/Q1 Predictions Min                   19.1332
trainer/Q2 Predictions Mean                 371.969
trainer/Q2 Predictions Std                  112.442
trainer/Q2 Predictions Max                  452.857
trainer/Q2 Predictions Min                   18.6842
trainer/Q Targets Mean                      371.532
trainer/Q Targets Std                       112.387
trainer/Q Targets Max                       453.365
trainer/Q Targets Min                        17.9431
trainer/Log Pis Mean                          5.72131
trainer/Log Pis Std                           4.52396
trainer/Log Pis Max                          15.4034
trainer/Log Pis Min                          -5.38541
trainer/policy/mean Mean                      0.0838885
trainer/policy/mean Std                       0.765298
trainer/policy/mean Max                       0.995716
trainer/policy/mean Min                      -0.999782
trainer/policy/normal/std Mean                0.451361
trainer/policy/normal/std Std                 0.145231
trainer/policy/normal/std Max                 0.973168
trainer/policy/normal/std Min                 0.0757023
trainer/policy/normal/log_std Mean           -0.864746
trainer/policy/normal/log_std Std             0.409922
trainer/policy/normal/log_std Max            -0.0271989
trainer/policy/normal/log_std Min            -2.58095
trainer/Alpha                                 0.137089
trainer/Alpha Loss                           -0.553787
expl/num steps total                     311000
expl/num paths total                        311
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.59654
expl/Rewards Std                              1.3055
expl/Rewards Max                              8.16624
expl/Rewards Min                             -0.881097
expl/Returns Mean                          5596.54
expl/Returns Std                              0
expl/Returns Max                           5596.54
expl/Returns Min                           5596.54
expl/Actions Mean                             0.115148
expl/Actions Std                              0.807377
expl/Actions Max                              0.999665
expl/Actions Min                             -0.999528
expl/Num Paths                                1
expl/Average Returns                       5596.54
expl/env_infos/final/reward_run Mean          7.06083
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.06083
expl/env_infos/final/reward_run Min           7.06083
expl/env_infos/initial/reward_run Mean       -0.671615
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.671615
expl/env_infos/initial/reward_run Min        -0.671615
expl/env_infos/reward_run Mean                5.99561
expl/env_infos/reward_run Std                 1.29999
expl/env_infos/reward_run Max                 8.59074
expl/env_infos/reward_run Min                -0.671615
expl/env_infos/final/reward_ctrl Mean        -0.397874
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.397874
expl/env_infos/final/reward_ctrl Min         -0.397874
expl/env_infos/initial/reward_ctrl Mean      -0.209483
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.209483
expl/env_infos/initial/reward_ctrl Min       -0.209483
expl/env_infos/reward_ctrl Mean              -0.39907
expl/env_infos/reward_ctrl Std                0.0955899
expl/env_infos/reward_ctrl Max               -0.061178
expl/env_infos/reward_ctrl Min               -0.576293
eval/num steps total                          1.55e+06
eval/num paths total                       1550
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.93642
eval/Rewards Std                              1.30191
eval/Rewards Max                              8.50593
eval/Rewards Min                             -0.762956
eval/Returns Mean                          5936.42
eval/Returns Std                             73.9376
eval/Returns Max                           6058.16
eval/Returns Min                           5856.8
eval/Actions Mean                             0.119027
eval/Actions Std                              0.824485
eval/Actions Max                              0.997577
eval/Actions Min                             -0.997144
eval/Num Paths                                5
eval/Average Returns                       5936.42
eval/env_infos/final/reward_run Mean          7.24773
eval/env_infos/final/reward_run Std           0.669829
eval/env_infos/final/reward_run Max           8.23061
eval/env_infos/final/reward_run Min           6.15136
eval/env_infos/initial/reward_run Mean       -0.323441
eval/env_infos/initial/reward_run Std         0.126785
eval/env_infos/initial/reward_run Max        -0.209599
eval/env_infos/initial/reward_run Min        -0.495622
eval/env_infos/reward_run Mean                6.35278
eval/env_infos/reward_run Std                 1.28757
eval/env_infos/reward_run Max                 9.02176
eval/env_infos/reward_run Min                -0.495622
eval/env_infos/final/reward_ctrl Mean        -0.456828
eval/env_infos/final/reward_ctrl Std          0.0439186
eval/env_infos/final/reward_ctrl Max         -0.402119
eval/env_infos/final/reward_ctrl Min         -0.528727
eval/env_infos/initial/reward_ctrl Mean      -0.24101
eval/env_infos/initial/reward_ctrl Std        0.0366019
eval/env_infos/initial/reward_ctrl Max       -0.197258
eval/env_infos/initial/reward_ctrl Min       -0.293119
eval/env_infos/reward_ctrl Mean              -0.416365
eval/env_infos/reward_ctrl Std                0.096632
eval/env_infos/reward_ctrl Max               -0.0873135
eval/env_infos/reward_ctrl Min               -0.575194
time/data storing (s)                         0.00451779
time/evaluation sampling (s)                  2.05645
time/exploration sampling (s)                 0.540859
time/logging (s)                              0.0137534
time/sac training (s)                         7.59345
time/saving (s)                               0.00381302
time/training (s)                             3.8125e-05
time/epoch (s)                               10.2129
time/total (s)                             3286.92
Epoch                                       309
---------------------------------------  ---------------
2021-11-24 01:24:12.065390 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 310 finished
---------------------------------------  ---------------
epoch                                       310
replay_buffer/size                       312000
trainer/num train calls                  311000
trainer/QF1 Loss                              5.37841
trainer/QF2 Loss                              6.02791
trainer/Policy Loss                        -364.848
trainer/Q1 Predictions Mean                 365.184
trainer/Q1 Predictions Std                  112.198
trainer/Q1 Predictions Max                  452.946
trainer/Q1 Predictions Min                   16.9705
trainer/Q2 Predictions Mean                 365.581
trainer/Q2 Predictions Std                  112.492
trainer/Q2 Predictions Max                  453.379
trainer/Q2 Predictions Min                   17.6808
trainer/Q Targets Mean                      365.69
trainer/Q Targets Std                       112.324
trainer/Q Targets Max                       456.98
trainer/Q Targets Min                        17.7469
trainer/Log Pis Mean                          5.79641
trainer/Log Pis Std                           4.43727
trainer/Log Pis Max                          17.7824
trainer/Log Pis Min                          -5.24768
trainer/policy/mean Mean                      0.0867806
trainer/policy/mean Std                       0.769315
trainer/policy/mean Max                       0.997505
trainer/policy/mean Min                      -0.994472
trainer/policy/normal/std Mean                0.443768
trainer/policy/normal/std Std                 0.143469
trainer/policy/normal/std Max                 0.958015
trainer/policy/normal/std Min                 0.0633599
trainer/policy/normal/log_std Mean           -0.880413
trainer/policy/normal/log_std Std             0.405242
trainer/policy/normal/log_std Max            -0.0428922
trainer/policy/normal/log_std Min            -2.75892
trainer/Alpha                                 0.134323
trainer/Alpha Loss                           -0.408709
expl/num steps total                     312000
expl/num paths total                        312
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.79578
expl/Rewards Std                              1.28055
expl/Rewards Max                              8.0707
expl/Rewards Min                             -0.562967
expl/Returns Mean                          5795.78
expl/Returns Std                              0
expl/Returns Max                           5795.78
expl/Returns Min                           5795.78
expl/Actions Mean                             0.0900911
expl/Actions Std                              0.812028
expl/Actions Max                              0.999389
expl/Actions Min                             -0.99913
expl/Num Paths                                1
expl/Average Returns                       5795.78
expl/env_infos/final/reward_run Mean          7.38528
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.38528
expl/env_infos/final/reward_run Min           7.38528
expl/env_infos/initial/reward_run Mean       -0.219309
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.219309
expl/env_infos/initial/reward_run Min        -0.219309
expl/env_infos/reward_run Mean                6.19628
expl/env_infos/reward_run Std                 1.27512
expl/env_infos/reward_run Max                 8.59135
expl/env_infos/reward_run Min                -0.280174
expl/env_infos/final/reward_ctrl Mean        -0.529449
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.529449
expl/env_infos/final/reward_ctrl Min         -0.529449
expl/env_infos/initial/reward_ctrl Mean      -0.343658
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.343658
expl/env_infos/initial/reward_ctrl Min       -0.343658
expl/env_infos/reward_ctrl Mean              -0.400503
expl/env_infos/reward_ctrl Std                0.0923414
expl/env_infos/reward_ctrl Max               -0.0889896
expl/env_infos/reward_ctrl Min               -0.58223
eval/num steps total                          1.555e+06
eval/num paths total                       1555
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.98682
eval/Rewards Std                              1.31145
eval/Rewards Max                              8.41468
eval/Rewards Min                             -0.521956
eval/Returns Mean                          5986.82
eval/Returns Std                             54.0488
eval/Returns Max                           6032.48
eval/Returns Min                           5887.41
eval/Actions Mean                             0.0947882
eval/Actions Std                              0.826812
eval/Actions Max                              0.997566
eval/Actions Min                             -0.996484
eval/Num Paths                                5
eval/Average Returns                       5986.82
eval/env_infos/final/reward_run Mean          7.64336
eval/env_infos/final/reward_run Std           0.979348
eval/env_infos/final/reward_run Max           8.92713
eval/env_infos/final/reward_run Min           6.0289
eval/env_infos/initial/reward_run Mean       -0.172866
eval/env_infos/initial/reward_run Std         0.0646046
eval/env_infos/initial/reward_run Max        -0.105983
eval/env_infos/initial/reward_run Min        -0.258297
eval/env_infos/reward_run Mean                6.40239
eval/env_infos/reward_run Std                 1.30514
eval/env_infos/reward_run Max                 8.9407
eval/env_infos/reward_run Min                -0.258297
eval/env_infos/final/reward_ctrl Mean        -0.476372
eval/env_infos/final/reward_ctrl Std          0.0466736
eval/env_infos/final/reward_ctrl Max         -0.412812
eval/env_infos/final/reward_ctrl Min         -0.52692
eval/env_infos/initial/reward_ctrl Mean      -0.250873
eval/env_infos/initial/reward_ctrl Std        0.0250884
eval/env_infos/initial/reward_ctrl Max       -0.226247
eval/env_infos/initial/reward_ctrl Min       -0.292812
eval/env_infos/reward_ctrl Mean              -0.415562
eval/env_infos/reward_ctrl Std                0.08964
eval/env_infos/reward_ctrl Max               -0.0940128
eval/env_infos/reward_ctrl Min               -0.586538
time/data storing (s)                         0.0045686
time/evaluation sampling (s)                  2.04451
time/exploration sampling (s)                 0.533568
time/logging (s)                              0.0136922
time/sac training (s)                         7.57075
time/saving (s)                               0.00380238
time/training (s)                             3.7516e-05
time/epoch (s)                               10.1709
time/total (s)                             3297.38
Epoch                                       310
---------------------------------------  ---------------
2021-11-24 01:24:22.524700 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 311 finished
---------------------------------------  ---------------
epoch                                       311
replay_buffer/size                       313000
trainer/num train calls                  312000
trainer/QF1 Loss                              4.69947
trainer/QF2 Loss                              5.67108
trainer/Policy Loss                        -357.488
trainer/Q1 Predictions Mean                 357.906
trainer/Q1 Predictions Std                  131.341
trainer/Q1 Predictions Max                  454.295
trainer/Q1 Predictions Min                   17.1379
trainer/Q2 Predictions Mean                 357.863
trainer/Q2 Predictions Std                  131.33
trainer/Q2 Predictions Max                  455.788
trainer/Q2 Predictions Min                   17.276
trainer/Q Targets Mean                      357.702
trainer/Q Targets Std                       131.412
trainer/Q Targets Max                       454.623
trainer/Q Targets Min                        17.4854
trainer/Log Pis Mean                          5.29223
trainer/Log Pis Std                           4.95392
trainer/Log Pis Max                          16.4233
trainer/Log Pis Min                          -6.96768
trainer/policy/mean Mean                      0.0791759
trainer/policy/mean Std                       0.760033
trainer/policy/mean Max                       0.997038
trainer/policy/mean Min                      -0.995923
trainer/policy/normal/std Mean                0.459939
trainer/policy/normal/std Std                 0.153747
trainer/policy/normal/std Max                 1.00716
trainer/policy/normal/std Min                 0.0696803
trainer/policy/normal/log_std Mean           -0.849611
trainer/policy/normal/log_std Std             0.421235
trainer/policy/normal/log_std Max             0.0071361
trainer/policy/normal/log_std Min            -2.66384
trainer/Alpha                                 0.136478
trainer/Alpha Loss                           -1.40959
expl/num steps total                     313000
expl/num paths total                        313
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.49956
expl/Rewards Std                              1.2529
expl/Rewards Max                              7.81966
expl/Rewards Min                             -0.819388
expl/Returns Mean                          5499.56
expl/Returns Std                              0
expl/Returns Max                           5499.56
expl/Returns Min                           5499.56
expl/Actions Mean                             0.107705
expl/Actions Std                              0.799915
expl/Actions Max                              0.999749
expl/Actions Min                             -0.998841
expl/Num Paths                                1
expl/Average Returns                       5499.56
expl/env_infos/final/reward_run Mean          4.56383
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.56383
expl/env_infos/final/reward_run Min           4.56383
expl/env_infos/initial/reward_run Mean       -0.551889
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.551889
expl/env_infos/initial/reward_run Min        -0.551889
expl/env_infos/reward_run Mean                5.89044
expl/env_infos/reward_run Std                 1.24651
expl/env_infos/reward_run Max                 8.31749
expl/env_infos/reward_run Min                -0.551889
expl/env_infos/final/reward_ctrl Mean        -0.450802
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.450802
expl/env_infos/final/reward_ctrl Min         -0.450802
expl/env_infos/initial/reward_ctrl Mean      -0.267499
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.267499
expl/env_infos/initial/reward_ctrl Min       -0.267499
expl/env_infos/reward_ctrl Mean              -0.390878
expl/env_infos/reward_ctrl Std                0.0942293
expl/env_infos/reward_ctrl Max               -0.099538
expl/env_infos/reward_ctrl Min               -0.575196
eval/num steps total                          1.56e+06
eval/num paths total                       1560
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.90299
eval/Rewards Std                              1.27557
eval/Rewards Max                              8.67752
eval/Rewards Min                             -0.886691
eval/Returns Mean                          5902.99
eval/Returns Std                             42.8132
eval/Returns Max                           5954.16
eval/Returns Min                           5844.9
eval/Actions Mean                             0.115465
eval/Actions Std                              0.817434
eval/Actions Max                              0.997821
eval/Actions Min                             -0.996145
eval/Num Paths                                5
eval/Average Returns                       5902.99
eval/env_infos/final/reward_run Mean          6.75522
eval/env_infos/final/reward_run Std           0.934935
eval/env_infos/final/reward_run Max           8.17226
eval/env_infos/final/reward_run Min           5.95532
eval/env_infos/initial/reward_run Mean       -0.345144
eval/env_infos/initial/reward_run Std         0.191706
eval/env_infos/initial/reward_run Max        -0.163499
eval/env_infos/initial/reward_run Min        -0.670084
eval/env_infos/reward_run Mean                6.31191
eval/env_infos/reward_run Std                 1.26605
eval/env_infos/reward_run Max                 9.17694
eval/env_infos/reward_run Min                -0.670084
eval/env_infos/final/reward_ctrl Mean        -0.417805
eval/env_infos/final/reward_ctrl Std          0.0800881
eval/env_infos/final/reward_ctrl Max         -0.269808
eval/env_infos/final/reward_ctrl Min         -0.494763
eval/env_infos/initial/reward_ctrl Mean      -0.247412
eval/env_infos/initial/reward_ctrl Std        0.032094
eval/env_infos/initial/reward_ctrl Max       -0.212258
eval/env_infos/initial/reward_ctrl Min       -0.300061
eval/env_infos/reward_ctrl Mean              -0.408918
eval/env_infos/reward_ctrl Std                0.093205
eval/env_infos/reward_ctrl Max               -0.0883409
eval/env_infos/reward_ctrl Min               -0.57595
time/data storing (s)                         0.00452262
time/evaluation sampling (s)                  2.02329
time/exploration sampling (s)                 0.539311
time/logging (s)                              0.0136871
time/sac training (s)                         7.57375
time/saving (s)                               0.0038293
time/training (s)                             3.4723e-05
time/epoch (s)                               10.1584
time/total (s)                             3307.82
Epoch                                       311
---------------------------------------  ---------------
2021-11-24 01:24:33.092246 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 312 finished
---------------------------------------  ---------------
epoch                                       312
replay_buffer/size                       314000
trainer/num train calls                  313000
trainer/QF1 Loss                              5.96906
trainer/QF2 Loss                              7.06298
trainer/Policy Loss                        -375.076
trainer/Q1 Predictions Mean                 375.719
trainer/Q1 Predictions Std                  103.543
trainer/Q1 Predictions Max                  458.674
trainer/Q1 Predictions Min                   18.0289
trainer/Q2 Predictions Mean                 375.944
trainer/Q2 Predictions Std                  103.425
trainer/Q2 Predictions Max                  457.642
trainer/Q2 Predictions Min                   18.4264
trainer/Q Targets Mean                      376.14
trainer/Q Targets Std                       103.678
trainer/Q Targets Max                       458.039
trainer/Q Targets Min                        18.4001
trainer/Log Pis Mean                          5.9059
trainer/Log Pis Std                           4.31958
trainer/Log Pis Max                          15.2038
trainer/Log Pis Min                          -4.09513
trainer/policy/mean Mean                      0.090404
trainer/policy/mean Std                       0.772598
trainer/policy/mean Max                       0.999997
trainer/policy/mean Min                      -0.997131
trainer/policy/normal/std Mean                0.445319
trainer/policy/normal/std Std                 0.147884
trainer/policy/normal/std Max                 1.94175
trainer/policy/normal/std Min                 0.0733615
trainer/policy/normal/log_std Mean           -0.87745
trainer/policy/normal/log_std Std             0.404348
trainer/policy/normal/log_std Max             0.663591
trainer/policy/normal/log_std Min            -2.61236
trainer/Alpha                                 0.136717
trainer/Alpha Loss                           -0.187237
expl/num steps total                     314000
expl/num paths total                        314
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.4961
expl/Rewards Std                              1.2484
expl/Rewards Max                              8.07382
expl/Rewards Min                             -0.212325
expl/Returns Mean                          5496.1
expl/Returns Std                              0
expl/Returns Max                           5496.1
expl/Returns Min                           5496.1
expl/Actions Mean                             0.113449
expl/Actions Std                              0.798693
expl/Actions Max                              0.999824
expl/Actions Min                             -0.999918
expl/Num Paths                                1
expl/Average Returns                       5496.1
expl/env_infos/final/reward_run Mean          7.14575
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.14575
expl/env_infos/final/reward_run Min           7.14575
expl/env_infos/initial/reward_run Mean        0.129712
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.129712
expl/env_infos/initial/reward_run Min         0.129712
expl/env_infos/reward_run Mean                5.88657
expl/env_infos/reward_run Std                 1.23811
expl/env_infos/reward_run Max                 8.60487
expl/env_infos/reward_run Min                 0.0219703
expl/env_infos/final/reward_ctrl Mean        -0.345852
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.345852
expl/env_infos/final/reward_ctrl Min         -0.345852
expl/env_infos/initial/reward_ctrl Mean      -0.270419
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.270419
expl/env_infos/initial/reward_ctrl Min       -0.270419
expl/env_infos/reward_ctrl Mean              -0.390469
expl/env_infos/reward_ctrl Std                0.093741
expl/env_infos/reward_ctrl Max               -0.0458593
expl/env_infos/reward_ctrl Min               -0.587225
eval/num steps total                          1.565e+06
eval/num paths total                       1565
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.91992
eval/Rewards Std                              1.29099
eval/Rewards Max                              8.54662
eval/Rewards Min                             -0.776834
eval/Returns Mean                          5919.92
eval/Returns Std                             20.5407
eval/Returns Max                           5956.97
eval/Returns Min                           5895.87
eval/Actions Mean                             0.119075
eval/Actions Std                              0.815103
eval/Actions Max                              0.998457
eval/Actions Min                             -0.998111
eval/Num Paths                                5
eval/Average Returns                       5919.92
eval/env_infos/final/reward_run Mean          6.55068
eval/env_infos/final/reward_run Std           0.83784
eval/env_infos/final/reward_run Max           8.11737
eval/env_infos/final/reward_run Min           5.70806
eval/env_infos/initial/reward_run Mean       -0.325654
eval/env_infos/initial/reward_run Std         0.185377
eval/env_infos/initial/reward_run Max        -0.00652846
eval/env_infos/initial/reward_run Min        -0.528648
eval/env_infos/reward_run Mean                6.32707
eval/env_infos/reward_run Std                 1.27587
eval/env_infos/reward_run Max                 9.05385
eval/env_infos/reward_run Min                -0.528648
eval/env_infos/final/reward_ctrl Mean        -0.456133
eval/env_infos/final/reward_ctrl Std          0.0224937
eval/env_infos/final/reward_ctrl Max         -0.431829
eval/env_infos/final/reward_ctrl Min         -0.492741
eval/env_infos/initial/reward_ctrl Mean      -0.218177
eval/env_infos/initial/reward_ctrl Std        0.0192455
eval/env_infos/initial/reward_ctrl Max       -0.196986
eval/env_infos/initial/reward_ctrl Min       -0.248187
eval/env_infos/reward_ctrl Mean              -0.407143
eval/env_infos/reward_ctrl Std                0.0917588
eval/env_infos/reward_ctrl Max               -0.101486
eval/env_infos/reward_ctrl Min               -0.582169
time/data storing (s)                         0.00450835
time/evaluation sampling (s)                  2.08712
time/exploration sampling (s)                 0.519829
time/logging (s)                              0.0136319
time/sac training (s)                         7.63503
time/saving (s)                               0.00383938
time/training (s)                             3.4851e-05
time/epoch (s)                               10.264
time/total (s)                             3318.38
Epoch                                       312
---------------------------------------  ---------------
2021-11-24 01:24:43.595205 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 313 finished
---------------------------------------  ---------------
epoch                                       313
replay_buffer/size                       315000
trainer/num train calls                  314000
trainer/QF1 Loss                              6.25131
trainer/QF2 Loss                              6.75043
trainer/Policy Loss                        -374.06
trainer/Q1 Predictions Mean                 374.255
trainer/Q1 Predictions Std                  105.871
trainer/Q1 Predictions Max                  462.873
trainer/Q1 Predictions Min                   18.6407
trainer/Q2 Predictions Mean                 374.566
trainer/Q2 Predictions Std                  105.882
trainer/Q2 Predictions Max                  465.036
trainer/Q2 Predictions Min                   17.7886
trainer/Q Targets Mean                      374.117
trainer/Q Targets Std                       105.736
trainer/Q Targets Max                       464.481
trainer/Q Targets Min                        18.8725
trainer/Log Pis Mean                          6.00428
trainer/Log Pis Std                           4.32184
trainer/Log Pis Max                          15.9334
trainer/Log Pis Min                          -4.13618
trainer/policy/mean Mean                      0.0924504
trainer/policy/mean Std                       0.769073
trainer/policy/mean Max                       0.996583
trainer/policy/mean Min                      -0.999264
trainer/policy/normal/std Mean                0.438905
trainer/policy/normal/std Std                 0.14913
trainer/policy/normal/std Max                 0.927678
trainer/policy/normal/std Min                 0.0706298
trainer/policy/normal/log_std Mean           -0.897725
trainer/policy/normal/log_std Std             0.421739
trainer/policy/normal/log_std Max            -0.0750709
trainer/policy/normal/log_std Min            -2.6503
trainer/Alpha                                 0.135299
trainer/Alpha Loss                            0.00856933
expl/num steps total                     315000
expl/num paths total                        315
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.69477
expl/Rewards Std                              1.28234
expl/Rewards Max                              8.37192
expl/Rewards Min                             -0.469939
expl/Returns Mean                          5694.77
expl/Returns Std                              0
expl/Returns Max                           5694.77
expl/Returns Min                           5694.77
expl/Actions Mean                             0.0793743
expl/Actions Std                              0.802766
expl/Actions Max                              0.999605
expl/Actions Min                             -0.998779
expl/Num Paths                                1
expl/Average Returns                       5694.77
expl/env_infos/final/reward_run Mean          6.88872
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.88872
expl/env_infos/final/reward_run Min           6.88872
expl/env_infos/initial/reward_run Mean       -0.045286
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.045286
expl/env_infos/initial/reward_run Min        -0.045286
expl/env_infos/reward_run Mean                6.08521
expl/env_infos/reward_run Std                 1.27872
expl/env_infos/reward_run Max                 8.79183
expl/env_infos/reward_run Min                -0.0570118
expl/env_infos/final/reward_ctrl Mean        -0.323591
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.323591
expl/env_infos/final/reward_ctrl Min         -0.323591
expl/env_infos/initial/reward_ctrl Mean      -0.281519
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.281519
expl/env_infos/initial/reward_ctrl Min       -0.281519
expl/env_infos/reward_ctrl Mean              -0.39044
expl/env_infos/reward_ctrl Std                0.0893438
expl/env_infos/reward_ctrl Max               -0.111215
expl/env_infos/reward_ctrl Min               -0.575151
eval/num steps total                          1.57e+06
eval/num paths total                       1570
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.93696
eval/Rewards Std                              1.26542
eval/Rewards Max                              8.64165
eval/Rewards Min                             -0.909117
eval/Returns Mean                          5936.96
eval/Returns Std                             98.4764
eval/Returns Max                           6057.88
eval/Returns Min                           5843.86
eval/Actions Mean                             0.085606
eval/Actions Std                              0.818536
eval/Actions Max                              0.996268
eval/Actions Min                             -0.995792
eval/Num Paths                                5
eval/Average Returns                       5936.96
eval/env_infos/final/reward_run Mean          7.37541
eval/env_infos/final/reward_run Std           0.929836
eval/env_infos/final/reward_run Max           8.28017
eval/env_infos/final/reward_run Min           6.21037
eval/env_infos/initial/reward_run Mean       -0.417918
eval/env_infos/initial/reward_run Std         0.195006
eval/env_infos/initial/reward_run Max        -0.17164
eval/env_infos/initial/reward_run Min        -0.648473
eval/env_infos/reward_run Mean                6.34335
eval/env_infos/reward_run Std                 1.26113
eval/env_infos/reward_run Max                 9.14504
eval/env_infos/reward_run Min                -0.648473
eval/env_infos/final/reward_ctrl Mean        -0.4878
eval/env_infos/final/reward_ctrl Std          0.0310724
eval/env_infos/final/reward_ctrl Max         -0.441914
eval/env_infos/final/reward_ctrl Min         -0.533257
eval/env_infos/initial/reward_ctrl Mean      -0.265637
eval/env_infos/initial/reward_ctrl Std        0.0533603
eval/env_infos/initial/reward_ctrl Max       -0.195251
eval/env_infos/initial/reward_ctrl Min       -0.327391
eval/env_infos/reward_ctrl Mean              -0.406397
eval/env_infos/reward_ctrl Std                0.0876186
eval/env_infos/reward_ctrl Max               -0.0998307
eval/env_infos/reward_ctrl Min               -0.583371
time/data storing (s)                         0.00448653
time/evaluation sampling (s)                  2.04937
time/exploration sampling (s)                 0.538396
time/logging (s)                              0.0137439
time/sac training (s)                         7.59074
time/saving (s)                               0.00379113
time/training (s)                             3.4727e-05
time/epoch (s)                               10.2006
time/total (s)                             3328.87
Epoch                                       313
---------------------------------------  ---------------
2021-11-24 01:24:54.057639 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 314 finished
---------------------------------------  ---------------
epoch                                       314
replay_buffer/size                       316000
trainer/num train calls                  315000
trainer/QF1 Loss                              7.37405
trainer/QF2 Loss                              5.11624
trainer/Policy Loss                        -380.381
trainer/Q1 Predictions Mean                 380.894
trainer/Q1 Predictions Std                   97.6542
trainer/Q1 Predictions Max                  453.771
trainer/Q1 Predictions Min                   18.6982
trainer/Q2 Predictions Mean                 381.04
trainer/Q2 Predictions Std                   97.5094
trainer/Q2 Predictions Max                  453.164
trainer/Q2 Predictions Min                   19.8866
trainer/Q Targets Mean                      380.72
trainer/Q Targets Std                        97.3897
trainer/Q Targets Max                       453.859
trainer/Q Targets Min                        19.0356
trainer/Log Pis Mean                          5.91758
trainer/Log Pis Std                           4.47956
trainer/Log Pis Max                          16.9261
trainer/Log Pis Min                          -7.37499
trainer/policy/mean Mean                      0.0667187
trainer/policy/mean Std                       0.785619
trainer/policy/mean Max                       0.998477
trainer/policy/mean Min                      -0.998576
trainer/policy/normal/std Mean                0.454407
trainer/policy/normal/std Std                 0.139444
trainer/policy/normal/std Max                 0.909177
trainer/policy/normal/std Min                 0.0784117
trainer/policy/normal/log_std Mean           -0.851371
trainer/policy/normal/log_std Std             0.390578
trainer/policy/normal/log_std Max            -0.0952151
trainer/policy/normal/log_std Min            -2.54578
trainer/Alpha                                 0.137673
trainer/Alpha Loss                           -0.163424
expl/num steps total                     316000
expl/num paths total                        316
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.67309
expl/Rewards Std                              1.26578
expl/Rewards Max                              8.24906
expl/Rewards Min                             -0.619225
expl/Returns Mean                          5673.09
expl/Returns Std                              0
expl/Returns Max                           5673.09
expl/Returns Min                           5673.09
expl/Actions Mean                             0.104794
expl/Actions Std                              0.808483
expl/Actions Max                              0.99957
expl/Actions Min                             -0.999696
expl/Num Paths                                1
expl/Average Returns                       5673.09
expl/env_infos/final/reward_run Mean          5.75131
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.75131
expl/env_infos/final/reward_run Min           5.75131
expl/env_infos/initial/reward_run Mean       -0.237649
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.237649
expl/env_infos/initial/reward_run Min        -0.237649
expl/env_infos/reward_run Mean                6.07187
expl/env_infos/reward_run Std                 1.26124
expl/env_infos/reward_run Max                 8.75949
expl/env_infos/reward_run Min                -0.237649
expl/env_infos/final/reward_ctrl Mean        -0.465239
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.465239
expl/env_infos/final/reward_ctrl Min         -0.465239
expl/env_infos/initial/reward_ctrl Mean      -0.381576
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.381576
expl/env_infos/initial/reward_ctrl Min       -0.381576
expl/env_infos/reward_ctrl Mean              -0.398776
expl/env_infos/reward_ctrl Std                0.0890813
expl/env_infos/reward_ctrl Max               -0.0559287
expl/env_infos/reward_ctrl Min               -0.583612
eval/num steps total                          1.575e+06
eval/num paths total                       1575
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.98701
eval/Rewards Std                              1.28428
eval/Rewards Max                              8.46203
eval/Rewards Min                             -0.714429
eval/Returns Mean                          5987.01
eval/Returns Std                             69.1833
eval/Returns Max                           6094.86
eval/Returns Min                           5903.35
eval/Actions Mean                             0.111184
eval/Actions Std                              0.822842
eval/Actions Max                              0.997063
eval/Actions Min                             -0.995718
eval/Num Paths                                5
eval/Average Returns                       5987.01
eval/env_infos/final/reward_run Mean          6.95341
eval/env_infos/final/reward_run Std           0.634107
eval/env_infos/final/reward_run Max           7.9758
eval/env_infos/final/reward_run Min           6.19077
eval/env_infos/initial/reward_run Mean       -0.393137
eval/env_infos/initial/reward_run Std         0.0649854
eval/env_infos/initial/reward_run Max        -0.292515
eval/env_infos/initial/reward_run Min        -0.492276
eval/env_infos/reward_run Mean                6.40067
eval/env_infos/reward_run Std                 1.2797
eval/env_infos/reward_run Max                 8.97101
eval/env_infos/reward_run Min                -0.492276
eval/env_infos/final/reward_ctrl Mean        -0.460523
eval/env_infos/final/reward_ctrl Std          0.035838
eval/env_infos/final/reward_ctrl Max         -0.406281
eval/env_infos/final/reward_ctrl Min         -0.505246
eval/env_infos/initial/reward_ctrl Mean      -0.194484
eval/env_infos/initial/reward_ctrl Std        0.0144594
eval/env_infos/initial/reward_ctrl Max       -0.182159
eval/env_infos/initial/reward_ctrl Min       -0.222153
eval/env_infos/reward_ctrl Mean              -0.413658
eval/env_infos/reward_ctrl Std                0.0869335
eval/env_infos/reward_ctrl Max               -0.0955419
eval/env_infos/reward_ctrl Min               -0.584284
time/data storing (s)                         0.00454416
time/evaluation sampling (s)                  2.07172
time/exploration sampling (s)                 0.544661
time/logging (s)                              0.0136189
time/sac training (s)                         7.52181
time/saving (s)                               0.00378722
time/training (s)                             3.4015e-05
time/epoch (s)                               10.1602
time/total (s)                             3339.32
Epoch                                       314
---------------------------------------  ---------------
2021-11-24 01:25:04.379420 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 315 finished
---------------------------------------  ---------------
epoch                                       315
replay_buffer/size                       317000
trainer/num train calls                  316000
trainer/QF1 Loss                              4.93988
trainer/QF2 Loss                              5.25832
trainer/Policy Loss                        -373.052
trainer/Q1 Predictions Mean                 373.439
trainer/Q1 Predictions Std                  114.752
trainer/Q1 Predictions Max                  461.714
trainer/Q1 Predictions Min                   16.5785
trainer/Q2 Predictions Mean                 373.824
trainer/Q2 Predictions Std                  114.937
trainer/Q2 Predictions Max                  462.876
trainer/Q2 Predictions Min                   18.8656
trainer/Q Targets Mean                      373.849
trainer/Q Targets Std                       114.863
trainer/Q Targets Max                       461.971
trainer/Q Targets Min                        18.656
trainer/Log Pis Mean                          5.807
trainer/Log Pis Std                           4.41338
trainer/Log Pis Max                          16.1474
trainer/Log Pis Min                          -4.39238
trainer/policy/mean Mean                      0.0698906
trainer/policy/mean Std                       0.784714
trainer/policy/mean Max                       0.996698
trainer/policy/mean Min                      -0.994499
trainer/policy/normal/std Mean                0.459232
trainer/policy/normal/std Std                 0.144817
trainer/policy/normal/std Max                 1.01462
trainer/policy/normal/std Min                 0.0804493
trainer/policy/normal/log_std Mean           -0.842856
trainer/policy/normal/log_std Std             0.394058
trainer/policy/normal/log_std Max             0.0145141
trainer/policy/normal/log_std Min            -2.52013
trainer/Alpha                                 0.139493
trainer/Alpha Loss                           -0.380161
expl/num steps total                     317000
expl/num paths total                        317
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.56261
expl/Rewards Std                              1.27118
expl/Rewards Max                              8.20163
expl/Rewards Min                             -0.446404
expl/Returns Mean                          5562.61
expl/Returns Std                              0
expl/Returns Max                           5562.61
expl/Returns Min                           5562.61
expl/Actions Mean                             0.0974966
expl/Actions Std                              0.804841
expl/Actions Max                              0.99938
expl/Actions Min                             -0.999831
expl/Num Paths                                1
expl/Average Returns                       5562.61
expl/env_infos/final/reward_run Mean          7.69749
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.69749
expl/env_infos/final/reward_run Min           7.69749
expl/env_infos/initial/reward_run Mean       -0.127376
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.127376
expl/env_infos/initial/reward_run Min        -0.127376
expl/env_infos/reward_run Mean                5.95697
expl/env_infos/reward_run Std                 1.26892
expl/env_infos/reward_run Max                 8.71466
expl/env_infos/reward_run Min                -0.127376
expl/env_infos/final/reward_ctrl Mean        -0.424761
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.424761
expl/env_infos/final/reward_ctrl Min         -0.424761
expl/env_infos/initial/reward_ctrl Mean      -0.319028
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.319028
expl/env_infos/initial/reward_ctrl Min       -0.319028
expl/env_infos/reward_ctrl Mean              -0.394365
expl/env_infos/reward_ctrl Std                0.086879
expl/env_infos/reward_ctrl Max               -0.111128
expl/env_infos/reward_ctrl Min               -0.58222
eval/num steps total                          1.58e+06
eval/num paths total                       1580
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.89657
eval/Rewards Std                              1.2876
eval/Rewards Max                              8.38967
eval/Rewards Min                             -0.847832
eval/Returns Mean                          5896.57
eval/Returns Std                             61.8356
eval/Returns Max                           5967.37
eval/Returns Min                           5781.68
eval/Actions Mean                             0.0993866
eval/Actions Std                              0.823366
eval/Actions Max                              0.99858
eval/Actions Min                             -0.9964
eval/Num Paths                                5
eval/Average Returns                       5896.57
eval/env_infos/final/reward_run Mean          6.35771
eval/env_infos/final/reward_run Std           1.33542
eval/env_infos/final/reward_run Max           8.26211
eval/env_infos/final/reward_run Min           4.4967
eval/env_infos/initial/reward_run Mean       -0.320015
eval/env_infos/initial/reward_run Std         0.151547
eval/env_infos/initial/reward_run Max        -0.103952
eval/env_infos/initial/reward_run Min        -0.515218
eval/env_infos/reward_run Mean                6.30925
eval/env_infos/reward_run Std                 1.2842
eval/env_infos/reward_run Max                 8.84773
eval/env_infos/reward_run Min                -0.515218
eval/env_infos/final/reward_ctrl Mean        -0.438622
eval/env_infos/final/reward_ctrl Std          0.0658541
eval/env_infos/final/reward_ctrl Max         -0.348388
eval/env_infos/final/reward_ctrl Min         -0.539785
eval/env_infos/initial/reward_ctrl Mean      -0.283121
eval/env_infos/initial/reward_ctrl Std        0.0291128
eval/env_infos/initial/reward_ctrl Max       -0.245664
eval/env_infos/initial/reward_ctrl Min       -0.332614
eval/env_infos/reward_ctrl Mean              -0.412686
eval/env_infos/reward_ctrl Std                0.0850436
eval/env_infos/reward_ctrl Max               -0.0981751
eval/env_infos/reward_ctrl Min               -0.581211
time/data storing (s)                         0.00453522
time/evaluation sampling (s)                  1.99307
time/exploration sampling (s)                 0.53212
time/logging (s)                              0.0136539
time/sac training (s)                         7.47589
time/saving (s)                               0.00382097
time/training (s)                             3.6079e-05
time/epoch (s)                               10.0231
time/total (s)                             3349.62
Epoch                                       315
---------------------------------------  ---------------
2021-11-24 01:25:14.822952 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 316 finished
---------------------------------------  ----------------
epoch                                       316
replay_buffer/size                       318000
trainer/num train calls                  317000
trainer/QF1 Loss                              4.6971
trainer/QF2 Loss                              4.79548
trainer/Policy Loss                        -378.877
trainer/Q1 Predictions Mean                 379.451
trainer/Q1 Predictions Std                  104.502
trainer/Q1 Predictions Max                  458.235
trainer/Q1 Predictions Min                   17.7626
trainer/Q2 Predictions Mean                 379.57
trainer/Q2 Predictions Std                  104.786
trainer/Q2 Predictions Max                  456.377
trainer/Q2 Predictions Min                   19.137
trainer/Q Targets Mean                      379.514
trainer/Q Targets Std                       104.689
trainer/Q Targets Max                       457.451
trainer/Q Targets Min                        19.3176
trainer/Log Pis Mean                          5.86283
trainer/Log Pis Std                           4.34915
trainer/Log Pis Max                          19.5853
trainer/Log Pis Min                          -4.66858
trainer/policy/mean Mean                      0.065632
trainer/policy/mean Std                       0.769304
trainer/policy/mean Max                       0.998704
trainer/policy/mean Min                      -0.997617
trainer/policy/normal/std Mean                0.437567
trainer/policy/normal/std Std                 0.151173
trainer/policy/normal/std Max                 0.968096
trainer/policy/normal/std Min                 0.0669548
trainer/policy/normal/log_std Mean           -0.905847
trainer/policy/normal/log_std Std             0.43963
trainer/policy/normal/log_std Max            -0.0324242
trainer/policy/normal/log_std Min            -2.70374
trainer/Alpha                                 0.139291
trainer/Alpha Loss                           -0.270392
expl/num steps total                     318000
expl/num paths total                        318
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.44292
expl/Rewards Std                              1.22215
expl/Rewards Max                              7.92862
expl/Rewards Min                             -0.353697
expl/Returns Mean                          5442.92
expl/Returns Std                              0
expl/Returns Max                           5442.92
expl/Returns Min                           5442.92
expl/Actions Mean                             0.104981
expl/Actions Std                              0.799031
expl/Actions Max                              0.999678
expl/Actions Min                             -0.999679
expl/Num Paths                                1
expl/Average Returns                       5442.92
expl/env_infos/final/reward_run Mean          6.19905
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.19905
expl/env_infos/final/reward_run Min           6.19905
expl/env_infos/initial/reward_run Mean       -0.0707898
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0707898
expl/env_infos/initial/reward_run Min        -0.0707898
expl/env_infos/reward_run Mean                5.83261
expl/env_infos/reward_run Std                 1.21744
expl/env_infos/reward_run Max                 8.4335
expl/env_infos/reward_run Min                -0.0785045
expl/env_infos/final/reward_ctrl Mean        -0.461109
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.461109
expl/env_infos/final/reward_ctrl Min         -0.461109
expl/env_infos/initial/reward_ctrl Mean      -0.282907
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.282907
expl/env_infos/initial/reward_ctrl Min       -0.282907
expl/env_infos/reward_ctrl Mean              -0.389683
expl/env_infos/reward_ctrl Std                0.0953297
expl/env_infos/reward_ctrl Max               -0.088174
expl/env_infos/reward_ctrl Min               -0.575604
eval/num steps total                          1.585e+06
eval/num paths total                       1585
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.94319
eval/Rewards Std                              1.27531
eval/Rewards Max                              8.40292
eval/Rewards Min                             -0.763788
eval/Returns Mean                          5943.19
eval/Returns Std                             59.799
eval/Returns Max                           6026.75
eval/Returns Min                           5869.39
eval/Actions Mean                             0.100282
eval/Actions Std                              0.820362
eval/Actions Max                              0.996034
eval/Actions Min                             -0.996201
eval/Num Paths                                5
eval/Average Returns                       5943.19
eval/env_infos/final/reward_run Mean          7.12925
eval/env_infos/final/reward_run Std           0.538848
eval/env_infos/final/reward_run Max           7.87508
eval/env_infos/final/reward_run Min           6.37738
eval/env_infos/initial/reward_run Mean       -0.3104
eval/env_infos/initial/reward_run Std         0.11248
eval/env_infos/initial/reward_run Max        -0.156407
eval/env_infos/initial/reward_run Min        -0.457216
eval/env_infos/reward_run Mean                6.35302
eval/env_infos/reward_run Std                 1.26618
eval/env_infos/reward_run Max                 8.92911
eval/env_infos/reward_run Min                -0.457216
eval/env_infos/final/reward_ctrl Mean        -0.459452
eval/env_infos/final/reward_ctrl Std          0.0292077
eval/env_infos/final/reward_ctrl Max         -0.402608
eval/env_infos/final/reward_ctrl Min         -0.482708
eval/env_infos/initial/reward_ctrl Mean      -0.238276
eval/env_infos/initial/reward_ctrl Std        0.0445553
eval/env_infos/initial/reward_ctrl Max       -0.176871
eval/env_infos/initial/reward_ctrl Min       -0.306571
eval/env_infos/reward_ctrl Mean              -0.40983
eval/env_infos/reward_ctrl Std                0.0947532
eval/env_infos/reward_ctrl Max               -0.0552164
eval/env_infos/reward_ctrl Min               -0.583209
time/data storing (s)                         0.0044996
time/evaluation sampling (s)                  2.09463
time/exploration sampling (s)                 0.530859
time/logging (s)                              0.0136589
time/sac training (s)                         7.49584
time/saving (s)                               0.00378419
time/training (s)                             3.76281e-05
time/epoch (s)                               10.1433
time/total (s)                             3360.05
Epoch                                       316
---------------------------------------  ----------------
2021-11-24 01:25:25.408954 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 317 finished
---------------------------------------  ---------------
epoch                                       317
replay_buffer/size                       319000
trainer/num train calls                  318000
trainer/QF1 Loss                              6.09921
trainer/QF2 Loss                              5.60074
trainer/Policy Loss                        -388.567
trainer/Q1 Predictions Mean                 389.121
trainer/Q1 Predictions Std                   78.0988
trainer/Q1 Predictions Max                  456.542
trainer/Q1 Predictions Min                   17.8191
trainer/Q2 Predictions Mean                 389.119
trainer/Q2 Predictions Std                   77.9308
trainer/Q2 Predictions Max                  456.674
trainer/Q2 Predictions Min                   18.9495
trainer/Q Targets Mean                      389.074
trainer/Q Targets Std                        77.8787
trainer/Q Targets Max                       455.493
trainer/Q Targets Min                        19.4008
trainer/Log Pis Mean                          6.47771
trainer/Log Pis Std                           4.57303
trainer/Log Pis Max                          20.7409
trainer/Log Pis Min                          -7.88852
trainer/policy/mean Mean                      0.068788
trainer/policy/mean Std                       0.793402
trainer/policy/mean Max                       0.996788
trainer/policy/mean Min                      -0.999249
trainer/policy/normal/std Mean                0.438097
trainer/policy/normal/std Std                 0.137131
trainer/policy/normal/std Max                 1.11409
trainer/policy/normal/std Min                 0.0693556
trainer/policy/normal/log_std Mean           -0.8918
trainer/policy/normal/log_std Std             0.403028
trainer/policy/normal/log_std Max             0.108036
trainer/policy/normal/log_std Min            -2.66851
trainer/Alpha                                 0.138534
trainer/Alpha Loss                            0.944262
expl/num steps total                     319000
expl/num paths total                        319
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.57795
expl/Rewards Std                              1.23342
expl/Rewards Max                              7.92315
expl/Rewards Min                             -0.690754
expl/Returns Mean                          5577.95
expl/Returns Std                              0
expl/Returns Max                           5577.95
expl/Returns Min                           5577.95
expl/Actions Mean                             0.0912044
expl/Actions Std                              0.794506
expl/Actions Max                              0.999673
expl/Actions Min                             -0.998977
expl/Num Paths                                1
expl/Average Returns                       5577.95
expl/env_infos/final/reward_run Mean          5.88183
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.88183
expl/env_infos/final/reward_run Min           5.88183
expl/env_infos/initial/reward_run Mean       -0.354931
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.354931
expl/env_infos/initial/reward_run Min        -0.354931
expl/env_infos/reward_run Mean                5.96169
expl/env_infos/reward_run Std                 1.22658
expl/env_infos/reward_run Max                 8.46955
expl/env_infos/reward_run Min                -0.354931
expl/env_infos/final/reward_ctrl Mean        -0.415429
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.415429
expl/env_infos/final/reward_ctrl Min         -0.415429
expl/env_infos/initial/reward_ctrl Mean      -0.335823
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.335823
expl/env_infos/initial/reward_ctrl Min       -0.335823
expl/env_infos/reward_ctrl Mean              -0.383735
expl/env_infos/reward_ctrl Std                0.0957396
expl/env_infos/reward_ctrl Max               -0.0590678
expl/env_infos/reward_ctrl Min               -0.57822
eval/num steps total                          1.59e+06
eval/num paths total                       1590
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.93946
eval/Rewards Std                              1.29495
eval/Rewards Max                              8.32234
eval/Rewards Min                             -0.78964
eval/Returns Mean                          5939.46
eval/Returns Std                             70.6801
eval/Returns Max                           6031.76
eval/Returns Min                           5836.77
eval/Actions Mean                             0.0971593
eval/Actions Std                              0.815564
eval/Actions Max                              0.995511
eval/Actions Min                             -0.995416
eval/Num Paths                                5
eval/Average Returns                       5939.46
eval/env_infos/final/reward_run Mean          7.03753
eval/env_infos/final/reward_run Std           1.05121
eval/env_infos/final/reward_run Max           8.48801
eval/env_infos/final/reward_run Min           5.52059
eval/env_infos/initial/reward_run Mean       -0.368841
eval/env_infos/initial/reward_run Std         0.202378
eval/env_infos/initial/reward_run Max        -0.0722394
eval/env_infos/initial/reward_run Min        -0.604589
eval/env_infos/reward_run Mean                6.34421
eval/env_infos/reward_run Std                 1.29129
eval/env_infos/reward_run Max                 8.81902
eval/env_infos/reward_run Min                -0.604589
eval/env_infos/final/reward_ctrl Mean        -0.486452
eval/env_infos/final/reward_ctrl Std          0.045036
eval/env_infos/final/reward_ctrl Max         -0.412985
eval/env_infos/final/reward_ctrl Min         -0.536358
eval/env_infos/initial/reward_ctrl Mean      -0.217089
eval/env_infos/initial/reward_ctrl Std        0.0395646
eval/env_infos/initial/reward_ctrl Max       -0.18388
eval/env_infos/initial/reward_ctrl Min       -0.282594
eval/env_infos/reward_ctrl Mean              -0.404751
eval/env_infos/reward_ctrl Std                0.0949906
eval/env_infos/reward_ctrl Max               -0.0635828
eval/env_infos/reward_ctrl Min               -0.584428
time/data storing (s)                         0.00451967
time/evaluation sampling (s)                  2.03257
time/exploration sampling (s)                 0.535411
time/logging (s)                              0.0137005
time/sac training (s)                         7.68857
time/saving (s)                               0.00384477
time/training (s)                             3.55e-05
time/epoch (s)                               10.2786
time/total (s)                             3370.62
Epoch                                       317
---------------------------------------  ---------------
2021-11-24 01:25:35.843819 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 318 finished
---------------------------------------  ---------------
epoch                                       318
replay_buffer/size                       320000
trainer/num train calls                  319000
trainer/QF1 Loss                              5.15119
trainer/QF2 Loss                              5.70118
trainer/Policy Loss                        -390.256
trainer/Q1 Predictions Mean                 391.159
trainer/Q1 Predictions Std                   79.2967
trainer/Q1 Predictions Max                  464.447
trainer/Q1 Predictions Min                   19.1411
trainer/Q2 Predictions Mean                 390.776
trainer/Q2 Predictions Std                   79.2363
trainer/Q2 Predictions Max                  464.341
trainer/Q2 Predictions Min                   18.226
trainer/Q Targets Mean                      390.718
trainer/Q Targets Std                        79.2615
trainer/Q Targets Max                       464.483
trainer/Q Targets Min                        17.4511
trainer/Log Pis Mean                          5.86755
trainer/Log Pis Std                           4.18901
trainer/Log Pis Max                          14.8636
trainer/Log Pis Min                          -4.88307
trainer/policy/mean Mean                      0.0723247
trainer/policy/mean Std                       0.78176
trainer/policy/mean Max                       0.998835
trainer/policy/mean Min                      -0.993913
trainer/policy/normal/std Mean                0.42952
trainer/policy/normal/std Std                 0.14203
trainer/policy/normal/std Max                 1.02861
trainer/policy/normal/std Min                 0.0719186
trainer/policy/normal/log_std Mean           -0.916814
trainer/policy/normal/log_std Std             0.416299
trainer/policy/normal/log_std Max             0.0282069
trainer/policy/normal/log_std Min            -2.63222
trainer/Alpha                                 0.138592
trainer/Alpha Loss                           -0.261757
expl/num steps total                     320000
expl/num paths total                        320
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.57706
expl/Rewards Std                              1.21708
expl/Rewards Max                              8.01624
expl/Rewards Min                             -0.345212
expl/Returns Mean                          5577.06
expl/Returns Std                              0
expl/Returns Max                           5577.06
expl/Returns Min                           5577.06
expl/Actions Mean                             0.0865737
expl/Actions Std                              0.806804
expl/Actions Max                              0.99979
expl/Actions Min                             -0.998659
expl/Num Paths                                1
expl/Average Returns                       5577.06
expl/env_infos/final/reward_run Mean          6.8384
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.8384
expl/env_infos/final/reward_run Min           6.8384
expl/env_infos/initial/reward_run Mean       -0.0812958
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0812958
expl/env_infos/initial/reward_run Min        -0.0812958
expl/env_infos/reward_run Mean                5.97212
expl/env_infos/reward_run Std                 1.21339
expl/env_infos/reward_run Max                 8.53438
expl/env_infos/reward_run Min                -0.0812958
expl/env_infos/final/reward_ctrl Mean        -0.436747
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.436747
expl/env_infos/final/reward_ctrl Min         -0.436747
expl/env_infos/initial/reward_ctrl Mean      -0.263917
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.263917
expl/env_infos/initial/reward_ctrl Min       -0.263917
expl/env_infos/reward_ctrl Mean              -0.395057
expl/env_infos/reward_ctrl Std                0.0925584
expl/env_infos/reward_ctrl Max               -0.0842768
expl/env_infos/reward_ctrl Min               -0.583962
eval/num steps total                          1.595e+06
eval/num paths total                       1595
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.86819
eval/Rewards Std                              1.26309
eval/Rewards Max                              8.29823
eval/Rewards Min                             -0.781866
eval/Returns Mean                          5868.19
eval/Returns Std                             46.9173
eval/Returns Max                           5919.22
eval/Returns Min                           5789.3
eval/Actions Mean                             0.0856759
eval/Actions Std                              0.82043
eval/Actions Max                              0.995616
eval/Actions Min                             -0.992916
eval/Num Paths                                5
eval/Average Returns                       5868.19
eval/env_infos/final/reward_run Mean          7.03396
eval/env_infos/final/reward_run Std           0.359947
eval/env_infos/final/reward_run Max           7.47519
eval/env_infos/final/reward_run Min           6.47293
eval/env_infos/initial/reward_run Mean       -0.223102
eval/env_infos/initial/reward_run Std         0.186376
eval/env_infos/initial/reward_run Max         0.0475189
eval/env_infos/initial/reward_run Min        -0.524607
eval/env_infos/reward_run Mean                6.27645
eval/env_infos/reward_run Std                 1.25749
eval/env_infos/reward_run Max                 8.80828
eval/env_infos/reward_run Min                -0.524607
eval/env_infos/final/reward_ctrl Mean        -0.408267
eval/env_infos/final/reward_ctrl Std          0.0425597
eval/env_infos/final/reward_ctrl Max         -0.329446
eval/env_infos/final/reward_ctrl Min         -0.448118
eval/env_infos/initial/reward_ctrl Mean      -0.23714
eval/env_infos/initial/reward_ctrl Std        0.0250053
eval/env_infos/initial/reward_ctrl Max       -0.2023
eval/env_infos/initial/reward_ctrl Min       -0.261065
eval/env_infos/reward_ctrl Mean              -0.408267
eval/env_infos/reward_ctrl Std                0.0933356
eval/env_infos/reward_ctrl Max               -0.088614
eval/env_infos/reward_ctrl Min               -0.582452
time/data storing (s)                         0.00450108
time/evaluation sampling (s)                  2.01623
time/exploration sampling (s)                 0.537357
time/logging (s)                              0.0136425
time/sac training (s)                         7.55875
time/saving (s)                               0.00377681
time/training (s)                             3.538e-05
time/epoch (s)                               10.1343
time/total (s)                             3381.05
Epoch                                       318
---------------------------------------  ---------------
2021-11-24 01:25:46.367204 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 319 finished
---------------------------------------  ---------------
epoch                                       319
replay_buffer/size                       321000
trainer/num train calls                  320000
trainer/QF1 Loss                              6.32015
trainer/QF2 Loss                              5.76724
trainer/Policy Loss                        -368.205
trainer/Q1 Predictions Mean                 368.78
trainer/Q1 Predictions Std                  112.333
trainer/Q1 Predictions Max                  455.944
trainer/Q1 Predictions Min                   17.8644
trainer/Q2 Predictions Mean                 368.365
trainer/Q2 Predictions Std                  112.201
trainer/Q2 Predictions Max                  455.49
trainer/Q2 Predictions Min                   18.5545
trainer/Q Targets Mean                      368.608
trainer/Q Targets Std                       112.34
trainer/Q Targets Max                       459.832
trainer/Q Targets Min                        18.1705
trainer/Log Pis Mean                          4.88811
trainer/Log Pis Std                           4.48002
trainer/Log Pis Max                          17.4906
trainer/Log Pis Min                          -5.50219
trainer/policy/mean Mean                      0.0709736
trainer/policy/mean Std                       0.760309
trainer/policy/mean Max                       0.997545
trainer/policy/mean Min                      -0.995785
trainer/policy/normal/std Mean                0.454443
trainer/policy/normal/std Std                 0.150805
trainer/policy/normal/std Max                 0.920276
trainer/policy/normal/std Min                 0.0705019
trainer/policy/normal/log_std Mean           -0.858959
trainer/policy/normal/log_std Std             0.408465
trainer/policy/normal/log_std Max            -0.0830812
trainer/policy/normal/log_std Min            -2.65211
trainer/Alpha                                 0.139999
trainer/Alpha Loss                           -2.18612
expl/num steps total                     321000
expl/num paths total                        321
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.6096
expl/Rewards Std                              1.2448
expl/Rewards Max                              8.21605
expl/Rewards Min                             -0.807974
expl/Returns Mean                          5609.6
expl/Returns Std                              0
expl/Returns Max                           5609.6
expl/Returns Min                           5609.6
expl/Actions Mean                             0.0966511
expl/Actions Std                              0.799528
expl/Actions Max                              0.999541
expl/Actions Min                             -0.999509
expl/Num Paths                                1
expl/Average Returns                       5609.6
expl/env_infos/final/reward_run Mean          6.61706
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.61706
expl/env_infos/final/reward_run Min           6.61706
expl/env_infos/initial/reward_run Mean       -0.547299
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.547299
expl/env_infos/initial/reward_run Min        -0.547299
expl/env_infos/reward_run Mean                5.99875
expl/env_infos/reward_run Std                 1.24031
expl/env_infos/reward_run Max                 8.69259
expl/env_infos/reward_run Min                -0.547299
expl/env_infos/final/reward_ctrl Mean        -0.128804
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.128804
expl/env_infos/final/reward_ctrl Min         -0.128804
expl/env_infos/initial/reward_ctrl Mean      -0.260675
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.260675
expl/env_infos/initial/reward_ctrl Min       -0.260675
expl/env_infos/reward_ctrl Mean              -0.389152
expl/env_infos/reward_ctrl Std                0.0961367
expl/env_infos/reward_ctrl Max               -0.108796
expl/env_infos/reward_ctrl Min               -0.571247
eval/num steps total                          1.6e+06
eval/num paths total                       1600
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.97784
eval/Rewards Std                              1.26976
eval/Rewards Max                              8.49679
eval/Rewards Min                             -0.790794
eval/Returns Mean                          5977.84
eval/Returns Std                             24.2448
eval/Returns Max                           5997.85
eval/Returns Min                           5930.95
eval/Actions Mean                             0.0912538
eval/Actions Std                              0.816034
eval/Actions Max                              0.9968
eval/Actions Min                             -0.995284
eval/Num Paths                                5
eval/Average Returns                       5977.84
eval/env_infos/final/reward_run Mean          6.8471
eval/env_infos/final/reward_run Std           1.18787
eval/env_infos/final/reward_run Max           8.86159
eval/env_infos/final/reward_run Min           5.41326
eval/env_infos/initial/reward_run Mean       -0.321178
eval/env_infos/initial/reward_run Std         0.104459
eval/env_infos/initial/reward_run Max        -0.222387
eval/env_infos/initial/reward_run Min        -0.493108
eval/env_infos/reward_run Mean                6.38239
eval/env_infos/reward_run Std                 1.26629
eval/env_infos/reward_run Max                 9.01346
eval/env_infos/reward_run Min                -0.493108
eval/env_infos/final/reward_ctrl Mean        -0.414946
eval/env_infos/final/reward_ctrl Std          0.0780299
eval/env_infos/final/reward_ctrl Max         -0.299256
eval/env_infos/final/reward_ctrl Min         -0.509518
eval/env_infos/initial/reward_ctrl Mean      -0.248747
eval/env_infos/initial/reward_ctrl Std        0.0229875
eval/env_infos/initial/reward_ctrl Max       -0.221449
eval/env_infos/initial/reward_ctrl Min       -0.291338
eval/env_infos/reward_ctrl Mean              -0.404543
eval/env_infos/reward_ctrl Std                0.0965441
eval/env_infos/reward_ctrl Max               -0.0983859
eval/env_infos/reward_ctrl Min               -0.587935
time/data storing (s)                         0.0044804
time/evaluation sampling (s)                  2.03926
time/exploration sampling (s)                 0.538664
time/logging (s)                              0.013625
time/sac training (s)                         7.61712
time/saving (s)                               0.00377689
time/training (s)                             3.5073e-05
time/epoch (s)                               10.217
time/total (s)                             3391.55
Epoch                                       319
---------------------------------------  ---------------
2021-11-24 01:25:56.824724 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 320 finished
---------------------------------------  ---------------
epoch                                       320
replay_buffer/size                       322000
trainer/num train calls                  321000
trainer/QF1 Loss                              7.36098
trainer/QF2 Loss                              7.84728
trainer/Policy Loss                        -388.507
trainer/Q1 Predictions Mean                 389.117
trainer/Q1 Predictions Std                   85.6256
trainer/Q1 Predictions Max                  463.358
trainer/Q1 Predictions Min                   20.1332
trainer/Q2 Predictions Mean                 389.009
trainer/Q2 Predictions Std                   85.4773
trainer/Q2 Predictions Max                  462.697
trainer/Q2 Predictions Min                   19.7293
trainer/Q Targets Mean                      388.775
trainer/Q Targets Std                        85.5693
trainer/Q Targets Max                       461.281
trainer/Q Targets Min                        19.0283
trainer/Log Pis Mean                          5.9872
trainer/Log Pis Std                           4.1483
trainer/Log Pis Max                          15.8202
trainer/Log Pis Min                          -4.05328
trainer/policy/mean Mean                      0.101522
trainer/policy/mean Std                       0.774662
trainer/policy/mean Max                       0.994803
trainer/policy/mean Min                      -0.998114
trainer/policy/normal/std Mean                0.428773
trainer/policy/normal/std Std                 0.140911
trainer/policy/normal/std Max                 1.21971
trainer/policy/normal/std Min                 0.0669554
trainer/policy/normal/log_std Mean           -0.921722
trainer/policy/normal/log_std Std             0.431333
trainer/policy/normal/log_std Max             0.198609
trainer/policy/normal/log_std Min            -2.70373
trainer/Alpha                                 0.138243
trainer/Alpha Loss                           -0.0253232
expl/num steps total                     322000
expl/num paths total                        322
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.77234
expl/Rewards Std                              1.29956
expl/Rewards Max                              8.23763
expl/Rewards Min                             -0.675802
expl/Returns Mean                          5772.34
expl/Returns Std                              0
expl/Returns Max                           5772.34
expl/Returns Min                           5772.34
expl/Actions Mean                             0.0978415
expl/Actions Std                              0.811184
expl/Actions Max                              0.999105
expl/Actions Min                             -0.998976
expl/Num Paths                                1
expl/Average Returns                       5772.34
expl/env_infos/final/reward_run Mean          7.74718
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.74718
expl/env_infos/final/reward_run Min           7.74718
expl/env_infos/initial/reward_run Mean       -0.350691
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.350691
expl/env_infos/initial/reward_run Min        -0.350691
expl/env_infos/reward_run Mean                6.1729
expl/env_infos/reward_run Std                 1.29832
expl/env_infos/reward_run Max                 8.73595
expl/env_infos/reward_run Min                -0.350691
expl/env_infos/final/reward_ctrl Mean        -0.386296
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.386296
expl/env_infos/final/reward_ctrl Min         -0.386296
expl/env_infos/initial/reward_ctrl Mean      -0.325111
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.325111
expl/env_infos/initial/reward_ctrl Min       -0.325111
expl/env_infos/reward_ctrl Mean              -0.400555
expl/env_infos/reward_ctrl Std                0.0886501
expl/env_infos/reward_ctrl Max               -0.0770218
expl/env_infos/reward_ctrl Min               -0.574373
eval/num steps total                          1.605e+06
eval/num paths total                       1605
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.93833
eval/Rewards Std                              1.2967
eval/Rewards Max                              8.34242
eval/Rewards Min                             -0.74805
eval/Returns Mean                          5938.33
eval/Returns Std                             87.097
eval/Returns Max                           6006.02
eval/Returns Min                           5771.84
eval/Actions Mean                             0.109459
eval/Actions Std                              0.821328
eval/Actions Max                              0.995663
eval/Actions Min                             -0.997006
eval/Num Paths                                5
eval/Average Returns                       5938.33
eval/env_infos/final/reward_run Mean          7.078
eval/env_infos/final/reward_run Std           0.555561
eval/env_infos/final/reward_run Max           7.98994
eval/env_infos/final/reward_run Min           6.37998
eval/env_infos/initial/reward_run Mean       -0.147903
eval/env_infos/initial/reward_run Std         0.286812
eval/env_infos/initial/reward_run Max         0.332653
eval/env_infos/initial/reward_run Min        -0.487206
eval/env_infos/reward_run Mean                6.35027
eval/env_infos/reward_run Std                 1.28779
eval/env_infos/reward_run Max                 8.85709
eval/env_infos/reward_run Min                -0.487206
eval/env_infos/final/reward_ctrl Mean        -0.370784
eval/env_infos/final/reward_ctrl Std          0.113463
eval/env_infos/final/reward_ctrl Max         -0.181061
eval/env_infos/final/reward_ctrl Min         -0.485993
eval/env_infos/initial/reward_ctrl Mean      -0.218294
eval/env_infos/initial/reward_ctrl Std        0.0480204
eval/env_infos/initial/reward_ctrl Max       -0.128149
eval/env_infos/initial/reward_ctrl Min       -0.260844
eval/env_infos/reward_ctrl Mean              -0.411937
eval/env_infos/reward_ctrl Std                0.0875031
eval/env_infos/reward_ctrl Max               -0.0627042
eval/env_infos/reward_ctrl Min               -0.58101
time/data storing (s)                         0.00464963
time/evaluation sampling (s)                  2.0489
time/exploration sampling (s)                 0.537825
time/logging (s)                              0.013671
time/sac training (s)                         7.55091
time/saving (s)                               0.00379005
time/training (s)                             3.4734e-05
time/epoch (s)                               10.1598
time/total (s)                             3402
Epoch                                       320
---------------------------------------  ---------------
2021-11-24 01:26:07.061398 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 321 finished
---------------------------------------  ---------------
epoch                                       321
replay_buffer/size                       323000
trainer/num train calls                  322000
trainer/QF1 Loss                              5.49158
trainer/QF2 Loss                              5.13757
trainer/Policy Loss                        -374.908
trainer/Q1 Predictions Mean                 375.791
trainer/Q1 Predictions Std                  109.511
trainer/Q1 Predictions Max                  461.601
trainer/Q1 Predictions Min                   19.0421
trainer/Q2 Predictions Mean                 375.031
trainer/Q2 Predictions Std                  109.287
trainer/Q2 Predictions Max                  459.707
trainer/Q2 Predictions Min                   18.6962
trainer/Q Targets Mean                      375.449
trainer/Q Targets Std                       109.418
trainer/Q Targets Max                       460.115
trainer/Q Targets Min                        18.7593
trainer/Log Pis Mean                          5.93631
trainer/Log Pis Std                           4.91213
trainer/Log Pis Max                          16.6087
trainer/Log Pis Min                          -7.6491
trainer/policy/mean Mean                      0.0719224
trainer/policy/mean Std                       0.769041
trainer/policy/mean Max                       0.998564
trainer/policy/mean Min                      -0.999299
trainer/policy/normal/std Mean                0.435596
trainer/policy/normal/std Std                 0.145772
trainer/policy/normal/std Max                 0.924322
trainer/policy/normal/std Min                 0.0697664
trainer/policy/normal/log_std Mean           -0.903066
trainer/policy/normal/log_std Std             0.415686
trainer/policy/normal/log_std Max            -0.0786948
trainer/policy/normal/log_std Min            -2.6626
trainer/Alpha                                 0.138933
trainer/Alpha Loss                           -0.125713
expl/num steps total                     323000
expl/num paths total                        323
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.73441
expl/Rewards Std                              1.20192
expl/Rewards Max                              8.1612
expl/Rewards Min                             -0.121797
expl/Returns Mean                          5734.41
expl/Returns Std                              0
expl/Returns Max                           5734.41
expl/Returns Min                           5734.41
expl/Actions Mean                             0.0856959
expl/Actions Std                              0.808236
expl/Actions Max                              0.99947
expl/Actions Min                             -0.999592
expl/Num Paths                                1
expl/Average Returns                       5734.41
expl/env_infos/final/reward_run Mean          7.19749
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.19749
expl/env_infos/final/reward_run Min           7.19749
expl/env_infos/initial/reward_run Mean        0.186135
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.186135
expl/env_infos/initial/reward_run Min         0.186135
expl/env_infos/reward_run Mean                6.13077
expl/env_infos/reward_run Std                 1.19263
expl/env_infos/reward_run Max                 8.6414
expl/env_infos/reward_run Min                 0.170262
expl/env_infos/final/reward_ctrl Mean        -0.240657
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.240657
expl/env_infos/final/reward_ctrl Min         -0.240657
expl/env_infos/initial/reward_ctrl Mean      -0.307932
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.307932
expl/env_infos/initial/reward_ctrl Min       -0.307932
expl/env_infos/reward_ctrl Mean              -0.396354
expl/env_infos/reward_ctrl Std                0.0939409
expl/env_infos/reward_ctrl Max               -0.0657658
expl/env_infos/reward_ctrl Min               -0.583125
eval/num steps total                          1.61e+06
eval/num paths total                       1610
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.05497
eval/Rewards Std                              1.2993
eval/Rewards Max                              8.63621
eval/Rewards Min                             -0.824843
eval/Returns Mean                          6054.97
eval/Returns Std                             44.2634
eval/Returns Max                           6110.78
eval/Returns Min                           5985.2
eval/Actions Mean                             0.0886195
eval/Actions Std                              0.824796
eval/Actions Max                              0.997647
eval/Actions Min                             -0.998859
eval/Num Paths                                5
eval/Average Returns                       6054.97
eval/env_infos/final/reward_run Mean          7.13213
eval/env_infos/final/reward_run Std           0.715548
eval/env_infos/final/reward_run Max           8.14586
eval/env_infos/final/reward_run Min           6.1908
eval/env_infos/initial/reward_run Mean       -0.172548
eval/env_infos/initial/reward_run Std         0.244657
eval/env_infos/initial/reward_run Max         0.189438
eval/env_infos/initial/reward_run Min        -0.516592
eval/env_infos/reward_run Mean                6.46786
eval/env_infos/reward_run Std                 1.28943
eval/env_infos/reward_run Max                 9.1256
eval/env_infos/reward_run Min                -0.516592
eval/env_infos/final/reward_ctrl Mean        -0.379506
eval/env_infos/final/reward_ctrl Std          0.0751548
eval/env_infos/final/reward_ctrl Max         -0.273143
eval/env_infos/final/reward_ctrl Min         -0.47308
eval/env_infos/initial/reward_ctrl Mean      -0.250309
eval/env_infos/initial/reward_ctrl Std        0.0397289
eval/env_infos/initial/reward_ctrl Max       -0.190195
eval/env_infos/initial/reward_ctrl Min       -0.30825
eval/env_infos/reward_ctrl Mean              -0.412885
eval/env_infos/reward_ctrl Std                0.0943734
eval/env_infos/reward_ctrl Max               -0.0627721
eval/env_infos/reward_ctrl Min               -0.586208
time/data storing (s)                         0.00454965
time/evaluation sampling (s)                  2.00578
time/exploration sampling (s)                 0.526193
time/logging (s)                              0.0136621
time/sac training (s)                         7.38617
time/saving (s)                               0.00376031
time/training (s)                             3.4524e-05
time/epoch (s)                                9.94015
time/total (s)                             3412.22
Epoch                                       321
---------------------------------------  ---------------
2021-11-24 01:26:17.583615 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 322 finished
---------------------------------------  ---------------
epoch                                       322
replay_buffer/size                       324000
trainer/num train calls                  323000
trainer/QF1 Loss                              6.8724
trainer/QF2 Loss                              7.1563
trainer/Policy Loss                        -379.311
trainer/Q1 Predictions Mean                 379.913
trainer/Q1 Predictions Std                  102.397
trainer/Q1 Predictions Max                  464.572
trainer/Q1 Predictions Min                   17.8018
trainer/Q2 Predictions Mean                 379.438
trainer/Q2 Predictions Std                  102.29
trainer/Q2 Predictions Max                  464.712
trainer/Q2 Predictions Min                   18.8975
trainer/Q Targets Mean                      379.404
trainer/Q Targets Std                       102.428
trainer/Q Targets Max                       463.458
trainer/Q Targets Min                        16.2632
trainer/Log Pis Mean                          5.72013
trainer/Log Pis Std                           4.47712
trainer/Log Pis Max                          18.8204
trainer/Log Pis Min                          -6.00188
trainer/policy/mean Mean                      0.0567942
trainer/policy/mean Std                       0.775874
trainer/policy/mean Max                       0.994357
trainer/policy/mean Min                      -0.998294
trainer/policy/normal/std Mean                0.444206
trainer/policy/normal/std Std                 0.14276
trainer/policy/normal/std Max                 1.00604
trainer/policy/normal/std Min                 0.0773495
trainer/policy/normal/log_std Mean           -0.878092
trainer/policy/normal/log_std Std             0.399727
trainer/policy/normal/log_std Max             0.00602489
trainer/policy/normal/log_std Min            -2.55942
trainer/Alpha                                 0.140265
trainer/Alpha Loss                           -0.54973
expl/num steps total                     324000
expl/num paths total                        324
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.81976
expl/Rewards Std                              1.29157
expl/Rewards Max                              8.16038
expl/Rewards Min                             -0.675243
expl/Returns Mean                          5819.76
expl/Returns Std                              0
expl/Returns Max                           5819.76
expl/Returns Min                           5819.76
expl/Actions Mean                             0.0982744
expl/Actions Std                              0.805805
expl/Actions Max                              0.999191
expl/Actions Min                             -0.99844
expl/Num Paths                                1
expl/Average Returns                       5819.76
expl/env_infos/final/reward_run Mean          5.55908
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.55908
expl/env_infos/final/reward_run Min           5.55908
expl/env_infos/initial/reward_run Mean       -0.224054
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.224054
expl/env_infos/initial/reward_run Min        -0.224054
expl/env_infos/reward_run Mean                6.21514
expl/env_infos/reward_run Std                 1.28529
expl/env_infos/reward_run Max                 8.62375
expl/env_infos/reward_run Min                -0.25066
expl/env_infos/final/reward_ctrl Mean        -0.349168
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.349168
expl/env_infos/final/reward_ctrl Min         -0.349168
expl/env_infos/initial/reward_ctrl Mean      -0.301572
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.301572
expl/env_infos/initial/reward_ctrl Min       -0.301572
expl/env_infos/reward_ctrl Mean              -0.395387
expl/env_infos/reward_ctrl Std                0.093303
expl/env_infos/reward_ctrl Max               -0.1006
expl/env_infos/reward_ctrl Min               -0.587174
eval/num steps total                          1.615e+06
eval/num paths total                       1615
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.96179
eval/Rewards Std                              1.31656
eval/Rewards Max                              8.49179
eval/Rewards Min                             -0.671028
eval/Returns Mean                          5961.79
eval/Returns Std                             51.7625
eval/Returns Max                           6033.07
eval/Returns Min                           5882.83
eval/Actions Mean                             0.0908375
eval/Actions Std                              0.8213
eval/Actions Max                              0.998387
eval/Actions Min                             -0.998486
eval/Num Paths                                5
eval/Average Returns                       5961.79
eval/env_infos/final/reward_run Mean          6.62096
eval/env_infos/final/reward_run Std           1.54749
eval/env_infos/final/reward_run Max           9.01623
eval/env_infos/final/reward_run Min           4.87893
eval/env_infos/initial/reward_run Mean       -0.227512
eval/env_infos/initial/reward_run Std         0.174063
eval/env_infos/initial/reward_run Max         0.043676
eval/env_infos/initial/reward_run Min        -0.41624
eval/env_infos/reward_run Mean                6.37147
eval/env_infos/reward_run Std                 1.31364
eval/env_infos/reward_run Max                 9.01623
eval/env_infos/reward_run Min                -0.41624
eval/env_infos/final/reward_ctrl Mean        -0.488905
eval/env_infos/final/reward_ctrl Std          0.0523618
eval/env_infos/final/reward_ctrl Max         -0.420511
eval/env_infos/final/reward_ctrl Min         -0.567849
eval/env_infos/initial/reward_ctrl Mean      -0.218644
eval/env_infos/initial/reward_ctrl Std        0.0289665
eval/env_infos/initial/reward_ctrl Max       -0.174019
eval/env_infos/initial/reward_ctrl Min       -0.254788
eval/env_infos/reward_ctrl Mean              -0.409671
eval/env_infos/reward_ctrl Std                0.0909387
eval/env_infos/reward_ctrl Max               -0.0968588
eval/env_infos/reward_ctrl Min               -0.587369
time/data storing (s)                         0.00449423
time/evaluation sampling (s)                  2.13279
time/exploration sampling (s)                 0.534209
time/logging (s)                              0.0136288
time/sac training (s)                         7.5329
time/saving (s)                               0.00383691
time/training (s)                             3.455e-05
time/epoch (s)                               10.2219
time/total (s)                             3422.73
Epoch                                       322
---------------------------------------  ---------------
2021-11-24 01:26:28.015545 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 323 finished
---------------------------------------  ---------------
epoch                                       323
replay_buffer/size                       325000
trainer/num train calls                  324000
trainer/QF1 Loss                              9.04956
trainer/QF2 Loss                              6.83227
trainer/Policy Loss                        -387.308
trainer/Q1 Predictions Mean                 388.097
trainer/Q1 Predictions Std                   87.9372
trainer/Q1 Predictions Max                  465.245
trainer/Q1 Predictions Min                   20.2627
trainer/Q2 Predictions Mean                 387.4
trainer/Q2 Predictions Std                   88.0616
trainer/Q2 Predictions Max                  463.708
trainer/Q2 Predictions Min                   20.3235
trainer/Q Targets Mean                      387.757
trainer/Q Targets Std                        88.1652
trainer/Q Targets Max                       462.716
trainer/Q Targets Min                        19.9092
trainer/Log Pis Mean                          6.43428
trainer/Log Pis Std                           4.70317
trainer/Log Pis Max                          17.9465
trainer/Log Pis Min                          -4.63742
trainer/policy/mean Mean                      0.0741328
trainer/policy/mean Std                       0.789509
trainer/policy/mean Max                       0.995484
trainer/policy/mean Min                      -0.997026
trainer/policy/normal/std Mean                0.438276
trainer/policy/normal/std Std                 0.13815
trainer/policy/normal/std Max                 0.855474
trainer/policy/normal/std Min                 0.0771446
trainer/policy/normal/log_std Mean           -0.892274
trainer/policy/normal/log_std Std             0.406152
trainer/policy/normal/log_std Max            -0.1561
trainer/policy/normal/log_std Min            -2.56207
trainer/Alpha                                 0.140596
trainer/Alpha Loss                            0.851993
expl/num steps total                     325000
expl/num paths total                        325
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.63724
expl/Rewards Std                              1.20234
expl/Rewards Max                              7.84748
expl/Rewards Min                             -0.621187
expl/Returns Mean                          5637.24
expl/Returns Std                              0
expl/Returns Max                           5637.24
expl/Returns Min                           5637.24
expl/Actions Mean                             0.0851678
expl/Actions Std                              0.801368
expl/Actions Max                              0.999599
expl/Actions Min                             -0.999007
expl/Num Paths                                1
expl/Average Returns                       5637.24
expl/env_infos/final/reward_run Mean          5.03824
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.03824
expl/env_infos/final/reward_run Min           5.03824
expl/env_infos/initial/reward_run Mean       -0.110045
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.110045
expl/env_infos/initial/reward_run Min        -0.110045
expl/env_infos/reward_run Mean                6.02691
expl/env_infos/reward_run Std                 1.20188
expl/env_infos/reward_run Max                 8.40775
expl/env_infos/reward_run Min                -0.349938
expl/env_infos/final/reward_ctrl Mean        -0.301277
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.301277
expl/env_infos/final/reward_ctrl Min         -0.301277
expl/env_infos/initial/reward_ctrl Mean      -0.26661
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.26661
expl/env_infos/initial/reward_ctrl Min       -0.26661
expl/env_infos/reward_ctrl Mean              -0.389666
expl/env_infos/reward_ctrl Std                0.0921888
expl/env_infos/reward_ctrl Max               -0.0863435
expl/env_infos/reward_ctrl Min               -0.571296
eval/num steps total                          1.62e+06
eval/num paths total                       1620
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.02462
eval/Rewards Std                              1.29627
eval/Rewards Max                              8.6543
eval/Rewards Min                             -0.932573
eval/Returns Mean                          6024.62
eval/Returns Std                             56.2938
eval/Returns Max                           6088.86
eval/Returns Min                           5952.55
eval/Actions Mean                             0.0921384
eval/Actions Std                              0.823525
eval/Actions Max                              0.99794
eval/Actions Min                             -0.998811
eval/Num Paths                                5
eval/Average Returns                       6024.62
eval/env_infos/final/reward_run Mean          7.61441
eval/env_infos/final/reward_run Std           0.574737
eval/env_infos/final/reward_run Max           8.32079
eval/env_infos/final/reward_run Min           6.70614
eval/env_infos/initial/reward_run Mean       -0.31734
eval/env_infos/initial/reward_run Std         0.193219
eval/env_infos/initial/reward_run Max        -0.101882
eval/env_infos/initial/reward_run Min        -0.65187
eval/env_infos/reward_run Mean                6.43663
eval/env_infos/reward_run Std                 1.29421
eval/env_infos/reward_run Max                 9.17501
eval/env_infos/reward_run Min                -0.65187
eval/env_infos/final/reward_ctrl Mean        -0.389621
eval/env_infos/final/reward_ctrl Std          0.0810555
eval/env_infos/final/reward_ctrl Max         -0.267846
eval/env_infos/final/reward_ctrl Min         -0.519884
eval/env_infos/initial/reward_ctrl Mean      -0.232529
eval/env_infos/initial/reward_ctrl Std        0.0406882
eval/env_infos/initial/reward_ctrl Max       -0.182034
eval/env_infos/initial/reward_ctrl Min       -0.280703
eval/env_infos/reward_ctrl Mean              -0.41201
eval/env_infos/reward_ctrl Std                0.0881046
eval/env_infos/reward_ctrl Max               -0.0765167
eval/env_infos/reward_ctrl Min               -0.576734
time/data storing (s)                         0.00446533
time/evaluation sampling (s)                  2.1007
time/exploration sampling (s)                 0.531294
time/logging (s)                              0.0135731
time/sac training (s)                         7.476
time/saving (s)                               0.00376944
time/training (s)                             3.4181e-05
time/epoch (s)                               10.1298
time/total (s)                             3433.15
Epoch                                       323
---------------------------------------  ---------------
2021-11-24 01:26:38.213515 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 324 finished
---------------------------------------  ---------------
epoch                                       324
replay_buffer/size                       326000
trainer/num train calls                  325000
trainer/QF1 Loss                             10.6841
trainer/QF2 Loss                              9.31652
trainer/Policy Loss                        -384.554
trainer/Q1 Predictions Mean                 384.678
trainer/Q1 Predictions Std                   89.1521
trainer/Q1 Predictions Max                  461.267
trainer/Q1 Predictions Min                   17.6807
trainer/Q2 Predictions Mean                 384.743
trainer/Q2 Predictions Std                   89.0691
trainer/Q2 Predictions Max                  463.309
trainer/Q2 Predictions Min                   20.252
trainer/Q Targets Mean                      384.49
trainer/Q Targets Std                        89.6155
trainer/Q Targets Max                       461.216
trainer/Q Targets Min                        20.414
trainer/Log Pis Mean                          6.08057
trainer/Log Pis Std                           4.18448
trainer/Log Pis Max                          17.8983
trainer/Log Pis Min                          -5.84406
trainer/policy/mean Mean                      0.0968011
trainer/policy/mean Std                       0.779674
trainer/policy/mean Max                       0.996278
trainer/policy/mean Min                      -0.996163
trainer/policy/normal/std Mean                0.429117
trainer/policy/normal/std Std                 0.137383
trainer/policy/normal/std Max                 1.05833
trainer/policy/normal/std Min                 0.0747218
trainer/policy/normal/log_std Mean           -0.91503
trainer/policy/normal/log_std Std             0.410154
trainer/policy/normal/log_std Max             0.0566883
trainer/policy/normal/log_std Min            -2.59398
trainer/Alpha                                 0.13879
trainer/Alpha Loss                            0.159114
expl/num steps total                     326000
expl/num paths total                        326
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.68713
expl/Rewards Std                              1.24642
expl/Rewards Max                              8.01345
expl/Rewards Min                             -0.587349
expl/Returns Mean                          5687.13
expl/Returns Std                              0
expl/Returns Max                           5687.13
expl/Returns Min                           5687.13
expl/Actions Mean                             0.100584
expl/Actions Std                              0.806486
expl/Actions Max                              0.999414
expl/Actions Min                             -0.999838
expl/Num Paths                                1
expl/Average Returns                       5687.13
expl/env_infos/final/reward_run Mean          6.88646
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.88646
expl/env_infos/final/reward_run Min           6.88646
expl/env_infos/initial/reward_run Mean       -0.223095
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.223095
expl/env_infos/initial/reward_run Min        -0.223095
expl/env_infos/reward_run Mean                6.08346
expl/env_infos/reward_run Std                 1.23036
expl/env_infos/reward_run Max                 8.47565
expl/env_infos/reward_run Min                -0.307061
expl/env_infos/final/reward_ctrl Mean        -0.352905
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.352905
expl/env_infos/final/reward_ctrl Min         -0.352905
expl/env_infos/initial/reward_ctrl Mean      -0.364254
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.364254
expl/env_infos/initial/reward_ctrl Min       -0.364254
expl/env_infos/reward_ctrl Mean              -0.396322
expl/env_infos/reward_ctrl Std                0.0957683
expl/env_infos/reward_ctrl Max               -0.0765254
expl/env_infos/reward_ctrl Min               -0.586097
eval/num steps total                          1.625e+06
eval/num paths total                       1625
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.0731
eval/Rewards Std                              1.287
eval/Rewards Max                              8.55768
eval/Rewards Min                             -0.71044
eval/Returns Mean                          6073.1
eval/Returns Std                             38.6634
eval/Returns Max                           6121.23
eval/Returns Min                           6013.06
eval/Actions Mean                             0.0947518
eval/Actions Std                              0.822565
eval/Actions Max                              0.997121
eval/Actions Min                             -0.997978
eval/Num Paths                                5
eval/Average Returns                       6073.1
eval/env_infos/final/reward_run Mean          6.57189
eval/env_infos/final/reward_run Std           0.876692
eval/env_infos/final/reward_run Max           8.2267
eval/env_infos/final/reward_run Min           5.74579
eval/env_infos/initial/reward_run Mean       -0.209742
eval/env_infos/initial/reward_run Std         0.181827
eval/env_infos/initial/reward_run Max         0.0433407
eval/env_infos/initial/reward_run Min        -0.49545
eval/env_infos/reward_run Mean                6.48445
eval/env_infos/reward_run Std                 1.27224
eval/env_infos/reward_run Max                 9.05556
eval/env_infos/reward_run Min                -0.49545
eval/env_infos/final/reward_ctrl Mean        -0.442227
eval/env_infos/final/reward_ctrl Std          0.0335245
eval/env_infos/final/reward_ctrl Max         -0.400716
eval/env_infos/final/reward_ctrl Min         -0.49597
eval/env_infos/initial/reward_ctrl Mean      -0.227298
eval/env_infos/initial/reward_ctrl Std        0.019484
eval/env_infos/initial/reward_ctrl Max       -0.19884
eval/env_infos/initial/reward_ctrl Min       -0.254671
eval/env_infos/reward_ctrl Mean              -0.411355
eval/env_infos/reward_ctrl Std                0.092168
eval/env_infos/reward_ctrl Max               -0.0819107
eval/env_infos/reward_ctrl Min               -0.583414
time/data storing (s)                         0.00444913
time/evaluation sampling (s)                  1.99539
time/exploration sampling (s)                 0.535369
time/logging (s)                              0.0135795
time/sac training (s)                         7.3521
time/saving (s)                               0.00377465
time/training (s)                             3.4215e-05
time/epoch (s)                                9.9047
time/total (s)                             3443.33
Epoch                                       324
---------------------------------------  ---------------
2021-11-24 01:26:48.471453 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 325 finished
---------------------------------------  ---------------
epoch                                       325
replay_buffer/size                       327000
trainer/num train calls                  326000
trainer/QF1 Loss                              6.9519
trainer/QF2 Loss                              7.07566
trainer/Policy Loss                        -373.585
trainer/Q1 Predictions Mean                 374.162
trainer/Q1 Predictions Std                  113.459
trainer/Q1 Predictions Max                  454.437
trainer/Q1 Predictions Min                   18.5734
trainer/Q2 Predictions Mean                 374.17
trainer/Q2 Predictions Std                  113.402
trainer/Q2 Predictions Max                  455.252
trainer/Q2 Predictions Min                   18.7735
trainer/Q Targets Mean                      374.055
trainer/Q Targets Std                       113.687
trainer/Q Targets Max                       455.252
trainer/Q Targets Min                        17.8285
trainer/Log Pis Mean                          5.58748
trainer/Log Pis Std                           4.43011
trainer/Log Pis Max                          18.0084
trainer/Log Pis Min                          -5.09606
trainer/policy/mean Mean                      0.0842733
trainer/policy/mean Std                       0.76734
trainer/policy/mean Max                       0.998656
trainer/policy/mean Min                      -0.998445
trainer/policy/normal/std Mean                0.447041
trainer/policy/normal/std Std                 0.150639
trainer/policy/normal/std Max                 1.23344
trainer/policy/normal/std Min                 0.0696949
trainer/policy/normal/log_std Mean           -0.879014
trainer/policy/normal/log_std Std             0.421843
trainer/policy/normal/log_std Max             0.209804
trainer/policy/normal/log_std Min            -2.66363
trainer/Alpha                                 0.13945
trainer/Alpha Loss                           -0.812694
expl/num steps total                     327000
expl/num paths total                        327
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.54994
expl/Rewards Std                              1.18588
expl/Rewards Max                              7.95913
expl/Rewards Min                             -0.332689
expl/Returns Mean                          5549.94
expl/Returns Std                              0
expl/Returns Max                           5549.94
expl/Returns Min                           5549.94
expl/Actions Mean                             0.0905576
expl/Actions Std                              0.792423
expl/Actions Max                              0.999803
expl/Actions Min                             -0.999325
expl/Num Paths                                1
expl/Average Returns                       5549.94
expl/env_infos/final/reward_run Mean          6.33667
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.33667
expl/env_infos/final/reward_run Min           6.33667
expl/env_infos/initial/reward_run Mean       -0.111679
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.111679
expl/env_infos/initial/reward_run Min        -0.111679
expl/env_infos/reward_run Mean                5.93162
expl/env_infos/reward_run Std                 1.18686
expl/env_infos/reward_run Max                 8.38604
expl/env_infos/reward_run Min                -0.111679
expl/env_infos/final/reward_ctrl Mean        -0.524757
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.524757
expl/env_infos/final/reward_ctrl Min         -0.524757
expl/env_infos/initial/reward_ctrl Mean      -0.221011
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.221011
expl/env_infos/initial/reward_ctrl Min       -0.221011
expl/env_infos/reward_ctrl Mean              -0.381681
expl/env_infos/reward_ctrl Std                0.0912458
expl/env_infos/reward_ctrl Max               -0.0941515
expl/env_infos/reward_ctrl Min               -0.57372
eval/num steps total                          1.63e+06
eval/num paths total                       1630
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.85605
eval/Rewards Std                              1.2661
eval/Rewards Max                              8.48871
eval/Rewards Min                             -0.794541
eval/Returns Mean                          5856.05
eval/Returns Std                             54.2428
eval/Returns Max                           5926.11
eval/Returns Min                           5773.92
eval/Actions Mean                             0.0916162
eval/Actions Std                              0.81287
eval/Actions Max                              0.997454
eval/Actions Min                             -0.995645
eval/Num Paths                                5
eval/Average Returns                       5856.05
eval/env_infos/final/reward_run Mean          7.52359
eval/env_infos/final/reward_run Std           0.937441
eval/env_infos/final/reward_run Max           8.82101
eval/env_infos/final/reward_run Min           5.90682
eval/env_infos/initial/reward_run Mean       -0.383881
eval/env_infos/initial/reward_run Std         0.0963015
eval/env_infos/initial/reward_run Max        -0.289891
eval/env_infos/initial/reward_run Min        -0.565398
eval/env_infos/reward_run Mean                6.25754
eval/env_infos/reward_run Std                 1.26382
eval/env_infos/reward_run Max                 8.99078
eval/env_infos/reward_run Min                -0.565398
eval/env_infos/final/reward_ctrl Mean        -0.429788
eval/env_infos/final/reward_ctrl Std          0.0577606
eval/env_infos/final/reward_ctrl Max         -0.343576
eval/env_infos/final/reward_ctrl Min         -0.524775
eval/env_infos/initial/reward_ctrl Mean      -0.228541
eval/env_infos/initial/reward_ctrl Std        0.0675302
eval/env_infos/initial/reward_ctrl Max       -0.16902
eval/env_infos/initial/reward_ctrl Min       -0.359705
eval/env_infos/reward_ctrl Mean              -0.401491
eval/env_infos/reward_ctrl Std                0.0881865
eval/env_infos/reward_ctrl Max               -0.10461
eval/env_infos/reward_ctrl Min               -0.58034
time/data storing (s)                         0.004472
time/evaluation sampling (s)                  2.00874
time/exploration sampling (s)                 0.532843
time/logging (s)                              0.0137165
time/sac training (s)                         7.39616
time/saving (s)                               0.00375362
time/training (s)                             3.4838e-05
time/epoch (s)                                9.95971
time/total (s)                             3453.58
Epoch                                       325
---------------------------------------  ---------------
2021-11-24 01:26:58.816286 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 326 finished
---------------------------------------  ---------------
epoch                                       326
replay_buffer/size                       328000
trainer/num train calls                  327000
trainer/QF1 Loss                              6.51088
trainer/QF2 Loss                              6.4613
trainer/Policy Loss                        -390.834
trainer/Q1 Predictions Mean                 391.12
trainer/Q1 Predictions Std                   82.1955
trainer/Q1 Predictions Max                  459.724
trainer/Q1 Predictions Min                   19.2274
trainer/Q2 Predictions Mean                 391.081
trainer/Q2 Predictions Std                   82.1418
trainer/Q2 Predictions Max                  458.41
trainer/Q2 Predictions Min                   19.4499
trainer/Q Targets Mean                      391.681
trainer/Q Targets Std                        82.4513
trainer/Q Targets Max                       463.56
trainer/Q Targets Min                        19.9861
trainer/Log Pis Mean                          5.49823
trainer/Log Pis Std                           4.1758
trainer/Log Pis Max                          16.9472
trainer/Log Pis Min                          -8.05598
trainer/policy/mean Mean                      0.0840473
trainer/policy/mean Std                       0.770107
trainer/policy/mean Max                       0.993765
trainer/policy/mean Min                      -0.996957
trainer/policy/normal/std Mean                0.425447
trainer/policy/normal/std Std                 0.136431
trainer/policy/normal/std Max                 0.856152
trainer/policy/normal/std Min                 0.0716507
trainer/policy/normal/log_std Mean           -0.922849
trainer/policy/normal/log_std Std             0.405305
trainer/policy/normal/log_std Max            -0.155307
trainer/policy/normal/log_std Min            -2.63595
trainer/Alpha                                 0.137259
trainer/Alpha Loss                           -0.996455
expl/num steps total                     328000
expl/num paths total                        328
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.62844
expl/Rewards Std                              1.2562
expl/Rewards Max                              8.14546
expl/Rewards Min                             -0.750139
expl/Returns Mean                          5628.44
expl/Returns Std                              0
expl/Returns Max                           5628.44
expl/Returns Min                           5628.44
expl/Actions Mean                             0.116951
expl/Actions Std                              0.801758
expl/Actions Max                              0.999349
expl/Actions Min                             -0.999495
expl/Num Paths                                1
expl/Average Returns                       5628.44
expl/env_infos/final/reward_run Mean          6.77705
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.77705
expl/env_infos/final/reward_run Min           6.77705
expl/env_infos/initial/reward_run Mean       -0.490003
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.490003
expl/env_infos/initial/reward_run Min        -0.490003
expl/env_infos/reward_run Mean                6.02234
expl/env_infos/reward_run Std                 1.25166
expl/env_infos/reward_run Max                 8.67579
expl/env_infos/reward_run Min                -0.490003
expl/env_infos/final/reward_ctrl Mean        -0.316894
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.316894
expl/env_infos/final/reward_ctrl Min         -0.316894
expl/env_infos/initial/reward_ctrl Mean      -0.260135
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.260135
expl/env_infos/initial/reward_ctrl Min       -0.260135
expl/env_infos/reward_ctrl Mean              -0.393896
expl/env_infos/reward_ctrl Std                0.090755
expl/env_infos/reward_ctrl Max               -0.0902982
expl/env_infos/reward_ctrl Min               -0.587242
eval/num steps total                          1.635e+06
eval/num paths total                       1635
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.961
eval/Rewards Std                              1.28486
eval/Rewards Max                              8.55845
eval/Rewards Min                             -0.751194
eval/Returns Mean                          5961
eval/Returns Std                             30.7588
eval/Returns Max                           5990.95
eval/Returns Min                           5903.32
eval/Actions Mean                             0.115538
eval/Actions Std                              0.819299
eval/Actions Max                              0.996571
eval/Actions Min                             -0.995731
eval/Num Paths                                5
eval/Average Returns                       5961
eval/env_infos/final/reward_run Mean          6.50818
eval/env_infos/final/reward_run Std           0.822816
eval/env_infos/final/reward_run Max           7.79946
eval/env_infos/final/reward_run Min           5.2889
eval/env_infos/initial/reward_run Mean       -0.299934
eval/env_infos/initial/reward_run Std         0.185314
eval/env_infos/initial/reward_run Max        -0.0239562
eval/env_infos/initial/reward_run Min        -0.505933
eval/env_infos/reward_run Mean                6.37176
eval/env_infos/reward_run Std                 1.27569
eval/env_infos/reward_run Max                 9.05873
eval/env_infos/reward_run Min                -0.505933
eval/env_infos/final/reward_ctrl Mean        -0.466798
eval/env_infos/final/reward_ctrl Std          0.0379499
eval/env_infos/final/reward_ctrl Max         -0.399916
eval/env_infos/final/reward_ctrl Min         -0.517236
eval/env_infos/initial/reward_ctrl Mean      -0.207879
eval/env_infos/initial/reward_ctrl Std        0.033516
eval/env_infos/initial/reward_ctrl Max       -0.156092
eval/env_infos/initial/reward_ctrl Min       -0.245261
eval/env_infos/reward_ctrl Mean              -0.41076
eval/env_infos/reward_ctrl Std                0.0900468
eval/env_infos/reward_ctrl Max               -0.0916605
eval/env_infos/reward_ctrl Min               -0.57932
time/data storing (s)                         0.00456764
time/evaluation sampling (s)                  2.13543
time/exploration sampling (s)                 0.530273
time/logging (s)                              0.0136074
time/sac training (s)                         7.3617
time/saving (s)                               0.00527085
time/training (s)                             3.3903e-05
time/epoch (s)                               10.0509
time/total (s)                             3463.91
Epoch                                       326
---------------------------------------  ---------------
2021-11-24 01:27:09.012823 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 327 finished
---------------------------------------  ---------------
epoch                                       327
replay_buffer/size                       329000
trainer/num train calls                  328000
trainer/QF1 Loss                              5.39468
trainer/QF2 Loss                              5.4605
trainer/Policy Loss                        -385.599
trainer/Q1 Predictions Mean                 386.029
trainer/Q1 Predictions Std                   92.9379
trainer/Q1 Predictions Max                  458.499
trainer/Q1 Predictions Min                   20.1014
trainer/Q2 Predictions Mean                 386.082
trainer/Q2 Predictions Std                   93.0583
trainer/Q2 Predictions Max                  460.855
trainer/Q2 Predictions Min                   19.2026
trainer/Q Targets Mean                      385.688
trainer/Q Targets Std                        92.8388
trainer/Q Targets Max                       462.185
trainer/Q Targets Min                        18.1655
trainer/Log Pis Mean                          6.44136
trainer/Log Pis Std                           4.26949
trainer/Log Pis Max                          15.5453
trainer/Log Pis Min                          -5.44684
trainer/policy/mean Mean                      0.108277
trainer/policy/mean Std                       0.781574
trainer/policy/mean Max                       0.998148
trainer/policy/mean Min                      -0.997094
trainer/policy/normal/std Mean                0.43353
trainer/policy/normal/std Std                 0.139041
trainer/policy/normal/std Max                 0.937214
trainer/policy/normal/std Min                 0.064789
trainer/policy/normal/log_std Mean           -0.907255
trainer/policy/normal/log_std Std             0.421651
trainer/policy/normal/log_std Max            -0.0648441
trainer/policy/normal/log_std Min            -2.73662
trainer/Alpha                                 0.137445
trainer/Alpha Loss                            0.8759
expl/num steps total                     329000
expl/num paths total                        329
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.70887
expl/Rewards Std                              1.19479
expl/Rewards Max                              8.03398
expl/Rewards Min                             -0.669157
expl/Returns Mean                          5708.87
expl/Returns Std                              0
expl/Returns Max                           5708.87
expl/Returns Min                           5708.87
expl/Actions Mean                             0.101662
expl/Actions Std                              0.799789
expl/Actions Max                              0.999884
expl/Actions Min                             -0.99909
expl/Num Paths                                1
expl/Average Returns                       5708.87
expl/env_infos/final/reward_run Mean          6.07037
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.07037
expl/env_infos/final/reward_run Min           6.07037
expl/env_infos/initial/reward_run Mean       -0.453642
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.453642
expl/env_infos/initial/reward_run Min        -0.453642
expl/env_infos/reward_run Mean                6.09887
expl/env_infos/reward_run Std                 1.19604
expl/env_infos/reward_run Max                 8.50453
expl/env_infos/reward_run Min                -0.453642
expl/env_infos/final/reward_ctrl Mean        -0.475406
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.475406
expl/env_infos/final/reward_ctrl Min         -0.475406
expl/env_infos/initial/reward_ctrl Mean      -0.215516
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.215516
expl/env_infos/initial/reward_ctrl Min       -0.215516
expl/env_infos/reward_ctrl Mean              -0.389998
expl/env_infos/reward_ctrl Std                0.0918575
expl/env_infos/reward_ctrl Max               -0.0666947
expl/env_infos/reward_ctrl Min               -0.580859
eval/num steps total                          1.64e+06
eval/num paths total                       1640
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.97305
eval/Rewards Std                              1.25755
eval/Rewards Max                              8.50595
eval/Rewards Min                             -0.774173
eval/Returns Mean                          5973.05
eval/Returns Std                             65.2037
eval/Returns Max                           6087.44
eval/Returns Min                           5893.24
eval/Actions Mean                             0.0986671
eval/Actions Std                              0.813867
eval/Actions Max                              0.997431
eval/Actions Min                             -0.997661
eval/Num Paths                                5
eval/Average Returns                       5973.05
eval/env_infos/final/reward_run Mean          6.38662
eval/env_infos/final/reward_run Std           0.925054
eval/env_infos/final/reward_run Max           7.86184
eval/env_infos/final/reward_run Min           5.30189
eval/env_infos/initial/reward_run Mean       -0.295032
eval/env_infos/initial/reward_run Std         0.154005
eval/env_infos/initial/reward_run Max        -0.119118
eval/env_infos/initial/reward_run Min        -0.564649
eval/env_infos/reward_run Mean                6.37632
eval/env_infos/reward_run Std                 1.25688
eval/env_infos/reward_run Max                 9.01432
eval/env_infos/reward_run Min                -0.564649
eval/env_infos/final/reward_ctrl Mean        -0.425385
eval/env_infos/final/reward_ctrl Std          0.061069
eval/env_infos/final/reward_ctrl Max         -0.313671
eval/env_infos/final/reward_ctrl Min         -0.489645
eval/env_infos/initial/reward_ctrl Mean      -0.204127
eval/env_infos/initial/reward_ctrl Std        0.0164733
eval/env_infos/initial/reward_ctrl Max       -0.180923
eval/env_infos/initial/reward_ctrl Min       -0.230424
eval/env_infos/reward_ctrl Mean              -0.403269
eval/env_infos/reward_ctrl Std                0.0921565
eval/env_infos/reward_ctrl Max               -0.106456
eval/env_infos/reward_ctrl Min               -0.580841
time/data storing (s)                         0.00450433
time/evaluation sampling (s)                  2.00347
time/exploration sampling (s)                 0.52749
time/logging (s)                              0.0135669
time/sac training (s)                         7.34963
time/saving (s)                               0.00375429
time/training (s)                             3.3521e-05
time/epoch (s)                                9.90246
time/total (s)                             3474.09
Epoch                                       327
---------------------------------------  ---------------
2021-11-24 01:27:19.213494 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 328 finished
---------------------------------------  ---------------
epoch                                       328
replay_buffer/size                       330000
trainer/num train calls                  329000
trainer/QF1 Loss                              6.06272
trainer/QF2 Loss                              8.13612
trainer/Policy Loss                        -384.068
trainer/Q1 Predictions Mean                 384.698
trainer/Q1 Predictions Std                   95.0094
trainer/Q1 Predictions Max                  464.214
trainer/Q1 Predictions Min                   19.079
trainer/Q2 Predictions Mean                 384.635
trainer/Q2 Predictions Std                   95.0298
trainer/Q2 Predictions Max                  465.046
trainer/Q2 Predictions Min                   19.2277
trainer/Q Targets Mean                      383.998
trainer/Q Targets Std                        94.7087
trainer/Q Targets Max                       463.669
trainer/Q Targets Min                        17.6794
trainer/Log Pis Mean                          5.96901
trainer/Log Pis Std                           4.31922
trainer/Log Pis Max                          17.0688
trainer/Log Pis Min                          -8.21214
trainer/policy/mean Mean                      0.0971108
trainer/policy/mean Std                       0.782071
trainer/policy/mean Max                       0.994929
trainer/policy/mean Min                      -0.993802
trainer/policy/normal/std Mean                0.443065
trainer/policy/normal/std Std                 0.137121
trainer/policy/normal/std Max                 0.840036
trainer/policy/normal/std Min                 0.072387
trainer/policy/normal/log_std Mean           -0.879575
trainer/policy/normal/log_std Std             0.400708
trainer/policy/normal/log_std Max            -0.17431
trainer/policy/normal/log_std Min            -2.62573
trainer/Alpha                                 0.138072
trainer/Alpha Loss                           -0.0613514
expl/num steps total                     330000
expl/num paths total                        330
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.52896
expl/Rewards Std                              1.18617
expl/Rewards Max                              7.75008
expl/Rewards Min                             -0.697416
expl/Returns Mean                          5528.96
expl/Returns Std                              0
expl/Returns Max                           5528.96
expl/Returns Min                           5528.96
expl/Actions Mean                             0.128719
expl/Actions Std                              0.800382
expl/Actions Max                              0.999721
expl/Actions Min                             -0.998822
expl/Num Paths                                1
expl/Average Returns                       5528.96
expl/env_infos/final/reward_run Mean          8.07864
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.07864
expl/env_infos/final/reward_run Min           8.07864
expl/env_infos/initial/reward_run Mean       -0.458685
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.458685
expl/env_infos/initial/reward_run Min        -0.458685
expl/env_infos/reward_run Mean                5.92327
expl/env_infos/reward_run Std                 1.17689
expl/env_infos/reward_run Max                 8.26052
expl/env_infos/reward_run Min                -0.458685
expl/env_infos/final/reward_ctrl Mean        -0.388318
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.388318
expl/env_infos/final/reward_ctrl Min         -0.388318
expl/env_infos/initial/reward_ctrl Mean      -0.238731
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.238731
expl/env_infos/initial/reward_ctrl Min       -0.238731
expl/env_infos/reward_ctrl Mean              -0.394308
expl/env_infos/reward_ctrl Std                0.0841543
expl/env_infos/reward_ctrl Max               -0.121055
expl/env_infos/reward_ctrl Min               -0.584132
eval/num steps total                          1.645e+06
eval/num paths total                       1645
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.82195
eval/Rewards Std                              1.24693
eval/Rewards Max                              8.14445
eval/Rewards Min                             -0.74784
eval/Returns Mean                          5821.95
eval/Returns Std                             47.5369
eval/Returns Max                           5895.28
eval/Returns Min                           5747.63
eval/Actions Mean                             0.140906
eval/Actions Std                              0.811884
eval/Actions Max                              0.997236
eval/Actions Min                             -0.994487
eval/Num Paths                                5
eval/Average Returns                       5821.95
eval/env_infos/final/reward_run Mean          6.80454
eval/env_infos/final/reward_run Std           0.648437
eval/env_infos/final/reward_run Max           7.42999
eval/env_infos/final/reward_run Min           5.71908
eval/env_infos/initial/reward_run Mean       -0.356302
eval/env_infos/initial/reward_run Std         0.127142
eval/env_infos/initial/reward_run Max        -0.20382
eval/env_infos/initial/reward_run Min        -0.52759
eval/env_infos/reward_run Mean                6.22935
eval/env_infos/reward_run Std                 1.23484
eval/env_infos/reward_run Max                 8.67522
eval/env_infos/reward_run Min                -0.52759
eval/env_infos/final/reward_ctrl Mean        -0.40743
eval/env_infos/final/reward_ctrl Std          0.0450334
eval/env_infos/final/reward_ctrl Max         -0.359417
eval/env_infos/final/reward_ctrl Min         -0.478576
eval/env_infos/initial/reward_ctrl Mean      -0.247424
eval/env_infos/initial/reward_ctrl Std        0.0211395
eval/env_infos/initial/reward_ctrl Max       -0.22025
eval/env_infos/initial/reward_ctrl Min       -0.281138
eval/env_infos/reward_ctrl Mean              -0.407406
eval/env_infos/reward_ctrl Std                0.0842932
eval/env_infos/reward_ctrl Max               -0.106511
eval/env_infos/reward_ctrl Min               -0.572554
time/data storing (s)                         0.00457366
time/evaluation sampling (s)                  1.99952
time/exploration sampling (s)                 0.529211
time/logging (s)                              0.0135675
time/sac training (s)                         7.355
time/saving (s)                               0.00375288
time/training (s)                             3.4391e-05
time/epoch (s)                                9.90566
time/total (s)                             3484.28
Epoch                                       328
---------------------------------------  ---------------
2021-11-24 01:27:29.410600 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 329 finished
---------------------------------------  ---------------
epoch                                       329
replay_buffer/size                       331000
trainer/num train calls                  330000
trainer/QF1 Loss                              6.10529
trainer/QF2 Loss                              4.89182
trainer/Policy Loss                        -383.009
trainer/Q1 Predictions Mean                 383.564
trainer/Q1 Predictions Std                  102.114
trainer/Q1 Predictions Max                  459.614
trainer/Q1 Predictions Min                   19.5005
trainer/Q2 Predictions Mean                 383.35
trainer/Q2 Predictions Std                  102.145
trainer/Q2 Predictions Max                  461.106
trainer/Q2 Predictions Min                   19.3187
trainer/Q Targets Mean                      383.724
trainer/Q Targets Std                       102.163
trainer/Q Targets Max                       460.282
trainer/Q Targets Min                        19.8815
trainer/Log Pis Mean                          5.875
trainer/Log Pis Std                           4.5555
trainer/Log Pis Max                          25.693
trainer/Log Pis Min                          -6.1942
trainer/policy/mean Mean                      0.0997572
trainer/policy/mean Std                       0.76793
trainer/policy/mean Max                       0.997629
trainer/policy/mean Min                      -0.998488
trainer/policy/normal/std Mean                0.432651
trainer/policy/normal/std Std                 0.143759
trainer/policy/normal/std Max                 0.955762
trainer/policy/normal/std Min                 0.0580178
trainer/policy/normal/log_std Mean           -0.912286
trainer/policy/normal/log_std Std             0.42745
trainer/policy/normal/log_std Max            -0.0452465
trainer/policy/normal/log_std Min            -2.84701
trainer/Alpha                                 0.136764
trainer/Alpha Loss                           -0.248683
expl/num steps total                     331000
expl/num paths total                        331
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.65675
expl/Rewards Std                              1.19152
expl/Rewards Max                              8.30079
expl/Rewards Min                             -0.635858
expl/Returns Mean                          5656.75
expl/Returns Std                              0
expl/Returns Max                           5656.75
expl/Returns Min                           5656.75
expl/Actions Mean                             0.0908724
expl/Actions Std                              0.793637
expl/Actions Max                              0.999799
expl/Actions Min                             -0.999205
expl/Num Paths                                1
expl/Average Returns                       5656.75
expl/env_infos/final/reward_run Mean          6.51105
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.51105
expl/env_infos/final/reward_run Min           6.51105
expl/env_infos/initial/reward_run Mean        0.508695
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.508695
expl/env_infos/initial/reward_run Min         0.508695
expl/env_infos/reward_run Mean                6.03962
expl/env_infos/reward_run Std                 1.18372
expl/env_infos/reward_run Max                 8.79699
expl/env_infos/reward_run Min                -0.160592
expl/env_infos/final/reward_ctrl Mean        -0.210491
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.210491
expl/env_infos/final/reward_ctrl Min         -0.210491
expl/env_infos/initial/reward_ctrl Mean      -0.112057
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.112057
expl/env_infos/initial/reward_ctrl Min       -0.112057
expl/env_infos/reward_ctrl Mean              -0.382871
expl/env_infos/reward_ctrl Std                0.0955236
expl/env_infos/reward_ctrl Max               -0.0461419
expl/env_infos/reward_ctrl Min               -0.590392
eval/num steps total                          1.65e+06
eval/num paths total                       1650
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.9859
eval/Rewards Std                              1.27455
eval/Rewards Max                              8.44169
eval/Rewards Min                             -0.60887
eval/Returns Mean                          5985.9
eval/Returns Std                             67.8164
eval/Returns Max                           6085.33
eval/Returns Min                           5883.77
eval/Actions Mean                             0.0910472
eval/Actions Std                              0.815658
eval/Actions Max                              0.995853
eval/Actions Min                             -0.993849
eval/Num Paths                                5
eval/Average Returns                       5985.9
eval/env_infos/final/reward_run Mean          7.17842
eval/env_infos/final/reward_run Std           0.547487
eval/env_infos/final/reward_run Max           7.83854
eval/env_infos/final/reward_run Min           6.29404
eval/env_infos/initial/reward_run Mean       -0.245532
eval/env_infos/initial/reward_run Std         0.131634
eval/env_infos/initial/reward_run Max        -0.0219422
eval/env_infos/initial/reward_run Min        -0.398228
eval/env_infos/reward_run Mean                6.39005
eval/env_infos/reward_run Std                 1.26946
eval/env_infos/reward_run Max                 8.94753
eval/env_infos/reward_run Min                -0.398228
eval/env_infos/final/reward_ctrl Mean        -0.376893
eval/env_infos/final/reward_ctrl Std          0.0512397
eval/env_infos/final/reward_ctrl Max         -0.314356
eval/env_infos/final/reward_ctrl Min         -0.436387
eval/env_infos/initial/reward_ctrl Mean      -0.223597
eval/env_infos/initial/reward_ctrl Std        0.0153064
eval/env_infos/initial/reward_ctrl Max       -0.200614
eval/env_infos/initial/reward_ctrl Min       -0.241029
eval/env_infos/reward_ctrl Mean              -0.404153
eval/env_infos/reward_ctrl Std                0.0906941
eval/env_infos/reward_ctrl Max               -0.0628563
eval/env_infos/reward_ctrl Min               -0.5832
time/data storing (s)                         0.00447394
time/evaluation sampling (s)                  1.99988
time/exploration sampling (s)                 0.52124
time/logging (s)                              0.0136559
time/sac training (s)                         7.35965
time/saving (s)                               0.00371945
time/training (s)                             3.5072e-05
time/epoch (s)                                9.90266
time/total (s)                             3494.46
Epoch                                       329
---------------------------------------  ---------------
2021-11-24 01:27:39.620042 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 330 finished
---------------------------------------  ---------------
epoch                                       330
replay_buffer/size                       332000
trainer/num train calls                  331000
trainer/QF1 Loss                              6.73357
trainer/QF2 Loss                              7.04493
trainer/Policy Loss                        -379.722
trainer/Q1 Predictions Mean                 380.321
trainer/Q1 Predictions Std                  105.838
trainer/Q1 Predictions Max                  460.881
trainer/Q1 Predictions Min                   21.3875
trainer/Q2 Predictions Mean                 380.354
trainer/Q2 Predictions Std                  105.928
trainer/Q2 Predictions Max                  463.209
trainer/Q2 Predictions Min                   20.6426
trainer/Q Targets Mean                      380.657
trainer/Q Targets Std                       106.013
trainer/Q Targets Max                       462.518
trainer/Q Targets Min                        20.4383
trainer/Log Pis Mean                          5.82958
trainer/Log Pis Std                           4.56543
trainer/Log Pis Max                          16.0795
trainer/Log Pis Min                          -5.0233
trainer/policy/mean Mean                      0.0463932
trainer/policy/mean Std                       0.778137
trainer/policy/mean Max                       0.999817
trainer/policy/mean Min                      -0.996952
trainer/policy/normal/std Mean                0.443307
trainer/policy/normal/std Std                 0.149049
trainer/policy/normal/std Max                 1.16607
trainer/policy/normal/std Min                 0.070205
trainer/policy/normal/log_std Mean           -0.885553
trainer/policy/normal/log_std Std             0.415517
trainer/policy/normal/log_std Max             0.15364
trainer/policy/normal/log_std Min            -2.65634
trainer/Alpha                                 0.137397
trainer/Alpha Loss                           -0.338268
expl/num steps total                     332000
expl/num paths total                        332
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.84037
expl/Rewards Std                              1.18935
expl/Rewards Max                              7.966
expl/Rewards Min                             -0.728872
expl/Returns Mean                          5840.37
expl/Returns Std                              0
expl/Returns Max                           5840.37
expl/Returns Min                           5840.37
expl/Actions Mean                             0.083326
expl/Actions Std                              0.80113
expl/Actions Max                              0.999636
expl/Actions Min                             -0.999054
expl/Num Paths                                1
expl/Average Returns                       5840.37
expl/env_infos/final/reward_run Mean          5.72541
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.72541
expl/env_infos/final/reward_run Min           5.72541
expl/env_infos/initial/reward_run Mean       -0.470626
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.470626
expl/env_infos/initial/reward_run Min        -0.470626
expl/env_infos/reward_run Mean                6.22962
expl/env_infos/reward_run Std                 1.18269
expl/env_infos/reward_run Max                 8.45167
expl/env_infos/reward_run Min                -0.470626
expl/env_infos/final/reward_ctrl Mean        -0.367059
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.367059
expl/env_infos/final/reward_ctrl Min         -0.367059
expl/env_infos/initial/reward_ctrl Mean      -0.258246
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.258246
expl/env_infos/initial/reward_ctrl Min       -0.258246
expl/env_infos/reward_ctrl Mean              -0.389251
expl/env_infos/reward_ctrl Std                0.0941347
expl/env_infos/reward_ctrl Max               -0.0381176
expl/env_infos/reward_ctrl Min               -0.577132
eval/num steps total                          1.655e+06
eval/num paths total                       1655
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.99102
eval/Rewards Std                              1.26264
eval/Rewards Max                              8.37199
eval/Rewards Min                             -0.909817
eval/Returns Mean                          5991.02
eval/Returns Std                             81.7094
eval/Returns Max                           6077.14
eval/Returns Min                           5861.01
eval/Actions Mean                             0.0863488
eval/Actions Std                              0.815649
eval/Actions Max                              0.996616
eval/Actions Min                             -0.993446
eval/Num Paths                                5
eval/Average Returns                       5991.02
eval/env_infos/final/reward_run Mean          7.22265
eval/env_infos/final/reward_run Std           0.83839
eval/env_infos/final/reward_run Max           8.37304
eval/env_infos/final/reward_run Min           6.34954
eval/env_infos/initial/reward_run Mean       -0.501494
eval/env_infos/initial/reward_run Std         0.143181
eval/env_infos/initial/reward_run Max        -0.317611
eval/env_infos/initial/reward_run Min        -0.716559
eval/env_infos/reward_run Mean                6.39467
eval/env_infos/reward_run Std                 1.26198
eval/env_infos/reward_run Max                 8.88959
eval/env_infos/reward_run Min                -0.716559
eval/env_infos/final/reward_ctrl Mean        -0.486634
eval/env_infos/final/reward_ctrl Std          0.0287074
eval/env_infos/final/reward_ctrl Max         -0.431914
eval/env_infos/final/reward_ctrl Min         -0.51202
eval/env_infos/initial/reward_ctrl Mean      -0.235343
eval/env_infos/initial/reward_ctrl Std        0.0233114
eval/env_infos/initial/reward_ctrl Max       -0.193258
eval/env_infos/initial/reward_ctrl Min       -0.265167
eval/env_infos/reward_ctrl Mean              -0.403644
eval/env_infos/reward_ctrl Std                0.0918232
eval/env_infos/reward_ctrl Max               -0.102471
eval/env_infos/reward_ctrl Min               -0.583196
time/data storing (s)                         0.00451285
time/evaluation sampling (s)                  1.9983
time/exploration sampling (s)                 0.532765
time/logging (s)                              0.0135891
time/sac training (s)                         7.3624
time/saving (s)                               0.00375836
time/training (s)                             3.5129e-05
time/epoch (s)                                9.91536
time/total (s)                             3504.66
Epoch                                       330
---------------------------------------  ---------------
2021-11-24 01:27:49.880119 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 331 finished
---------------------------------------  ---------------
epoch                                       331
replay_buffer/size                       333000
trainer/num train calls                  332000
trainer/QF1 Loss                              5.15726
trainer/QF2 Loss                              5.98579
trainer/Policy Loss                        -376.988
trainer/Q1 Predictions Mean                 378.09
trainer/Q1 Predictions Std                  110.701
trainer/Q1 Predictions Max                  463.986
trainer/Q1 Predictions Min                   20.0765
trainer/Q2 Predictions Mean                 377.537
trainer/Q2 Predictions Std                  110.613
trainer/Q2 Predictions Max                  461.055
trainer/Q2 Predictions Min                   19.2362
trainer/Q Targets Mean                      377.624
trainer/Q Targets Std                       110.858
trainer/Q Targets Max                       462.855
trainer/Q Targets Min                        19.0786
trainer/Log Pis Mean                          5.63332
trainer/Log Pis Std                           4.60002
trainer/Log Pis Max                          18.2753
trainer/Log Pis Min                          -5.62195
trainer/policy/mean Mean                      0.101948
trainer/policy/mean Std                       0.761787
trainer/policy/mean Max                       0.99489
trainer/policy/mean Min                      -0.997426
trainer/policy/normal/std Mean                0.452829
trainer/policy/normal/std Std                 0.143822
trainer/policy/normal/std Max                 0.983442
trainer/policy/normal/std Min                 0.0779244
trainer/policy/normal/log_std Mean           -0.858352
trainer/policy/normal/log_std Std             0.398685
trainer/policy/normal/log_std Max            -0.0166968
trainer/policy/normal/log_std Min            -2.55202
trainer/Alpha                                 0.139225
trainer/Alpha Loss                           -0.722969
expl/num steps total                     333000
expl/num paths total                        333
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.67003
expl/Rewards Std                              1.22702
expl/Rewards Max                              7.93699
expl/Rewards Min                             -0.492122
expl/Returns Mean                          5670.03
expl/Returns Std                              0
expl/Returns Max                           5670.03
expl/Returns Min                           5670.03
expl/Actions Mean                             0.100311
expl/Actions Std                              0.808913
expl/Actions Max                              0.999738
expl/Actions Min                             -0.999896
expl/Num Paths                                1
expl/Average Returns                       5670.03
expl/env_infos/final/reward_run Mean          7.10259
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.10259
expl/env_infos/final/reward_run Min           7.10259
expl/env_infos/initial/reward_run Mean       -0.0581627
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0581627
expl/env_infos/initial/reward_run Min        -0.0581627
expl/env_infos/reward_run Mean                6.06867
expl/env_infos/reward_run Std                 1.21843
expl/env_infos/reward_run Max                 8.44463
expl/env_infos/reward_run Min                -0.189138
expl/env_infos/final/reward_ctrl Mean        -0.289875
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.289875
expl/env_infos/final/reward_ctrl Min         -0.289875
expl/env_infos/initial/reward_ctrl Mean      -0.298029
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.298029
expl/env_infos/initial/reward_ctrl Min       -0.298029
expl/env_infos/reward_ctrl Mean              -0.398641
expl/env_infos/reward_ctrl Std                0.0882084
expl/env_infos/reward_ctrl Max               -0.0532542
expl/env_infos/reward_ctrl Min               -0.581073
eval/num steps total                          1.66e+06
eval/num paths total                       1660
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.04692
eval/Rewards Std                              1.33706
eval/Rewards Max                              8.7842
eval/Rewards Min                             -0.683577
eval/Returns Mean                          6046.92
eval/Returns Std                             61.3739
eval/Returns Max                           6101.14
eval/Returns Min                           5932.73
eval/Actions Mean                             0.110617
eval/Actions Std                              0.824851
eval/Actions Max                              0.99751
eval/Actions Min                             -0.997554
eval/Num Paths                                5
eval/Average Returns                       6046.92
eval/env_infos/final/reward_run Mean          6.68347
eval/env_infos/final/reward_run Std           0.511047
eval/env_infos/final/reward_run Max           7.67611
eval/env_infos/final/reward_run Min           6.25104
eval/env_infos/initial/reward_run Mean       -0.343745
eval/env_infos/initial/reward_run Std         0.0878235
eval/env_infos/initial/reward_run Max        -0.195902
eval/env_infos/initial/reward_run Min        -0.446353
eval/env_infos/reward_run Mean                6.46249
eval/env_infos/reward_run Std                 1.32908
eval/env_infos/reward_run Max                 9.27596
eval/env_infos/reward_run Min                -0.446353
eval/env_infos/final/reward_ctrl Mean        -0.386435
eval/env_infos/final/reward_ctrl Std          0.0501663
eval/env_infos/final/reward_ctrl Max         -0.306548
eval/env_infos/final/reward_ctrl Min         -0.431736
eval/env_infos/initial/reward_ctrl Mean      -0.20622
eval/env_infos/initial/reward_ctrl Std        0.0411507
eval/env_infos/initial/reward_ctrl Max       -0.166381
eval/env_infos/initial/reward_ctrl Min       -0.278086
eval/env_infos/reward_ctrl Mean              -0.415569
eval/env_infos/reward_ctrl Std                0.0848252
eval/env_infos/reward_ctrl Max               -0.0916356
eval/env_infos/reward_ctrl Min               -0.579648
time/data storing (s)                         0.00451707
time/evaluation sampling (s)                  2.05014
time/exploration sampling (s)                 0.537405
time/logging (s)                              0.013632
time/sac training (s)                         7.3576
time/saving (s)                               0.00376384
time/training (s)                             3.4205e-05
time/epoch (s)                                9.96709
time/total (s)                             3514.9
Epoch                                       331
---------------------------------------  ---------------
2021-11-24 01:28:00.076343 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 332 finished
---------------------------------------  ---------------
epoch                                       332
replay_buffer/size                       334000
trainer/num train calls                  333000
trainer/QF1 Loss                              6.90007
trainer/QF2 Loss                              7.17304
trainer/Policy Loss                        -382.422
trainer/Q1 Predictions Mean                 382.782
trainer/Q1 Predictions Std                  103.498
trainer/Q1 Predictions Max                  468.258
trainer/Q1 Predictions Min                   20.4727
trainer/Q2 Predictions Mean                 383.165
trainer/Q2 Predictions Std                  103.592
trainer/Q2 Predictions Max                  468.583
trainer/Q2 Predictions Min                   19.1216
trainer/Q Targets Mean                      382.399
trainer/Q Targets Std                       103.23
trainer/Q Targets Max                       469.694
trainer/Q Targets Min                        20.0923
trainer/Log Pis Mean                          5.97486
trainer/Log Pis Std                           4.53777
trainer/Log Pis Max                          17.8903
trainer/Log Pis Min                          -4.94393
trainer/policy/mean Mean                      0.0646407
trainer/policy/mean Std                       0.778382
trainer/policy/mean Max                       0.997782
trainer/policy/mean Min                      -0.994744
trainer/policy/normal/std Mean                0.440205
trainer/policy/normal/std Std                 0.140296
trainer/policy/normal/std Max                 0.866265
trainer/policy/normal/std Min                 0.0718697
trainer/policy/normal/log_std Mean           -0.887587
trainer/policy/normal/log_std Std             0.403016
trainer/policy/normal/log_std Max            -0.143565
trainer/policy/normal/log_std Min            -2.6329
trainer/Alpha                                 0.138107
trainer/Alpha Loss                           -0.0497652
expl/num steps total                     334000
expl/num paths total                        334
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.6771
expl/Rewards Std                              1.23417
expl/Rewards Max                              7.95512
expl/Rewards Min                             -0.361369
expl/Returns Mean                          5677.1
expl/Returns Std                              0
expl/Returns Max                           5677.1
expl/Returns Min                           5677.1
expl/Actions Mean                             0.0895906
expl/Actions Std                              0.79778
expl/Actions Max                              0.999602
expl/Actions Min                             -0.99883
expl/Num Paths                                1
expl/Average Returns                       5677.1
expl/env_infos/final/reward_run Mean          4.56864
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.56864
expl/env_infos/final/reward_run Min           4.56864
expl/env_infos/initial/reward_run Mean       -0.143849
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.143849
expl/env_infos/initial/reward_run Min        -0.143849
expl/env_infos/reward_run Mean                6.06379
expl/env_infos/reward_run Std                 1.23427
expl/env_infos/reward_run Max                 8.44891
expl/env_infos/reward_run Min                -0.143849
expl/env_infos/final/reward_ctrl Mean        -0.439911
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.439911
expl/env_infos/final/reward_ctrl Min         -0.439911
expl/env_infos/initial/reward_ctrl Mean      -0.21752
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.21752
expl/env_infos/initial/reward_ctrl Min       -0.21752
expl/env_infos/reward_ctrl Mean              -0.386688
expl/env_infos/reward_ctrl Std                0.0927013
expl/env_infos/reward_ctrl Max               -0.0368503
expl/env_infos/reward_ctrl Min               -0.583386
eval/num steps total                          1.665e+06
eval/num paths total                       1665
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.98115
eval/Rewards Std                              1.29866
eval/Rewards Max                              8.74522
eval/Rewards Min                             -0.742277
eval/Returns Mean                          5981.15
eval/Returns Std                             14.5933
eval/Returns Max                           6009.77
eval/Returns Min                           5969.28
eval/Actions Mean                             0.079638
eval/Actions Std                              0.819281
eval/Actions Max                              0.996525
eval/Actions Min                             -0.995645
eval/Num Paths                                5
eval/Average Returns                       5981.15
eval/env_infos/final/reward_run Mean          7.42421
eval/env_infos/final/reward_run Std           0.501808
eval/env_infos/final/reward_run Max           7.84332
eval/env_infos/final/reward_run Min           6.45476
eval/env_infos/initial/reward_run Mean       -0.207038
eval/env_infos/initial/reward_run Std         0.290908
eval/env_infos/initial/reward_run Max         0.115293
eval/env_infos/initial/reward_run Min        -0.540081
eval/env_infos/reward_run Mean                6.38769
eval/env_infos/reward_run Std                 1.29733
eval/env_infos/reward_run Max                 9.26573
eval/env_infos/reward_run Min                -0.540081
eval/env_infos/final/reward_ctrl Mean        -0.431435
eval/env_infos/final/reward_ctrl Std          0.0407815
eval/env_infos/final/reward_ctrl Max         -0.402886
eval/env_infos/final/reward_ctrl Min         -0.511454
eval/env_infos/initial/reward_ctrl Mean      -0.217169
eval/env_infos/initial/reward_ctrl Std        0.021734
eval/env_infos/initial/reward_ctrl Max       -0.191422
eval/env_infos/initial/reward_ctrl Min       -0.247311
eval/env_infos/reward_ctrl Mean              -0.406538
eval/env_infos/reward_ctrl Std                0.0905601
eval/env_infos/reward_ctrl Max               -0.0977065
eval/env_infos/reward_ctrl Min               -0.583598
time/data storing (s)                         0.00453872
time/evaluation sampling (s)                  1.99642
time/exploration sampling (s)                 0.529673
time/logging (s)                              0.0135249
time/sac training (s)                         7.35462
time/saving (s)                               0.00372792
time/training (s)                             3.432e-05
time/epoch (s)                                9.90254
time/total (s)                             3525.08
Epoch                                       332
---------------------------------------  ---------------
2021-11-24 01:28:10.291330 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 333 finished
---------------------------------------  ---------------
epoch                                       333
replay_buffer/size                       335000
trainer/num train calls                  334000
trainer/QF1 Loss                              6.41905
trainer/QF2 Loss                              6.18677
trainer/Policy Loss                        -388.83
trainer/Q1 Predictions Mean                 389.393
trainer/Q1 Predictions Std                   97.9785
trainer/Q1 Predictions Max                  460.771
trainer/Q1 Predictions Min                   17.862
trainer/Q2 Predictions Mean                 389.464
trainer/Q2 Predictions Std                   97.9991
trainer/Q2 Predictions Max                  458.281
trainer/Q2 Predictions Min                   17.6054
trainer/Q Targets Mean                      389.549
trainer/Q Targets Std                        98.0848
trainer/Q Targets Max                       457.883
trainer/Q Targets Min                        17.8941
trainer/Log Pis Mean                          6.41486
trainer/Log Pis Std                           4.39618
trainer/Log Pis Max                          16.2757
trainer/Log Pis Min                          -6.14102
trainer/policy/mean Mean                      0.0902671
trainer/policy/mean Std                       0.785653
trainer/policy/mean Max                       0.99833
trainer/policy/mean Min                      -0.998053
trainer/policy/normal/std Mean                0.439194
trainer/policy/normal/std Std                 0.14298
trainer/policy/normal/std Max                 1.23221
trainer/policy/normal/std Min                 0.0611225
trainer/policy/normal/log_std Mean           -0.894812
trainer/policy/normal/log_std Std             0.420816
trainer/policy/normal/log_std Max             0.208808
trainer/policy/normal/log_std Min            -2.79488
trainer/Alpha                                 0.13963
trainer/Alpha Loss                            0.816751
expl/num steps total                     335000
expl/num paths total                        335
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.89432
expl/Rewards Std                              1.35155
expl/Rewards Max                              8.35242
expl/Rewards Min                             -0.567454
expl/Returns Mean                          5894.32
expl/Returns Std                              0
expl/Returns Max                           5894.32
expl/Returns Min                           5894.32
expl/Actions Mean                             0.106625
expl/Actions Std                              0.807287
expl/Actions Max                              0.999821
expl/Actions Min                             -0.999249
expl/Num Paths                                1
expl/Average Returns                       5894.32
expl/env_infos/final/reward_run Mean          5.2118
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.2118
expl/env_infos/final/reward_run Min           5.2118
expl/env_infos/initial/reward_run Mean       -0.150819
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.150819
expl/env_infos/initial/reward_run Min        -0.150819
expl/env_infos/reward_run Mean                6.29217
expl/env_infos/reward_run Std                 1.34935
expl/env_infos/reward_run Max                 8.79129
expl/env_infos/reward_run Min                -0.209467
expl/env_infos/final/reward_ctrl Mean        -0.474864
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.474864
expl/env_infos/final/reward_ctrl Min         -0.474864
expl/env_infos/initial/reward_ctrl Mean      -0.197788
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.197788
expl/env_infos/initial/reward_ctrl Min       -0.197788
expl/env_infos/reward_ctrl Mean              -0.397849
expl/env_infos/reward_ctrl Std                0.0898815
expl/env_infos/reward_ctrl Max               -0.114019
expl/env_infos/reward_ctrl Min               -0.579702
eval/num steps total                          1.67e+06
eval/num paths total                       1670
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.11585
eval/Rewards Std                              1.33004
eval/Rewards Max                              8.84213
eval/Rewards Min                             -0.981979
eval/Returns Mean                          6115.85
eval/Returns Std                             89.9436
eval/Returns Max                           6213.91
eval/Returns Min                           5952.63
eval/Actions Mean                             0.108272
eval/Actions Std                              0.820845
eval/Actions Max                              0.99708
eval/Actions Min                             -0.995983
eval/Num Paths                                5
eval/Average Returns                       6115.85
eval/env_infos/final/reward_run Mean          6.82761
eval/env_infos/final/reward_run Std           0.635651
eval/env_infos/final/reward_run Max           8.041
eval/env_infos/final/reward_run Min           6.314
eval/env_infos/initial/reward_run Mean       -0.289985
eval/env_infos/initial/reward_run Std         0.342353
eval/env_infos/initial/reward_run Max         0.246385
eval/env_infos/initial/reward_run Min        -0.733011
eval/env_infos/reward_run Mean                6.52716
eval/env_infos/reward_run Std                 1.31864
eval/env_infos/reward_run Max                 9.35269
eval/env_infos/reward_run Min                -0.733011
eval/env_infos/final/reward_ctrl Mean        -0.422676
eval/env_infos/final/reward_ctrl Std          0.0670844
eval/env_infos/final/reward_ctrl Max         -0.343256
eval/env_infos/final/reward_ctrl Min         -0.50557
eval/env_infos/initial/reward_ctrl Mean      -0.227638
eval/env_infos/initial/reward_ctrl Std        0.0354302
eval/env_infos/initial/reward_ctrl Max       -0.174822
eval/env_infos/initial/reward_ctrl Min       -0.270739
eval/env_infos/reward_ctrl Mean              -0.411305
eval/env_infos/reward_ctrl Std                0.0897399
eval/env_infos/reward_ctrl Max               -0.0947054
eval/env_infos/reward_ctrl Min               -0.578856
time/data storing (s)                         0.00449844
time/evaluation sampling (s)                  2.00458
time/exploration sampling (s)                 0.528193
time/logging (s)                              0.0135473
time/sac training (s)                         7.36488
time/saving (s)                               0.00520777
time/training (s)                             3.4078e-05
time/epoch (s)                                9.92095
time/total (s)                             3535.28
Epoch                                       333
---------------------------------------  ---------------
2021-11-24 01:28:20.507753 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 334 finished
---------------------------------------  ---------------
epoch                                       334
replay_buffer/size                       336000
trainer/num train calls                  335000
trainer/QF1 Loss                              8.76511
trainer/QF2 Loss                              8.28506
trainer/Policy Loss                        -388.471
trainer/Q1 Predictions Mean                 389.564
trainer/Q1 Predictions Std                   89.9599
trainer/Q1 Predictions Max                  466.03
trainer/Q1 Predictions Min                   21.7356
trainer/Q2 Predictions Mean                 388.842
trainer/Q2 Predictions Std                   89.9467
trainer/Q2 Predictions Max                  466.88
trainer/Q2 Predictions Min                   18.6329
trainer/Q Targets Mean                      388.715
trainer/Q Targets Std                        89.8417
trainer/Q Targets Max                       465.059
trainer/Q Targets Min                        20.6386
trainer/Log Pis Mean                          5.88833
trainer/Log Pis Std                           4.3329
trainer/Log Pis Max                          18.9562
trainer/Log Pis Min                          -6.90027
trainer/policy/mean Mean                      0.0862966
trainer/policy/mean Std                       0.771105
trainer/policy/mean Max                       0.999838
trainer/policy/mean Min                      -0.996658
trainer/policy/normal/std Mean                0.430806
trainer/policy/normal/std Std                 0.138449
trainer/policy/normal/std Max                 0.949598
trainer/policy/normal/std Min                 0.0691053
trainer/policy/normal/log_std Mean           -0.91224
trainer/policy/normal/log_std Std             0.414545
trainer/policy/normal/log_std Max            -0.0517165
trainer/policy/normal/log_std Min            -2.67212
trainer/Alpha                                 0.139192
trainer/Alpha Loss                           -0.220208
expl/num steps total                     336000
expl/num paths total                        336
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.60481
expl/Rewards Std                              1.21704
expl/Rewards Max                              7.86597
expl/Rewards Min                             -0.31868
expl/Returns Mean                          5604.81
expl/Returns Std                              0
expl/Returns Max                           5604.81
expl/Returns Min                           5604.81
expl/Actions Mean                             0.114162
expl/Actions Std                              0.796135
expl/Actions Max                              0.999538
expl/Actions Min                             -0.998735
expl/Num Paths                                1
expl/Average Returns                       5604.81
expl/env_infos/final/reward_run Mean          7.47071
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.47071
expl/env_infos/final/reward_run Min           7.47071
expl/env_infos/initial/reward_run Mean        0.0125962
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0125962
expl/env_infos/initial/reward_run Min         0.0125962
expl/env_infos/reward_run Mean                5.99293
expl/env_infos/reward_run Std                 1.21036
expl/env_infos/reward_run Max                 8.31223
expl/env_infos/reward_run Min                 0.0125962
expl/env_infos/final/reward_ctrl Mean        -0.502477
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.502477
expl/env_infos/final/reward_ctrl Min         -0.502477
expl/env_infos/initial/reward_ctrl Mean      -0.323715
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.323715
expl/env_infos/initial/reward_ctrl Min       -0.323715
expl/env_infos/reward_ctrl Mean              -0.388118
expl/env_infos/reward_ctrl Std                0.0954357
expl/env_infos/reward_ctrl Max               -0.0748028
expl/env_infos/reward_ctrl Min               -0.576095
eval/num steps total                          1.675e+06
eval/num paths total                       1675
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.99701
eval/Rewards Std                              1.29247
eval/Rewards Max                              8.49055
eval/Rewards Min                             -0.612278
eval/Returns Mean                          5997.01
eval/Returns Std                             52.7955
eval/Returns Max                           6090.97
eval/Returns Min                           5944.48
eval/Actions Mean                             0.107758
eval/Actions Std                              0.814317
eval/Actions Max                              0.998209
eval/Actions Min                             -0.993813
eval/Num Paths                                5
eval/Average Returns                       5997.01
eval/env_infos/final/reward_run Mean          6.00368
eval/env_infos/final/reward_run Std           0.677597
eval/env_infos/final/reward_run Max           6.91702
eval/env_infos/final/reward_run Min           5.04017
eval/env_infos/initial/reward_run Mean       -0.0405267
eval/env_infos/initial/reward_run Std         0.234839
eval/env_infos/initial/reward_run Max         0.283499
eval/env_infos/initial/reward_run Min        -0.367417
eval/env_infos/reward_run Mean                6.40185
eval/env_infos/reward_run Std                 1.28585
eval/env_infos/reward_run Max                 9.01357
eval/env_infos/reward_run Min                -0.367417
eval/env_infos/final/reward_ctrl Mean        -0.45316
eval/env_infos/final/reward_ctrl Std          0.0494038
eval/env_infos/final/reward_ctrl Max         -0.387217
eval/env_infos/final/reward_ctrl Min         -0.511904
eval/env_infos/initial/reward_ctrl Mean      -0.185017
eval/env_infos/initial/reward_ctrl Std        0.0520931
eval/env_infos/initial/reward_ctrl Max       -0.093088
eval/env_infos/initial/reward_ctrl Min       -0.244861
eval/env_infos/reward_ctrl Mean              -0.404835
eval/env_infos/reward_ctrl Std                0.09104
eval/env_infos/reward_ctrl Max               -0.0826126
eval/env_infos/reward_ctrl Min               -0.580521
time/data storing (s)                         0.00449996
time/evaluation sampling (s)                  2.00071
time/exploration sampling (s)                 0.531853
time/logging (s)                              0.0136305
time/sac training (s)                         7.3664
time/saving (s)                               0.00375306
time/training (s)                             3.4221e-05
time/epoch (s)                                9.92088
time/total (s)                             3545.49
Epoch                                       334
---------------------------------------  ---------------
2021-11-24 01:28:30.881004 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 335 finished
---------------------------------------  ---------------
epoch                                       335
replay_buffer/size                       337000
trainer/num train calls                  336000
trainer/QF1 Loss                              9.26442
trainer/QF2 Loss                             11.2848
trainer/Policy Loss                        -387.282
trainer/Q1 Predictions Mean                 387.567
trainer/Q1 Predictions Std                   94.558
trainer/Q1 Predictions Max                  462.739
trainer/Q1 Predictions Min                   18.7235
trainer/Q2 Predictions Mean                 387.439
trainer/Q2 Predictions Std                   94.6523
trainer/Q2 Predictions Max                  462.475
trainer/Q2 Predictions Min                   19.5861
trainer/Q Targets Mean                      387.42
trainer/Q Targets Std                        94.1924
trainer/Q Targets Max                       464.014
trainer/Q Targets Min                        18.7304
trainer/Log Pis Mean                          5.84362
trainer/Log Pis Std                           4.2294
trainer/Log Pis Max                          15.9967
trainer/Log Pis Min                          -4.08838
trainer/policy/mean Mean                      0.0675385
trainer/policy/mean Std                       0.777967
trainer/policy/mean Max                       0.999845
trainer/policy/mean Min                      -0.998477
trainer/policy/normal/std Mean                0.438204
trainer/policy/normal/std Std                 0.140365
trainer/policy/normal/std Max                 0.988033
trainer/policy/normal/std Min                 0.0650684
trainer/policy/normal/log_std Mean           -0.89368
trainer/policy/normal/log_std Std             0.409142
trainer/policy/normal/log_std Max            -0.0120394
trainer/policy/normal/log_std Min            -2.73232
trainer/Alpha                                 0.138069
trainer/Alpha Loss                           -0.309635
expl/num steps total                     337000
expl/num paths total                        337
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.79524
expl/Rewards Std                              1.27513
expl/Rewards Max                              8.2951
expl/Rewards Min                             -0.322802
expl/Returns Mean                          5795.24
expl/Returns Std                              0
expl/Returns Max                           5795.24
expl/Returns Min                           5795.24
expl/Actions Mean                             0.081373
expl/Actions Std                              0.802802
expl/Actions Max                              0.999196
expl/Actions Min                             -0.999157
expl/Num Paths                                1
expl/Average Returns                       5795.24
expl/env_infos/final/reward_run Mean          6.63161
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.63161
expl/env_infos/final/reward_run Min           6.63161
expl/env_infos/initial/reward_run Mean        0.108672
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.108672
expl/env_infos/initial/reward_run Min         0.108672
expl/env_infos/reward_run Mean                6.1859
expl/env_infos/reward_run Std                 1.26986
expl/env_infos/reward_run Max                 8.80853
expl/env_infos/reward_run Min                 0.0139699
expl/env_infos/final/reward_ctrl Mean        -0.481583
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.481583
expl/env_infos/final/reward_ctrl Min         -0.481583
expl/env_infos/initial/reward_ctrl Mean      -0.18495
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.18495
expl/env_infos/initial/reward_ctrl Min       -0.18495
expl/env_infos/reward_ctrl Mean              -0.390668
expl/env_infos/reward_ctrl Std                0.0911169
expl/env_infos/reward_ctrl Max               -0.0996014
expl/env_infos/reward_ctrl Min               -0.576363
eval/num steps total                          1.68e+06
eval/num paths total                       1680
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.00081
eval/Rewards Std                              1.2653
eval/Rewards Max                              8.45183
eval/Rewards Min                             -0.668067
eval/Returns Mean                          6000.81
eval/Returns Std                             64.3445
eval/Returns Max                           6095.28
eval/Returns Min                           5936.48
eval/Actions Mean                             0.0807433
eval/Actions Std                              0.816157
eval/Actions Max                              0.995698
eval/Actions Min                             -0.995495
eval/Num Paths                                5
eval/Average Returns                       6000.81
eval/env_infos/final/reward_run Mean          7.01388
eval/env_infos/final/reward_run Std           0.639163
eval/env_infos/final/reward_run Max           7.70422
eval/env_infos/final/reward_run Min           6.1238
eval/env_infos/initial/reward_run Mean       -0.194093
eval/env_infos/initial/reward_run Std         0.100352
eval/env_infos/initial/reward_run Max        -0.10961
eval/env_infos/initial/reward_run Min        -0.384927
eval/env_infos/reward_run Mean                6.40439
eval/env_infos/reward_run Std                 1.25507
eval/env_infos/reward_run Max                 8.95199
eval/env_infos/reward_run Min                -0.384927
eval/env_infos/final/reward_ctrl Mean        -0.453666
eval/env_infos/final/reward_ctrl Std          0.0106217
eval/env_infos/final/reward_ctrl Max         -0.435978
eval/env_infos/final/reward_ctrl Min         -0.463658
eval/env_infos/initial/reward_ctrl Mean      -0.229811
eval/env_infos/initial/reward_ctrl Std        0.034538
eval/env_infos/initial/reward_ctrl Max       -0.180468
eval/env_infos/initial/reward_ctrl Min       -0.28314
eval/env_infos/reward_ctrl Mean              -0.403579
eval/env_infos/reward_ctrl Std                0.0866711
eval/env_infos/reward_ctrl Max               -0.0853883
eval/env_infos/reward_ctrl Min               -0.580044
time/data storing (s)                         0.0045026
time/evaluation sampling (s)                  2.0036
time/exploration sampling (s)                 0.531733
time/logging (s)                              0.0136133
time/sac training (s)                         7.51307
time/saving (s)                               0.00380111
time/training (s)                             3.4621e-05
time/epoch (s)                               10.0704
time/total (s)                             3555.85
Epoch                                       335
---------------------------------------  ---------------
2021-11-24 01:28:41.421578 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 336 finished
---------------------------------------  ---------------
epoch                                       336
replay_buffer/size                       338000
trainer/num train calls                  337000
trainer/QF1 Loss                              5.17037
trainer/QF2 Loss                              6.8188
trainer/Policy Loss                        -395.39
trainer/Q1 Predictions Mean                 396.38
trainer/Q1 Predictions Std                   88.7879
trainer/Q1 Predictions Max                  464.804
trainer/Q1 Predictions Min                   19.9235
trainer/Q2 Predictions Mean                 396.265
trainer/Q2 Predictions Std                   88.8087
trainer/Q2 Predictions Max                  465.068
trainer/Q2 Predictions Min                   20.1496
trainer/Q Targets Mean                      396.277
trainer/Q Targets Std                        88.7785
trainer/Q Targets Max                       462.216
trainer/Q Targets Min                        19.8201
trainer/Log Pis Mean                          6.85664
trainer/Log Pis Std                           4.52893
trainer/Log Pis Max                          25.3305
trainer/Log Pis Min                          -4.29115
trainer/policy/mean Mean                      0.0873834
trainer/policy/mean Std                       0.801762
trainer/policy/mean Max                       0.999643
trainer/policy/mean Min                      -0.999881
trainer/policy/normal/std Mean                0.438227
trainer/policy/normal/std Std                 0.141993
trainer/policy/normal/std Max                 0.9987
trainer/policy/normal/std Min                 0.0701328
trainer/policy/normal/log_std Mean           -0.896865
trainer/policy/normal/log_std Std             0.421316
trainer/policy/normal/log_std Max            -0.00130035
trainer/policy/normal/log_std Min            -2.65736
trainer/Alpha                                 0.138548
trainer/Alpha Loss                            1.69319
expl/num steps total                     338000
expl/num paths total                        338
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.49859
expl/Rewards Std                              1.31151
expl/Rewards Max                              8.27892
expl/Rewards Min                             -0.0593147
expl/Returns Mean                          5498.59
expl/Returns Std                              0
expl/Returns Max                           5498.59
expl/Returns Min                           5498.59
expl/Actions Mean                             0.0912911
expl/Actions Std                              0.803076
expl/Actions Max                              0.999444
expl/Actions Min                             -0.999131
expl/Num Paths                                1
expl/Average Returns                       5498.59
expl/env_infos/final/reward_run Mean          4.73256
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.73256
expl/env_infos/final/reward_run Min           4.73256
expl/env_infos/initial/reward_run Mean        0.157224
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.157224
expl/env_infos/initial/reward_run Min         0.157224
expl/env_infos/reward_run Mean                5.89055
expl/env_infos/reward_run Std                 1.31132
expl/env_infos/reward_run Max                 8.74759
expl/env_infos/reward_run Min                 0.157224
expl/env_infos/final/reward_ctrl Mean        -0.382746
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.382746
expl/env_infos/final/reward_ctrl Min         -0.382746
expl/env_infos/initial/reward_ctrl Mean      -0.216539
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.216539
expl/env_infos/initial/reward_ctrl Min       -0.216539
expl/env_infos/reward_ctrl Mean              -0.391959
expl/env_infos/reward_ctrl Std                0.0935919
expl/env_infos/reward_ctrl Max               -0.0447889
expl/env_infos/reward_ctrl Min               -0.589556
eval/num steps total                          1.685e+06
eval/num paths total                       1685
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.0237
eval/Rewards Std                              1.29998
eval/Rewards Max                              8.46563
eval/Rewards Min                             -0.540647
eval/Returns Mean                          6023.7
eval/Returns Std                             52.4764
eval/Returns Max                           6107.16
eval/Returns Min                           5971.68
eval/Actions Mean                             0.0926158
eval/Actions Std                              0.825546
eval/Actions Max                              0.997721
eval/Actions Min                             -0.995228
eval/Num Paths                                5
eval/Average Returns                       6023.7
eval/env_infos/final/reward_run Mean          7.23041
eval/env_infos/final/reward_run Std           0.849873
eval/env_infos/final/reward_run Max           8.0321
eval/env_infos/final/reward_run Min           5.96458
eval/env_infos/initial/reward_run Mean       -0.243396
eval/env_infos/initial/reward_run Std         0.0631742
eval/env_infos/initial/reward_run Max        -0.134858
eval/env_infos/initial/reward_run Min        -0.329967
eval/env_infos/reward_run Mean                6.43776
eval/env_infos/reward_run Std                 1.29162
eval/env_infos/reward_run Max                 8.97171
eval/env_infos/reward_run Min                -0.329967
eval/env_infos/final/reward_ctrl Mean        -0.432984
eval/env_infos/final/reward_ctrl Std          0.0914646
eval/env_infos/final/reward_ctrl Max         -0.272516
eval/env_infos/final/reward_ctrl Min         -0.51796
eval/env_infos/initial/reward_ctrl Mean      -0.192651
eval/env_infos/initial/reward_ctrl Std        0.0108846
eval/env_infos/initial/reward_ctrl Max       -0.177053
eval/env_infos/initial/reward_ctrl Min       -0.21068
eval/env_infos/reward_ctrl Mean              -0.414062
eval/env_infos/reward_ctrl Std                0.0902177
eval/env_infos/reward_ctrl Max               -0.07908
eval/env_infos/reward_ctrl Min               -0.581114
time/data storing (s)                         0.00455392
time/evaluation sampling (s)                  2.09645
time/exploration sampling (s)                 0.53853
time/logging (s)                              0.0136978
time/sac training (s)                         7.57891
time/saving (s)                               0.00380184
time/training (s)                             3.6515e-05
time/epoch (s)                               10.236
time/total (s)                             3566.37
Epoch                                       336
---------------------------------------  ---------------
2021-11-24 01:28:51.842023 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 337 finished
---------------------------------------  ---------------
epoch                                       337
replay_buffer/size                       339000
trainer/num train calls                  338000
trainer/QF1 Loss                              5.28255
trainer/QF2 Loss                              5.44214
trainer/Policy Loss                        -384.044
trainer/Q1 Predictions Mean                 384.762
trainer/Q1 Predictions Std                  105.335
trainer/Q1 Predictions Max                  465.085
trainer/Q1 Predictions Min                   18.8285
trainer/Q2 Predictions Mean                 384.574
trainer/Q2 Predictions Std                  105.3
trainer/Q2 Predictions Max                  465.408
trainer/Q2 Predictions Min                   19.2598
trainer/Q Targets Mean                      384.742
trainer/Q Targets Std                       105.34
trainer/Q Targets Max                       463.705
trainer/Q Targets Min                        18.3624
trainer/Log Pis Mean                          5.8575
trainer/Log Pis Std                           4.64214
trainer/Log Pis Max                          15.9168
trainer/Log Pis Min                          -6.80344
trainer/policy/mean Mean                      0.0742632
trainer/policy/mean Std                       0.774005
trainer/policy/mean Max                       0.998416
trainer/policy/mean Min                      -0.994874
trainer/policy/normal/std Mean                0.437582
trainer/policy/normal/std Std                 0.142629
trainer/policy/normal/std Max                 0.848241
trainer/policy/normal/std Min                 0.07674
trainer/policy/normal/log_std Mean           -0.895918
trainer/policy/normal/log_std Std             0.408255
trainer/policy/normal/log_std Max            -0.164591
trainer/policy/normal/log_std Min            -2.56733
trainer/Alpha                                 0.140773
trainer/Alpha Loss                           -0.279384
expl/num steps total                     339000
expl/num paths total                        339
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.80935
expl/Rewards Std                              1.23782
expl/Rewards Max                              8.13655
expl/Rewards Min                             -0.532642
expl/Returns Mean                          5809.35
expl/Returns Std                              0
expl/Returns Max                           5809.35
expl/Returns Min                           5809.35
expl/Actions Mean                             0.0925868
expl/Actions Std                              0.803205
expl/Actions Max                              0.999782
expl/Actions Min                             -0.998931
expl/Num Paths                                1
expl/Average Returns                       5809.35
expl/env_infos/final/reward_run Mean          6.65289
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.65289
expl/env_infos/final/reward_run Min           6.65289
expl/env_infos/initial/reward_run Mean       -0.192944
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.192944
expl/env_infos/initial/reward_run Min        -0.192944
expl/env_infos/reward_run Mean                6.20158
expl/env_infos/reward_run Std                 1.23194
expl/env_infos/reward_run Max                 8.65854
expl/env_infos/reward_run Min                -0.192944
expl/env_infos/final/reward_ctrl Mean        -0.432221
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.432221
expl/env_infos/final/reward_ctrl Min         -0.432221
expl/env_infos/initial/reward_ctrl Mean      -0.339698
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.339698
expl/env_infos/initial/reward_ctrl Min       -0.339698
expl/env_infos/reward_ctrl Mean              -0.392226
expl/env_infos/reward_ctrl Std                0.0959246
expl/env_infos/reward_ctrl Max               -0.0797611
expl/env_infos/reward_ctrl Min               -0.570601
eval/num steps total                          1.69e+06
eval/num paths total                       1690
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.11448
eval/Rewards Std                              1.29243
eval/Rewards Max                              8.62775
eval/Rewards Min                             -0.775859
eval/Returns Mean                          6114.48
eval/Returns Std                             52.1483
eval/Returns Max                           6208.71
eval/Returns Min                           6066.23
eval/Actions Mean                             0.092066
eval/Actions Std                              0.819626
eval/Actions Max                              0.99703
eval/Actions Min                             -0.994709
eval/Num Paths                                5
eval/Average Returns                       6114.48
eval/env_infos/final/reward_run Mean          7.36854
eval/env_infos/final/reward_run Std           1.07053
eval/env_infos/final/reward_run Max           8.50464
eval/env_infos/final/reward_run Min           5.47409
eval/env_infos/initial/reward_run Mean       -0.267889
eval/env_infos/initial/reward_run Std         0.22303
eval/env_infos/initial/reward_run Max         0.128552
eval/env_infos/initial/reward_run Min        -0.477751
eval/env_infos/reward_run Mean                6.52264
eval/env_infos/reward_run Std                 1.28909
eval/env_infos/reward_run Max                 9.14441
eval/env_infos/reward_run Min                -0.477751
eval/env_infos/final/reward_ctrl Mean        -0.445748
eval/env_infos/final/reward_ctrl Std          0.0422916
eval/env_infos/final/reward_ctrl Max         -0.386987
eval/env_infos/final/reward_ctrl Min         -0.48445
eval/env_infos/initial/reward_ctrl Mean      -0.227788
eval/env_infos/initial/reward_ctrl Std        0.0528965
eval/env_infos/initial/reward_ctrl Max       -0.144169
eval/env_infos/initial/reward_ctrl Min       -0.306193
eval/env_infos/reward_ctrl Mean              -0.408158
eval/env_infos/reward_ctrl Std                0.0909355
eval/env_infos/reward_ctrl Max               -0.0966796
eval/env_infos/reward_ctrl Min               -0.568981
time/data storing (s)                         0.00453587
time/evaluation sampling (s)                  2.04
time/exploration sampling (s)                 0.537512
time/logging (s)                              0.0136641
time/sac training (s)                         7.52159
time/saving (s)                               0.00524025
time/training (s)                             3.5134e-05
time/epoch (s)                               10.1226
time/total (s)                             3576.78
Epoch                                       337
---------------------------------------  ---------------
2021-11-24 01:29:02.374394 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 338 finished
---------------------------------------  ----------------
epoch                                       338
replay_buffer/size                       340000
trainer/num train calls                  339000
trainer/QF1 Loss                              8.15417
trainer/QF2 Loss                              8.19056
trainer/Policy Loss                        -388.701
trainer/Q1 Predictions Mean                 389.569
trainer/Q1 Predictions Std                   93.0793
trainer/Q1 Predictions Max                  467.042
trainer/Q1 Predictions Min                   19.8058
trainer/Q2 Predictions Mean                 388.986
trainer/Q2 Predictions Std                   92.9918
trainer/Q2 Predictions Max                  467.508
trainer/Q2 Predictions Min                   20.7556
trainer/Q Targets Mean                      389.022
trainer/Q Targets Std                        93.071
trainer/Q Targets Max                       468.793
trainer/Q Targets Min                        18.8569
trainer/Log Pis Mean                          5.98756
trainer/Log Pis Std                           4.29136
trainer/Log Pis Max                          16.5368
trainer/Log Pis Min                          -5.35658
trainer/policy/mean Mean                      0.0831474
trainer/policy/mean Std                       0.77309
trainer/policy/mean Max                       0.99671
trainer/policy/mean Min                      -0.998839
trainer/policy/normal/std Mean                0.434564
trainer/policy/normal/std Std                 0.140813
trainer/policy/normal/std Max                 0.93073
trainer/policy/normal/std Min                 0.0773011
trainer/policy/normal/log_std Mean           -0.90166
trainer/policy/normal/log_std Std             0.403952
trainer/policy/normal/log_std Max            -0.0717859
trainer/policy/normal/log_std Min            -2.56005
trainer/Alpha                                 0.139818
trainer/Alpha Loss                           -0.0244669
expl/num steps total                     340000
expl/num paths total                        340
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.55133
expl/Rewards Std                              1.25025
expl/Rewards Max                              7.89235
expl/Rewards Min                             -0.569365
expl/Returns Mean                          5551.33
expl/Returns Std                              0
expl/Returns Max                           5551.33
expl/Returns Min                           5551.33
expl/Actions Mean                             0.101728
expl/Actions Std                              0.795633
expl/Actions Max                              0.999542
expl/Actions Min                             -0.999325
expl/Num Paths                                1
expl/Average Returns                       5551.33
expl/env_infos/final/reward_run Mean          7.22695
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.22695
expl/env_infos/final/reward_run Min           7.22695
expl/env_infos/initial/reward_run Mean       -0.295543
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.295543
expl/env_infos/initial/reward_run Min        -0.295543
expl/env_infos/reward_run Mean                5.93736
expl/env_infos/reward_run Std                 1.24592
expl/env_infos/reward_run Max                 8.25833
expl/env_infos/reward_run Min                -0.295543
expl/env_infos/final/reward_ctrl Mean        -0.34875
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.34875
expl/env_infos/final/reward_ctrl Min         -0.34875
expl/env_infos/initial/reward_ctrl Mean      -0.273822
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.273822
expl/env_infos/initial/reward_ctrl Min       -0.273822
expl/env_infos/reward_ctrl Mean              -0.386029
expl/env_infos/reward_ctrl Std                0.0924228
expl/env_infos/reward_ctrl Max               -0.0898118
expl/env_infos/reward_ctrl Min               -0.581009
eval/num steps total                          1.695e+06
eval/num paths total                       1695
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.03519
eval/Rewards Std                              1.30747
eval/Rewards Max                              8.57488
eval/Rewards Min                             -0.637377
eval/Returns Mean                          6035.19
eval/Returns Std                             98.7616
eval/Returns Max                           6149.84
eval/Returns Min                           5919.4
eval/Actions Mean                             0.10101
eval/Actions Std                              0.81623
eval/Actions Max                              0.996899
eval/Actions Min                             -0.996914
eval/Num Paths                                5
eval/Average Returns                       6035.19
eval/env_infos/final/reward_run Mean          7.05345
eval/env_infos/final/reward_run Std           0.465161
eval/env_infos/final/reward_run Max           7.82952
eval/env_infos/final/reward_run Min           6.51924
eval/env_infos/initial/reward_run Mean       -0.0231625
eval/env_infos/initial/reward_run Std         0.257446
eval/env_infos/initial/reward_run Max         0.431246
eval/env_infos/initial/reward_run Min        -0.319338
eval/env_infos/reward_run Mean                6.44105
eval/env_infos/reward_run Std                 1.30232
eval/env_infos/reward_run Max                 9.0675
eval/env_infos/reward_run Min                -0.319338
eval/env_infos/final/reward_ctrl Mean        -0.368335
eval/env_infos/final/reward_ctrl Std          0.122665
eval/env_infos/final/reward_ctrl Max         -0.154871
eval/env_infos/final/reward_ctrl Min         -0.483865
eval/env_infos/initial/reward_ctrl Mean      -0.143142
eval/env_infos/initial/reward_ctrl Std        0.0462889
eval/env_infos/initial/reward_ctrl Max       -0.0695977
eval/env_infos/initial/reward_ctrl Min       -0.187947
eval/env_infos/reward_ctrl Mean              -0.405861
eval/env_infos/reward_ctrl Std                0.0888308
eval/env_infos/reward_ctrl Max               -0.0695977
eval/env_infos/reward_ctrl Min               -0.577882
time/data storing (s)                         0.00450088
time/evaluation sampling (s)                  2.10204
time/exploration sampling (s)                 0.531935
time/logging (s)                              0.0193484
time/sac training (s)                         7.57651
time/saving (s)                               0.00475713
time/training (s)                             4.29309e-05
time/epoch (s)                               10.2391
time/total (s)                             3587.3
Epoch                                       338
---------------------------------------  ----------------
2021-11-24 01:29:12.749454 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 339 finished
---------------------------------------  ---------------
epoch                                       339
replay_buffer/size                       341000
trainer/num train calls                  340000
trainer/QF1 Loss                              5.87842
trainer/QF2 Loss                              6.48826
trainer/Policy Loss                        -392.515
trainer/Q1 Predictions Mean                 393.104
trainer/Q1 Predictions Std                   90.401
trainer/Q1 Predictions Max                  466.209
trainer/Q1 Predictions Min                   17.6488
trainer/Q2 Predictions Mean                 393.295
trainer/Q2 Predictions Std                   90.5948
trainer/Q2 Predictions Max                  464.922
trainer/Q2 Predictions Min                   16.0393
trainer/Q Targets Mean                      393.19
trainer/Q Targets Std                        90.4914
trainer/Q Targets Max                       467.922
trainer/Q Targets Min                        17.9315
trainer/Log Pis Mean                          5.61159
trainer/Log Pis Std                           4.51881
trainer/Log Pis Max                          20.5219
trainer/Log Pis Min                          -6.74854
trainer/policy/mean Mean                      0.0753999
trainer/policy/mean Std                       0.776942
trainer/policy/mean Max                       0.998195
trainer/policy/mean Min                      -0.999608
trainer/policy/normal/std Mean                0.439405
trainer/policy/normal/std Std                 0.135164
trainer/policy/normal/std Max                 0.994262
trainer/policy/normal/std Min                 0.0811048
trainer/policy/normal/log_std Mean           -0.886227
trainer/policy/normal/log_std Std             0.393859
trainer/policy/normal/log_std Max            -0.00575467
trainer/policy/normal/log_std Min            -2.51201
trainer/Alpha                                 0.141501
trainer/Alpha Loss                           -0.759521
expl/num steps total                     341000
expl/num paths total                        341
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.80547
expl/Rewards Std                              1.25107
expl/Rewards Max                              8.24224
expl/Rewards Min                             -0.58045
expl/Returns Mean                          5805.47
expl/Returns Std                              0
expl/Returns Max                           5805.47
expl/Returns Min                           5805.47
expl/Actions Mean                             0.101594
expl/Actions Std                              0.803691
expl/Actions Max                              0.999784
expl/Actions Min                             -0.999827
expl/Num Paths                                1
expl/Average Returns                       5805.47
expl/env_infos/final/reward_run Mean          7.08867
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.08867
expl/env_infos/final/reward_run Min           7.08867
expl/env_infos/initial/reward_run Mean       -0.300503
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.300503
expl/env_infos/initial/reward_run Min        -0.300503
expl/env_infos/reward_run Mean                6.19922
expl/env_infos/reward_run Std                 1.25016
expl/env_infos/reward_run Max                 8.79146
expl/env_infos/reward_run Min                -0.300503
expl/env_infos/final/reward_ctrl Mean        -0.412236
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.412236
expl/env_infos/final/reward_ctrl Min         -0.412236
expl/env_infos/initial/reward_ctrl Mean      -0.279947
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.279947
expl/env_infos/initial/reward_ctrl Min       -0.279947
expl/env_infos/reward_ctrl Mean              -0.393744
expl/env_infos/reward_ctrl Std                0.088648
expl/env_infos/reward_ctrl Max               -0.117328
expl/env_infos/reward_ctrl Min               -0.575928
eval/num steps total                          1.7e+06
eval/num paths total                       1700
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.11241
eval/Rewards Std                              1.31562
eval/Rewards Max                              8.78774
eval/Rewards Min                             -0.649727
eval/Returns Mean                          6112.41
eval/Returns Std                             59.4715
eval/Returns Max                           6226.96
eval/Returns Min                           6058.22
eval/Actions Mean                             0.0965693
eval/Actions Std                              0.822167
eval/Actions Max                              0.996544
eval/Actions Min                             -0.995685
eval/Num Paths                                5
eval/Average Returns                       6112.41
eval/env_infos/final/reward_run Mean          7.81236
eval/env_infos/final/reward_run Std           0.731489
eval/env_infos/final/reward_run Max           8.73961
eval/env_infos/final/reward_run Min           6.82973
eval/env_infos/initial/reward_run Mean       -0.282127
eval/env_infos/initial/reward_run Std         0.0900061
eval/env_infos/initial/reward_run Max        -0.17381
eval/env_infos/initial/reward_run Min        -0.447192
eval/env_infos/reward_run Mean                6.52358
eval/env_infos/reward_run Std                 1.3126
eval/env_infos/reward_run Max                 9.30328
eval/env_infos/reward_run Min                -0.447192
eval/env_infos/final/reward_ctrl Mean        -0.42384
eval/env_infos/final/reward_ctrl Std          0.0703128
eval/env_infos/final/reward_ctrl Max         -0.29995
eval/env_infos/final/reward_ctrl Min         -0.515735
eval/env_infos/initial/reward_ctrl Mean      -0.209288
eval/env_infos/initial/reward_ctrl Std        0.0128688
eval/env_infos/initial/reward_ctrl Max       -0.191192
eval/env_infos/initial/reward_ctrl Min       -0.228317
eval/env_infos/reward_ctrl Mean              -0.41117
eval/env_infos/reward_ctrl Std                0.0885826
eval/env_infos/reward_ctrl Max               -0.088568
eval/env_infos/reward_ctrl Min               -0.577445
time/data storing (s)                         0.00458423
time/evaluation sampling (s)                  2.0261
time/exploration sampling (s)                 0.52647
time/logging (s)                              0.0136575
time/sac training (s)                         7.49494
time/saving (s)                               0.00381624
time/training (s)                             3.4921e-05
time/epoch (s)                               10.0696
time/total (s)                             3597.66
Epoch                                       339
---------------------------------------  ---------------
2021-11-24 01:29:23.011635 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 340 finished
---------------------------------------  ---------------
epoch                                       340
replay_buffer/size                       342000
trainer/num train calls                  341000
trainer/QF1 Loss                              5.97793
trainer/QF2 Loss                              5.97857
trainer/Policy Loss                        -372.927
trainer/Q1 Predictions Mean                 373.588
trainer/Q1 Predictions Std                  122.638
trainer/Q1 Predictions Max                  461.36
trainer/Q1 Predictions Min                   19.6185
trainer/Q2 Predictions Mean                 373.444
trainer/Q2 Predictions Std                  122.708
trainer/Q2 Predictions Max                  461.232
trainer/Q2 Predictions Min                   19.8504
trainer/Q Targets Mean                      373.435
trainer/Q Targets Std                       122.657
trainer/Q Targets Max                       461.934
trainer/Q Targets Min                        19.5521
trainer/Log Pis Mean                          5.78368
trainer/Log Pis Std                           4.63659
trainer/Log Pis Max                          18.2095
trainer/Log Pis Min                          -5.00412
trainer/policy/mean Mean                      0.0987221
trainer/policy/mean Std                       0.762499
trainer/policy/mean Max                       0.997376
trainer/policy/mean Min                      -0.996627
trainer/policy/normal/std Mean                0.445931
trainer/policy/normal/std Std                 0.143919
trainer/policy/normal/std Max                 0.885059
trainer/policy/normal/std Min                 0.0625029
trainer/policy/normal/log_std Mean           -0.878728
trainer/policy/normal/log_std Std             0.418844
trainer/policy/normal/log_std Max            -0.122101
trainer/policy/normal/log_std Min            -2.77254
trainer/Alpha                                 0.13855
trainer/Alpha Loss                           -0.42756
expl/num steps total                     342000
expl/num paths total                        342
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.67743
expl/Rewards Std                              1.23506
expl/Rewards Max                              7.85444
expl/Rewards Min                             -0.966701
expl/Returns Mean                          5677.43
expl/Returns Std                              0
expl/Returns Max                           5677.43
expl/Returns Min                           5677.43
expl/Actions Mean                             0.110966
expl/Actions Std                              0.796859
expl/Actions Max                              0.999419
expl/Actions Min                             -0.999049
expl/Num Paths                                1
expl/Average Returns                       5677.43
expl/env_infos/final/reward_run Mean          5.39227
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.39227
expl/env_infos/final/reward_run Min           5.39227
expl/env_infos/initial/reward_run Mean       -0.592101
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.592101
expl/env_infos/initial/reward_run Min        -0.592101
expl/env_infos/reward_run Mean                6.06581
expl/env_infos/reward_run Std                 1.22656
expl/env_infos/reward_run Max                 8.33703
expl/env_infos/reward_run Min                -0.592101
expl/env_infos/final/reward_ctrl Mean        -0.424489
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.424489
expl/env_infos/final/reward_ctrl Min         -0.424489
expl/env_infos/initial/reward_ctrl Mean      -0.374599
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.374599
expl/env_infos/initial/reward_ctrl Min       -0.374599
expl/env_infos/reward_ctrl Mean              -0.388379
expl/env_infos/reward_ctrl Std                0.0925162
expl/env_infos/reward_ctrl Max               -0.0702525
expl/env_infos/reward_ctrl Min               -0.584969
eval/num steps total                          1.705e+06
eval/num paths total                       1705
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.07209
eval/Rewards Std                              1.31259
eval/Rewards Max                              8.49976
eval/Rewards Min                             -0.867109
eval/Returns Mean                          6072.09
eval/Returns Std                             91.0132
eval/Returns Max                           6169.23
eval/Returns Min                           5926.82
eval/Actions Mean                             0.0986297
eval/Actions Std                              0.820605
eval/Actions Max                              0.997699
eval/Actions Min                             -0.997709
eval/Num Paths                                5
eval/Average Returns                       6072.09
eval/env_infos/final/reward_run Mean          6.63192
eval/env_infos/final/reward_run Std           1.15531
eval/env_infos/final/reward_run Max           8.64657
eval/env_infos/final/reward_run Min           5.24146
eval/env_infos/initial/reward_run Mean       -0.201902
eval/env_infos/initial/reward_run Std         0.33224
eval/env_infos/initial/reward_run Max         0.301764
eval/env_infos/initial/reward_run Min        -0.679315
eval/env_infos/reward_run Mean                6.48196
eval/env_infos/reward_run Std                 1.30684
eval/env_infos/reward_run Max                 9.02857
eval/env_infos/reward_run Min                -0.679315
eval/env_infos/final/reward_ctrl Mean        -0.462438
eval/env_infos/final/reward_ctrl Std          0.0777317
eval/env_infos/final/reward_ctrl Max         -0.366587
eval/env_infos/final/reward_ctrl Min         -0.575012
eval/env_infos/initial/reward_ctrl Mean      -0.180733
eval/env_infos/initial/reward_ctrl Std        0.0593714
eval/env_infos/initial/reward_ctrl Max       -0.0837786
eval/env_infos/initial/reward_ctrl Min       -0.260118
eval/env_infos/reward_ctrl Mean              -0.409872
eval/env_infos/reward_ctrl Std                0.0900311
eval/env_infos/reward_ctrl Max               -0.0805356
eval/env_infos/reward_ctrl Min               -0.578924
time/data storing (s)                         0.00448622
time/evaluation sampling (s)                  2.07135
time/exploration sampling (s)                 0.533108
time/logging (s)                              0.0135751
time/sac training (s)                         7.34336
time/saving (s)                               0.00373777
time/training (s)                             3.39e-05
time/epoch (s)                                9.96965
time/total (s)                             3607.91
Epoch                                       340
---------------------------------------  ---------------
2021-11-24 01:29:33.189620 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 341 finished
---------------------------------------  ----------------
epoch                                       341
replay_buffer/size                       343000
trainer/num train calls                  342000
trainer/QF1 Loss                              7.30207
trainer/QF2 Loss                              7.81615
trainer/Policy Loss                        -383.909
trainer/Q1 Predictions Mean                 384.5
trainer/Q1 Predictions Std                  105.674
trainer/Q1 Predictions Max                  466.629
trainer/Q1 Predictions Min                   19.2866
trainer/Q2 Predictions Mean                 384.712
trainer/Q2 Predictions Std                  105.771
trainer/Q2 Predictions Max                  464.592
trainer/Q2 Predictions Min                   19.8974
trainer/Q Targets Mean                      384.372
trainer/Q Targets Std                       105.724
trainer/Q Targets Max                       465.077
trainer/Q Targets Min                        18.4055
trainer/Log Pis Mean                          5.93113
trainer/Log Pis Std                           4.70535
trainer/Log Pis Max                          16.5698
trainer/Log Pis Min                          -8.50862
trainer/policy/mean Mean                      0.101756
trainer/policy/mean Std                       0.77206
trainer/policy/mean Max                       0.997253
trainer/policy/mean Min                      -0.996829
trainer/policy/normal/std Mean                0.445232
trainer/policy/normal/std Std                 0.148014
trainer/policy/normal/std Max                 0.944921
trainer/policy/normal/std Min                 0.0686581
trainer/policy/normal/log_std Mean           -0.886713
trainer/policy/normal/log_std Std             0.44075
trainer/policy/normal/log_std Max            -0.0566544
trainer/policy/normal/log_std Min            -2.67862
trainer/Alpha                                 0.139384
trainer/Alpha Loss                           -0.135719
expl/num steps total                     343000
expl/num paths total                        343
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.71414
expl/Rewards Std                              1.21894
expl/Rewards Max                              8.08489
expl/Rewards Min                             -1.05379
expl/Returns Mean                          5714.14
expl/Returns Std                              0
expl/Returns Max                           5714.14
expl/Returns Min                           5714.14
expl/Actions Mean                             0.102734
expl/Actions Std                              0.806018
expl/Actions Max                              0.999761
expl/Actions Min                             -0.999117
expl/Num Paths                                1
expl/Average Returns                       5714.14
expl/env_infos/final/reward_run Mean          6.59628
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.59628
expl/env_infos/final/reward_run Min           6.59628
expl/env_infos/initial/reward_run Mean       -0.765028
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.765028
expl/env_infos/initial/reward_run Min        -0.765028
expl/env_infos/reward_run Mean                6.11027
expl/env_infos/reward_run Std                 1.21127
expl/env_infos/reward_run Max                 8.50794
expl/env_infos/reward_run Min                -0.765028
expl/env_infos/final/reward_ctrl Mean        -0.231972
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.231972
expl/env_infos/final/reward_ctrl Min         -0.231972
expl/env_infos/initial/reward_ctrl Mean      -0.288757
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.288757
expl/env_infos/initial/reward_ctrl Min       -0.288757
expl/env_infos/reward_ctrl Mean              -0.396131
expl/env_infos/reward_ctrl Std                0.0890031
expl/env_infos/reward_ctrl Max               -0.120852
expl/env_infos/reward_ctrl Min               -0.577965
eval/num steps total                          1.71e+06
eval/num paths total                       1710
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.11394
eval/Rewards Std                              1.31569
eval/Rewards Max                              8.82672
eval/Rewards Min                             -1.03395
eval/Returns Mean                          6113.94
eval/Returns Std                             41.6859
eval/Returns Max                           6164.21
eval/Returns Min                           6070.12
eval/Actions Mean                             0.111031
eval/Actions Std                              0.825893
eval/Actions Max                              0.997477
eval/Actions Min                             -0.995569
eval/Num Paths                                5
eval/Average Returns                       6113.94
eval/env_infos/final/reward_run Mean          6.69803
eval/env_infos/final/reward_run Std           0.570926
eval/env_infos/final/reward_run Max           7.68193
eval/env_infos/final/reward_run Min           6.05175
eval/env_infos/initial/reward_run Mean       -0.525434
eval/env_infos/initial/reward_run Std         0.27539
eval/env_infos/initial/reward_run Max         0.000506216
eval/env_infos/initial/reward_run Min        -0.767664
eval/env_infos/reward_run Mean                6.5306
eval/env_infos/reward_run Std                 1.30862
eval/env_infos/reward_run Max                 9.31975
eval/env_infos/reward_run Min                -0.767664
eval/env_infos/final/reward_ctrl Mean        -0.446609
eval/env_infos/final/reward_ctrl Std          0.0306017
eval/env_infos/final/reward_ctrl Max         -0.410795
eval/env_infos/final/reward_ctrl Min         -0.502579
eval/env_infos/initial/reward_ctrl Mean      -0.238538
eval/env_infos/initial/reward_ctrl Std        0.0771349
eval/env_infos/initial/reward_ctrl Max       -0.124383
eval/env_infos/initial/reward_ctrl Min       -0.315082
eval/env_infos/reward_ctrl Mean              -0.416656
eval/env_infos/reward_ctrl Std                0.0835882
eval/env_infos/reward_ctrl Max               -0.100295
eval/env_infos/reward_ctrl Min               -0.58184
time/data storing (s)                         0.00456473
time/evaluation sampling (s)                  2.01041
time/exploration sampling (s)                 0.528381
time/logging (s)                              0.0135708
time/sac training (s)                         7.32562
time/saving (s)                               0.00375202
time/training (s)                             3.36069e-05
time/epoch (s)                                9.88634
time/total (s)                             3618.07
Epoch                                       341
---------------------------------------  ----------------
2021-11-24 01:29:43.830192 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 342 finished
---------------------------------------  ---------------
epoch                                       342
replay_buffer/size                       344000
trainer/num train calls                  343000
trainer/QF1 Loss                              4.04135
trainer/QF2 Loss                              4.77098
trainer/Policy Loss                        -373.603
trainer/Q1 Predictions Mean                 374.144
trainer/Q1 Predictions Std                  120.674
trainer/Q1 Predictions Max                  460.786
trainer/Q1 Predictions Min                   18.8846
trainer/Q2 Predictions Mean                 374.451
trainer/Q2 Predictions Std                  120.773
trainer/Q2 Predictions Max                  459.527
trainer/Q2 Predictions Min                   19.3179
trainer/Q Targets Mean                      374.166
trainer/Q Targets Std                       120.842
trainer/Q Targets Max                       459.204
trainer/Q Targets Min                        17.6104
trainer/Log Pis Mean                          5.47187
trainer/Log Pis Std                           4.64972
trainer/Log Pis Max                          15.936
trainer/Log Pis Min                          -5.60397
trainer/policy/mean Mean                      0.104413
trainer/policy/mean Std                       0.763156
trainer/policy/mean Max                       0.994018
trainer/policy/mean Min                      -0.995802
trainer/policy/normal/std Mean                0.458563
trainer/policy/normal/std Std                 0.148712
trainer/policy/normal/std Max                 0.860996
trainer/policy/normal/std Min                 0.0626326
trainer/policy/normal/log_std Mean           -0.850119
trainer/policy/normal/log_std Std             0.416048
trainer/policy/normal/log_std Max            -0.149666
trainer/policy/normal/log_std Min            -2.77047
trainer/Alpha                                 0.141219
trainer/Alpha Loss                           -1.03378
expl/num steps total                     344000
expl/num paths total                        344
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.69614
expl/Rewards Std                              1.20623
expl/Rewards Max                              7.98119
expl/Rewards Min                             -0.581917
expl/Returns Mean                          5696.14
expl/Returns Std                              0
expl/Returns Max                           5696.14
expl/Returns Min                           5696.14
expl/Actions Mean                             0.105652
expl/Actions Std                              0.807764
expl/Actions Max                              0.999424
expl/Actions Min                             -0.99957
expl/Num Paths                                1
expl/Average Returns                       5696.14
expl/env_infos/final/reward_run Mean          5.96638
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.96638
expl/env_infos/final/reward_run Min           5.96638
expl/env_infos/initial/reward_run Mean       -0.325109
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.325109
expl/env_infos/initial/reward_run Min        -0.325109
expl/env_infos/reward_run Mean                6.09432
expl/env_infos/reward_run Std                 1.18762
expl/env_infos/reward_run Max                 8.4894
expl/env_infos/reward_run Min                -0.325109
expl/env_infos/final/reward_ctrl Mean        -0.406141
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.406141
expl/env_infos/final/reward_ctrl Min         -0.406141
expl/env_infos/initial/reward_ctrl Mean      -0.256809
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.256809
expl/env_infos/initial/reward_ctrl Min       -0.256809
expl/env_infos/reward_ctrl Mean              -0.398187
expl/env_infos/reward_ctrl Std                0.09385
expl/env_infos/reward_ctrl Max               -0.10057
expl/env_infos/reward_ctrl Min               -0.587982
eval/num steps total                          1.715e+06
eval/num paths total                       1715
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.04567
eval/Rewards Std                              1.33351
eval/Rewards Max                              8.66746
eval/Rewards Min                             -0.780258
eval/Returns Mean                          6045.67
eval/Returns Std                             58.3869
eval/Returns Max                           6094.92
eval/Returns Min                           5938.78
eval/Actions Mean                             0.113533
eval/Actions Std                              0.821867
eval/Actions Max                              0.997988
eval/Actions Min                             -0.997279
eval/Num Paths                                5
eval/Average Returns                       6045.67
eval/env_infos/final/reward_run Mean          6.86313
eval/env_infos/final/reward_run Std           0.48484
eval/env_infos/final/reward_run Max           7.45204
eval/env_infos/final/reward_run Min           6.18361
eval/env_infos/initial/reward_run Mean       -0.290486
eval/env_infos/initial/reward_run Std         0.176042
eval/env_infos/initial/reward_run Max        -0.0471956
eval/env_infos/initial/reward_run Min        -0.490824
eval/env_infos/reward_run Mean                6.45868
eval/env_infos/reward_run Std                 1.31538
eval/env_infos/reward_run Max                 9.16322
eval/env_infos/reward_run Min                -0.490824
eval/env_infos/final/reward_ctrl Mean        -0.398959
eval/env_infos/final/reward_ctrl Std          0.0799505
eval/env_infos/final/reward_ctrl Max         -0.304393
eval/env_infos/final/reward_ctrl Min         -0.512941
eval/env_infos/initial/reward_ctrl Mean      -0.199545
eval/env_infos/initial/reward_ctrl Std        0.0373249
eval/env_infos/initial/reward_ctrl Max       -0.137336
eval/env_infos/initial/reward_ctrl Min       -0.232235
eval/env_infos/reward_ctrl Mean              -0.413013
eval/env_infos/reward_ctrl Std                0.0936575
eval/env_infos/reward_ctrl Max               -0.0675941
eval/env_infos/reward_ctrl Min               -0.581812
time/data storing (s)                         0.0046269
time/evaluation sampling (s)                  2.09123
time/exploration sampling (s)                 0.579592
time/logging (s)                              0.0137304
time/sac training (s)                         7.64137
time/saving (s)                               0.0037786
time/training (s)                             3.4532e-05
time/epoch (s)                               10.3344
time/total (s)                             3628.7
Epoch                                       342
---------------------------------------  ---------------
2021-11-24 01:29:54.270792 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 343 finished
---------------------------------------  ---------------
epoch                                       343
replay_buffer/size                       345000
trainer/num train calls                  344000
trainer/QF1 Loss                              5.57998
trainer/QF2 Loss                              5.23096
trainer/Policy Loss                        -390.188
trainer/Q1 Predictions Mean                 390.898
trainer/Q1 Predictions Std                  100.06
trainer/Q1 Predictions Max                  458.771
trainer/Q1 Predictions Min                   17.6958
trainer/Q2 Predictions Mean                 390.818
trainer/Q2 Predictions Std                   99.9727
trainer/Q2 Predictions Max                  458.338
trainer/Q2 Predictions Min                   18.6687
trainer/Q Targets Mean                      391.424
trainer/Q Targets Std                       100.133
trainer/Q Targets Max                       459.03
trainer/Q Targets Min                        17.996
trainer/Log Pis Mean                          6.0332
trainer/Log Pis Std                           4.32112
trainer/Log Pis Max                          15.0746
trainer/Log Pis Min                          -5.86599
trainer/policy/mean Mean                      0.0617986
trainer/policy/mean Std                       0.784548
trainer/policy/mean Max                       0.99246
trainer/policy/mean Min                      -0.998054
trainer/policy/normal/std Mean                0.433002
trainer/policy/normal/std Std                 0.140614
trainer/policy/normal/std Max                 0.929541
trainer/policy/normal/std Min                 0.0725539
trainer/policy/normal/log_std Mean           -0.907587
trainer/policy/normal/log_std Std             0.413758
trainer/policy/normal/log_std Max            -0.073064
trainer/policy/normal/log_std Min            -2.62343
trainer/Alpha                                 0.140486
trainer/Alpha Loss                            0.0651595
expl/num steps total                     345000
expl/num paths total                        345
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.57319
expl/Rewards Std                              1.22784
expl/Rewards Max                              7.97591
expl/Rewards Min                             -1.05035
expl/Returns Mean                          5573.19
expl/Returns Std                              0
expl/Returns Max                           5573.19
expl/Returns Min                           5573.19
expl/Actions Mean                             0.0791547
expl/Actions Std                              0.795336
expl/Actions Max                              0.999263
expl/Actions Min                             -0.999685
expl/Num Paths                                1
expl/Average Returns                       5573.19
expl/env_infos/final/reward_run Mean          6.59664
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.59664
expl/env_infos/final/reward_run Min           6.59664
expl/env_infos/initial/reward_run Mean       -0.752213
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.752213
expl/env_infos/initial/reward_run Min        -0.752213
expl/env_infos/reward_run Mean                5.95648
expl/env_infos/reward_run Std                 1.22032
expl/env_infos/reward_run Max                 8.43561
expl/env_infos/reward_run Min                -0.752213
expl/env_infos/final/reward_ctrl Mean        -0.269898
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.269898
expl/env_infos/final/reward_ctrl Min         -0.269898
expl/env_infos/initial/reward_ctrl Mean      -0.298137
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.298137
expl/env_infos/initial/reward_ctrl Min       -0.298137
expl/env_infos/reward_ctrl Mean              -0.383295
expl/env_infos/reward_ctrl Std                0.0927243
expl/env_infos/reward_ctrl Max               -0.112539
expl/env_infos/reward_ctrl Min               -0.579368
eval/num steps total                          1.72e+06
eval/num paths total                       1720
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.10261
eval/Rewards Std                              1.30657
eval/Rewards Max                              8.65569
eval/Rewards Min                             -0.761671
eval/Returns Mean                          6102.61
eval/Returns Std                             60.975
eval/Returns Max                           6193.27
eval/Returns Min                           6021.43
eval/Actions Mean                             0.0727812
eval/Actions Std                              0.812725
eval/Actions Max                              0.99496
eval/Actions Min                             -0.99582
eval/Num Paths                                5
eval/Average Returns                       6102.61
eval/env_infos/final/reward_run Mean          6.60383
eval/env_infos/final/reward_run Std           1.12615
eval/env_infos/final/reward_run Max           7.6328
eval/env_infos/final/reward_run Min           5.18017
eval/env_infos/initial/reward_run Mean       -0.344351
eval/env_infos/initial/reward_run Std         0.0918982
eval/env_infos/initial/reward_run Max        -0.207625
eval/env_infos/initial/reward_run Min        -0.485369
eval/env_infos/reward_run Mean                6.5021
eval/env_infos/reward_run Std                 1.30032
eval/env_infos/reward_run Max                 9.15108
eval/env_infos/reward_run Min                -0.485369
eval/env_infos/final/reward_ctrl Mean        -0.389145
eval/env_infos/final/reward_ctrl Std          0.0768667
eval/env_infos/final/reward_ctrl Max         -0.299499
eval/env_infos/final/reward_ctrl Min         -0.531225
eval/env_infos/initial/reward_ctrl Mean      -0.243456
eval/env_infos/initial/reward_ctrl Std        0.0264427
eval/env_infos/initial/reward_ctrl Max       -0.20304
eval/env_infos/initial/reward_ctrl Min       -0.276302
eval/env_infos/reward_ctrl Mean              -0.399491
eval/env_infos/reward_ctrl Std                0.0883299
eval/env_infos/reward_ctrl Max               -0.0635378
eval/env_infos/reward_ctrl Min               -0.579067
time/data storing (s)                         0.00455932
time/evaluation sampling (s)                  2.03373
time/exploration sampling (s)                 0.540145
time/logging (s)                              0.0194243
time/sac training (s)                         7.54653
time/saving (s)                               0.00471434
time/training (s)                             4.3309e-05
time/epoch (s)                               10.1491
time/total (s)                             3639.13
Epoch                                       343
---------------------------------------  ---------------
2021-11-24 01:30:04.546904 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 344 finished
---------------------------------------  ---------------
epoch                                       344
replay_buffer/size                       346000
trainer/num train calls                  345000
trainer/QF1 Loss                              8.02971
trainer/QF2 Loss                              6.53332
trainer/Policy Loss                        -386.04
trainer/Q1 Predictions Mean                 386.691
trainer/Q1 Predictions Std                  103.344
trainer/Q1 Predictions Max                  463.216
trainer/Q1 Predictions Min                   19.1999
trainer/Q2 Predictions Mean                 386.444
trainer/Q2 Predictions Std                  103.476
trainer/Q2 Predictions Max                  462.421
trainer/Q2 Predictions Min                   18.7702
trainer/Q Targets Mean                      386.802
trainer/Q Targets Std                       103.606
trainer/Q Targets Max                       461.91
trainer/Q Targets Min                        19.4211
trainer/Log Pis Mean                          5.80358
trainer/Log Pis Std                           4.27456
trainer/Log Pis Max                          19.2754
trainer/Log Pis Min                          -7.21026
trainer/policy/mean Mean                      0.0953414
trainer/policy/mean Std                       0.77061
trainer/policy/mean Max                       0.99664
trainer/policy/mean Min                      -0.993119
trainer/policy/normal/std Mean                0.447661
trainer/policy/normal/std Std                 0.143862
trainer/policy/normal/std Max                 1.03929
trainer/policy/normal/std Min                 0.076781
trainer/policy/normal/log_std Mean           -0.874258
trainer/policy/normal/log_std Std             0.417055
trainer/policy/normal/log_std Max             0.0385374
trainer/policy/normal/log_std Min            -2.5668
trainer/Alpha                                 0.139954
trainer/Alpha Loss                           -0.386243
expl/num steps total                     346000
expl/num paths total                        346
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.52066
expl/Rewards Std                              1.22385
expl/Rewards Max                              7.74842
expl/Rewards Min                             -0.344787
expl/Returns Mean                          5520.66
expl/Returns Std                              0
expl/Returns Max                           5520.66
expl/Returns Min                           5520.66
expl/Actions Mean                             0.0949209
expl/Actions Std                              0.799149
expl/Actions Max                              0.999241
expl/Actions Min                             -0.999908
expl/Num Paths                                1
expl/Average Returns                       5520.66
expl/env_infos/final/reward_run Mean          8.23196
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.23196
expl/env_infos/final/reward_run Min           8.23196
expl/env_infos/initial/reward_run Mean       -0.0414886
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0414886
expl/env_infos/initial/reward_run Min        -0.0414886
expl/env_infos/reward_run Mean                5.90925
expl/env_infos/reward_run Std                 1.21482
expl/env_infos/reward_run Max                 8.23196
expl/env_infos/reward_run Min                -0.0414886
expl/env_infos/final/reward_ctrl Mean        -0.499556
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.499556
expl/env_infos/final/reward_ctrl Min         -0.499556
expl/env_infos/initial/reward_ctrl Mean      -0.303299
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.303299
expl/env_infos/initial/reward_ctrl Min       -0.303299
expl/env_infos/reward_ctrl Mean              -0.388589
expl/env_infos/reward_ctrl Std                0.093375
expl/env_infos/reward_ctrl Max               -0.0561858
expl/env_infos/reward_ctrl Min               -0.587812
eval/num steps total                          1.725e+06
eval/num paths total                       1725
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.02667
eval/Rewards Std                              1.33469
eval/Rewards Max                              8.6738
eval/Rewards Min                             -0.563277
eval/Returns Mean                          6026.67
eval/Returns Std                            125.839
eval/Returns Max                           6220.18
eval/Returns Min                           5844.85
eval/Actions Mean                             0.108269
eval/Actions Std                              0.819997
eval/Actions Max                              0.998935
eval/Actions Min                             -0.999371
eval/Num Paths                                5
eval/Average Returns                       6026.67
eval/env_infos/final/reward_run Mean          7.35975
eval/env_infos/final/reward_run Std           0.941397
eval/env_infos/final/reward_run Max           8.97581
eval/env_infos/final/reward_run Min           6.14715
eval/env_infos/initial/reward_run Mean       -0.226057
eval/env_infos/initial/reward_run Std         0.12449
eval/env_infos/initial/reward_run Max         0.00398395
eval/env_infos/initial/reward_run Min        -0.353647
eval/env_infos/reward_run Mean                6.43714
eval/env_infos/reward_run Std                 1.3267
eval/env_infos/reward_run Max                 9.20709
eval/env_infos/reward_run Min                -0.353647
eval/env_infos/final/reward_ctrl Mean        -0.438809
eval/env_infos/final/reward_ctrl Std          0.0792335
eval/env_infos/final/reward_ctrl Max         -0.285814
eval/env_infos/final/reward_ctrl Min         -0.509409
eval/env_infos/initial/reward_ctrl Mean      -0.173102
eval/env_infos/initial/reward_ctrl Std        0.0289224
eval/env_infos/initial/reward_ctrl Max       -0.11966
eval/env_infos/initial/reward_ctrl Min       -0.202925
eval/env_infos/reward_ctrl Mean              -0.410471
eval/env_infos/reward_ctrl Std                0.087481
eval/env_infos/reward_ctrl Max               -0.108892
eval/env_infos/reward_ctrl Min               -0.582246
time/data storing (s)                         0.00453879
time/evaluation sampling (s)                  2.01455
time/exploration sampling (s)                 0.579139
time/logging (s)                              0.0136125
time/sac training (s)                         7.35997
time/saving (s)                               0.00375207
time/training (s)                             3.398e-05
time/epoch (s)                                9.9756
time/total (s)                             3649.38
Epoch                                       344
---------------------------------------  ---------------
2021-11-24 01:30:14.885667 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 345 finished
---------------------------------------  ----------------
epoch                                       345
replay_buffer/size                       347000
trainer/num train calls                  346000
trainer/QF1 Loss                              7.11606
trainer/QF2 Loss                              6.66347
trainer/Policy Loss                        -390.437
trainer/Q1 Predictions Mean                 391.434
trainer/Q1 Predictions Std                   99.3322
trainer/Q1 Predictions Max                  467.261
trainer/Q1 Predictions Min                   20.066
trainer/Q2 Predictions Mean                 390.811
trainer/Q2 Predictions Std                   99.516
trainer/Q2 Predictions Max                  468.263
trainer/Q2 Predictions Min                   18.8652
trainer/Q Targets Mean                      391.454
trainer/Q Targets Std                        99.6578
trainer/Q Targets Max                       468.373
trainer/Q Targets Min                        20.4652
trainer/Log Pis Mean                          6.0228
trainer/Log Pis Std                           4.34528
trainer/Log Pis Max                          15.3352
trainer/Log Pis Min                          -6.91506
trainer/policy/mean Mean                      0.0852685
trainer/policy/mean Std                       0.775113
trainer/policy/mean Max                       0.998763
trainer/policy/mean Min                      -0.996074
trainer/policy/normal/std Mean                0.43538
trainer/policy/normal/std Std                 0.142578
trainer/policy/normal/std Max                 0.999575
trainer/policy/normal/std Min                 0.0684069
trainer/policy/normal/log_std Mean           -0.902616
trainer/policy/normal/log_std Std             0.415623
trainer/policy/normal/log_std Max            -0.000425608
trainer/policy/normal/log_std Min            -2.68228
trainer/Alpha                                 0.141311
trainer/Alpha Loss                            0.0446256
expl/num steps total                     347000
expl/num paths total                        347
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.73783
expl/Rewards Std                              1.23574
expl/Rewards Max                              8.05245
expl/Rewards Min                             -0.862945
expl/Returns Mean                          5737.83
expl/Returns Std                              0
expl/Returns Max                           5737.83
expl/Returns Min                           5737.83
expl/Actions Mean                             0.099134
expl/Actions Std                              0.804382
expl/Actions Max                              0.999543
expl/Actions Min                             -0.99895
expl/Num Paths                                1
expl/Average Returns                       5737.83
expl/env_infos/final/reward_run Mean          5.03546
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.03546
expl/env_infos/final/reward_run Min           5.03546
expl/env_infos/initial/reward_run Mean        0.895908
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.895908
expl/env_infos/initial/reward_run Min         0.895908
expl/env_infos/reward_run Mean                6.13194
expl/env_infos/reward_run Std                 1.2271
expl/env_infos/reward_run Max                 8.57232
expl/env_infos/reward_run Min                -0.427762
expl/env_infos/final/reward_ctrl Mean        -0.542862
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.542862
expl/env_infos/final/reward_ctrl Min         -0.542862
expl/env_infos/initial/reward_ctrl Mean      -0.106071
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.106071
expl/env_infos/initial/reward_ctrl Min       -0.106071
expl/env_infos/reward_ctrl Mean              -0.394115
expl/env_infos/reward_ctrl Std                0.0895692
expl/env_infos/reward_ctrl Max               -0.098908
expl/env_infos/reward_ctrl Min               -0.586485
eval/num steps total                          1.73e+06
eval/num paths total                       1730
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.12836
eval/Rewards Std                              1.29369
eval/Rewards Max                              8.68196
eval/Rewards Min                             -0.662116
eval/Returns Mean                          6128.36
eval/Returns Std                             76.0214
eval/Returns Max                           6230.06
eval/Returns Min                           5997.31
eval/Actions Mean                             0.0942241
eval/Actions Std                              0.819994
eval/Actions Max                              0.997367
eval/Actions Min                             -0.996778
eval/Num Paths                                5
eval/Average Returns                       6128.36
eval/env_infos/final/reward_run Mean          7.50933
eval/env_infos/final/reward_run Std           0.629161
eval/env_infos/final/reward_run Max           8.35353
eval/env_infos/final/reward_run Min           6.70075
eval/env_infos/initial/reward_run Mean       -0.246594
eval/env_infos/initial/reward_run Std         0.18295
eval/env_infos/initial/reward_run Max         0.0221543
eval/env_infos/initial/reward_run Min        -0.450479
eval/env_infos/reward_run Mean                6.53712
eval/env_infos/reward_run Std                 1.28487
eval/env_infos/reward_run Max                 9.18029
eval/env_infos/reward_run Min                -0.450479
eval/env_infos/final/reward_ctrl Mean        -0.420463
eval/env_infos/final/reward_ctrl Std          0.100226
eval/env_infos/final/reward_ctrl Max         -0.265268
eval/env_infos/final/reward_ctrl Min         -0.52411
eval/env_infos/initial/reward_ctrl Mean      -0.194458
eval/env_infos/initial/reward_ctrl Std        0.0221265
eval/env_infos/initial/reward_ctrl Max       -0.161413
eval/env_infos/initial/reward_ctrl Min       -0.214469
eval/env_infos/reward_ctrl Mean              -0.408761
eval/env_infos/reward_ctrl Std                0.0920791
eval/env_infos/reward_ctrl Max               -0.0825751
eval/env_infos/reward_ctrl Min               -0.582825
time/data storing (s)                         0.00452133
time/evaluation sampling (s)                  2.0032
time/exploration sampling (s)                 0.530175
time/logging (s)                              0.0136071
time/sac training (s)                         7.4855
time/saving (s)                               0.00378396
time/training (s)                             3.381e-05
time/epoch (s)                               10.0408
time/total (s)                             3659.71
Epoch                                       345
---------------------------------------  ----------------
2021-11-24 01:30:25.235520 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 346 finished
---------------------------------------  ---------------
epoch                                       346
replay_buffer/size                       348000
trainer/num train calls                  347000
trainer/QF1 Loss                              5.0698
trainer/QF2 Loss                              4.741
trainer/Policy Loss                        -393.103
trainer/Q1 Predictions Mean                 393.799
trainer/Q1 Predictions Std                   96.0089
trainer/Q1 Predictions Max                  469.854
trainer/Q1 Predictions Min                   19.2449
trainer/Q2 Predictions Mean                 394.05
trainer/Q2 Predictions Std                   95.9428
trainer/Q2 Predictions Max                  467.706
trainer/Q2 Predictions Min                   19.6849
trainer/Q Targets Mean                      393.564
trainer/Q Targets Std                        95.9314
trainer/Q Targets Max                       468.17
trainer/Q Targets Min                        18.9308
trainer/Log Pis Mean                          6.25357
trainer/Log Pis Std                           4.52017
trainer/Log Pis Max                          17.1529
trainer/Log Pis Min                          -5.79582
trainer/policy/mean Mean                      0.0679939
trainer/policy/mean Std                       0.784823
trainer/policy/mean Max                       0.996184
trainer/policy/mean Min                      -0.995015
trainer/policy/normal/std Mean                0.439372
trainer/policy/normal/std Std                 0.138722
trainer/policy/normal/std Max                 1.11375
trainer/policy/normal/std Min                 0.0726991
trainer/policy/normal/log_std Mean           -0.887721
trainer/policy/normal/log_std Std             0.397202
trainer/policy/normal/log_std Max             0.107734
trainer/policy/normal/log_std Min            -2.62143
trainer/Alpha                                 0.142024
trainer/Alpha Loss                            0.494906
expl/num steps total                     348000
expl/num paths total                        348
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.76328
expl/Rewards Std                              1.20351
expl/Rewards Max                              7.80748
expl/Rewards Min                             -0.808651
expl/Returns Mean                          5763.28
expl/Returns Std                              0
expl/Returns Max                           5763.28
expl/Returns Min                           5763.28
expl/Actions Mean                             0.0777529
expl/Actions Std                              0.799057
expl/Actions Max                              0.999722
expl/Actions Min                             -0.998621
expl/Num Paths                                1
expl/Average Returns                       5763.28
expl/env_infos/final/reward_run Mean          6.97804
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.97804
expl/env_infos/final/reward_run Min           6.97804
expl/env_infos/initial/reward_run Mean       -0.500962
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.500962
expl/env_infos/initial/reward_run Min        -0.500962
expl/env_infos/reward_run Mean                6.15
expl/env_infos/reward_run Std                 1.20332
expl/env_infos/reward_run Max                 8.25934
expl/env_infos/reward_run Min                -0.500962
expl/env_infos/final/reward_ctrl Mean        -0.339968
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.339968
expl/env_infos/final/reward_ctrl Min         -0.339968
expl/env_infos/initial/reward_ctrl Mean      -0.30769
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.30769
expl/env_infos/initial/reward_ctrl Min       -0.30769
expl/env_infos/reward_ctrl Mean              -0.386723
expl/env_infos/reward_ctrl Std                0.0973637
expl/env_infos/reward_ctrl Max               -0.0628067
expl/env_infos/reward_ctrl Min               -0.573766
eval/num steps total                          1.735e+06
eval/num paths total                       1735
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.04525
eval/Rewards Std                              1.2642
eval/Rewards Max                              8.71383
eval/Rewards Min                             -0.441507
eval/Returns Mean                          6045.25
eval/Returns Std                             37.9773
eval/Returns Max                           6095.94
eval/Returns Min                           5994.32
eval/Actions Mean                             0.0818604
eval/Actions Std                              0.819613
eval/Actions Max                              0.996984
eval/Actions Min                             -0.995745
eval/Num Paths                                5
eval/Average Returns                       6045.25
eval/env_infos/final/reward_run Mean          6.72418
eval/env_infos/final/reward_run Std           0.724775
eval/env_infos/final/reward_run Max           8.12648
eval/env_infos/final/reward_run Min           6.16802
eval/env_infos/initial/reward_run Mean       -0.16395
eval/env_infos/initial/reward_run Std         0.0467803
eval/env_infos/initial/reward_run Max        -0.107956
eval/env_infos/initial/reward_run Min        -0.2272
eval/env_infos/reward_run Mean                6.45233
eval/env_infos/reward_run Std                 1.26153
eval/env_infos/reward_run Max                 9.25255
eval/env_infos/reward_run Min                -0.2272
eval/env_infos/final/reward_ctrl Mean        -0.463532
eval/env_infos/final/reward_ctrl Std          0.0678553
eval/env_infos/final/reward_ctrl Max         -0.3454
eval/env_infos/final/reward_ctrl Min         -0.551677
eval/env_infos/initial/reward_ctrl Mean      -0.202271
eval/env_infos/initial/reward_ctrl Std        0.0139087
eval/env_infos/initial/reward_ctrl Max       -0.182322
eval/env_infos/initial/reward_ctrl Min       -0.220899
eval/env_infos/reward_ctrl Mean              -0.40708
eval/env_infos/reward_ctrl Std                0.092633
eval/env_infos/reward_ctrl Max               -0.0991855
eval/env_infos/reward_ctrl Min               -0.584053
time/data storing (s)                         0.00449444
time/evaluation sampling (s)                  2.00085
time/exploration sampling (s)                 0.530008
time/logging (s)                              0.0135605
time/sac training (s)                         7.49552
time/saving (s)                               0.00374885
time/training (s)                             3.3253e-05
time/epoch (s)                               10.0482
time/total (s)                             3670.05
Epoch                                       346
---------------------------------------  ---------------
2021-11-24 01:30:35.595172 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 347 finished
---------------------------------------  ---------------
epoch                                       347
replay_buffer/size                       349000
trainer/num train calls                  348000
trainer/QF1 Loss                             10.7339
trainer/QF2 Loss                              5.73304
trainer/Policy Loss                        -393.073
trainer/Q1 Predictions Mean                 393.501
trainer/Q1 Predictions Std                   88.5319
trainer/Q1 Predictions Max                  465.395
trainer/Q1 Predictions Min                   19.7452
trainer/Q2 Predictions Mean                 394.066
trainer/Q2 Predictions Std                   88.2853
trainer/Q2 Predictions Max                  465.543
trainer/Q2 Predictions Min                   19.2728
trainer/Q Targets Mean                      394.188
trainer/Q Targets Std                        88.3945
trainer/Q Targets Max                       468.529
trainer/Q Targets Min                        19.4789
trainer/Log Pis Mean                          5.95621
trainer/Log Pis Std                           4.37138
trainer/Log Pis Max                          22.4125
trainer/Log Pis Min                          -4.9557
trainer/policy/mean Mean                      0.0719494
trainer/policy/mean Std                       0.781755
trainer/policy/mean Max                       0.998539
trainer/policy/mean Min                      -0.99743
trainer/policy/normal/std Mean                0.44174
trainer/policy/normal/std Std                 0.142415
trainer/policy/normal/std Max                 1.04799
trainer/policy/normal/std Min                 0.0717011
trainer/policy/normal/log_std Mean           -0.885197
trainer/policy/normal/log_std Std             0.405956
trainer/policy/normal/log_std Max             0.04687
trainer/policy/normal/log_std Min            -2.63525
trainer/Alpha                                 0.141472
trainer/Alpha Loss                           -0.0856338
expl/num steps total                     349000
expl/num paths total                        349
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.61338
expl/Rewards Std                              1.24159
expl/Rewards Max                              8.28276
expl/Rewards Min                             -0.708033
expl/Returns Mean                          5613.38
expl/Returns Std                              0
expl/Returns Max                           5613.38
expl/Returns Min                           5613.38
expl/Actions Mean                             0.0927328
expl/Actions Std                              0.797661
expl/Actions Max                              0.999679
expl/Actions Min                             -0.999593
expl/Num Paths                                1
expl/Average Returns                       5613.38
expl/env_infos/final/reward_run Mean          6.11493
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.11493
expl/env_infos/final/reward_run Min           6.11493
expl/env_infos/initial/reward_run Mean       -0.437755
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.437755
expl/env_infos/initial/reward_run Min        -0.437755
expl/env_infos/reward_run Mean                6.00029
expl/env_infos/reward_run Std                 1.23893
expl/env_infos/reward_run Max                 8.81529
expl/env_infos/reward_run Min                -0.437755
expl/env_infos/final/reward_ctrl Mean        -0.163218
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.163218
expl/env_infos/final/reward_ctrl Min         -0.163218
expl/env_infos/initial/reward_ctrl Mean      -0.270277
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.270277
expl/env_infos/initial/reward_ctrl Min       -0.270277
expl/env_infos/reward_ctrl Mean              -0.386918
expl/env_infos/reward_ctrl Std                0.0911488
expl/env_infos/reward_ctrl Max               -0.0854291
expl/env_infos/reward_ctrl Min               -0.566986
eval/num steps total                          1.74e+06
eval/num paths total                       1740
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.18055
eval/Rewards Std                              1.29917
eval/Rewards Max                              8.62961
eval/Rewards Min                             -0.548891
eval/Returns Mean                          6180.55
eval/Returns Std                             86.0457
eval/Returns Max                           6233.81
eval/Returns Min                           6009.04
eval/Actions Mean                             0.0948946
eval/Actions Std                              0.81916
eval/Actions Max                              0.998104
eval/Actions Min                             -0.996104
eval/Num Paths                                5
eval/Average Returns                       6180.55
eval/env_infos/final/reward_run Mean          6.93956
eval/env_infos/final/reward_run Std           0.869418
eval/env_infos/final/reward_run Max           8.52031
eval/env_infos/final/reward_run Min           6.13894
eval/env_infos/initial/reward_run Mean       -0.245305
eval/env_infos/initial/reward_run Std         0.110989
eval/env_infos/initial/reward_run Max        -0.059497
eval/env_infos/initial/reward_run Min        -0.369254
eval/env_infos/reward_run Mean                6.58857
eval/env_infos/reward_run Std                 1.30083
eval/env_infos/reward_run Max                 9.14601
eval/env_infos/reward_run Min                -0.369254
eval/env_infos/final/reward_ctrl Mean        -0.490283
eval/env_infos/final/reward_ctrl Std          0.0447361
eval/env_infos/final/reward_ctrl Max         -0.4085
eval/env_infos/final/reward_ctrl Min         -0.534016
eval/env_infos/initial/reward_ctrl Mean      -0.206285
eval/env_infos/initial/reward_ctrl Std        0.0463295
eval/env_infos/initial/reward_ctrl Max       -0.160048
eval/env_infos/initial/reward_ctrl Min       -0.283626
eval/env_infos/reward_ctrl Mean              -0.408017
eval/env_infos/reward_ctrl Std                0.088665
eval/env_infos/reward_ctrl Max               -0.10378
eval/env_infos/reward_ctrl Min               -0.580894
time/data storing (s)                         0.00451628
time/evaluation sampling (s)                  1.98933
time/exploration sampling (s)                 0.53029
time/logging (s)                              0.0136709
time/sac training (s)                         7.51965
time/saving (s)                               0.00379992
time/training (s)                             3.4569e-05
time/epoch (s)                               10.0613
time/total (s)                             3680.39
Epoch                                       347
---------------------------------------  ---------------
2021-11-24 01:30:46.130228 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 348 finished
---------------------------------------  ---------------
epoch                                       348
replay_buffer/size                       350000
trainer/num train calls                  349000
trainer/QF1 Loss                              5.10702
trainer/QF2 Loss                              4.68952
trainer/Policy Loss                        -392.213
trainer/Q1 Predictions Mean                 393.038
trainer/Q1 Predictions Std                  101.319
trainer/Q1 Predictions Max                  465.064
trainer/Q1 Predictions Min                   20.0026
trainer/Q2 Predictions Mean                 392.765
trainer/Q2 Predictions Std                  101.265
trainer/Q2 Predictions Max                  465.201
trainer/Q2 Predictions Min                   19.7414
trainer/Q Targets Mean                      392.974
trainer/Q Targets Std                       101.271
trainer/Q Targets Max                       464.641
trainer/Q Targets Min                        20.352
trainer/Log Pis Mean                          5.83297
trainer/Log Pis Std                           4.56559
trainer/Log Pis Max                          16.6963
trainer/Log Pis Min                          -7.65302
trainer/policy/mean Mean                      0.0951061
trainer/policy/mean Std                       0.780867
trainer/policy/mean Max                       0.995502
trainer/policy/mean Min                      -0.995482
trainer/policy/normal/std Mean                0.446943
trainer/policy/normal/std Std                 0.140444
trainer/policy/normal/std Max                 1.04293
trainer/policy/normal/std Min                 0.0739654
trainer/policy/normal/log_std Mean           -0.870319
trainer/policy/normal/log_std Std             0.396842
trainer/policy/normal/log_std Max             0.0420384
trainer/policy/normal/log_std Min            -2.60416
trainer/Alpha                                 0.141903
trainer/Alpha Loss                           -0.32615
expl/num steps total                     350000
expl/num paths total                        350
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.83961
expl/Rewards Std                              1.25197
expl/Rewards Max                              8.34136
expl/Rewards Min                             -0.779087
expl/Returns Mean                          5839.61
expl/Returns Std                              0
expl/Returns Max                           5839.61
expl/Returns Min                           5839.61
expl/Actions Mean                             0.103824
expl/Actions Std                              0.803401
expl/Actions Max                              0.999371
expl/Actions Min                             -0.999633
expl/Num Paths                                1
expl/Average Returns                       5839.61
expl/env_infos/final/reward_run Mean          6.89038
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.89038
expl/env_infos/final/reward_run Min           6.89038
expl/env_infos/initial/reward_run Mean       -0.542167
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.542167
expl/env_infos/initial/reward_run Min        -0.542167
expl/env_infos/reward_run Mean                6.23335
expl/env_infos/reward_run Std                 1.24658
expl/env_infos/reward_run Max                 8.85777
expl/env_infos/reward_run Min                -0.542167
expl/env_infos/final/reward_ctrl Mean        -0.244251
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.244251
expl/env_infos/final/reward_ctrl Min         -0.244251
expl/env_infos/initial/reward_ctrl Mean      -0.23692
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.23692
expl/env_infos/initial/reward_ctrl Min       -0.23692
expl/env_infos/reward_ctrl Mean              -0.39374
expl/env_infos/reward_ctrl Std                0.0911627
expl/env_infos/reward_ctrl Max               -0.119583
expl/env_infos/reward_ctrl Min               -0.576866
eval/num steps total                          1.745e+06
eval/num paths total                       1745
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             5.99987
eval/Rewards Std                              1.3041
eval/Rewards Max                              8.5499
eval/Rewards Min                             -0.839291
eval/Returns Mean                          5999.87
eval/Returns Std                             56.7757
eval/Returns Max                           6088.64
eval/Returns Min                           5922.6
eval/Actions Mean                             0.100476
eval/Actions Std                              0.815432
eval/Actions Max                              0.99468
eval/Actions Min                             -0.997053
eval/Num Paths                                5
eval/Average Returns                       5999.87
eval/env_infos/final/reward_run Mean          6.13869
eval/env_infos/final/reward_run Std           0.691965
eval/env_infos/final/reward_run Max           6.92887
eval/env_infos/final/reward_run Min           4.99778
eval/env_infos/initial/reward_run Mean       -0.414454
eval/env_infos/initial/reward_run Std         0.158247
eval/env_infos/initial/reward_run Max        -0.180874
eval/env_infos/initial/reward_run Min        -0.604086
eval/env_infos/reward_run Mean                6.40489
eval/env_infos/reward_run Std                 1.30432
eval/env_infos/reward_run Max                 9.04408
eval/env_infos/reward_run Min                -0.604086
eval/env_infos/final/reward_ctrl Mean        -0.449206
eval/env_infos/final/reward_ctrl Std          0.0506229
eval/env_infos/final/reward_ctrl Max         -0.396424
eval/env_infos/final/reward_ctrl Min         -0.514685
eval/env_infos/initial/reward_ctrl Mean      -0.217053
eval/env_infos/initial/reward_ctrl Std        0.0295029
eval/env_infos/initial/reward_ctrl Max       -0.17785
eval/env_infos/initial/reward_ctrl Min       -0.252563
eval/env_infos/reward_ctrl Mean              -0.405015
eval/env_infos/reward_ctrl Std                0.0900161
eval/env_infos/reward_ctrl Max               -0.0649915
eval/env_infos/reward_ctrl Min               -0.585107
time/data storing (s)                         0.00452316
time/evaluation sampling (s)                  2.07539
time/exploration sampling (s)                 0.597595
time/logging (s)                              0.0136932
time/sac training (s)                         7.54177
time/saving (s)                               0.0037847
time/training (s)                             3.4877e-05
time/epoch (s)                               10.2368
time/total (s)                             3690.91
Epoch                                       348
---------------------------------------  ---------------
2021-11-24 01:30:56.695902 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 349 finished
---------------------------------------  ---------------
epoch                                       349
replay_buffer/size                       351000
trainer/num train calls                  350000
trainer/QF1 Loss                              5.59411
trainer/QF2 Loss                              5.57582
trainer/Policy Loss                        -393.666
trainer/Q1 Predictions Mean                 394.157
trainer/Q1 Predictions Std                   90.452
trainer/Q1 Predictions Max                  460.739
trainer/Q1 Predictions Min                   20.3207
trainer/Q2 Predictions Mean                 394.338
trainer/Q2 Predictions Std                   90.3702
trainer/Q2 Predictions Max                  459.869
trainer/Q2 Predictions Min                   20.4363
trainer/Q Targets Mean                      394.634
trainer/Q Targets Std                        90.7026
trainer/Q Targets Max                       461.868
trainer/Q Targets Min                        19.3394
trainer/Log Pis Mean                          5.93213
trainer/Log Pis Std                           3.89806
trainer/Log Pis Max                          15.1262
trainer/Log Pis Min                          -7.18683
trainer/policy/mean Mean                      0.0832335
trainer/policy/mean Std                       0.770628
trainer/policy/mean Max                       0.999689
trainer/policy/mean Min                      -0.996682
trainer/policy/normal/std Mean                0.435357
trainer/policy/normal/std Std                 0.148326
trainer/policy/normal/std Max                 1.80955
trainer/policy/normal/std Min                 0.0696558
trainer/policy/normal/log_std Mean           -0.908547
trainer/policy/normal/log_std Std             0.433842
trainer/policy/normal/log_std Max             0.593078
trainer/policy/normal/log_std Min            -2.66419
trainer/Alpha                                 0.141983
trainer/Alpha Loss                           -0.132491
expl/num steps total                     351000
expl/num paths total                        351
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.74824
expl/Rewards Std                              1.24299
expl/Rewards Max                              8.19756
expl/Rewards Min                             -0.739319
expl/Returns Mean                          5748.24
expl/Returns Std                              0
expl/Returns Max                           5748.24
expl/Returns Min                           5748.24
expl/Actions Mean                             0.0905276
expl/Actions Std                              0.798497
expl/Actions Max                              0.999305
expl/Actions Min                             -0.999019
expl/Num Paths                                1
expl/Average Returns                       5748.24
expl/env_infos/final/reward_run Mean          7.83399
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.83399
expl/env_infos/final/reward_run Min           7.83399
expl/env_infos/initial/reward_run Mean       -0.533027
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.533027
expl/env_infos/initial/reward_run Min        -0.533027
expl/env_infos/reward_run Mean                6.13571
expl/env_infos/reward_run Std                 1.24524
expl/env_infos/reward_run Max                 8.6106
expl/env_infos/reward_run Min                -0.533027
expl/env_infos/final/reward_ctrl Mean        -0.450446
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.450446
expl/env_infos/final/reward_ctrl Min         -0.450446
expl/env_infos/initial/reward_ctrl Mean      -0.206292
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.206292
expl/env_infos/initial/reward_ctrl Min       -0.206292
expl/env_infos/reward_ctrl Mean              -0.387475
expl/env_infos/reward_ctrl Std                0.0906866
expl/env_infos/reward_ctrl Max               -0.0825937
expl/env_infos/reward_ctrl Min               -0.580235
eval/num steps total                          1.75e+06
eval/num paths total                       1750
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.08731
eval/Rewards Std                              1.31195
eval/Rewards Max                              8.56665
eval/Rewards Min                             -0.829422
eval/Returns Mean                          6087.31
eval/Returns Std                            116.316
eval/Returns Max                           6289.12
eval/Returns Min                           5933.36
eval/Actions Mean                             0.0930707
eval/Actions Std                              0.81913
eval/Actions Max                              0.997158
eval/Actions Min                             -0.995249
eval/Num Paths                                5
eval/Average Returns                       6087.31
eval/env_infos/final/reward_run Mean          6.96089
eval/env_infos/final/reward_run Std           0.777945
eval/env_infos/final/reward_run Max           8.1391
eval/env_infos/final/reward_run Min           6.31897
eval/env_infos/initial/reward_run Mean       -0.363085
eval/env_infos/initial/reward_run Std         0.192879
eval/env_infos/initial/reward_run Max        -0.10465
eval/env_infos/initial/reward_run Min        -0.579022
eval/env_infos/reward_run Mean                6.49509
eval/env_infos/reward_run Std                 1.31465
eval/env_infos/reward_run Max                 9.08586
eval/env_infos/reward_run Min                -0.579022
eval/env_infos/final/reward_ctrl Mean        -0.429945
eval/env_infos/final/reward_ctrl Std          0.0811463
eval/env_infos/final/reward_ctrl Max         -0.306609
eval/env_infos/final/reward_ctrl Min         -0.546034
eval/env_infos/initial/reward_ctrl Mean      -0.231646
eval/env_infos/initial/reward_ctrl Std        0.00915839
eval/env_infos/initial/reward_ctrl Max       -0.216673
eval/env_infos/initial/reward_ctrl Min       -0.243942
eval/env_infos/reward_ctrl Mean              -0.407782
eval/env_infos/reward_ctrl Std                0.0874684
eval/env_infos/reward_ctrl Max               -0.0700098
eval/env_infos/reward_ctrl Min               -0.584063
time/data storing (s)                         0.0045586
time/evaluation sampling (s)                  2.12734
time/exploration sampling (s)                 0.583489
time/logging (s)                              0.0136086
time/sac training (s)                         7.53639
time/saving (s)                               0.0038032
time/training (s)                             3.4754e-05
time/epoch (s)                               10.2692
time/total (s)                             3701.46
Epoch                                       349
---------------------------------------  ---------------
2021-11-24 01:31:07.207865 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 350 finished
---------------------------------------  ---------------
epoch                                       350
replay_buffer/size                       352000
trainer/num train calls                  351000
trainer/QF1 Loss                              5.18062
trainer/QF2 Loss                              5.93539
trainer/Policy Loss                        -405.13
trainer/Q1 Predictions Mean                 405.924
trainer/Q1 Predictions Std                   66.2957
trainer/Q1 Predictions Max                  464.711
trainer/Q1 Predictions Min                   23.8345
trainer/Q2 Predictions Mean                 406.04
trainer/Q2 Predictions Std                   66.3256
trainer/Q2 Predictions Max                  464.725
trainer/Q2 Predictions Min                   22.6009
trainer/Q Targets Mean                      405.665
trainer/Q Targets Std                        66.1054
trainer/Q Targets Max                       463.392
trainer/Q Targets Min                        23.2965
trainer/Log Pis Mean                          6.24494
trainer/Log Pis Std                           4.27507
trainer/Log Pis Max                          18.2986
trainer/Log Pis Min                          -4.6976
trainer/policy/mean Mean                      0.0848177
trainer/policy/mean Std                       0.783869
trainer/policy/mean Max                       0.996112
trainer/policy/mean Min                      -0.997498
trainer/policy/normal/std Mean                0.428554
trainer/policy/normal/std Std                 0.134057
trainer/policy/normal/std Max                 0.853766
trainer/policy/normal/std Min                 0.0546167
trainer/policy/normal/log_std Mean           -0.916694
trainer/policy/normal/log_std Std             0.416068
trainer/policy/normal/log_std Max            -0.158098
trainer/policy/normal/log_std Min            -2.90741
trainer/Alpha                                 0.142237
trainer/Alpha Loss                            0.477687
expl/num steps total                     352000
expl/num paths total                        352
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.81537
expl/Rewards Std                              1.25302
expl/Rewards Max                              8.16357
expl/Rewards Min                             -0.419088
expl/Returns Mean                          5815.37
expl/Returns Std                              0
expl/Returns Max                           5815.37
expl/Returns Min                           5815.37
expl/Actions Mean                             0.0934558
expl/Actions Std                              0.798537
expl/Actions Max                              0.999366
expl/Actions Min                             -0.999717
expl/Num Paths                                1
expl/Average Returns                       5815.37
expl/env_infos/final/reward_run Mean          6.62009
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.62009
expl/env_infos/final/reward_run Min           6.62009
expl/env_infos/initial/reward_run Mean       -0.175352
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.175352
expl/env_infos/initial/reward_run Min        -0.175352
expl/env_infos/reward_run Mean                6.20321
expl/env_infos/reward_run Std                 1.24839
expl/env_infos/reward_run Max                 8.62075
expl/env_infos/reward_run Min                -0.175352
expl/env_infos/final/reward_ctrl Mean        -0.294062
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.294062
expl/env_infos/final/reward_ctrl Min         -0.294062
expl/env_infos/initial/reward_ctrl Mean      -0.153475
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.153475
expl/env_infos/initial/reward_ctrl Min       -0.153475
expl/env_infos/reward_ctrl Mean              -0.387837
expl/env_infos/reward_ctrl Std                0.0916778
expl/env_infos/reward_ctrl Max               -0.10025
expl/env_infos/reward_ctrl Min               -0.583232
eval/num steps total                          1.755e+06
eval/num paths total                       1755
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.12999
eval/Rewards Std                              1.31063
eval/Rewards Max                              8.81182
eval/Rewards Min                             -0.7902
eval/Returns Mean                          6129.99
eval/Returns Std                             95.1417
eval/Returns Max                           6291.59
eval/Returns Min                           6034.48
eval/Actions Mean                             0.0909902
eval/Actions Std                              0.817357
eval/Actions Max                              0.998389
eval/Actions Min                             -0.996856
eval/Num Paths                                5
eval/Average Returns                       6129.99
eval/env_infos/final/reward_run Mean          6.99461
eval/env_infos/final/reward_run Std           0.644021
eval/env_infos/final/reward_run Max           8.18441
eval/env_infos/final/reward_run Min           6.25888
eval/env_infos/initial/reward_run Mean       -0.2548
eval/env_infos/initial/reward_run Std         0.364698
eval/env_infos/initial/reward_run Max         0.451556
eval/env_infos/initial/reward_run Min        -0.605323
eval/env_infos/reward_run Mean                6.5358
eval/env_infos/reward_run Std                 1.30635
eval/env_infos/reward_run Max                 9.27883
eval/env_infos/reward_run Min                -0.605323
eval/env_infos/final/reward_ctrl Mean        -0.429011
eval/env_infos/final/reward_ctrl Std          0.0922281
eval/env_infos/final/reward_ctrl Max         -0.261592
eval/env_infos/final/reward_ctrl Min         -0.534366
eval/env_infos/initial/reward_ctrl Mean      -0.185964
eval/env_infos/initial/reward_ctrl Std        0.0445209
eval/env_infos/initial/reward_ctrl Max       -0.134593
eval/env_infos/initial/reward_ctrl Min       -0.250719
eval/env_infos/reward_ctrl Mean              -0.405811
eval/env_infos/reward_ctrl Std                0.0886124
eval/env_infos/reward_ctrl Max               -0.111022
eval/env_infos/reward_ctrl Min               -0.581459
time/data storing (s)                         0.00454569
time/evaluation sampling (s)                  2.0498
time/exploration sampling (s)                 0.539705
time/logging (s)                              0.0136888
time/sac training (s)                         7.59847
time/saving (s)                               0.00377016
time/training (s)                             3.4108e-05
time/epoch (s)                               10.21
time/total (s)                             3711.96
Epoch                                       350
---------------------------------------  ---------------
2021-11-24 01:31:17.693370 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 351 finished
---------------------------------------  ---------------
epoch                                       351
replay_buffer/size                       353000
trainer/num train calls                  352000
trainer/QF1 Loss                              5.79611
trainer/QF2 Loss                              6.97749
trainer/Policy Loss                        -385.156
trainer/Q1 Predictions Mean                 385.684
trainer/Q1 Predictions Std                  100.13
trainer/Q1 Predictions Max                  465.411
trainer/Q1 Predictions Min                   21.1787
trainer/Q2 Predictions Mean                 385.744
trainer/Q2 Predictions Std                   99.9379
trainer/Q2 Predictions Max                  463.847
trainer/Q2 Predictions Min                   21.2691
trainer/Q Targets Mean                      385.534
trainer/Q Targets Std                       100.088
trainer/Q Targets Max                       464.089
trainer/Q Targets Min                        20.6367
trainer/Log Pis Mean                          6.23606
trainer/Log Pis Std                           4.4798
trainer/Log Pis Max                          18.371
trainer/Log Pis Min                          -4.89471
trainer/policy/mean Mean                      0.0549761
trainer/policy/mean Std                       0.787445
trainer/policy/mean Max                       0.999084
trainer/policy/mean Min                      -0.997711
trainer/policy/normal/std Mean                0.444733
trainer/policy/normal/std Std                 0.14402
trainer/policy/normal/std Max                 1.02258
trainer/policy/normal/std Min                 0.0760249
trainer/policy/normal/log_std Mean           -0.879314
trainer/policy/normal/log_std Std             0.408067
trainer/policy/normal/log_std Max             0.0223327
trainer/policy/normal/log_std Min            -2.57669
trainer/Alpha                                 0.141896
trainer/Alpha Loss                            0.460947
expl/num steps total                     353000
expl/num paths total                        353
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.79621
expl/Rewards Std                              1.20809
expl/Rewards Max                              8.18186
expl/Rewards Min                             -0.513895
expl/Returns Mean                          5796.21
expl/Returns Std                              0
expl/Returns Max                           5796.21
expl/Returns Min                           5796.21
expl/Actions Mean                             0.0889327
expl/Actions Std                              0.804371
expl/Actions Max                              0.999473
expl/Actions Min                             -0.999462
expl/Num Paths                                1
expl/Average Returns                       5796.21
expl/env_infos/final/reward_run Mean          7.64225
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.64225
expl/env_infos/final/reward_run Min           7.64225
expl/env_infos/initial/reward_run Mean       -0.357706
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.357706
expl/env_infos/initial/reward_run Min        -0.357706
expl/env_infos/reward_run Mean                6.18916
expl/env_infos/reward_run Std                 1.20094
expl/env_infos/reward_run Max                 8.67897
expl/env_infos/reward_run Min                -0.357706
expl/env_infos/final/reward_ctrl Mean        -0.327018
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.327018
expl/env_infos/final/reward_ctrl Min         -0.327018
expl/env_infos/initial/reward_ctrl Mean      -0.140788
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.140788
expl/env_infos/initial/reward_ctrl Min       -0.140788
expl/env_infos/reward_ctrl Mean              -0.392953
expl/env_infos/reward_ctrl Std                0.0921025
expl/env_infos/reward_ctrl Max               -0.0969288
expl/env_infos/reward_ctrl Min               -0.582734
eval/num steps total                          1.76e+06
eval/num paths total                       1760
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.16787
eval/Rewards Std                              1.31169
eval/Rewards Max                              8.62344
eval/Rewards Min                             -0.9772
eval/Returns Mean                          6167.87
eval/Returns Std                             56.1379
eval/Returns Max                           6224.3
eval/Returns Min                           6083.53
eval/Actions Mean                             0.0889396
eval/Actions Std                              0.824603
eval/Actions Max                              0.998059
eval/Actions Min                             -0.996403
eval/Num Paths                                5
eval/Average Returns                       6167.87
eval/env_infos/final/reward_run Mean          6.7767
eval/env_infos/final/reward_run Std           0.625336
eval/env_infos/final/reward_run Max           7.65519
eval/env_infos/final/reward_run Min           5.90707
eval/env_infos/initial/reward_run Mean       -0.369694
eval/env_infos/initial/reward_run Std         0.292871
eval/env_infos/initial/reward_run Max         0.108802
eval/env_infos/initial/reward_run Min        -0.675547
eval/env_infos/reward_run Mean                6.5806
eval/env_infos/reward_run Std                 1.30601
eval/env_infos/reward_run Max                 9.12791
eval/env_infos/reward_run Min                -0.675547
eval/env_infos/final/reward_ctrl Mean        -0.386002
eval/env_infos/final/reward_ctrl Std          0.101453
eval/env_infos/final/reward_ctrl Max         -0.25316
eval/env_infos/final/reward_ctrl Min         -0.52283
eval/env_infos/initial/reward_ctrl Mean      -0.212824
eval/env_infos/initial/reward_ctrl Std        0.0494572
eval/env_infos/initial/reward_ctrl Max       -0.154849
eval/env_infos/initial/reward_ctrl Min       -0.301653
eval/env_infos/reward_ctrl Mean              -0.412728
eval/env_infos/reward_ctrl Std                0.0924682
eval/env_infos/reward_ctrl Max               -0.0940077
eval/env_infos/reward_ctrl Min               -0.582101
time/data storing (s)                         0.00454935
time/evaluation sampling (s)                  2.03603
time/exploration sampling (s)                 0.552752
time/logging (s)                              0.0136133
time/sac training (s)                         7.57562
time/saving (s)                               0.00381022
time/training (s)                             3.4474e-05
time/epoch (s)                               10.1864
time/total (s)                             3722.43
Epoch                                       351
---------------------------------------  ---------------
2021-11-24 01:31:28.203333 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 352 finished
---------------------------------------  ---------------
epoch                                       352
replay_buffer/size                       354000
trainer/num train calls                  353000
trainer/QF1 Loss                              5.03886
trainer/QF2 Loss                              5.03624
trainer/Policy Loss                        -397.884
trainer/Q1 Predictions Mean                 398.47
trainer/Q1 Predictions Std                   79.9612
trainer/Q1 Predictions Max                  465.682
trainer/Q1 Predictions Min                   17.6309
trainer/Q2 Predictions Mean                 398.407
trainer/Q2 Predictions Std                   79.9805
trainer/Q2 Predictions Max                  465.801
trainer/Q2 Predictions Min                   18.0426
trainer/Q Targets Mean                      399.13
trainer/Q Targets Std                        80.0951
trainer/Q Targets Max                       465.943
trainer/Q Targets Min                        18.8955
trainer/Log Pis Mean                          5.55019
trainer/Log Pis Std                           4.19873
trainer/Log Pis Max                          16.0282
trainer/Log Pis Min                          -7.94131
trainer/policy/mean Mean                      0.0908994
trainer/policy/mean Std                       0.762782
trainer/policy/mean Max                       0.997079
trainer/policy/mean Min                      -0.994564
trainer/policy/normal/std Mean                0.436133
trainer/policy/normal/std Std                 0.139639
trainer/policy/normal/std Max                 0.896227
trainer/policy/normal/std Min                 0.0815826
trainer/policy/normal/log_std Mean           -0.898439
trainer/policy/normal/log_std Std             0.408199
trainer/policy/normal/log_std Max            -0.109561
trainer/policy/normal/log_std Min            -2.50614
trainer/Alpha                                 0.143184
trainer/Alpha Loss                           -0.874261
expl/num steps total                     354000
expl/num paths total                        354
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.65039
expl/Rewards Std                              1.27143
expl/Rewards Max                              8.55801
expl/Rewards Min                             -1.15796
expl/Returns Mean                          5650.39
expl/Returns Std                              0
expl/Returns Max                           5650.39
expl/Returns Min                           5650.39
expl/Actions Mean                             0.100825
expl/Actions Std                              0.794491
expl/Actions Max                              0.999703
expl/Actions Min                             -0.999247
expl/Num Paths                                1
expl/Average Returns                       5650.39
expl/env_infos/final/reward_run Mean          5.18769
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.18769
expl/env_infos/final/reward_run Min           5.18769
expl/env_infos/initial/reward_run Mean       -0.825712
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.825712
expl/env_infos/initial/reward_run Min        -0.825712
expl/env_infos/reward_run Mean                6.03522
expl/env_infos/reward_run Std                 1.26387
expl/env_infos/reward_run Max                 9.12503
expl/env_infos/reward_run Min                -0.825712
expl/env_infos/final/reward_ctrl Mean        -0.436201
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.436201
expl/env_infos/final/reward_ctrl Min         -0.436201
expl/env_infos/initial/reward_ctrl Mean      -0.332252
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.332252
expl/env_infos/initial/reward_ctrl Min       -0.332252
expl/env_infos/reward_ctrl Mean              -0.384829
expl/env_infos/reward_ctrl Std                0.0930331
expl/env_infos/reward_ctrl Max               -0.09716
expl/env_infos/reward_ctrl Min               -0.584162
eval/num steps total                          1.765e+06
eval/num paths total                       1765
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.08924
eval/Rewards Std                              1.31597
eval/Rewards Max                              8.65296
eval/Rewards Min                             -0.619726
eval/Returns Mean                          6089.24
eval/Returns Std                             78.9031
eval/Returns Max                           6203.68
eval/Returns Min                           5956
eval/Actions Mean                             0.104201
eval/Actions Std                              0.811495
eval/Actions Max                              0.998553
eval/Actions Min                             -0.994964
eval/Num Paths                                5
eval/Average Returns                       6089.24
eval/env_infos/final/reward_run Mean          7.71325
eval/env_infos/final/reward_run Std           0.541709
eval/env_infos/final/reward_run Max           8.20078
eval/env_infos/final/reward_run Min           6.91409
eval/env_infos/initial/reward_run Mean       -0.250815
eval/env_infos/initial/reward_run Std         0.13563
eval/env_infos/initial/reward_run Max        -0.0323832
eval/env_infos/initial/reward_run Min        -0.417114
eval/env_infos/reward_run Mean                6.49087
eval/env_infos/reward_run Std                 1.31174
eval/env_infos/reward_run Max                 9.16852
eval/env_infos/reward_run Min                -0.417114
eval/env_infos/final/reward_ctrl Mean        -0.386678
eval/env_infos/final/reward_ctrl Std          0.0630225
eval/env_infos/final/reward_ctrl Max         -0.297651
eval/env_infos/final/reward_ctrl Min         -0.480424
eval/env_infos/initial/reward_ctrl Mean      -0.205259
eval/env_infos/initial/reward_ctrl Std        0.010615
eval/env_infos/initial/reward_ctrl Max       -0.197769
eval/env_infos/initial/reward_ctrl Min       -0.226259
eval/env_infos/reward_ctrl Mean              -0.401629
eval/env_infos/reward_ctrl Std                0.0934029
eval/env_infos/reward_ctrl Max               -0.0823486
eval/env_infos/reward_ctrl Min               -0.579136
time/data storing (s)                         0.00450066
time/evaluation sampling (s)                  2.08755
time/exploration sampling (s)                 0.528197
time/logging (s)                              0.0194703
time/sac training (s)                         7.56915
time/saving (s)                               0.00621454
time/training (s)                             3.4879e-05
time/epoch (s)                               10.2151
time/total (s)                             3732.94
Epoch                                       352
---------------------------------------  ---------------
2021-11-24 01:31:38.555142 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 353 finished
---------------------------------------  ---------------
epoch                                       353
replay_buffer/size                       355000
trainer/num train calls                  354000
trainer/QF1 Loss                              5.82254
trainer/QF2 Loss                              6.44902
trainer/Policy Loss                        -396.671
trainer/Q1 Predictions Mean                 397.553
trainer/Q1 Predictions Std                   94.3777
trainer/Q1 Predictions Max                  474.859
trainer/Q1 Predictions Min                   18.8835
trainer/Q2 Predictions Mean                 397.537
trainer/Q2 Predictions Std                   94.269
trainer/Q2 Predictions Max                  473.285
trainer/Q2 Predictions Min                   19.1849
trainer/Q Targets Mean                      396.959
trainer/Q Targets Std                        94.2648
trainer/Q Targets Max                       474.238
trainer/Q Targets Min                        17.2286
trainer/Log Pis Mean                          6.36625
trainer/Log Pis Std                           4.53549
trainer/Log Pis Max                          17.3389
trainer/Log Pis Min                          -5.47576
trainer/policy/mean Mean                      0.102021
trainer/policy/mean Std                       0.780994
trainer/policy/mean Max                       0.996867
trainer/policy/mean Min                      -0.99921
trainer/policy/normal/std Mean                0.444892
trainer/policy/normal/std Std                 0.146248
trainer/policy/normal/std Max                 1.08176
trainer/policy/normal/std Min                 0.0690629
trainer/policy/normal/log_std Mean           -0.885067
trainer/policy/normal/log_std Std             0.43131
trainer/policy/normal/log_std Max             0.07859
trainer/policy/normal/log_std Min            -2.67274
trainer/Alpha                                 0.1441
trainer/Alpha Loss                            0.709518
expl/num steps total                     355000
expl/num paths total                        355
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.69514
expl/Rewards Std                              1.27804
expl/Rewards Max                              7.98595
expl/Rewards Min                             -0.715549
expl/Returns Mean                          5695.14
expl/Returns Std                              0
expl/Returns Max                           5695.14
expl/Returns Min                           5695.14
expl/Actions Mean                             0.111029
expl/Actions Std                              0.799994
expl/Actions Max                              0.999626
expl/Actions Min                             -0.999354
expl/Num Paths                                1
expl/Average Returns                       5695.14
expl/env_infos/final/reward_run Mean          8.38088
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.38088
expl/env_infos/final/reward_run Min           8.38088
expl/env_infos/initial/reward_run Mean       -0.567579
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.567579
expl/env_infos/initial/reward_run Min        -0.567579
expl/env_infos/reward_run Mean                6.08653
expl/env_infos/reward_run Std                 1.26965
expl/env_infos/reward_run Max                 8.53779
expl/env_infos/reward_run Min                -0.567579
expl/env_infos/final/reward_ctrl Mean        -0.448513
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.448513
expl/env_infos/final/reward_ctrl Min         -0.448513
expl/env_infos/initial/reward_ctrl Mean      -0.147971
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.147971
expl/env_infos/initial/reward_ctrl Min       -0.147971
expl/env_infos/reward_ctrl Mean              -0.391391
expl/env_infos/reward_ctrl Std                0.0939151
expl/env_infos/reward_ctrl Max               -0.0357999
expl/env_infos/reward_ctrl Min               -0.581023
eval/num steps total                          1.77e+06
eval/num paths total                       1770
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.23706
eval/Rewards Std                              1.33467
eval/Rewards Max                              8.78125
eval/Rewards Min                             -0.891743
eval/Returns Mean                          6237.06
eval/Returns Std                             70.0458
eval/Returns Max                           6292.49
eval/Returns Min                           6101.94
eval/Actions Mean                             0.100913
eval/Actions Std                              0.818851
eval/Actions Max                              0.999186
eval/Actions Min                             -0.996783
eval/Num Paths                                5
eval/Average Returns                       6237.06
eval/env_infos/final/reward_run Mean          7.02918
eval/env_infos/final/reward_run Std           0.852543
eval/env_infos/final/reward_run Max           8.12629
eval/env_infos/final/reward_run Min           5.79427
eval/env_infos/initial/reward_run Mean       -0.171727
eval/env_infos/initial/reward_run Std         0.267513
eval/env_infos/initial/reward_run Max         0.295097
eval/env_infos/initial/reward_run Min        -0.438014
eval/env_infos/reward_run Mean                6.64548
eval/env_infos/reward_run Std                 1.32872
eval/env_infos/reward_run Max                 9.31992
eval/env_infos/reward_run Min                -0.497068
eval/env_infos/final/reward_ctrl Mean        -0.374815
eval/env_infos/final/reward_ctrl Std          0.0793872
eval/env_infos/final/reward_ctrl Max         -0.232759
eval/env_infos/final/reward_ctrl Min         -0.451394
eval/env_infos/initial/reward_ctrl Mean      -0.152714
eval/env_infos/initial/reward_ctrl Std        0.023537
eval/env_infos/initial/reward_ctrl Max       -0.130626
eval/env_infos/initial/reward_ctrl Min       -0.183409
eval/env_infos/reward_ctrl Mean              -0.40842
eval/env_infos/reward_ctrl Std                0.0889971
eval/env_infos/reward_ctrl Max               -0.0448281
eval/env_infos/reward_ctrl Min               -0.578985
time/data storing (s)                         0.00452079
time/evaluation sampling (s)                  2.01777
time/exploration sampling (s)                 0.52631
time/logging (s)                              0.0136805
time/sac training (s)                         7.47743
time/saving (s)                               0.00380544
time/training (s)                             3.4517e-05
time/epoch (s)                               10.0435
time/total (s)                             3743.27
Epoch                                       353
---------------------------------------  ---------------
2021-11-24 01:31:48.923791 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 354 finished
---------------------------------------  ---------------
epoch                                       354
replay_buffer/size                       356000
trainer/num train calls                  355000
trainer/QF1 Loss                              7.01505
trainer/QF2 Loss                              5.0675
trainer/Policy Loss                        -390.896
trainer/Q1 Predictions Mean                 391.849
trainer/Q1 Predictions Std                   98.9233
trainer/Q1 Predictions Max                  469.414
trainer/Q1 Predictions Min                   17.938
trainer/Q2 Predictions Mean                 391.452
trainer/Q2 Predictions Std                   98.7455
trainer/Q2 Predictions Max                  467.329
trainer/Q2 Predictions Min                   18.2406
trainer/Q Targets Mean                      391.404
trainer/Q Targets Std                        98.9374
trainer/Q Targets Max                       469.121
trainer/Q Targets Min                        17.1111
trainer/Log Pis Mean                          6.0224
trainer/Log Pis Std                           4.21054
trainer/Log Pis Max                          16.2245
trainer/Log Pis Min                          -6.1211
trainer/policy/mean Mean                      0.0571434
trainer/policy/mean Std                       0.778538
trainer/policy/mean Max                       0.995891
trainer/policy/mean Min                      -0.995472
trainer/policy/normal/std Mean                0.439324
trainer/policy/normal/std Std                 0.14228
trainer/policy/normal/std Max                 0.857444
trainer/policy/normal/std Min                 0.0685931
trainer/policy/normal/log_std Mean           -0.893641
trainer/policy/normal/log_std Std             0.416978
trainer/policy/normal/log_std Max            -0.1538
trainer/policy/normal/log_std Min            -2.67956
trainer/Alpha                                 0.142047
trainer/Alpha Loss                            0.0437131
expl/num steps total                     356000
expl/num paths total                        356
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.86549
expl/Rewards Std                              1.234
expl/Rewards Max                              8.29778
expl/Rewards Min                             -0.193429
expl/Returns Mean                          5865.49
expl/Returns Std                              0
expl/Returns Max                           5865.49
expl/Returns Min                           5865.49
expl/Actions Mean                             0.0974078
expl/Actions Std                              0.804044
expl/Actions Max                              0.999624
expl/Actions Min                             -0.999945
expl/Num Paths                                1
expl/Average Returns                       5865.49
expl/env_infos/final/reward_run Mean          7.52395
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.52395
expl/env_infos/final/reward_run Min           7.52395
expl/env_infos/initial/reward_run Mean        0.470377
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.470377
expl/env_infos/initial/reward_run Min         0.470377
expl/env_infos/reward_run Mean                6.25907
expl/env_infos/reward_run Std                 1.22108
expl/env_infos/reward_run Max                 8.79205
expl/env_infos/reward_run Min                 0.159867
expl/env_infos/final/reward_ctrl Mean        -0.355344
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.355344
expl/env_infos/final/reward_ctrl Min         -0.355344
expl/env_infos/initial/reward_ctrl Mean      -0.232629
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.232629
expl/env_infos/initial/reward_ctrl Min       -0.232629
expl/env_infos/reward_ctrl Mean              -0.393585
expl/env_infos/reward_ctrl Std                0.0919853
expl/env_infos/reward_ctrl Max               -0.066087
expl/env_infos/reward_ctrl Min               -0.580578
eval/num steps total                          1.775e+06
eval/num paths total                       1775
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.06133
eval/Rewards Std                              1.31274
eval/Rewards Max                              8.60245
eval/Rewards Min                             -0.703221
eval/Returns Mean                          6061.33
eval/Returns Std                             32.3025
eval/Returns Max                           6105.55
eval/Returns Min                           6008.75
eval/Actions Mean                             0.0951269
eval/Actions Std                              0.816453
eval/Actions Max                              0.996897
eval/Actions Min                             -0.995416
eval/Num Paths                                5
eval/Average Returns                       6061.33
eval/env_infos/final/reward_run Mean          6.42784
eval/env_infos/final/reward_run Std           0.739943
eval/env_infos/final/reward_run Max           7.87089
eval/env_infos/final/reward_run Min           5.87046
eval/env_infos/initial/reward_run Mean       -0.290246
eval/env_infos/initial/reward_run Std         0.152143
eval/env_infos/initial/reward_run Max        -0.0843581
eval/env_infos/initial/reward_run Min        -0.492777
eval/env_infos/reward_run Mean                6.46672
eval/env_infos/reward_run Std                 1.30248
eval/env_infos/reward_run Max                 9.12682
eval/env_infos/reward_run Min                -0.492777
eval/env_infos/final/reward_ctrl Mean        -0.388032
eval/env_infos/final/reward_ctrl Std          0.0530583
eval/env_infos/final/reward_ctrl Max         -0.299048
eval/env_infos/final/reward_ctrl Min         -0.444663
eval/env_infos/initial/reward_ctrl Mean      -0.202922
eval/env_infos/initial/reward_ctrl Std        0.0299216
eval/env_infos/initial/reward_ctrl Max       -0.14575
eval/env_infos/initial/reward_ctrl Min       -0.228195
eval/env_infos/reward_ctrl Mean              -0.405386
eval/env_infos/reward_ctrl Std                0.0942255
eval/env_infos/reward_ctrl Max               -0.0953158
eval/env_infos/reward_ctrl Min               -0.575184
time/data storing (s)                         0.0045177
time/evaluation sampling (s)                  2.03713
time/exploration sampling (s)                 0.537205
time/logging (s)                              0.0136425
time/sac training (s)                         7.47524
time/saving (s)                               0.00375017
time/training (s)                             3.4084e-05
time/epoch (s)                               10.0715
time/total (s)                             3753.62
Epoch                                       354
---------------------------------------  ---------------
2021-11-24 01:31:59.192695 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 355 finished
---------------------------------------  ---------------
epoch                                       355
replay_buffer/size                       357000
trainer/num train calls                  356000
trainer/QF1 Loss                              6.14152
trainer/QF2 Loss                              5.16455
trainer/Policy Loss                        -388.427
trainer/Q1 Predictions Mean                 389.139
trainer/Q1 Predictions Std                  108.879
trainer/Q1 Predictions Max                  466.241
trainer/Q1 Predictions Min                   19.7512
trainer/Q2 Predictions Mean                 389.277
trainer/Q2 Predictions Std                  108.938
trainer/Q2 Predictions Max                  465.538
trainer/Q2 Predictions Min                   18.2842
trainer/Q Targets Mean                      389.659
trainer/Q Targets Std                       108.952
trainer/Q Targets Max                       466.114
trainer/Q Targets Min                        20.1698
trainer/Log Pis Mean                          5.8151
trainer/Log Pis Std                           4.34902
trainer/Log Pis Max                          17.3412
trainer/Log Pis Min                          -5.76387
trainer/policy/mean Mean                      0.100788
trainer/policy/mean Std                       0.761795
trainer/policy/mean Max                       0.99981
trainer/policy/mean Min                      -0.998932
trainer/policy/normal/std Mean                0.44406
trainer/policy/normal/std Std                 0.144906
trainer/policy/normal/std Max                 0.936893
trainer/policy/normal/std Min                 0.0644605
trainer/policy/normal/log_std Mean           -0.881457
trainer/policy/normal/log_std Std             0.408904
trainer/policy/normal/log_std Max            -0.0651866
trainer/policy/normal/log_std Min            -2.7417
trainer/Alpha                                 0.143645
trainer/Alpha Loss                           -0.358788
expl/num steps total                     357000
expl/num paths total                        357
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.79698
expl/Rewards Std                              1.23672
expl/Rewards Max                              8.25281
expl/Rewards Min                             -0.731141
expl/Returns Mean                          5796.98
expl/Returns Std                              0
expl/Returns Max                           5796.98
expl/Returns Min                           5796.98
expl/Actions Mean                             0.112546
expl/Actions Std                              0.798211
expl/Actions Max                              0.999407
expl/Actions Min                             -0.999395
expl/Num Paths                                1
expl/Average Returns                       5796.98
expl/env_infos/final/reward_run Mean          7.57025
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.57025
expl/env_infos/final/reward_run Min           7.57025
expl/env_infos/initial/reward_run Mean       -0.527553
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.527553
expl/env_infos/initial/reward_run Min        -0.527553
expl/env_infos/reward_run Mean                6.18687
expl/env_infos/reward_run Std                 1.22964
expl/env_infos/reward_run Max                 8.75387
expl/env_infos/reward_run Min                -0.527553
expl/env_infos/final/reward_ctrl Mean        -0.2705
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.2705
expl/env_infos/final/reward_ctrl Min         -0.2705
expl/env_infos/initial/reward_ctrl Mean      -0.203588
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.203588
expl/env_infos/initial/reward_ctrl Min       -0.203588
expl/env_infos/reward_ctrl Mean              -0.389885
expl/env_infos/reward_ctrl Std                0.0887189
expl/env_infos/reward_ctrl Max               -0.101058
expl/env_infos/reward_ctrl Min               -0.577569
eval/num steps total                          1.78e+06
eval/num paths total                       1780
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.11808
eval/Rewards Std                              1.31442
eval/Rewards Max                              8.65086
eval/Rewards Min                             -0.517428
eval/Returns Mean                          6118.08
eval/Returns Std                             71.2705
eval/Returns Max                           6186.94
eval/Returns Min                           5987.38
eval/Actions Mean                             0.0998248
eval/Actions Std                              0.814395
eval/Actions Max                              0.996688
eval/Actions Min                             -0.99704
eval/Num Paths                                5
eval/Average Returns                       6118.08
eval/env_infos/final/reward_run Mean          6.89672
eval/env_infos/final/reward_run Std           0.950316
eval/env_infos/final/reward_run Max           8.08931
eval/env_infos/final/reward_run Min           5.76811
eval/env_infos/initial/reward_run Mean       -0.115737
eval/env_infos/initial/reward_run Std         0.186494
eval/env_infos/initial/reward_run Max         0.136635
eval/env_infos/initial/reward_run Min        -0.373032
eval/env_infos/reward_run Mean                6.52201
eval/env_infos/reward_run Std                 1.31057
eval/env_infos/reward_run Max                 9.16834
eval/env_infos/reward_run Min                -0.373032
eval/env_infos/final/reward_ctrl Mean        -0.45392
eval/env_infos/final/reward_ctrl Std          0.0404792
eval/env_infos/final/reward_ctrl Max         -0.399527
eval/env_infos/final/reward_ctrl Min         -0.51195
eval/env_infos/initial/reward_ctrl Mean      -0.186105
eval/env_infos/initial/reward_ctrl Std        0.0279831
eval/env_infos/initial/reward_ctrl Max       -0.144396
eval/env_infos/initial/reward_ctrl Min       -0.219049
eval/env_infos/reward_ctrl Mean              -0.403922
eval/env_infos/reward_ctrl Std                0.0871174
eval/env_infos/reward_ctrl Max               -0.0899406
eval/env_infos/reward_ctrl Min               -0.579677
time/data storing (s)                         0.00454509
time/evaluation sampling (s)                  2.01322
time/exploration sampling (s)                 0.531659
time/logging (s)                              0.013637
time/sac training (s)                         7.41019
time/saving (s)                               0.00375641
time/training (s)                             3.3132e-05
time/epoch (s)                                9.97704
time/total (s)                             3763.88
Epoch                                       355
---------------------------------------  ---------------
2021-11-24 01:32:09.445818 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 356 finished
---------------------------------------  ---------------
epoch                                       356
replay_buffer/size                       358000
trainer/num train calls                  357000
trainer/QF1 Loss                              5.05082
trainer/QF2 Loss                              5.14424
trainer/Policy Loss                        -392.01
trainer/Q1 Predictions Mean                 392.645
trainer/Q1 Predictions Std                  103.316
trainer/Q1 Predictions Max                  467.34
trainer/Q1 Predictions Min                   19.4535
trainer/Q2 Predictions Mean                 392.327
trainer/Q2 Predictions Std                  103.193
trainer/Q2 Predictions Max                  468.006
trainer/Q2 Predictions Min                   19.8004
trainer/Q Targets Mean                      391.935
trainer/Q Targets Std                       103.261
trainer/Q Targets Max                       469.816
trainer/Q Targets Min                        18.0709
trainer/Log Pis Mean                          6.43154
trainer/Log Pis Std                           4.53935
trainer/Log Pis Max                          17.0901
trainer/Log Pis Min                          -6.33971
trainer/policy/mean Mean                      0.0697905
trainer/policy/mean Std                       0.791376
trainer/policy/mean Max                       0.996245
trainer/policy/mean Min                      -0.994647
trainer/policy/normal/std Mean                0.445234
trainer/policy/normal/std Std                 0.148036
trainer/policy/normal/std Max                 1.0992
trainer/policy/normal/std Min                 0.0724842
trainer/policy/normal/log_std Mean           -0.883765
trainer/policy/normal/log_std Std             0.429887
trainer/policy/normal/log_std Max             0.0945809
trainer/policy/normal/log_std Min            -2.62439
trainer/Alpha                                 0.144874
trainer/Alpha Loss                            0.833679
expl/num steps total                     358000
expl/num paths total                        358
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.03423
expl/Rewards Std                              1.29709
expl/Rewards Max                              8.54601
expl/Rewards Min                             -0.827798
expl/Returns Mean                          6034.23
expl/Returns Std                              0
expl/Returns Max                           6034.23
expl/Returns Min                           6034.23
expl/Actions Mean                             0.0906639
expl/Actions Std                              0.806754
expl/Actions Max                              0.999307
expl/Actions Min                             -0.999584
expl/Num Paths                                1
expl/Average Returns                       6034.23
expl/env_infos/final/reward_run Mean          6.9466
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.9466
expl/env_infos/final/reward_run Min           6.9466
expl/env_infos/initial/reward_run Mean       -0.5401
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.5401
expl/env_infos/initial/reward_run Min        -0.5401
expl/env_infos/reward_run Mean                6.42967
expl/env_infos/reward_run Std                 1.28987
expl/env_infos/reward_run Max                 9.06436
expl/env_infos/reward_run Min                -0.5401
expl/env_infos/final/reward_ctrl Mean        -0.301899
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.301899
expl/env_infos/final/reward_ctrl Min         -0.301899
expl/env_infos/initial/reward_ctrl Mean      -0.287698
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.287698
expl/env_infos/initial/reward_ctrl Min       -0.287698
expl/env_infos/reward_ctrl Mean              -0.395443
expl/env_infos/reward_ctrl Std                0.0920148
expl/env_infos/reward_ctrl Max               -0.109272
expl/env_infos/reward_ctrl Min               -0.570392
eval/num steps total                          1.785e+06
eval/num paths total                       1785
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.22159
eval/Rewards Std                              1.30458
eval/Rewards Max                              8.66879
eval/Rewards Min                             -0.752606
eval/Returns Mean                          6221.59
eval/Returns Std                             53.5321
eval/Returns Max                           6270.62
eval/Returns Min                           6125.01
eval/Actions Mean                             0.0922233
eval/Actions Std                              0.822934
eval/Actions Max                              0.996898
eval/Actions Min                             -0.995483
eval/Num Paths                                5
eval/Average Returns                       6221.59
eval/env_infos/final/reward_run Mean          7.00373
eval/env_infos/final/reward_run Std           0.857483
eval/env_infos/final/reward_run Max           8.57707
eval/env_infos/final/reward_run Min           6.08646
eval/env_infos/initial/reward_run Mean       -0.0933337
eval/env_infos/initial/reward_run Std         0.305436
eval/env_infos/initial/reward_run Max         0.400987
eval/env_infos/initial/reward_run Min        -0.513697
eval/env_infos/reward_run Mean                6.63303
eval/env_infos/reward_run Std                 1.29537
eval/env_infos/reward_run Max                 9.20155
eval/env_infos/reward_run Min                -0.513697
eval/env_infos/final/reward_ctrl Mean        -0.430678
eval/env_infos/final/reward_ctrl Std          0.106188
eval/env_infos/final/reward_ctrl Max         -0.267631
eval/env_infos/final/reward_ctrl Min         -0.550768
eval/env_infos/initial/reward_ctrl Mean      -0.230961
eval/env_infos/initial/reward_ctrl Std        0.0296571
eval/env_infos/initial/reward_ctrl Max       -0.174078
eval/env_infos/initial/reward_ctrl Min       -0.258266
eval/env_infos/reward_ctrl Mean              -0.411436
eval/env_infos/reward_ctrl Std                0.0913849
eval/env_infos/reward_ctrl Max               -0.0951829
eval/env_infos/reward_ctrl Min               -0.577815
time/data storing (s)                         0.004553
time/evaluation sampling (s)                  2.00832
time/exploration sampling (s)                 0.5302
time/logging (s)                              0.0136571
time/sac training (s)                         7.4007
time/saving (s)                               0.00376757
time/training (s)                             3.4307e-05
time/epoch (s)                                9.96123
time/total (s)                             3774.11
Epoch                                       356
---------------------------------------  ---------------
2021-11-24 01:32:19.719685 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 357 finished
---------------------------------------  ---------------
epoch                                       357
replay_buffer/size                       359000
trainer/num train calls                  358000
trainer/QF1 Loss                              5.85825
trainer/QF2 Loss                              5.46663
trainer/Policy Loss                        -394.562
trainer/Q1 Predictions Mean                 395.375
trainer/Q1 Predictions Std                   96.9155
trainer/Q1 Predictions Max                  467.587
trainer/Q1 Predictions Min                   20.4171
trainer/Q2 Predictions Mean                 395.199
trainer/Q2 Predictions Std                   96.8993
trainer/Q2 Predictions Max                  466.233
trainer/Q2 Predictions Min                   19.5751
trainer/Q Targets Mean                      395.661
trainer/Q Targets Std                        97.0895
trainer/Q Targets Max                       468.747
trainer/Q Targets Min                        20.307
trainer/Log Pis Mean                          6.02452
trainer/Log Pis Std                           4.63973
trainer/Log Pis Max                          16.2932
trainer/Log Pis Min                          -4.08359
trainer/policy/mean Mean                      0.0888774
trainer/policy/mean Std                       0.77554
trainer/policy/mean Max                       0.998803
trainer/policy/mean Min                      -0.995941
trainer/policy/normal/std Mean                0.436976
trainer/policy/normal/std Std                 0.147701
trainer/policy/normal/std Max                 1.12612
trainer/policy/normal/std Min                 0.0654087
trainer/policy/normal/log_std Mean           -0.903219
trainer/policy/normal/log_std Std             0.427879
trainer/policy/normal/log_std Max             0.118776
trainer/policy/normal/log_std Min            -2.7271
trainer/Alpha                                 0.144944
trainer/Alpha Loss                            0.047358
expl/num steps total                     359000
expl/num paths total                        359
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.72665
expl/Rewards Std                              1.26001
expl/Rewards Max                              8.13408
expl/Rewards Min                             -0.44052
expl/Returns Mean                          5726.65
expl/Returns Std                              0
expl/Returns Max                           5726.65
expl/Returns Min                           5726.65
expl/Actions Mean                             0.0912377
expl/Actions Std                              0.800103
expl/Actions Max                              0.99971
expl/Actions Min                             -0.998737
expl/Num Paths                                1
expl/Average Returns                       5726.65
expl/env_infos/final/reward_run Mean          7.19631
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.19631
expl/env_infos/final/reward_run Min           7.19631
expl/env_infos/initial/reward_run Mean       -0.243186
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.243186
expl/env_infos/initial/reward_run Min        -0.243186
expl/env_infos/reward_run Mean                6.11575
expl/env_infos/reward_run Std                 1.25631
expl/env_infos/reward_run Max                 8.66914
expl/env_infos/reward_run Min                -0.243186
expl/env_infos/final/reward_ctrl Mean        -0.466694
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.466694
expl/env_infos/final/reward_ctrl Min         -0.466694
expl/env_infos/initial/reward_ctrl Mean      -0.197335
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.197335
expl/env_infos/initial/reward_ctrl Min       -0.197335
expl/env_infos/reward_ctrl Mean              -0.389093
expl/env_infos/reward_ctrl Std                0.0921834
expl/env_infos/reward_ctrl Max               -0.0620645
expl/env_infos/reward_ctrl Min               -0.5857
eval/num steps total                          1.79e+06
eval/num paths total                       1790
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.16651
eval/Rewards Std                              1.31956
eval/Rewards Max                              8.79306
eval/Rewards Min                             -0.860031
eval/Returns Mean                          6166.51
eval/Returns Std                             57.1251
eval/Returns Max                           6272.13
eval/Returns Min                           6106.71
eval/Actions Mean                             0.0979257
eval/Actions Std                              0.823364
eval/Actions Max                              0.998142
eval/Actions Min                             -0.996079
eval/Num Paths                                5
eval/Average Returns                       6166.51
eval/env_infos/final/reward_run Mean          7.38451
eval/env_infos/final/reward_run Std           0.473608
eval/env_infos/final/reward_run Max           7.74932
eval/env_infos/final/reward_run Min           6.46563
eval/env_infos/initial/reward_run Mean       -0.336511
eval/env_infos/initial/reward_run Std         0.225033
eval/env_infos/initial/reward_run Max         0.0316367
eval/env_infos/initial/reward_run Min        -0.646429
eval/env_infos/reward_run Mean                6.57902
eval/env_infos/reward_run Std                 1.31072
eval/env_infos/reward_run Max                 9.33564
eval/env_infos/reward_run Min                -0.646429
eval/env_infos/final/reward_ctrl Mean        -0.372572
eval/env_infos/final/reward_ctrl Std          0.058709
eval/env_infos/final/reward_ctrl Max         -0.270201
eval/env_infos/final/reward_ctrl Min         -0.430233
eval/env_infos/initial/reward_ctrl Mean      -0.187885
eval/env_infos/initial/reward_ctrl Std        0.0259595
eval/env_infos/initial/reward_ctrl Max       -0.149799
eval/env_infos/initial/reward_ctrl Min       -0.21799
eval/env_infos/reward_ctrl Mean              -0.412511
eval/env_infos/reward_ctrl Std                0.0889876
eval/env_infos/reward_ctrl Max               -0.0938771
eval/env_infos/reward_ctrl Min               -0.574565
time/data storing (s)                         0.00440042
time/evaluation sampling (s)                  2.01335
time/exploration sampling (s)                 0.524742
time/logging (s)                              0.0136277
time/sac training (s)                         7.42066
time/saving (s)                               0.00375886
time/training (s)                             4.0025e-05
time/epoch (s)                                9.98058
time/total (s)                             3784.37
Epoch                                       357
---------------------------------------  ---------------
2021-11-24 01:32:30.024347 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 358 finished
---------------------------------------  ---------------
epoch                                       358
replay_buffer/size                       360000
trainer/num train calls                  359000
trainer/QF1 Loss                              6.24264
trainer/QF2 Loss                              5.1965
trainer/Policy Loss                        -393.108
trainer/Q1 Predictions Mean                 393.887
trainer/Q1 Predictions Std                  101.743
trainer/Q1 Predictions Max                  467.862
trainer/Q1 Predictions Min                   18.5697
trainer/Q2 Predictions Mean                 393.864
trainer/Q2 Predictions Std                  101.647
trainer/Q2 Predictions Max                  467.159
trainer/Q2 Predictions Min                   18.8344
trainer/Q Targets Mean                      393.637
trainer/Q Targets Std                       101.759
trainer/Q Targets Max                       467.104
trainer/Q Targets Min                        16.6837
trainer/Log Pis Mean                          5.69208
trainer/Log Pis Std                           4.5722
trainer/Log Pis Max                          17.1045
trainer/Log Pis Min                          -5.13274
trainer/policy/mean Mean                      0.07423
trainer/policy/mean Std                       0.775306
trainer/policy/mean Max                       0.995131
trainer/policy/mean Min                      -0.997919
trainer/policy/normal/std Mean                0.443732
trainer/policy/normal/std Std                 0.149306
trainer/policy/normal/std Max                 1.38444
trainer/policy/normal/std Min                 0.0661941
trainer/policy/normal/log_std Mean           -0.888077
trainer/policy/normal/log_std Std             0.430047
trainer/policy/normal/log_std Max             0.325294
trainer/policy/normal/log_std Min            -2.71516
trainer/Alpha                                 0.143881
trainer/Alpha Loss                           -0.596982
expl/num steps total                     360000
expl/num paths total                        360
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.89002
expl/Rewards Std                              1.22907
expl/Rewards Max                              8.20513
expl/Rewards Min                             -0.278341
expl/Returns Mean                          5890.02
expl/Returns Std                              0
expl/Returns Max                           5890.02
expl/Returns Min                           5890.02
expl/Actions Mean                             0.0853874
expl/Actions Std                              0.795431
expl/Actions Max                              0.999708
expl/Actions Min                             -0.998912
expl/Num Paths                                1
expl/Average Returns                       5890.02
expl/env_infos/final/reward_run Mean          8.40272
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.40272
expl/env_infos/final/reward_run Min           8.40272
expl/env_infos/initial/reward_run Mean        0.609633
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.609633
expl/env_infos/initial/reward_run Min         0.609633
expl/env_infos/reward_run Mean                6.27402
expl/env_infos/reward_run Std                 1.22479
expl/env_infos/reward_run Max                 8.67618
expl/env_infos/reward_run Min                 0.0749475
expl/env_infos/final/reward_ctrl Mean        -0.471192
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.471192
expl/env_infos/final/reward_ctrl Min         -0.471192
expl/env_infos/initial/reward_ctrl Mean      -0.0757969
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0757969
expl/env_infos/initial/reward_ctrl Min       -0.0757969
expl/env_infos/reward_ctrl Mean              -0.384
expl/env_infos/reward_ctrl Std                0.0895866
expl/env_infos/reward_ctrl Max               -0.0757969
expl/env_infos/reward_ctrl Min               -0.572154
eval/num steps total                          1.795e+06
eval/num paths total                       1795
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.24047
eval/Rewards Std                              1.32963
eval/Rewards Max                              8.82036
eval/Rewards Min                             -0.895457
eval/Returns Mean                          6240.47
eval/Returns Std                             81.7703
eval/Returns Max                           6332.47
eval/Returns Min                           6118.23
eval/Actions Mean                             0.0811063
eval/Actions Std                              0.816004
eval/Actions Max                              0.99548
eval/Actions Min                             -0.995478
eval/Num Paths                                5
eval/Average Returns                       6240.47
eval/env_infos/final/reward_run Mean          6.61958
eval/env_infos/final/reward_run Std           0.584989
eval/env_infos/final/reward_run Max           7.78176
eval/env_infos/final/reward_run Min           6.22575
eval/env_infos/initial/reward_run Mean       -0.319708
eval/env_infos/initial/reward_run Std         0.148368
eval/env_infos/initial/reward_run Max        -0.0728145
eval/env_infos/initial/reward_run Min        -0.477125
eval/env_infos/reward_run Mean                6.64394
eval/env_infos/reward_run Std                 1.32726
eval/env_infos/reward_run Max                 9.33028
eval/env_infos/reward_run Min                -0.477125
eval/env_infos/final/reward_ctrl Mean        -0.40172
eval/env_infos/final/reward_ctrl Std          0.0637451
eval/env_infos/final/reward_ctrl Max         -0.287896
eval/env_infos/final/reward_ctrl Min         -0.484415
eval/env_infos/initial/reward_ctrl Mean      -0.156603
eval/env_infos/initial/reward_ctrl Std        0.0321288
eval/env_infos/initial/reward_ctrl Max       -0.103892
eval/env_infos/initial/reward_ctrl Min       -0.197553
eval/env_infos/reward_ctrl Mean              -0.403464
eval/env_infos/reward_ctrl Std                0.0850261
eval/env_infos/reward_ctrl Max               -0.0967338
eval/env_infos/reward_ctrl Min               -0.584301
time/data storing (s)                         0.00450618
time/evaluation sampling (s)                  2.05944
time/exploration sampling (s)                 0.536372
time/logging (s)                              0.0136568
time/sac training (s)                         7.39231
time/saving (s)                               0.003818
time/training (s)                             3.4324e-05
time/epoch (s)                               10.0101
time/total (s)                             3794.67
Epoch                                       358
---------------------------------------  ---------------
2021-11-24 01:32:40.298456 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 359 finished
---------------------------------------  ---------------
epoch                                       359
replay_buffer/size                       361000
trainer/num train calls                  360000
trainer/QF1 Loss                              5.37867
trainer/QF2 Loss                              5.47332
trainer/Policy Loss                        -399.672
trainer/Q1 Predictions Mean                 400.405
trainer/Q1 Predictions Std                   87.9208
trainer/Q1 Predictions Max                  462.465
trainer/Q1 Predictions Min                   18.9453
trainer/Q2 Predictions Mean                 400.393
trainer/Q2 Predictions Std                   87.7642
trainer/Q2 Predictions Max                  464.678
trainer/Q2 Predictions Min                   20.3968
trainer/Q Targets Mean                      400.024
trainer/Q Targets Std                        87.7201
trainer/Q Targets Max                       464.593
trainer/Q Targets Min                        19.1649
trainer/Log Pis Mean                          6.49604
trainer/Log Pis Std                           4.61981
trainer/Log Pis Max                          19.0329
trainer/Log Pis Min                          -4.14619
trainer/policy/mean Mean                      0.0681481
trainer/policy/mean Std                       0.781593
trainer/policy/mean Max                       0.994387
trainer/policy/mean Min                      -0.996741
trainer/policy/normal/std Mean                0.428426
trainer/policy/normal/std Std                 0.141556
trainer/policy/normal/std Max                 1.00277
trainer/policy/normal/std Min                 0.0717767
trainer/policy/normal/log_std Mean           -0.920073
trainer/policy/normal/log_std Std             0.41945
trainer/policy/normal/log_std Max             0.00276433
trainer/policy/normal/log_std Min            -2.6342
trainer/Alpha                                 0.142493
trainer/Alpha Loss                            0.966511
expl/num steps total                     361000
expl/num paths total                        361
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.92958
expl/Rewards Std                              1.26073
expl/Rewards Max                              8.10303
expl/Rewards Min                             -0.451293
expl/Returns Mean                          5929.58
expl/Returns Std                              0
expl/Returns Max                           5929.58
expl/Returns Min                           5929.58
expl/Actions Mean                             0.0839472
expl/Actions Std                              0.802524
expl/Actions Max                              0.999096
expl/Actions Min                             -0.998563
expl/Num Paths                                1
expl/Average Returns                       5929.58
expl/env_infos/final/reward_run Mean          6.64989
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.64989
expl/env_infos/final/reward_run Min           6.64989
expl/env_infos/initial/reward_run Mean       -0.256843
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.256843
expl/env_infos/initial/reward_run Min        -0.256843
expl/env_infos/reward_run Mean                6.32023
expl/env_infos/reward_run Std                 1.26421
expl/env_infos/reward_run Max                 8.64586
expl/env_infos/reward_run Min                -0.256843
expl/env_infos/final/reward_ctrl Mean        -0.264004
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.264004
expl/env_infos/final/reward_ctrl Min         -0.264004
expl/env_infos/initial/reward_ctrl Mean      -0.19445
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.19445
expl/env_infos/initial/reward_ctrl Min       -0.19445
expl/env_infos/reward_ctrl Mean              -0.390655
expl/env_infos/reward_ctrl Std                0.0945933
expl/env_infos/reward_ctrl Max               -0.0823938
expl/env_infos/reward_ctrl Min               -0.578423
eval/num steps total                          1.8e+06
eval/num paths total                       1800
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.09189
eval/Rewards Std                              1.30932
eval/Rewards Max                              8.71303
eval/Rewards Min                             -0.766534
eval/Returns Mean                          6091.89
eval/Returns Std                             54.2124
eval/Returns Max                           6153.33
eval/Returns Min                           6022.14
eval/Actions Mean                             0.0880471
eval/Actions Std                              0.818274
eval/Actions Max                              0.997192
eval/Actions Min                             -0.994123
eval/Num Paths                                5
eval/Average Returns                       6091.89
eval/env_infos/final/reward_run Mean          6.84927
eval/env_infos/final/reward_run Std           0.81658
eval/env_infos/final/reward_run Max           7.72007
eval/env_infos/final/reward_run Min           5.53928
eval/env_infos/initial/reward_run Mean       -0.175384
eval/env_infos/initial/reward_run Std         0.2854
eval/env_infos/initial/reward_run Max         0.26365
eval/env_infos/initial/reward_run Min        -0.566672
eval/env_infos/reward_run Mean                6.49828
eval/env_infos/reward_run Std                 1.30949
eval/env_infos/reward_run Max                 9.20529
eval/env_infos/reward_run Min                -0.566672
eval/env_infos/final/reward_ctrl Mean        -0.388909
eval/env_infos/final/reward_ctrl Std          0.0663244
eval/env_infos/final/reward_ctrl Max         -0.267964
eval/env_infos/final/reward_ctrl Min         -0.451081
eval/env_infos/initial/reward_ctrl Mean      -0.188604
eval/env_infos/initial/reward_ctrl Std        0.0409548
eval/env_infos/initial/reward_ctrl Max       -0.131067
eval/env_infos/initial/reward_ctrl Min       -0.257055
eval/env_infos/reward_ctrl Mean              -0.406395
eval/env_infos/reward_ctrl Std                0.0947069
eval/env_infos/reward_ctrl Max               -0.0852771
eval/env_infos/reward_ctrl Min               -0.579832
time/data storing (s)                         0.00449808
time/evaluation sampling (s)                  2.01414
time/exploration sampling (s)                 0.533471
time/logging (s)                              0.0136791
time/sac training (s)                         7.41064
time/saving (s)                               0.00377248
time/training (s)                             3.4323e-05
time/epoch (s)                                9.98023
time/total (s)                             3804.93
Epoch                                       359
---------------------------------------  ---------------
2021-11-24 01:32:50.568597 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 360 finished
---------------------------------------  ---------------
epoch                                       360
replay_buffer/size                       362000
trainer/num train calls                  361000
trainer/QF1 Loss                              5.99987
trainer/QF2 Loss                              6.92901
trainer/Policy Loss                        -396.42
trainer/Q1 Predictions Mean                 396.982
trainer/Q1 Predictions Std                   88.361
trainer/Q1 Predictions Max                  468.825
trainer/Q1 Predictions Min                   19.7847
trainer/Q2 Predictions Mean                 396.742
trainer/Q2 Predictions Std                   88.3324
trainer/Q2 Predictions Max                  466.471
trainer/Q2 Predictions Min                   19.5581
trainer/Q Targets Mean                      396.194
trainer/Q Targets Std                        88.2741
trainer/Q Targets Max                       467.486
trainer/Q Targets Min                        19.2545
trainer/Log Pis Mean                          6.53032
trainer/Log Pis Std                           4.3366
trainer/Log Pis Max                          18.1081
trainer/Log Pis Min                          -4.9927
trainer/policy/mean Mean                      0.0705251
trainer/policy/mean Std                       0.786842
trainer/policy/mean Max                       0.999369
trainer/policy/mean Min                      -0.998683
trainer/policy/normal/std Mean                0.439539
trainer/policy/normal/std Std                 0.1393
trainer/policy/normal/std Max                 1.08592
trainer/policy/normal/std Min                 0.0671577
trainer/policy/normal/log_std Mean           -0.888399
trainer/policy/normal/log_std Std             0.401232
trainer/policy/normal/log_std Max             0.0824248
trainer/policy/normal/log_std Min            -2.70071
trainer/Alpha                                 0.145416
trainer/Alpha Loss                            1.02254
expl/num steps total                     362000
expl/num paths total                        362
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.90321
expl/Rewards Std                              1.28206
expl/Rewards Max                              8.38225
expl/Rewards Min                             -0.760597
expl/Returns Mean                          5903.21
expl/Returns Std                              0
expl/Returns Max                           5903.21
expl/Returns Min                           5903.21
expl/Actions Mean                             0.0914853
expl/Actions Std                              0.795796
expl/Actions Max                              0.999622
expl/Actions Min                             -0.999285
expl/Num Paths                                1
expl/Average Returns                       5903.21
expl/env_infos/final/reward_run Mean          6.80536
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.80536
expl/env_infos/final/reward_run Min           6.80536
expl/env_infos/initial/reward_run Mean       -0.576051
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.576051
expl/env_infos/initial/reward_run Min        -0.576051
expl/env_infos/reward_run Mean                6.28821
expl/env_infos/reward_run Std                 1.27837
expl/env_infos/reward_run Max                 8.84649
expl/env_infos/reward_run Min                -0.576051
expl/env_infos/final/reward_ctrl Mean        -0.396775
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.396775
expl/env_infos/final/reward_ctrl Min         -0.396775
expl/env_infos/initial/reward_ctrl Mean      -0.184546
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.184546
expl/env_infos/initial/reward_ctrl Min       -0.184546
expl/env_infos/reward_ctrl Mean              -0.384996
expl/env_infos/reward_ctrl Std                0.0938541
expl/env_infos/reward_ctrl Max               -0.0796563
expl/env_infos/reward_ctrl Min               -0.585796
eval/num steps total                          1.805e+06
eval/num paths total                       1805
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.12514
eval/Rewards Std                              1.28219
eval/Rewards Max                              8.59905
eval/Rewards Min                             -0.607465
eval/Returns Mean                          6125.14
eval/Returns Std                             41.4634
eval/Returns Max                           6203.75
eval/Returns Min                           6086.79
eval/Actions Mean                             0.0921596
eval/Actions Std                              0.813611
eval/Actions Max                              0.995736
eval/Actions Min                             -0.99661
eval/Num Paths                                5
eval/Average Returns                       6125.14
eval/env_infos/final/reward_run Mean          6.52737
eval/env_infos/final/reward_run Std           1.02491
eval/env_infos/final/reward_run Max           8.18083
eval/env_infos/final/reward_run Min           5.23035
eval/env_infos/initial/reward_run Mean       -0.283386
eval/env_infos/initial/reward_run Std         0.122853
eval/env_infos/initial/reward_run Max        -0.0915406
eval/env_infos/initial/reward_run Min        -0.433987
eval/env_infos/reward_run Mean                6.52741
eval/env_infos/reward_run Std                 1.27616
eval/env_infos/reward_run Max                 9.12376
eval/env_infos/reward_run Min                -0.433987
eval/env_infos/final/reward_ctrl Mean        -0.410617
eval/env_infos/final/reward_ctrl Std          0.0204115
eval/env_infos/final/reward_ctrl Max         -0.376044
eval/env_infos/final/reward_ctrl Min         -0.432323
eval/env_infos/initial/reward_ctrl Mean      -0.19189
eval/env_infos/initial/reward_ctrl Std        0.019227
eval/env_infos/initial/reward_ctrl Max       -0.173479
eval/env_infos/initial/reward_ctrl Min       -0.222394
eval/env_infos/reward_ctrl Mean              -0.402274
eval/env_infos/reward_ctrl Std                0.0923494
eval/env_infos/reward_ctrl Max               -0.0865333
eval/env_infos/reward_ctrl Min               -0.582426
time/data storing (s)                         0.00454471
time/evaluation sampling (s)                  2.01351
time/exploration sampling (s)                 0.534421
time/logging (s)                              0.0136738
time/sac training (s)                         7.4056
time/saving (s)                               0.00378401
time/training (s)                             3.3598e-05
time/epoch (s)                                9.97557
time/total (s)                             3815.18
Epoch                                       360
---------------------------------------  ---------------
2021-11-24 01:33:00.876640 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 361 finished
---------------------------------------  ---------------
epoch                                       361
replay_buffer/size                       363000
trainer/num train calls                  362000
trainer/QF1 Loss                              7.4149
trainer/QF2 Loss                              6.63
trainer/Policy Loss                        -392.723
trainer/Q1 Predictions Mean                 393.033
trainer/Q1 Predictions Std                   99.6422
trainer/Q1 Predictions Max                  463.623
trainer/Q1 Predictions Min                   20.4747
trainer/Q2 Predictions Mean                 393.317
trainer/Q2 Predictions Std                   99.7861
trainer/Q2 Predictions Max                  464.227
trainer/Q2 Predictions Min                   20.1308
trainer/Q Targets Mean                      393.262
trainer/Q Targets Std                        99.7893
trainer/Q Targets Max                       464.113
trainer/Q Targets Min                        19.2239
trainer/Log Pis Mean                          5.92363
trainer/Log Pis Std                           4.40619
trainer/Log Pis Max                          16.757
trainer/Log Pis Min                          -5.8187
trainer/policy/mean Mean                      0.063558
trainer/policy/mean Std                       0.778217
trainer/policy/mean Max                       0.996249
trainer/policy/mean Min                      -0.999137
trainer/policy/normal/std Mean                0.447026
trainer/policy/normal/std Std                 0.149139
trainer/policy/normal/std Max                 1.22445
trainer/policy/normal/std Min                 0.0717286
trainer/policy/normal/log_std Mean           -0.879762
trainer/policy/normal/log_std Std             0.427868
trainer/policy/normal/log_std Max             0.20249
trainer/policy/normal/log_std Min            -2.63487
trainer/Alpha                                 0.143218
trainer/Alpha Loss                           -0.148425
expl/num steps total                     363000
expl/num paths total                        363
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.67553
expl/Rewards Std                              1.19404
expl/Rewards Max                              8.06699
expl/Rewards Min                             -0.686887
expl/Returns Mean                          5675.53
expl/Returns Std                              0
expl/Returns Max                           5675.53
expl/Returns Min                           5675.53
expl/Actions Mean                             0.104111
expl/Actions Std                              0.792309
expl/Actions Max                              0.999792
expl/Actions Min                             -0.999569
expl/Num Paths                                1
expl/Average Returns                       5675.53
expl/env_infos/final/reward_run Mean          6.40091
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.40091
expl/env_infos/final/reward_run Min           6.40091
expl/env_infos/initial/reward_run Mean        0.853769
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.853769
expl/env_infos/initial/reward_run Min         0.853769
expl/env_infos/reward_run Mean                6.05868
expl/env_infos/reward_run Std                 1.18875
expl/env_infos/reward_run Max                 8.54114
expl/env_infos/reward_run Min                -0.258458
expl/env_infos/final/reward_ctrl Mean        -0.340409
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.340409
expl/env_infos/final/reward_ctrl Min         -0.340409
expl/env_infos/initial/reward_ctrl Mean      -0.228883
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.228883
expl/env_infos/initial/reward_ctrl Min       -0.228883
expl/env_infos/reward_ctrl Mean              -0.383156
expl/env_infos/reward_ctrl Std                0.0915994
expl/env_infos/reward_ctrl Max               -0.08536
expl/env_infos/reward_ctrl Min               -0.580147
eval/num steps total                          1.81e+06
eval/num paths total                       1810
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.09563
eval/Rewards Std                              1.2886
eval/Rewards Max                              8.67111
eval/Rewards Min                             -0.816358
eval/Returns Mean                          6095.63
eval/Returns Std                             80.6764
eval/Returns Max                           6186.2
eval/Returns Min                           5963.19
eval/Actions Mean                             0.0981617
eval/Actions Std                              0.812992
eval/Actions Max                              0.996532
eval/Actions Min                             -0.99782
eval/Num Paths                                5
eval/Average Returns                       6095.63
eval/env_infos/final/reward_run Mean          6.58136
eval/env_infos/final/reward_run Std           0.693458
eval/env_infos/final/reward_run Max           7.82756
eval/env_infos/final/reward_run Min           5.89974
eval/env_infos/initial/reward_run Mean       -0.0630037
eval/env_infos/initial/reward_run Std         0.353072
eval/env_infos/initial/reward_run Max         0.355933
eval/env_infos/initial/reward_run Min        -0.593478
eval/env_infos/reward_run Mean                6.49798
eval/env_infos/reward_run Std                 1.2861
eval/env_infos/reward_run Max                 9.20353
eval/env_infos/reward_run Min                -0.593478
eval/env_infos/final/reward_ctrl Mean        -0.377006
eval/env_infos/final/reward_ctrl Std          0.0467854
eval/env_infos/final/reward_ctrl Max         -0.296322
eval/env_infos/final/reward_ctrl Min         -0.430913
eval/env_infos/initial/reward_ctrl Mean      -0.173986
eval/env_infos/initial/reward_ctrl Std        0.0501358
eval/env_infos/initial/reward_ctrl Max       -0.0974336
eval/env_infos/initial/reward_ctrl Min       -0.22288
eval/env_infos/reward_ctrl Mean              -0.402355
eval/env_infos/reward_ctrl Std                0.0889277
eval/env_infos/reward_ctrl Max               -0.0974336
eval/env_infos/reward_ctrl Min               -0.575602
time/data storing (s)                         0.00448946
time/evaluation sampling (s)                  2.01017
time/exploration sampling (s)                 0.533786
time/logging (s)                              0.0136549
time/sac training (s)                         7.44693
time/saving (s)                               0.00379025
time/training (s)                             3.4713e-05
time/epoch (s)                               10.0128
time/total (s)                             3825.48
Epoch                                       361
---------------------------------------  ---------------
2021-11-24 01:33:11.172910 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 362 finished
---------------------------------------  ---------------
epoch                                       362
replay_buffer/size                       364000
trainer/num train calls                  363000
trainer/QF1 Loss                              6.94813
trainer/QF2 Loss                              6.07164
trainer/Policy Loss                        -398.266
trainer/Q1 Predictions Mean                 399.019
trainer/Q1 Predictions Std                   88.692
trainer/Q1 Predictions Max                  471.388
trainer/Q1 Predictions Min                   21.033
trainer/Q2 Predictions Mean                 398.416
trainer/Q2 Predictions Std                   88.7406
trainer/Q2 Predictions Max                  470.819
trainer/Q2 Predictions Min                   21.0304
trainer/Q Targets Mean                      398.191
trainer/Q Targets Std                        88.5805
trainer/Q Targets Max                       472.609
trainer/Q Targets Min                        21.8932
trainer/Log Pis Mean                          5.87004
trainer/Log Pis Std                           4.29941
trainer/Log Pis Max                          17.5096
trainer/Log Pis Min                          -5.58129
trainer/policy/mean Mean                      0.104688
trainer/policy/mean Std                       0.765519
trainer/policy/mean Max                       0.996873
trainer/policy/mean Min                      -0.999562
trainer/policy/normal/std Mean                0.43412
trainer/policy/normal/std Std                 0.144499
trainer/policy/normal/std Max                 1.12143
trainer/policy/normal/std Min                 0.0607022
trainer/policy/normal/log_std Mean           -0.910369
trainer/policy/normal/log_std Std             0.432865
trainer/policy/normal/log_std Max             0.114601
trainer/policy/normal/log_std Min            -2.80177
trainer/Alpha                                 0.144439
trainer/Alpha Loss                           -0.251467
expl/num steps total                     364000
expl/num paths total                        364
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.94937
expl/Rewards Std                              1.26482
expl/Rewards Max                              8.30498
expl/Rewards Min                             -0.605467
expl/Returns Mean                          5949.37
expl/Returns Std                              0
expl/Returns Max                           5949.37
expl/Returns Min                           5949.37
expl/Actions Mean                             0.106835
expl/Actions Std                              0.802545
expl/Actions Max                              0.999803
expl/Actions Min                             -0.999794
expl/Num Paths                                1
expl/Average Returns                       5949.37
expl/env_infos/final/reward_run Mean          5.5038
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.5038
expl/env_infos/final/reward_run Min           5.5038
expl/env_infos/initial/reward_run Mean       -0.314084
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.314084
expl/env_infos/initial/reward_run Min        -0.314084
expl/env_infos/reward_run Mean                6.34266
expl/env_infos/reward_run Std                 1.25776
expl/env_infos/reward_run Max                 8.70631
expl/env_infos/reward_run Min                -0.314084
expl/env_infos/final/reward_ctrl Mean        -0.341106
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.341106
expl/env_infos/final/reward_ctrl Min         -0.341106
expl/env_infos/initial/reward_ctrl Mean      -0.291383
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.291383
expl/env_infos/initial/reward_ctrl Min       -0.291383
expl/env_infos/reward_ctrl Mean              -0.393296
expl/env_infos/reward_ctrl Std                0.0931435
expl/env_infos/reward_ctrl Max               -0.0869478
expl/env_infos/reward_ctrl Min               -0.57742
eval/num steps total                          1.815e+06
eval/num paths total                       1815
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.24958
eval/Rewards Std                              1.33766
eval/Rewards Max                              8.91484
eval/Rewards Min                             -0.729932
eval/Returns Mean                          6249.58
eval/Returns Std                             53.0326
eval/Returns Max                           6319.74
eval/Returns Min                           6181.5
eval/Actions Mean                             0.10249
eval/Actions Std                              0.821557
eval/Actions Max                              0.997807
eval/Actions Min                             -0.997468
eval/Num Paths                                5
eval/Average Returns                       6249.58
eval/env_infos/final/reward_run Mean          6.85996
eval/env_infos/final/reward_run Std           0.944041
eval/env_infos/final/reward_run Max           7.9502
eval/env_infos/final/reward_run Min           5.107
eval/env_infos/initial/reward_run Mean       -0.258115
eval/env_infos/initial/reward_run Std         0.258978
eval/env_infos/initial/reward_run Max         0.188639
eval/env_infos/initial/reward_run Min        -0.544309
eval/env_infos/reward_run Mean                6.66086
eval/env_infos/reward_run Std                 1.33083
eval/env_infos/reward_run Max                 9.43284
eval/env_infos/reward_run Min                -0.544309
eval/env_infos/final/reward_ctrl Mean        -0.402844
eval/env_infos/final/reward_ctrl Std          0.132773
eval/env_infos/final/reward_ctrl Max         -0.182252
eval/env_infos/final/reward_ctrl Min         -0.54727
eval/env_infos/initial/reward_ctrl Mean      -0.160293
eval/env_infos/initial/reward_ctrl Std        0.0396331
eval/env_infos/initial/reward_ctrl Max       -0.0834339
eval/env_infos/initial/reward_ctrl Min       -0.195537
eval/env_infos/reward_ctrl Mean              -0.411276
eval/env_infos/reward_ctrl Std                0.0903989
eval/env_infos/reward_ctrl Max               -0.0834339
eval/env_infos/reward_ctrl Min               -0.57886
time/data storing (s)                         0.00451362
time/evaluation sampling (s)                  2.0104
time/exploration sampling (s)                 0.533469
time/logging (s)                              0.0136596
time/sac training (s)                         7.43544
time/saving (s)                               0.00377975
time/training (s)                             3.4446e-05
time/epoch (s)                               10.0013
time/total (s)                             3835.76
Epoch                                       362
---------------------------------------  ---------------
2021-11-24 01:33:21.478927 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 363 finished
---------------------------------------  ---------------
epoch                                       363
replay_buffer/size                       365000
trainer/num train calls                  364000
trainer/QF1 Loss                              6.57814
trainer/QF2 Loss                              5.35428
trainer/Policy Loss                        -394.494
trainer/Q1 Predictions Mean                 394.911
trainer/Q1 Predictions Std                   96.7563
trainer/Q1 Predictions Max                  460.947
trainer/Q1 Predictions Min                   19.7892
trainer/Q2 Predictions Mean                 395.495
trainer/Q2 Predictions Std                   96.6832
trainer/Q2 Predictions Max                  461.569
trainer/Q2 Predictions Min                   20.768
trainer/Q Targets Mean                      395.818
trainer/Q Targets Std                        96.7203
trainer/Q Targets Max                       463.06
trainer/Q Targets Min                        19.5447
trainer/Log Pis Mean                          5.9976
trainer/Log Pis Std                           4.37767
trainer/Log Pis Max                          15.2541
trainer/Log Pis Min                          -5.65327
trainer/policy/mean Mean                      0.0773984
trainer/policy/mean Std                       0.779479
trainer/policy/mean Max                       0.998379
trainer/policy/mean Min                      -0.994197
trainer/policy/normal/std Mean                0.441795
trainer/policy/normal/std Std                 0.144787
trainer/policy/normal/std Max                 0.964124
trainer/policy/normal/std Min                 0.0683036
trainer/policy/normal/log_std Mean           -0.889658
trainer/policy/normal/log_std Std             0.422658
trainer/policy/normal/log_std Max            -0.0365353
trainer/policy/normal/log_std Min            -2.68379
trainer/Alpha                                 0.142347
trainer/Alpha Loss                           -0.00468644
expl/num steps total                     365000
expl/num paths total                        365
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.73144
expl/Rewards Std                              1.24617
expl/Rewards Max                              7.87324
expl/Rewards Min                             -0.794558
expl/Returns Mean                          5731.44
expl/Returns Std                              0
expl/Returns Max                           5731.44
expl/Returns Min                           5731.44
expl/Actions Mean                             0.0830254
expl/Actions Std                              0.792514
expl/Actions Max                              0.999214
expl/Actions Min                             -0.999549
expl/Num Paths                                1
expl/Average Returns                       5731.44
expl/env_infos/final/reward_run Mean          6.39742
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.39742
expl/env_infos/final/reward_run Min           6.39742
expl/env_infos/initial/reward_run Mean       -0.554527
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.554527
expl/env_infos/initial/reward_run Min        -0.554527
expl/env_infos/reward_run Mean                6.11242
expl/env_infos/reward_run Std                 1.23968
expl/env_infos/reward_run Max                 8.38461
expl/env_infos/reward_run Min                -0.554527
expl/env_infos/final/reward_ctrl Mean        -0.316116
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.316116
expl/env_infos/final/reward_ctrl Min         -0.316116
expl/env_infos/initial/reward_ctrl Mean      -0.240031
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.240031
expl/env_infos/initial/reward_ctrl Min       -0.240031
expl/env_infos/reward_ctrl Mean              -0.380983
expl/env_infos/reward_ctrl Std                0.0952884
expl/env_infos/reward_ctrl Max               -0.11335
expl/env_infos/reward_ctrl Min               -0.580608
eval/num steps total                          1.82e+06
eval/num paths total                       1820
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.05593
eval/Rewards Std                              1.31219
eval/Rewards Max                              8.62753
eval/Rewards Min                             -1.13075
eval/Returns Mean                          6055.93
eval/Returns Std                             67.0696
eval/Returns Max                           6156.28
eval/Returns Min                           5986.06
eval/Actions Mean                             0.0829259
eval/Actions Std                              0.812296
eval/Actions Max                              0.999437
eval/Actions Min                             -0.998253
eval/Num Paths                                5
eval/Average Returns                       6055.93
eval/env_infos/final/reward_run Mean          7.12342
eval/env_infos/final/reward_run Std           1.11136
eval/env_infos/final/reward_run Max           8.04759
eval/env_infos/final/reward_run Min           4.98796
eval/env_infos/initial/reward_run Mean       -0.336954
eval/env_infos/initial/reward_run Std         0.29491
eval/env_infos/initial/reward_run Max         0.0017663
eval/env_infos/initial/reward_run Min        -0.836118
eval/env_infos/reward_run Mean                6.45596
eval/env_infos/reward_run Std                 1.30815
eval/env_infos/reward_run Max                 9.12176
eval/env_infos/reward_run Min                -0.836118
eval/env_infos/final/reward_ctrl Mean        -0.393977
eval/env_infos/final/reward_ctrl Std          0.0803692
eval/env_infos/final/reward_ctrl Max         -0.28352
eval/env_infos/final/reward_ctrl Min         -0.491002
eval/env_infos/initial/reward_ctrl Mean      -0.206558
eval/env_infos/initial/reward_ctrl Std        0.0555421
eval/env_infos/initial/reward_ctrl Max       -0.127228
eval/env_infos/initial/reward_ctrl Min       -0.294636
eval/env_infos/reward_ctrl Mean              -0.400021
eval/env_infos/reward_ctrl Std                0.0944186
eval/env_infos/reward_ctrl Max               -0.0572213
eval/env_infos/reward_ctrl Min               -0.58039
time/data storing (s)                         0.0045247
time/evaluation sampling (s)                  2.02037
time/exploration sampling (s)                 0.531975
time/logging (s)                              0.0136688
time/sac training (s)                         7.43605
time/saving (s)                               0.00377643
time/training (s)                             3.4472e-05
time/epoch (s)                               10.0104
time/total (s)                             3846.05
Epoch                                       363
---------------------------------------  ---------------
2021-11-24 01:33:31.787966 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 364 finished
---------------------------------------  ---------------
epoch                                       364
replay_buffer/size                       366000
trainer/num train calls                  365000
trainer/QF1 Loss                              8.30772
trainer/QF2 Loss                              6.5995
trainer/Policy Loss                        -393.041
trainer/Q1 Predictions Mean                 393.577
trainer/Q1 Predictions Std                   99.8345
trainer/Q1 Predictions Max                  464.095
trainer/Q1 Predictions Min                   20.079
trainer/Q2 Predictions Mean                 393.698
trainer/Q2 Predictions Std                  100.077
trainer/Q2 Predictions Max                  463.106
trainer/Q2 Predictions Min                   17.8989
trainer/Q Targets Mean                      394.266
trainer/Q Targets Std                       100.171
trainer/Q Targets Max                       466.266
trainer/Q Targets Min                        18.6322
trainer/Log Pis Mean                          6.05479
trainer/Log Pis Std                           4.28305
trainer/Log Pis Max                          15.2848
trainer/Log Pis Min                          -5.47621
trainer/policy/mean Mean                      0.0927272
trainer/policy/mean Std                       0.775192
trainer/policy/mean Max                       0.996202
trainer/policy/mean Min                      -0.997932
trainer/policy/normal/std Mean                0.44878
trainer/policy/normal/std Std                 0.150036
trainer/policy/normal/std Max                 1.7434
trainer/policy/normal/std Min                 0.0707688
trainer/policy/normal/log_std Mean           -0.872045
trainer/policy/normal/log_std Std             0.410648
trainer/policy/normal/log_std Max             0.555839
trainer/policy/normal/log_std Min            -2.64834
trainer/Alpha                                 0.144898
trainer/Alpha Loss                            0.105848
expl/num steps total                     366000
expl/num paths total                        366
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.73406
expl/Rewards Std                              1.27253
expl/Rewards Max                              8.20519
expl/Rewards Min                             -0.416104
expl/Returns Mean                          5734.06
expl/Returns Std                              0
expl/Returns Max                           5734.06
expl/Returns Min                           5734.06
expl/Actions Mean                             0.0928385
expl/Actions Std                              0.797798
expl/Actions Max                              0.999526
expl/Actions Min                             -0.999979
expl/Num Paths                                1
expl/Average Returns                       5734.06
expl/env_infos/final/reward_run Mean          4.88017
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.88017
expl/env_infos/final/reward_run Min           4.88017
expl/env_infos/initial/reward_run Mean       -0.226556
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.226556
expl/env_infos/initial/reward_run Min        -0.226556
expl/env_infos/reward_run Mean                6.12112
expl/env_infos/reward_run Std                 1.268
expl/env_infos/reward_run Max                 8.68913
expl/env_infos/reward_run Min                -0.226556
expl/env_infos/final/reward_ctrl Mean        -0.393649
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.393649
expl/env_infos/final/reward_ctrl Min         -0.393649
expl/env_infos/initial/reward_ctrl Mean      -0.189547
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.189547
expl/env_infos/initial/reward_ctrl Min       -0.189547
expl/env_infos/reward_ctrl Mean              -0.387061
expl/env_infos/reward_ctrl Std                0.0923604
expl/env_infos/reward_ctrl Max               -0.0926098
expl/env_infos/reward_ctrl Min               -0.566568
eval/num steps total                          1.825e+06
eval/num paths total                       1825
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.17548
eval/Rewards Std                              1.31649
eval/Rewards Max                              8.71422
eval/Rewards Min                             -0.831475
eval/Returns Mean                          6175.48
eval/Returns Std                             92.0505
eval/Returns Max                           6280
eval/Returns Min                           6014.46
eval/Actions Mean                             0.0956938
eval/Actions Std                              0.821756
eval/Actions Max                              0.997805
eval/Actions Min                             -0.998055
eval/Num Paths                                5
eval/Average Returns                       6175.48
eval/env_infos/final/reward_run Mean          8.22368
eval/env_infos/final/reward_run Std           0.41922
eval/env_infos/final/reward_run Max           8.93745
eval/env_infos/final/reward_run Min           7.62296
eval/env_infos/initial/reward_run Mean       -0.27141
eval/env_infos/initial/reward_run Std         0.205876
eval/env_infos/initial/reward_run Max        -0.0302372
eval/env_infos/initial/reward_run Min        -0.599405
eval/env_infos/reward_run Mean                6.58614
eval/env_infos/reward_run Std                 1.30893
eval/env_infos/reward_run Max                 9.2282
eval/env_infos/reward_run Min                -0.599405
eval/env_infos/final/reward_ctrl Mean        -0.401734
eval/env_infos/final/reward_ctrl Std          0.0544498
eval/env_infos/final/reward_ctrl Max         -0.36057
eval/env_infos/final/reward_ctrl Min         -0.507438
eval/env_infos/initial/reward_ctrl Mean      -0.223911
eval/env_infos/initial/reward_ctrl Std        0.0217649
eval/env_infos/initial/reward_ctrl Max       -0.188113
eval/env_infos/initial/reward_ctrl Min       -0.253677
eval/env_infos/reward_ctrl Mean              -0.410664
eval/env_infos/reward_ctrl Std                0.0870464
eval/env_infos/reward_ctrl Max               -0.105673
eval/env_infos/reward_ctrl Min               -0.568956
time/data storing (s)                         0.00448519
time/evaluation sampling (s)                  2.01877
time/exploration sampling (s)                 0.532827
time/logging (s)                              0.0136474
time/sac training (s)                         7.44051
time/saving (s)                               0.00378612
time/training (s)                             3.4776e-05
time/epoch (s)                               10.0141
time/total (s)                             3856.34
Epoch                                       364
---------------------------------------  ---------------
2021-11-24 01:33:42.052993 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 365 finished
---------------------------------------  ---------------
epoch                                       365
replay_buffer/size                       367000
trainer/num train calls                  366000
trainer/QF1 Loss                              5.38746
trainer/QF2 Loss                              4.81395
trainer/Policy Loss                        -387.08
trainer/Q1 Predictions Mean                 387.667
trainer/Q1 Predictions Std                   99.9757
trainer/Q1 Predictions Max                  465.635
trainer/Q1 Predictions Min                   20.0207
trainer/Q2 Predictions Mean                 387.317
trainer/Q2 Predictions Std                  100.011
trainer/Q2 Predictions Max                  465.744
trainer/Q2 Predictions Min                   18.8795
trainer/Q Targets Mean                      387.234
trainer/Q Targets Std                       100.116
trainer/Q Targets Max                       464.73
trainer/Q Targets Min                        18.3348
trainer/Log Pis Mean                          6.42395
trainer/Log Pis Std                           4.40705
trainer/Log Pis Max                          16.0188
trainer/Log Pis Min                          -4.96857
trainer/policy/mean Mean                      0.0616968
trainer/policy/mean Std                       0.791265
trainer/policy/mean Max                       0.999104
trainer/policy/mean Min                      -0.997514
trainer/policy/normal/std Mean                0.44979
trainer/policy/normal/std Std                 0.144712
trainer/policy/normal/std Max                 1.0241
trainer/policy/normal/std Min                 0.0702207
trainer/policy/normal/log_std Mean           -0.867015
trainer/policy/normal/log_std Std             0.405553
trainer/policy/normal/log_std Max             0.0238133
trainer/policy/normal/log_std Min            -2.65611
trainer/Alpha                                 0.145143
trainer/Alpha Loss                            0.818232
expl/num steps total                     367000
expl/num paths total                        367
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.77496
expl/Rewards Std                              1.22902
expl/Rewards Max                              8.19791
expl/Rewards Min                             -0.489725
expl/Returns Mean                          5774.96
expl/Returns Std                              0
expl/Returns Max                           5774.96
expl/Returns Min                           5774.96
expl/Actions Mean                             0.0885671
expl/Actions Std                              0.79591
expl/Actions Max                              0.999186
expl/Actions Min                             -0.999988
expl/Num Paths                                1
expl/Average Returns                       5774.96
expl/env_infos/final/reward_run Mean          7.35298
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.35298
expl/env_infos/final/reward_run Min           7.35298
expl/env_infos/initial/reward_run Mean       -0.173557
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.173557
expl/env_infos/initial/reward_run Min        -0.173557
expl/env_infos/reward_run Mean                6.15975
expl/env_infos/reward_run Std                 1.22182
expl/env_infos/reward_run Max                 8.66403
expl/env_infos/reward_run Min                -0.173557
expl/env_infos/final/reward_ctrl Mean        -0.428533
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.428533
expl/env_infos/final/reward_ctrl Min         -0.428533
expl/env_infos/initial/reward_ctrl Mean      -0.24346
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.24346
expl/env_infos/initial/reward_ctrl Min       -0.24346
expl/env_infos/reward_ctrl Mean              -0.38479
expl/env_infos/reward_ctrl Std                0.0900518
expl/env_infos/reward_ctrl Max               -0.0945095
expl/env_infos/reward_ctrl Min               -0.581833
eval/num steps total                          1.83e+06
eval/num paths total                       1830
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.11429
eval/Rewards Std                              1.32408
eval/Rewards Max                              8.54379
eval/Rewards Min                             -0.686932
eval/Returns Mean                          6114.29
eval/Returns Std                             58.6182
eval/Returns Max                           6211.31
eval/Returns Min                           6041.51
eval/Actions Mean                             0.081773
eval/Actions Std                              0.813945
eval/Actions Max                              0.99655
eval/Actions Min                             -0.997323
eval/Num Paths                                5
eval/Average Returns                       6114.29
eval/env_infos/final/reward_run Mean          6.86494
eval/env_infos/final/reward_run Std           1.00702
eval/env_infos/final/reward_run Max           7.92559
eval/env_infos/final/reward_run Min           5.18624
eval/env_infos/initial/reward_run Mean       -0.231219
eval/env_infos/initial/reward_run Std         0.265936
eval/env_infos/initial/reward_run Max         0.183803
eval/env_infos/initial/reward_run Min        -0.501941
eval/env_infos/reward_run Mean                6.51581
eval/env_infos/reward_run Std                 1.32129
eval/env_infos/reward_run Max                 9.01136
eval/env_infos/reward_run Min                -0.501941
eval/env_infos/final/reward_ctrl Mean        -0.424939
eval/env_infos/final/reward_ctrl Std          0.0634225
eval/env_infos/final/reward_ctrl Max         -0.361688
eval/env_infos/final/reward_ctrl Min         -0.513761
eval/env_infos/initial/reward_ctrl Mean      -0.189611
eval/env_infos/initial/reward_ctrl Std        0.0296251
eval/env_infos/initial/reward_ctrl Max       -0.140374
eval/env_infos/initial/reward_ctrl Min       -0.229038
eval/env_infos/reward_ctrl Mean              -0.401516
eval/env_infos/reward_ctrl Std                0.0845263
eval/env_infos/reward_ctrl Max               -0.0837306
eval/env_infos/reward_ctrl Min               -0.58314
time/data storing (s)                         0.00448715
time/evaluation sampling (s)                  2.02289
time/exploration sampling (s)                 0.532878
time/logging (s)                              0.0136515
time/sac training (s)                         7.39013
time/saving (s)                               0.00520937
time/training (s)                             3.415e-05
time/epoch (s)                                9.96929
time/total (s)                             3866.6
Epoch                                       365
---------------------------------------  ---------------
2021-11-24 01:33:52.354232 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 366 finished
---------------------------------------  ---------------
epoch                                       366
replay_buffer/size                       368000
trainer/num train calls                  367000
trainer/QF1 Loss                              5.98831
trainer/QF2 Loss                              6.71541
trainer/Policy Loss                        -393.164
trainer/Q1 Predictions Mean                 394.003
trainer/Q1 Predictions Std                  102.122
trainer/Q1 Predictions Max                  464.924
trainer/Q1 Predictions Min                   21.2738
trainer/Q2 Predictions Mean                 394.011
trainer/Q2 Predictions Std                  102.122
trainer/Q2 Predictions Max                  464.797
trainer/Q2 Predictions Min                   20.4147
trainer/Q Targets Mean                      393.88
trainer/Q Targets Std                       102.052
trainer/Q Targets Max                       463.2
trainer/Q Targets Min                        21.2605
trainer/Log Pis Mean                          6.28978
trainer/Log Pis Std                           4.57951
trainer/Log Pis Max                          18.6681
trainer/Log Pis Min                          -5.49254
trainer/policy/mean Mean                      0.0746483
trainer/policy/mean Std                       0.780591
trainer/policy/mean Max                       0.995774
trainer/policy/mean Min                      -0.995021
trainer/policy/normal/std Mean                0.434865
trainer/policy/normal/std Std                 0.142033
trainer/policy/normal/std Max                 0.891184
trainer/policy/normal/std Min                 0.0631629
trainer/policy/normal/log_std Mean           -0.903659
trainer/policy/normal/log_std Std             0.414953
trainer/policy/normal/log_std Max            -0.115205
trainer/policy/normal/log_std Min            -2.76204
trainer/Alpha                                 0.141777
trainer/Alpha Loss                            0.566089
expl/num steps total                     368000
expl/num paths total                        368
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.8475
expl/Rewards Std                              1.2861
expl/Rewards Max                              8.36477
expl/Rewards Min                             -0.738631
expl/Returns Mean                          5847.5
expl/Returns Std                              0
expl/Returns Max                           5847.5
expl/Returns Min                           5847.5
expl/Actions Mean                             0.100448
expl/Actions Std                              0.808129
expl/Actions Max                              0.99988
expl/Actions Min                             -0.998054
expl/Num Paths                                1
expl/Average Returns                       5847.5
expl/env_infos/final/reward_run Mean          3.79722
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           3.79722
expl/env_infos/final/reward_run Min           3.79722
expl/env_infos/initial/reward_run Mean       -0.526785
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.526785
expl/env_infos/initial/reward_run Min        -0.526785
expl/env_infos/reward_run Mean                6.2454
expl/env_infos/reward_run Std                 1.28098
expl/env_infos/reward_run Max                 8.93314
expl/env_infos/reward_run Min                -0.526785
expl/env_infos/final/reward_ctrl Mean        -0.486893
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.486893
expl/env_infos/final/reward_ctrl Min         -0.486893
expl/env_infos/initial/reward_ctrl Mean      -0.211847
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.211847
expl/env_infos/initial/reward_ctrl Min       -0.211847
expl/env_infos/reward_ctrl Mean              -0.397898
expl/env_infos/reward_ctrl Std                0.088029
expl/env_infos/reward_ctrl Max               -0.117296
expl/env_infos/reward_ctrl Min               -0.570498
eval/num steps total                          1.835e+06
eval/num paths total                       1835
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.17049
eval/Rewards Std                              1.31816
eval/Rewards Max                              8.85722
eval/Rewards Min                             -0.890236
eval/Returns Mean                          6170.49
eval/Returns Std                             73.6353
eval/Returns Max                           6313.14
eval/Returns Min                           6099.74
eval/Actions Mean                             0.103196
eval/Actions Std                              0.82226
eval/Actions Max                              0.997696
eval/Actions Min                             -0.996485
eval/Num Paths                                5
eval/Average Returns                       6170.49
eval/env_infos/final/reward_run Mean          7.58279
eval/env_infos/final/reward_run Std           0.814792
eval/env_infos/final/reward_run Max           8.23668
eval/env_infos/final/reward_run Min           5.97827
eval/env_infos/initial/reward_run Mean       -0.354144
eval/env_infos/initial/reward_run Std         0.229516
eval/env_infos/initial/reward_run Max         0.0582398
eval/env_infos/initial/reward_run Min        -0.652058
eval/env_infos/reward_run Mean                6.58255
eval/env_infos/reward_run Std                 1.30962
eval/env_infos/reward_run Max                 9.3981
eval/env_infos/reward_run Min                -0.652058
eval/env_infos/final/reward_ctrl Mean        -0.469495
eval/env_infos/final/reward_ctrl Std          0.0328691
eval/env_infos/final/reward_ctrl Max         -0.404126
eval/env_infos/final/reward_ctrl Min         -0.491925
eval/env_infos/initial/reward_ctrl Mean      -0.226287
eval/env_infos/initial/reward_ctrl Std        0.0333772
eval/env_infos/initial/reward_ctrl Max       -0.179748
eval/env_infos/initial/reward_ctrl Min       -0.280187
eval/env_infos/reward_ctrl Mean              -0.412057
eval/env_infos/reward_ctrl Std                0.0876532
eval/env_infos/reward_ctrl Max               -0.105297
eval/env_infos/reward_ctrl Min               -0.574397
time/data storing (s)                         0.00446828
time/evaluation sampling (s)                  2.00856
time/exploration sampling (s)                 0.546057
time/logging (s)                              0.0136594
time/sac training (s)                         7.43067
time/saving (s)                               0.00376393
time/training (s)                             3.3682e-05
time/epoch (s)                               10.0072
time/total (s)                             3876.88
Epoch                                       366
---------------------------------------  ---------------
2021-11-24 01:34:02.982907 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 367 finished
---------------------------------------  ---------------
epoch                                       367
replay_buffer/size                       369000
trainer/num train calls                  368000
trainer/QF1 Loss                              5.22968
trainer/QF2 Loss                              5.64736
trainer/Policy Loss                        -397.542
trainer/Q1 Predictions Mean                 398.388
trainer/Q1 Predictions Std                   91.2075
trainer/Q1 Predictions Max                  467.653
trainer/Q1 Predictions Min                   20.5939
trainer/Q2 Predictions Mean                 398.224
trainer/Q2 Predictions Std                   91.048
trainer/Q2 Predictions Max                  467.275
trainer/Q2 Predictions Min                   21.552
trainer/Q Targets Mean                      398.317
trainer/Q Targets Std                        91.2307
trainer/Q Targets Max                       469.468
trainer/Q Targets Min                        20.7548
trainer/Log Pis Mean                          6.60208
trainer/Log Pis Std                           4.41827
trainer/Log Pis Max                          17.6741
trainer/Log Pis Min                          -3.79282
trainer/policy/mean Mean                      0.0717215
trainer/policy/mean Std                       0.79507
trainer/policy/mean Max                       0.996359
trainer/policy/mean Min                      -0.997071
trainer/policy/normal/std Mean                0.445122
trainer/policy/normal/std Std                 0.140124
trainer/policy/normal/std Max                 0.879638
trainer/policy/normal/std Min                 0.0659469
trainer/policy/normal/log_std Mean           -0.877585
trainer/policy/normal/log_std Std             0.410634
trainer/policy/normal/log_std Max            -0.128245
trainer/policy/normal/log_std Min            -2.71891
trainer/Alpha                                 0.145573
trainer/Alpha Loss                            1.16026
expl/num steps total                     369000
expl/num paths total                        369
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.59034
expl/Rewards Std                              1.22936
expl/Rewards Max                              8.48677
expl/Rewards Min                             -0.130891
expl/Returns Mean                          5590.34
expl/Returns Std                              0
expl/Returns Max                           5590.34
expl/Returns Min                           5590.34
expl/Actions Mean                             0.0880442
expl/Actions Std                              0.802155
expl/Actions Max                              0.999329
expl/Actions Min                             -0.998934
expl/Num Paths                                1
expl/Average Returns                       5590.34
expl/env_infos/final/reward_run Mean          5.72342
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.72342
expl/env_infos/final/reward_run Min           5.72342
expl/env_infos/initial/reward_run Mean        0.0509844
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0509844
expl/env_infos/initial/reward_run Min         0.0509844
expl/env_infos/reward_run Mean                5.98106
expl/env_infos/reward_run Std                 1.22607
expl/env_infos/reward_run Max                 9.01297
expl/env_infos/reward_run Min                 0.0509844
expl/env_infos/final/reward_ctrl Mean        -0.214607
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.214607
expl/env_infos/final/reward_ctrl Min         -0.214607
expl/env_infos/initial/reward_ctrl Mean      -0.181876
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.181876
expl/env_infos/initial/reward_ctrl Min       -0.181876
expl/env_infos/reward_ctrl Mean              -0.390722
expl/env_infos/reward_ctrl Std                0.0921707
expl/env_infos/reward_ctrl Max               -0.0395751
expl/env_infos/reward_ctrl Min               -0.571249
eval/num steps total                          1.84e+06
eval/num paths total                       1840
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.27081
eval/Rewards Std                              1.33375
eval/Rewards Max                              8.93697
eval/Rewards Min                             -0.83482
eval/Returns Mean                          6270.81
eval/Returns Std                            105.632
eval/Returns Max                           6398.06
eval/Returns Min                           6100.69
eval/Actions Mean                             0.091696
eval/Actions Std                              0.830188
eval/Actions Max                              0.998594
eval/Actions Min                             -0.997687
eval/Num Paths                                5
eval/Average Returns                       6270.81
eval/env_infos/final/reward_run Mean          7.7496
eval/env_infos/final/reward_run Std           1.10045
eval/env_infos/final/reward_run Max           9.2679
eval/env_infos/final/reward_run Min           5.91245
eval/env_infos/initial/reward_run Mean       -0.0239556
eval/env_infos/initial/reward_run Std         0.405013
eval/env_infos/initial/reward_run Max         0.339933
eval/env_infos/initial/reward_run Min        -0.620142
eval/env_infos/reward_run Mean                6.68938
eval/env_infos/reward_run Std                 1.33035
eval/env_infos/reward_run Max                 9.43292
eval/env_infos/reward_run Min                -0.620142
eval/env_infos/final/reward_ctrl Mean        -0.45408
eval/env_infos/final/reward_ctrl Std          0.0653128
eval/env_infos/final/reward_ctrl Max         -0.36891
eval/env_infos/final/reward_ctrl Min         -0.528648
eval/env_infos/initial/reward_ctrl Mean      -0.145728
eval/env_infos/initial/reward_ctrl Std        0.0516863
eval/env_infos/initial/reward_ctrl Max       -0.082233
eval/env_infos/initial/reward_ctrl Min       -0.214678
eval/env_infos/reward_ctrl Mean              -0.418573
eval/env_infos/reward_ctrl Std                0.0878008
eval/env_infos/reward_ctrl Max               -0.082233
eval/env_infos/reward_ctrl Min               -0.581813
time/data storing (s)                         0.0046065
time/evaluation sampling (s)                  2.02985
time/exploration sampling (s)                 0.538159
time/logging (s)                              0.0144655
time/sac training (s)                         7.70752
time/saving (s)                               0.00660885
time/training (s)                             3.5335e-05
time/epoch (s)                               10.3012
time/total (s)                             3887.5
Epoch                                       367
---------------------------------------  ---------------
2021-11-24 01:34:13.295492 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 368 finished
---------------------------------------  ---------------
epoch                                       368
replay_buffer/size                       370000
trainer/num train calls                  369000
trainer/QF1 Loss                              5.33346
trainer/QF2 Loss                              6.06994
trainer/Policy Loss                        -402.619
trainer/Q1 Predictions Mean                 403.171
trainer/Q1 Predictions Std                   77.8281
trainer/Q1 Predictions Max                  472.012
trainer/Q1 Predictions Min                   15.7251
trainer/Q2 Predictions Mean                 403.286
trainer/Q2 Predictions Std                   77.8384
trainer/Q2 Predictions Max                  472.248
trainer/Q2 Predictions Min                   20.5866
trainer/Q Targets Mean                      403.021
trainer/Q Targets Std                        77.603
trainer/Q Targets Max                       470.102
trainer/Q Targets Min                        19.8302
trainer/Log Pis Mean                          6.60894
trainer/Log Pis Std                           4.39527
trainer/Log Pis Max                          16.5083
trainer/Log Pis Min                          -6.33519
trainer/policy/mean Mean                      0.0956432
trainer/policy/mean Std                       0.780072
trainer/policy/mean Max                       0.998052
trainer/policy/mean Min                      -0.997794
trainer/policy/normal/std Mean                0.439656
trainer/policy/normal/std Std                 0.146491
trainer/policy/normal/std Max                 1.011
trainer/policy/normal/std Min                 0.070857
trainer/policy/normal/log_std Mean           -0.897318
trainer/policy/normal/log_std Std             0.429901
trainer/policy/normal/log_std Max             0.0109413
trainer/policy/normal/log_std Min            -2.64709
trainer/Alpha                                 0.14396
trainer/Alpha Loss                            1.18025
expl/num steps total                     370000
expl/num paths total                        370
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.74786
expl/Rewards Std                              1.21699
expl/Rewards Max                              8.08424
expl/Rewards Min                             -0.642817
expl/Returns Mean                          5747.86
expl/Returns Std                              0
expl/Returns Max                           5747.86
expl/Returns Min                           5747.86
expl/Actions Mean                             0.102351
expl/Actions Std                              0.800817
expl/Actions Max                              0.999499
expl/Actions Min                             -0.999854
expl/Num Paths                                1
expl/Average Returns                       5747.86
expl/env_infos/final/reward_run Mean          5.15903
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.15903
expl/env_infos/final/reward_run Min           5.15903
expl/env_infos/initial/reward_run Mean       -0.337956
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.337956
expl/env_infos/initial/reward_run Min        -0.337956
expl/env_infos/reward_run Mean                6.13893
expl/env_infos/reward_run Std                 1.21176
expl/env_infos/reward_run Max                 8.53423
expl/env_infos/reward_run Min                -0.337956
expl/env_infos/final/reward_ctrl Mean        -0.322777
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.322777
expl/env_infos/final/reward_ctrl Min         -0.322777
expl/env_infos/initial/reward_ctrl Mean      -0.304862
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.304862
expl/env_infos/initial/reward_ctrl Min       -0.304862
expl/env_infos/reward_ctrl Mean              -0.391071
expl/env_infos/reward_ctrl Std                0.0922312
expl/env_infos/reward_ctrl Max               -0.101709
expl/env_infos/reward_ctrl Min               -0.567202
eval/num steps total                          1.845e+06
eval/num paths total                       1845
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.10804
eval/Rewards Std                              1.29672
eval/Rewards Max                              8.61271
eval/Rewards Min                             -0.865232
eval/Returns Mean                          6108.04
eval/Returns Std                             73.2611
eval/Returns Max                           6248.78
eval/Returns Min                           6050.64
eval/Actions Mean                             0.0986693
eval/Actions Std                              0.811529
eval/Actions Max                              0.996484
eval/Actions Min                             -0.995382
eval/Num Paths                                5
eval/Average Returns                       6108.04
eval/env_infos/final/reward_run Mean          6.02385
eval/env_infos/final/reward_run Std           0.5054
eval/env_infos/final/reward_run Max           6.78628
eval/env_infos/final/reward_run Min           5.48073
eval/env_infos/initial/reward_run Mean       -0.276239
eval/env_infos/initial/reward_run Std         0.319079
eval/env_infos/initial/reward_run Max         0.316439
eval/env_infos/initial/reward_run Min        -0.635362
eval/env_infos/reward_run Mean                6.50903
eval/env_infos/reward_run Std                 1.29385
eval/env_infos/reward_run Max                 9.15411
eval/env_infos/reward_run Min                -0.635362
eval/env_infos/final/reward_ctrl Mean        -0.478122
eval/env_infos/final/reward_ctrl Std          0.0424105
eval/env_infos/final/reward_ctrl Max         -0.42243
eval/env_infos/final/reward_ctrl Min         -0.547074
eval/env_infos/initial/reward_ctrl Mean      -0.167414
eval/env_infos/initial/reward_ctrl Std        0.0586536
eval/env_infos/initial/reward_ctrl Max       -0.0574147
eval/env_infos/initial/reward_ctrl Min       -0.22987
eval/env_infos/reward_ctrl Mean              -0.400989
eval/env_infos/reward_ctrl Std                0.0929303
eval/env_infos/reward_ctrl Max               -0.0574147
eval/env_infos/reward_ctrl Min               -0.582278
time/data storing (s)                         0.0045226
time/evaluation sampling (s)                  2.02138
time/exploration sampling (s)                 0.535824
time/logging (s)                              0.0143246
time/sac training (s)                         7.4376
time/saving (s)                               0.00374857
time/training (s)                             3.4093e-05
time/epoch (s)                               10.0174
time/total (s)                             3897.8
Epoch                                       368
---------------------------------------  ---------------
2021-11-24 01:34:23.605622 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 369 finished
---------------------------------------  ---------------
epoch                                       369
replay_buffer/size                       371000
trainer/num train calls                  370000
trainer/QF1 Loss                              5.56722
trainer/QF2 Loss                              5.89082
trainer/Policy Loss                        -399.282
trainer/Q1 Predictions Mean                 399.866
trainer/Q1 Predictions Std                   89.189
trainer/Q1 Predictions Max                  468.996
trainer/Q1 Predictions Min                   21.3982
trainer/Q2 Predictions Mean                 400.114
trainer/Q2 Predictions Std                   89.1862
trainer/Q2 Predictions Max                  469.479
trainer/Q2 Predictions Min                   22.341
trainer/Q Targets Mean                      400.299
trainer/Q Targets Std                        89.3971
trainer/Q Targets Max                       468.301
trainer/Q Targets Min                        22.4715
trainer/Log Pis Mean                          6.6456
trainer/Log Pis Std                           4.4664
trainer/Log Pis Max                          16.8349
trainer/Log Pis Min                          -6.35531
trainer/policy/mean Mean                      0.0707472
trainer/policy/mean Std                       0.798415
trainer/policy/mean Max                       0.995908
trainer/policy/mean Min                      -0.995528
trainer/policy/normal/std Mean                0.444432
trainer/policy/normal/std Std                 0.14331
trainer/policy/normal/std Max                 0.960385
trainer/policy/normal/std Min                 0.060412
trainer/policy/normal/log_std Mean           -0.883018
trainer/policy/normal/log_std Std             0.424798
trainer/policy/normal/log_std Max            -0.0404213
trainer/policy/normal/log_std Min            -2.80657
trainer/Alpha                                 0.145297
trainer/Alpha Loss                            1.24535
expl/num steps total                     371000
expl/num paths total                        371
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.58698
expl/Rewards Std                              1.24473
expl/Rewards Max                              8.08505
expl/Rewards Min                             -0.218382
expl/Returns Mean                          5586.98
expl/Returns Std                              0
expl/Returns Max                           5586.98
expl/Returns Min                           5586.98
expl/Actions Mean                             0.0946274
expl/Actions Std                              0.797544
expl/Actions Max                              0.999448
expl/Actions Min                             -0.999096
expl/Num Paths                                1
expl/Average Returns                       5586.98
expl/env_infos/final/reward_run Mean          4.5715
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.5715
expl/env_infos/final/reward_run Min           4.5715
expl/env_infos/initial/reward_run Mean       -0.0985113
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0985113
expl/env_infos/initial/reward_run Min        -0.0985113
expl/env_infos/reward_run Mean                5.974
expl/env_infos/reward_run Std                 1.24498
expl/env_infos/reward_run Max                 8.61335
expl/env_infos/reward_run Min                -0.0985113
expl/env_infos/final/reward_ctrl Mean        -0.425145
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.425145
expl/env_infos/final/reward_ctrl Min         -0.425145
expl/env_infos/initial/reward_ctrl Mean      -0.119871
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.119871
expl/env_infos/initial/reward_ctrl Min       -0.119871
expl/env_infos/reward_ctrl Mean              -0.387018
expl/env_infos/reward_ctrl Std                0.0956222
expl/env_infos/reward_ctrl Max               -0.10966
expl/env_infos/reward_ctrl Min               -0.582424
eval/num steps total                          1.85e+06
eval/num paths total                       1850
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.20844
eval/Rewards Std                              1.31044
eval/Rewards Max                              8.76804
eval/Rewards Min                             -0.682424
eval/Returns Mean                          6208.44
eval/Returns Std                             35.592
eval/Returns Max                           6263.45
eval/Returns Min                           6156.76
eval/Actions Mean                             0.0992332
eval/Actions Std                              0.818514
eval/Actions Max                              0.997702
eval/Actions Min                             -0.997832
eval/Num Paths                                5
eval/Average Returns                       6208.44
eval/env_infos/final/reward_run Mean          6.93975
eval/env_infos/final/reward_run Std           0.911656
eval/env_infos/final/reward_run Max           8.42712
eval/env_infos/final/reward_run Min           5.99518
eval/env_infos/initial/reward_run Mean       -0.243853
eval/env_infos/initial/reward_run Std         0.133066
eval/env_infos/initial/reward_run Max        -0.0889317
eval/env_infos/initial/reward_run Min        -0.454988
eval/env_infos/reward_run Mean                6.61633
eval/env_infos/reward_run Std                 1.30754
eval/env_infos/reward_run Max                 9.30826
eval/env_infos/reward_run Min                -0.454988
eval/env_infos/final/reward_ctrl Mean        -0.390475
eval/env_infos/final/reward_ctrl Std          0.106333
eval/env_infos/final/reward_ctrl Max         -0.228302
eval/env_infos/final/reward_ctrl Min         -0.488358
eval/env_infos/initial/reward_ctrl Mean      -0.200519
eval/env_infos/initial/reward_ctrl Std        0.0335381
eval/env_infos/initial/reward_ctrl Max       -0.139383
eval/env_infos/initial/reward_ctrl Min       -0.233379
eval/env_infos/reward_ctrl Mean              -0.407888
eval/env_infos/reward_ctrl Std                0.0908794
eval/env_infos/reward_ctrl Max               -0.101722
eval/env_infos/reward_ctrl Min               -0.577393
time/data storing (s)                         0.00446073
time/evaluation sampling (s)                  2.0116
time/exploration sampling (s)                 0.532004
time/logging (s)                              0.0138704
time/sac training (s)                         7.449
time/saving (s)                               0.00377195
time/training (s)                             3.4533e-05
time/epoch (s)                               10.0147
time/total (s)                             3908.09
Epoch                                       369
---------------------------------------  ---------------
2021-11-24 01:34:33.944425 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 370 finished
---------------------------------------  ---------------
epoch                                       370
replay_buffer/size                       372000
trainer/num train calls                  371000
trainer/QF1 Loss                              5.04238
trainer/QF2 Loss                              5.30356
trainer/Policy Loss                        -395.412
trainer/Q1 Predictions Mean                 396.089
trainer/Q1 Predictions Std                   97.9421
trainer/Q1 Predictions Max                  464.748
trainer/Q1 Predictions Min                   19.5519
trainer/Q2 Predictions Mean                 396.085
trainer/Q2 Predictions Std                   97.9824
trainer/Q2 Predictions Max                  466.456
trainer/Q2 Predictions Min                   19.9119
trainer/Q Targets Mean                      396.183
trainer/Q Targets Std                        97.9073
trainer/Q Targets Max                       470.188
trainer/Q Targets Min                        17.6392
trainer/Log Pis Mean                          6.06639
trainer/Log Pis Std                           4.33867
trainer/Log Pis Max                          15.6087
trainer/Log Pis Min                          -6.08562
trainer/policy/mean Mean                      0.0762965
trainer/policy/mean Std                       0.788858
trainer/policy/mean Max                       0.995991
trainer/policy/mean Min                      -0.996861
trainer/policy/normal/std Mean                0.453434
trainer/policy/normal/std Std                 0.143074
trainer/policy/normal/std Max                 0.934993
trainer/policy/normal/std Min                 0.0780744
trainer/policy/normal/log_std Mean           -0.859561
trainer/policy/normal/log_std Std             0.41231
trainer/policy/normal/log_std Max            -0.0672164
trainer/policy/normal/log_std Min            -2.55009
trainer/Alpha                                 0.14723
trainer/Alpha Loss                            0.127185
expl/num steps total                     372000
expl/num paths total                        372
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.77448
expl/Rewards Std                              1.30972
expl/Rewards Max                              8.23295
expl/Rewards Min                             -0.812433
expl/Returns Mean                          5774.48
expl/Returns Std                              0
expl/Returns Max                           5774.48
expl/Returns Min                           5774.48
expl/Actions Mean                             0.0945371
expl/Actions Std                              0.80589
expl/Actions Max                              0.999809
expl/Actions Min                             -0.999206
expl/Num Paths                                1
expl/Average Returns                       5774.48
expl/env_infos/final/reward_run Mean          6.37158
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.37158
expl/env_infos/final/reward_run Min           6.37158
expl/env_infos/initial/reward_run Mean       -0.404482
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.404482
expl/env_infos/initial/reward_run Min        -0.404482
expl/env_infos/reward_run Mean                6.16952
expl/env_infos/reward_run Std                 1.30432
expl/env_infos/reward_run Max                 8.56822
expl/env_infos/reward_run Min                -0.555267
expl/env_infos/final/reward_ctrl Mean        -0.410285
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.410285
expl/env_infos/final/reward_ctrl Min         -0.410285
expl/env_infos/initial/reward_ctrl Mean      -0.145638
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.145638
expl/env_infos/initial/reward_ctrl Min       -0.145638
expl/env_infos/reward_ctrl Mean              -0.395038
expl/env_infos/reward_ctrl Std                0.088224
expl/env_infos/reward_ctrl Max               -0.0882706
expl/env_infos/reward_ctrl Min               -0.582217
eval/num steps total                          1.855e+06
eval/num paths total                       1855
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.26095
eval/Rewards Std                              1.33606
eval/Rewards Max                              9.06846
eval/Rewards Min                             -0.927251
eval/Returns Mean                          6260.95
eval/Returns Std                             79.4308
eval/Returns Max                           6362.27
eval/Returns Min                           6120.22
eval/Actions Mean                             0.090205
eval/Actions Std                              0.82358
eval/Actions Max                              0.998432
eval/Actions Min                             -0.997944
eval/Num Paths                                5
eval/Average Returns                       6260.95
eval/env_infos/final/reward_run Mean          6.90096
eval/env_infos/final/reward_run Std           0.608426
eval/env_infos/final/reward_run Max           7.71661
eval/env_infos/final/reward_run Min           6.10736
eval/env_infos/initial/reward_run Mean       -0.0948277
eval/env_infos/initial/reward_run Std         0.409582
eval/env_infos/initial/reward_run Max         0.377944
eval/env_infos/initial/reward_run Min        -0.694316
eval/env_infos/reward_run Mean                6.6728
eval/env_infos/reward_run Std                 1.32948
eval/env_infos/reward_run Max                 9.54746
eval/env_infos/reward_run Min                -0.694316
eval/env_infos/final/reward_ctrl Mean        -0.400587
eval/env_infos/final/reward_ctrl Std          0.0726524
eval/env_infos/final/reward_ctrl Max         -0.261238
eval/env_infos/final/reward_ctrl Min         -0.464909
eval/env_infos/initial/reward_ctrl Mean      -0.168828
eval/env_infos/initial/reward_ctrl Std        0.0382944
eval/env_infos/initial/reward_ctrl Max       -0.124158
eval/env_infos/initial/reward_ctrl Min       -0.212501
eval/env_infos/reward_ctrl Mean              -0.411852
eval/env_infos/reward_ctrl Std                0.0832477
eval/env_infos/reward_ctrl Max               -0.0964887
eval/env_infos/reward_ctrl Min               -0.577478
time/data storing (s)                         0.00449841
time/evaluation sampling (s)                  2.01859
time/exploration sampling (s)                 0.533661
time/logging (s)                              0.0138184
time/sac training (s)                         7.46912
time/saving (s)                               0.00377141
time/training (s)                             3.5054e-05
time/epoch (s)                               10.0435
time/total (s)                             3918.42
Epoch                                       370
---------------------------------------  ---------------
2021-11-24 01:34:44.211595 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 371 finished
---------------------------------------  ---------------
epoch                                       371
replay_buffer/size                       373000
trainer/num train calls                  372000
trainer/QF1 Loss                              5.83253
trainer/QF2 Loss                              7.94954
trainer/Policy Loss                        -385.278
trainer/Q1 Predictions Mean                 385.792
trainer/Q1 Predictions Std                  104.644
trainer/Q1 Predictions Max                  467.516
trainer/Q1 Predictions Min                   19.8454
trainer/Q2 Predictions Mean                 385.588
trainer/Q2 Predictions Std                  104.709
trainer/Q2 Predictions Max                  469.104
trainer/Q2 Predictions Min                   20.628
trainer/Q Targets Mean                      385.823
trainer/Q Targets Std                       104.949
trainer/Q Targets Max                       469.737
trainer/Q Targets Min                        19.0356
trainer/Log Pis Mean                          6.06078
trainer/Log Pis Std                           4.45359
trainer/Log Pis Max                          15.6677
trainer/Log Pis Min                          -4.31826
trainer/policy/mean Mean                      0.0855139
trainer/policy/mean Std                       0.773769
trainer/policy/mean Max                       0.996983
trainer/policy/mean Min                      -0.998083
trainer/policy/normal/std Mean                0.445724
trainer/policy/normal/std Std                 0.150986
trainer/policy/normal/std Max                 1.21136
trainer/policy/normal/std Min                 0.0719715
trainer/policy/normal/log_std Mean           -0.883956
trainer/policy/normal/log_std Std             0.429054
trainer/policy/normal/log_std Max             0.191741
trainer/policy/normal/log_std Min            -2.63149
trainer/Alpha                                 0.14569
trainer/Alpha Loss                            0.117079
expl/num steps total                     373000
expl/num paths total                        373
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.68911
expl/Rewards Std                              1.25227
expl/Rewards Max                              8.13207
expl/Rewards Min                             -0.495889
expl/Returns Mean                          5689.11
expl/Returns Std                              0
expl/Returns Max                           5689.11
expl/Returns Min                           5689.11
expl/Actions Mean                             0.0873897
expl/Actions Std                              0.800158
expl/Actions Max                              0.999446
expl/Actions Min                             -0.999505
expl/Num Paths                                1
expl/Average Returns                       5689.11
expl/env_infos/final/reward_run Mean          7.48501
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.48501
expl/env_infos/final/reward_run Min           7.48501
expl/env_infos/initial/reward_run Mean        0.383699
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.383699
expl/env_infos/initial/reward_run Min         0.383699
expl/env_infos/reward_run Mean                6.07785
expl/env_infos/reward_run Std                 1.25658
expl/env_infos/reward_run Max                 8.69079
expl/env_infos/reward_run Min                -0.119345
expl/env_infos/final/reward_ctrl Mean        -0.436473
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.436473
expl/env_infos/final/reward_ctrl Min         -0.436473
expl/env_infos/initial/reward_ctrl Mean      -0.205617
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.205617
expl/env_infos/initial/reward_ctrl Min       -0.205617
expl/env_infos/reward_ctrl Mean              -0.388734
expl/env_infos/reward_ctrl Std                0.0913295
expl/env_infos/reward_ctrl Max               -0.0785703
expl/env_infos/reward_ctrl Min               -0.567379
eval/num steps total                          1.86e+06
eval/num paths total                       1860
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.13286
eval/Rewards Std                              1.29853
eval/Rewards Max                              8.59969
eval/Rewards Min                             -0.743614
eval/Returns Mean                          6132.86
eval/Returns Std                             61.4584
eval/Returns Max                           6173.5
eval/Returns Min                           6011.24
eval/Actions Mean                             0.0873566
eval/Actions Std                              0.822883
eval/Actions Max                              0.997093
eval/Actions Min                             -0.995268
eval/Num Paths                                5
eval/Average Returns                       6132.86
eval/env_infos/final/reward_run Mean          6.59934
eval/env_infos/final/reward_run Std           0.428844
eval/env_infos/final/reward_run Max           7.07224
eval/env_infos/final/reward_run Min           6.07626
eval/env_infos/initial/reward_run Mean       -0.0417275
eval/env_infos/initial/reward_run Std         0.253803
eval/env_infos/initial/reward_run Max         0.359765
eval/env_infos/initial/reward_run Min        -0.292117
eval/env_infos/reward_run Mean                6.54372
eval/env_infos/reward_run Std                 1.29998
eval/env_infos/reward_run Max                 9.09109
eval/env_infos/reward_run Min                -0.48527
eval/env_infos/final/reward_ctrl Mean        -0.29917
eval/env_infos/final/reward_ctrl Std          0.0686337
eval/env_infos/final/reward_ctrl Max         -0.199288
eval/env_infos/final/reward_ctrl Min         -0.378354
eval/env_infos/initial/reward_ctrl Mean      -0.188364
eval/env_infos/initial/reward_ctrl Std        0.0158503
eval/env_infos/initial/reward_ctrl Max       -0.16771
eval/env_infos/initial/reward_ctrl Min       -0.207013
eval/env_infos/reward_ctrl Mean              -0.410861
eval/env_infos/reward_ctrl Std                0.0901076
eval/env_infos/reward_ctrl Max               -0.112827
eval/env_infos/reward_ctrl Min               -0.574147
time/data storing (s)                         0.00450051
time/evaluation sampling (s)                  2.01891
time/exploration sampling (s)                 0.536754
time/logging (s)                              0.0138423
time/sac training (s)                         7.3946
time/saving (s)                               0.00377055
time/training (s)                             3.3517e-05
time/epoch (s)                                9.97241
time/total (s)                             3928.67
Epoch                                       371
---------------------------------------  ---------------
2021-11-24 01:34:54.464853 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 372 finished
---------------------------------------  ---------------
epoch                                       372
replay_buffer/size                       374000
trainer/num train calls                  373000
trainer/QF1 Loss                              6.14787
trainer/QF2 Loss                              5.61678
trainer/Policy Loss                        -409.01
trainer/Q1 Predictions Mean                 409.733
trainer/Q1 Predictions Std                   78.0167
trainer/Q1 Predictions Max                  472.999
trainer/Q1 Predictions Min                   21.9238
trainer/Q2 Predictions Mean                 409.56
trainer/Q2 Predictions Std                   78.0562
trainer/Q2 Predictions Max                  471.53
trainer/Q2 Predictions Min                   21.1013
trainer/Q Targets Mean                      409.745
trainer/Q Targets Std                        78.2367
trainer/Q Targets Max                       474.564
trainer/Q Targets Min                        21.0798
trainer/Log Pis Mean                          6.08997
trainer/Log Pis Std                           4.02117
trainer/Log Pis Max                          14.9481
trainer/Log Pis Min                          -6.01382
trainer/policy/mean Mean                      0.0788403
trainer/policy/mean Std                       0.776791
trainer/policy/mean Max                       0.996095
trainer/policy/mean Min                      -0.997204
trainer/policy/normal/std Mean                0.430134
trainer/policy/normal/std Std                 0.138876
trainer/policy/normal/std Max                 0.980547
trainer/policy/normal/std Min                 0.0642191
trainer/policy/normal/log_std Mean           -0.915195
trainer/policy/normal/log_std Std             0.420209
trainer/policy/normal/log_std Max            -0.0196444
trainer/policy/normal/log_std Min            -2.74545
trainer/Alpha                                 0.145464
trainer/Alpha Loss                            0.173446
expl/num steps total                     374000
expl/num paths total                        374
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.90772
expl/Rewards Std                              1.28103
expl/Rewards Max                              8.29716
expl/Rewards Min                             -0.753405
expl/Returns Mean                          5907.72
expl/Returns Std                              0
expl/Returns Max                           5907.72
expl/Returns Min                           5907.72
expl/Actions Mean                             0.102847
expl/Actions Std                              0.797885
expl/Actions Max                              0.999561
expl/Actions Min                             -0.999263
expl/Num Paths                                1
expl/Average Returns                       5907.72
expl/env_infos/final/reward_run Mean          7.3999
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.3999
expl/env_infos/final/reward_run Min           7.3999
expl/env_infos/initial/reward_run Mean       -0.534746
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.534746
expl/env_infos/initial/reward_run Min        -0.534746
expl/env_infos/reward_run Mean                6.29604
expl/env_infos/reward_run Std                 1.27432
expl/env_infos/reward_run Max                 8.7601
expl/env_infos/reward_run Min                -0.534746
expl/env_infos/final/reward_ctrl Mean        -0.242942
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.242942
expl/env_infos/final/reward_ctrl Min         -0.242942
expl/env_infos/initial/reward_ctrl Mean      -0.218659
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.218659
expl/env_infos/initial/reward_ctrl Min       -0.218659
expl/env_infos/reward_ctrl Mean              -0.388319
expl/env_infos/reward_ctrl Std                0.0907864
expl/env_infos/reward_ctrl Max               -0.0809229
expl/env_infos/reward_ctrl Min               -0.5845
eval/num steps total                          1.865e+06
eval/num paths total                       1865
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.21944
eval/Rewards Std                              1.32598
eval/Rewards Max                              9.05324
eval/Rewards Min                             -0.810767
eval/Returns Mean                          6219.44
eval/Returns Std                             27.832
eval/Returns Max                           6254.03
eval/Returns Min                           6187.57
eval/Actions Mean                             0.101919
eval/Actions Std                              0.815766
eval/Actions Max                              0.996561
eval/Actions Min                             -0.997685
eval/Num Paths                                5
eval/Average Returns                       6219.44
eval/env_infos/final/reward_run Mean          7.41534
eval/env_infos/final/reward_run Std           0.790593
eval/env_infos/final/reward_run Max           8.79325
eval/env_infos/final/reward_run Min           6.32673
eval/env_infos/initial/reward_run Mean       -0.310168
eval/env_infos/initial/reward_run Std         0.257293
eval/env_infos/initial/reward_run Max         0.146703
eval/env_infos/initial/reward_run Min        -0.598447
eval/env_infos/reward_run Mean                6.62495
eval/env_infos/reward_run Std                 1.31631
eval/env_infos/reward_run Max                 9.59944
eval/env_infos/reward_run Min                -0.598447
eval/env_infos/final/reward_ctrl Mean        -0.431651
eval/env_infos/final/reward_ctrl Std          0.056824
eval/env_infos/final/reward_ctrl Max         -0.333288
eval/env_infos/final/reward_ctrl Min         -0.508915
eval/env_infos/initial/reward_ctrl Mean      -0.204904
eval/env_infos/initial/reward_ctrl Std        0.0543086
eval/env_infos/initial/reward_ctrl Max       -0.129345
eval/env_infos/initial/reward_ctrl Min       -0.295085
eval/env_infos/reward_ctrl Mean              -0.405517
eval/env_infos/reward_ctrl Std                0.0891631
eval/env_infos/reward_ctrl Max               -0.0730218
eval/env_infos/reward_ctrl Min               -0.582265
time/data storing (s)                         0.00448281
time/evaluation sampling (s)                  2.01209
time/exploration sampling (s)                 0.532775
time/logging (s)                              0.0138789
time/sac training (s)                         7.38953
time/saving (s)                               0.00377571
time/training (s)                             3.6317e-05
time/epoch (s)                                9.95656
time/total (s)                             3938.91
Epoch                                       372
---------------------------------------  ---------------
2021-11-24 01:35:04.773727 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 373 finished
---------------------------------------  ---------------
epoch                                       373
replay_buffer/size                       375000
trainer/num train calls                  374000
trainer/QF1 Loss                              5.23788
trainer/QF2 Loss                              5.22544
trainer/Policy Loss                        -392.814
trainer/Q1 Predictions Mean                 393.487
trainer/Q1 Predictions Std                  108.278
trainer/Q1 Predictions Max                  473.328
trainer/Q1 Predictions Min                   19.2272
trainer/Q2 Predictions Mean                 393.266
trainer/Q2 Predictions Std                  108.192
trainer/Q2 Predictions Max                  473.401
trainer/Q2 Predictions Min                   19.4367
trainer/Q Targets Mean                      392.584
trainer/Q Targets Std                       108.043
trainer/Q Targets Max                       475.201
trainer/Q Targets Min                        18.9483
trainer/Log Pis Mean                          5.40593
trainer/Log Pis Std                           4.42184
trainer/Log Pis Max                          18.6251
trainer/Log Pis Min                          -5.59663
trainer/policy/mean Mean                      0.0821753
trainer/policy/mean Std                       0.763294
trainer/policy/mean Max                       0.997208
trainer/policy/mean Min                      -0.995219
trainer/policy/normal/std Mean                0.452205
trainer/policy/normal/std Std                 0.151809
trainer/policy/normal/std Max                 0.986466
trainer/policy/normal/std Min                 0.0800487
trainer/policy/normal/log_std Mean           -0.868531
trainer/policy/normal/log_std Std             0.426269
trainer/policy/normal/log_std Max            -0.0136261
trainer/policy/normal/log_std Min            -2.52512
trainer/Alpha                                 0.146968
trainer/Alpha Loss                           -1.13916
expl/num steps total                     375000
expl/num paths total                        375
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.8165
expl/Rewards Std                              1.24066
expl/Rewards Max                              8.18743
expl/Rewards Min                             -0.518431
expl/Returns Mean                          5816.5
expl/Returns Std                              0
expl/Returns Max                           5816.5
expl/Returns Min                           5816.5
expl/Actions Mean                             0.107859
expl/Actions Std                              0.80494
expl/Actions Max                              0.999559
expl/Actions Min                             -0.999798
expl/Num Paths                                1
expl/Average Returns                       5816.5
expl/env_infos/final/reward_run Mean          6.6839
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.6839
expl/env_infos/final/reward_run Min           6.6839
expl/env_infos/initial/reward_run Mean       -0.337284
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.337284
expl/env_infos/initial/reward_run Min        -0.337284
expl/env_infos/reward_run Mean                6.21223
expl/env_infos/reward_run Std                 1.23323
expl/env_infos/reward_run Max                 8.60318
expl/env_infos/reward_run Min                -0.337284
expl/env_infos/final/reward_ctrl Mean        -0.175294
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.175294
expl/env_infos/final/reward_ctrl Min         -0.175294
expl/env_infos/initial/reward_ctrl Mean      -0.181147
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.181147
expl/env_infos/initial/reward_ctrl Min       -0.181147
expl/env_infos/reward_ctrl Mean              -0.395737
expl/env_infos/reward_ctrl Std                0.0901196
expl/env_infos/reward_ctrl Max               -0.136083
expl/env_infos/reward_ctrl Min               -0.571794
eval/num steps total                          1.87e+06
eval/num paths total                       1870
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.16801
eval/Rewards Std                              1.31131
eval/Rewards Max                              8.70269
eval/Rewards Min                             -0.827388
eval/Returns Mean                          6168.01
eval/Returns Std                             88.4423
eval/Returns Max                           6315.63
eval/Returns Min                           6080.32
eval/Actions Mean                             0.0954478
eval/Actions Std                              0.819877
eval/Actions Max                              0.997898
eval/Actions Min                             -0.998913
eval/Num Paths                                5
eval/Average Returns                       6168.01
eval/env_infos/final/reward_run Mean          6.58547
eval/env_infos/final/reward_run Std           1.1028
eval/env_infos/final/reward_run Max           8.1343
eval/env_infos/final/reward_run Min           5.05313
eval/env_infos/initial/reward_run Mean       -0.389456
eval/env_infos/initial/reward_run Std         0.258024
eval/env_infos/initial/reward_run Max         0.0615052
eval/env_infos/initial/reward_run Min        -0.631412
eval/env_infos/reward_run Mean                6.5768
eval/env_infos/reward_run Std                 1.30675
eval/env_infos/reward_run Max                 9.20703
eval/env_infos/reward_run Min                -0.631412
eval/env_infos/final/reward_ctrl Mean        -0.388365
eval/env_infos/final/reward_ctrl Std          0.0712528
eval/env_infos/final/reward_ctrl Max         -0.272584
eval/env_infos/final/reward_ctrl Min         -0.495045
eval/env_infos/initial/reward_ctrl Mean      -0.207026
eval/env_infos/initial/reward_ctrl Std        0.0254783
eval/env_infos/initial/reward_ctrl Max       -0.182196
eval/env_infos/initial/reward_ctrl Min       -0.242304
eval/env_infos/reward_ctrl Mean              -0.408785
eval/env_infos/reward_ctrl Std                0.0934606
eval/env_infos/reward_ctrl Max               -0.0974018
eval/env_infos/reward_ctrl Min               -0.581614
time/data storing (s)                         0.00450309
time/evaluation sampling (s)                  2.00758
time/exploration sampling (s)                 0.533927
time/logging (s)                              0.0139081
time/sac training (s)                         7.44988
time/saving (s)                               0.00377616
time/training (s)                             3.4226e-05
time/epoch (s)                               10.0136
time/total (s)                             3949.2
Epoch                                       373
---------------------------------------  ---------------
2021-11-24 01:35:15.025167 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 374 finished
---------------------------------------  ---------------
epoch                                       374
replay_buffer/size                       376000
trainer/num train calls                  375000
trainer/QF1 Loss                              6.34335
trainer/QF2 Loss                              4.38588
trainer/Policy Loss                        -401.915
trainer/Q1 Predictions Mean                 402.135
trainer/Q1 Predictions Std                   94.539
trainer/Q1 Predictions Max                  471.694
trainer/Q1 Predictions Min                   18.6849
trainer/Q2 Predictions Mean                 402.702
trainer/Q2 Predictions Std                   94.4398
trainer/Q2 Predictions Max                  471.356
trainer/Q2 Predictions Min                   20.0267
trainer/Q Targets Mean                      402.152
trainer/Q Targets Std                        94.1726
trainer/Q Targets Max                       469.992
trainer/Q Targets Min                        18.6951
trainer/Log Pis Mean                          5.5791
trainer/Log Pis Std                           4.20196
trainer/Log Pis Max                          17.4138
trainer/Log Pis Min                          -5.3709
trainer/policy/mean Mean                      0.0715406
trainer/policy/mean Std                       0.77482
trainer/policy/mean Max                       0.998958
trainer/policy/mean Min                      -0.994852
trainer/policy/normal/std Mean                0.447527
trainer/policy/normal/std Std                 0.152538
trainer/policy/normal/std Max                 0.967565
trainer/policy/normal/std Min                 0.0720404
trainer/policy/normal/log_std Mean           -0.883227
trainer/policy/normal/log_std Std             0.441844
trainer/policy/normal/log_std Max            -0.0329731
trainer/policy/normal/log_std Min            -2.63053
trainer/Alpha                                 0.146778
trainer/Alpha Loss                           -0.807632
expl/num steps total                     376000
expl/num paths total                        376
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.98625
expl/Rewards Std                              1.26276
expl/Rewards Max                              8.40004
expl/Rewards Min                             -0.603282
expl/Returns Mean                          5986.25
expl/Returns Std                              0
expl/Returns Max                           5986.25
expl/Returns Min                           5986.25
expl/Actions Mean                             0.0987082
expl/Actions Std                              0.807341
expl/Actions Max                              0.999866
expl/Actions Min                             -0.999156
expl/Num Paths                                1
expl/Average Returns                       5986.25
expl/env_infos/final/reward_run Mean          7.84913
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.84913
expl/env_infos/final/reward_run Min           7.84913
expl/env_infos/initial/reward_run Mean       -0.447561
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.447561
expl/env_infos/initial/reward_run Min        -0.447561
expl/env_infos/reward_run Mean                6.38317
expl/env_infos/reward_run Std                 1.26304
expl/env_infos/reward_run Max                 8.95975
expl/env_infos/reward_run Min                -0.447561
expl/env_infos/final/reward_ctrl Mean        -0.416868
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.416868
expl/env_infos/final/reward_ctrl Min         -0.416868
expl/env_infos/initial/reward_ctrl Mean      -0.155721
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.155721
expl/env_infos/initial/reward_ctrl Min       -0.155721
expl/env_infos/reward_ctrl Mean              -0.396925
expl/env_infos/reward_ctrl Std                0.0909557
expl/env_infos/reward_ctrl Max               -0.106046
expl/env_infos/reward_ctrl Min               -0.580385
eval/num steps total                          1.875e+06
eval/num paths total                       1875
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.24324
eval/Rewards Std                              1.3101
eval/Rewards Max                              8.76785
eval/Rewards Min                             -0.780279
eval/Returns Mean                          6243.24
eval/Returns Std                             41.6585
eval/Returns Max                           6322.21
eval/Returns Min                           6204.81
eval/Actions Mean                             0.0892952
eval/Actions Std                              0.82264
eval/Actions Max                              0.998967
eval/Actions Min                             -0.996477
eval/Num Paths                                5
eval/Average Returns                       6243.24
eval/env_infos/final/reward_run Mean          6.93136
eval/env_infos/final/reward_run Std           0.595679
eval/env_infos/final/reward_run Max           7.64561
eval/env_infos/final/reward_run Min           6.11239
eval/env_infos/initial/reward_run Mean       -0.150238
eval/env_infos/initial/reward_run Std         0.294855
eval/env_infos/initial/reward_run Max         0.310089
eval/env_infos/initial/reward_run Min        -0.557034
eval/env_infos/reward_run Mean                6.65406
eval/env_infos/reward_run Std                 1.30396
eval/env_infos/reward_run Max                 9.30182
eval/env_infos/reward_run Min                -0.557034
eval/env_infos/final/reward_ctrl Mean        -0.419312
eval/env_infos/final/reward_ctrl Std          0.0787954
eval/env_infos/final/reward_ctrl Max         -0.314993
eval/env_infos/final/reward_ctrl Min         -0.543025
eval/env_infos/initial/reward_ctrl Mean      -0.211326
eval/env_infos/initial/reward_ctrl Std        0.0220821
eval/env_infos/initial/reward_ctrl Max       -0.174292
eval/env_infos/initial/reward_ctrl Min       -0.240056
eval/env_infos/reward_ctrl Mean              -0.410826
eval/env_infos/reward_ctrl Std                0.0876212
eval/env_infos/reward_ctrl Max               -0.114858
eval/env_infos/reward_ctrl Min               -0.578277
time/data storing (s)                         0.00449594
time/evaluation sampling (s)                  2.00894
time/exploration sampling (s)                 0.527038
time/logging (s)                              0.0138198
time/sac training (s)                         7.39863
time/saving (s)                               0.003769
time/training (s)                             3.4094e-05
time/epoch (s)                                9.95673
time/total (s)                             3959.44
Epoch                                       374
---------------------------------------  ---------------
2021-11-24 01:35:25.382711 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 375 finished
---------------------------------------  ---------------
epoch                                       375
replay_buffer/size                       377000
trainer/num train calls                  376000
trainer/QF1 Loss                              6.34381
trainer/QF2 Loss                              6.53844
trainer/Policy Loss                        -389.759
trainer/Q1 Predictions Mean                 390.503
trainer/Q1 Predictions Std                  112.824
trainer/Q1 Predictions Max                  466.079
trainer/Q1 Predictions Min                   18.2065
trainer/Q2 Predictions Mean                 390.19
trainer/Q2 Predictions Std                  113.009
trainer/Q2 Predictions Max                  468.829
trainer/Q2 Predictions Min                   17.485
trainer/Q Targets Mean                      390.399
trainer/Q Targets Std                       112.837
trainer/Q Targets Max                       468.391
trainer/Q Targets Min                        19.2062
trainer/Log Pis Mean                          5.90804
trainer/Log Pis Std                           4.72473
trainer/Log Pis Max                          17.56
trainer/Log Pis Min                          -7.95216
trainer/policy/mean Mean                      0.0974637
trainer/policy/mean Std                       0.769114
trainer/policy/mean Max                       0.996478
trainer/policy/mean Min                      -0.997766
trainer/policy/normal/std Mean                0.446452
trainer/policy/normal/std Std                 0.149603
trainer/policy/normal/std Max                 1.13224
trainer/policy/normal/std Min                 0.0699794
trainer/policy/normal/log_std Mean           -0.882074
trainer/policy/normal/log_std Std             0.430107
trainer/policy/normal/log_std Max             0.124199
trainer/policy/normal/log_std Min            -2.65955
trainer/Alpha                                 0.146409
trainer/Alpha Loss                           -0.176695
expl/num steps total                     377000
expl/num paths total                        377
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.75484
expl/Rewards Std                              1.2565
expl/Rewards Max                              8.62876
expl/Rewards Min                             -0.754073
expl/Returns Mean                          5754.84
expl/Returns Std                              0
expl/Returns Max                           5754.84
expl/Returns Min                           5754.84
expl/Actions Mean                             0.0895932
expl/Actions Std                              0.798244
expl/Actions Max                              0.999701
expl/Actions Min                             -0.999526
expl/Num Paths                                1
expl/Average Returns                       5754.84
expl/env_infos/final/reward_run Mean          6.47183
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.47183
expl/env_infos/final/reward_run Min           6.47183
expl/env_infos/initial/reward_run Mean       -0.522677
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.522677
expl/env_infos/initial/reward_run Min        -0.522677
expl/env_infos/reward_run Mean                6.14197
expl/env_infos/reward_run Std                 1.2464
expl/env_infos/reward_run Max                 9.19001
expl/env_infos/reward_run Min                -0.522677
expl/env_infos/final/reward_ctrl Mean        -0.493972
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.493972
expl/env_infos/final/reward_ctrl Min         -0.493972
expl/env_infos/initial/reward_ctrl Mean      -0.231396
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.231396
expl/env_infos/initial/reward_ctrl Min       -0.231396
expl/env_infos/reward_ctrl Mean              -0.387132
expl/env_infos/reward_ctrl Std                0.0948509
expl/env_infos/reward_ctrl Max               -0.0927562
expl/env_infos/reward_ctrl Min               -0.591276
eval/num steps total                          1.88e+06
eval/num paths total                       1880
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.02302
eval/Rewards Std                              1.3207
eval/Rewards Max                              8.45077
eval/Rewards Min                             -0.924727
eval/Returns Mean                          6023.02
eval/Returns Std                             24.3198
eval/Returns Max                           6054.77
eval/Returns Min                           5988.19
eval/Actions Mean                             0.0975369
eval/Actions Std                              0.81581
eval/Actions Max                              0.998633
eval/Actions Min                             -0.998774
eval/Num Paths                                5
eval/Average Returns                       6023.02
eval/env_infos/final/reward_run Mean          6.74771
eval/env_infos/final/reward_run Std           0.993966
eval/env_infos/final/reward_run Max           7.80273
eval/env_infos/final/reward_run Min           5.11886
eval/env_infos/initial/reward_run Mean       -0.403845
eval/env_infos/initial/reward_run Std         0.190127
eval/env_infos/initial/reward_run Max        -0.103208
eval/env_infos/initial/reward_run Min        -0.694229
eval/env_infos/reward_run Mean                6.42805
eval/env_infos/reward_run Std                 1.30625
eval/env_infos/reward_run Max                 8.94834
eval/env_infos/reward_run Min                -0.694229
eval/env_infos/final/reward_ctrl Mean        -0.367683
eval/env_infos/final/reward_ctrl Std          0.0567122
eval/env_infos/final/reward_ctrl Max         -0.300636
eval/env_infos/final/reward_ctrl Min         -0.449565
eval/env_infos/initial/reward_ctrl Mean      -0.196537
eval/env_infos/initial/reward_ctrl Std        0.0216982
eval/env_infos/initial/reward_ctrl Max       -0.176989
eval/env_infos/initial/reward_ctrl Min       -0.230498
eval/env_infos/reward_ctrl Mean              -0.405036
eval/env_infos/reward_ctrl Std                0.0932972
eval/env_infos/reward_ctrl Max               -0.0596254
eval/env_infos/reward_ctrl Min               -0.579711
time/data storing (s)                         0.00451596
time/evaluation sampling (s)                  2.02223
time/exploration sampling (s)                 0.534489
time/logging (s)                              0.0138166
time/sac training (s)                         7.48186
time/saving (s)                               0.00375783
time/training (s)                             3.4345e-05
time/epoch (s)                               10.0607
time/total (s)                             3969.78
Epoch                                       375
---------------------------------------  ---------------
2021-11-24 01:35:35.671798 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 376 finished
---------------------------------------  ---------------
epoch                                       376
replay_buffer/size                       378000
trainer/num train calls                  377000
trainer/QF1 Loss                              5.25579
trainer/QF2 Loss                              5.95558
trainer/Policy Loss                        -397.539
trainer/Q1 Predictions Mean                 397.931
trainer/Q1 Predictions Std                  100.595
trainer/Q1 Predictions Max                  478.558
trainer/Q1 Predictions Min                   18.1375
trainer/Q2 Predictions Mean                 398.659
trainer/Q2 Predictions Std                  100.654
trainer/Q2 Predictions Max                  479.568
trainer/Q2 Predictions Min                   19.7098
trainer/Q Targets Mean                      398.325
trainer/Q Targets Std                       100.76
trainer/Q Targets Max                       479.62
trainer/Q Targets Min                        17.3065
trainer/Log Pis Mean                          6.7152
trainer/Log Pis Std                           4.45525
trainer/Log Pis Max                          16.4412
trainer/Log Pis Min                          -5.77788
trainer/policy/mean Mean                      0.0725661
trainer/policy/mean Std                       0.788858
trainer/policy/mean Max                       0.998326
trainer/policy/mean Min                      -0.99529
trainer/policy/normal/std Mean                0.440897
trainer/policy/normal/std Std                 0.144696
trainer/policy/normal/std Max                 1.04493
trainer/policy/normal/std Min                 0.0573527
trainer/policy/normal/log_std Mean           -0.892253
trainer/policy/normal/log_std Std             0.425857
trainer/policy/normal/log_std Max             0.0439453
trainer/policy/normal/log_std Min            -2.85854
trainer/Alpha                                 0.145772
trainer/Alpha Loss                            1.37727
expl/num steps total                     378000
expl/num paths total                        378
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.89002
expl/Rewards Std                              1.28548
expl/Rewards Max                              8.51781
expl/Rewards Min                             -0.619941
expl/Returns Mean                          5890.02
expl/Returns Std                              0
expl/Returns Max                           5890.02
expl/Returns Min                           5890.02
expl/Actions Mean                             0.0835204
expl/Actions Std                              0.806423
expl/Actions Max                              0.999414
expl/Actions Min                             -0.999271
expl/Num Paths                                1
expl/Average Returns                       5890.02
expl/env_infos/final/reward_run Mean          8.05052
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.05052
expl/env_infos/final/reward_run Min           8.05052
expl/env_infos/initial/reward_run Mean       -0.390917
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.390917
expl/env_infos/initial/reward_run Min        -0.390917
expl/env_infos/reward_run Mean                6.28439
expl/env_infos/reward_run Std                 1.27953
expl/env_infos/reward_run Max                 8.98115
expl/env_infos/reward_run Min                -0.390917
expl/env_infos/final/reward_ctrl Mean        -0.460955
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.460955
expl/env_infos/final/reward_ctrl Min         -0.460955
expl/env_infos/initial/reward_ctrl Mean      -0.229025
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.229025
expl/env_infos/initial/reward_ctrl Min       -0.229025
expl/env_infos/reward_ctrl Mean              -0.394376
expl/env_infos/reward_ctrl Std                0.0923791
expl/env_infos/reward_ctrl Max               -0.0832229
expl/env_infos/reward_ctrl Min               -0.573111
eval/num steps total                          1.885e+06
eval/num paths total                       1885
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.19247
eval/Rewards Std                              1.31621
eval/Rewards Max                              8.82925
eval/Rewards Min                             -0.704922
eval/Returns Mean                          6192.47
eval/Returns Std                             70.6338
eval/Returns Max                           6305.32
eval/Returns Min                           6094.6
eval/Actions Mean                             0.0875474
eval/Actions Std                              0.822977
eval/Actions Max                              0.995652
eval/Actions Min                             -0.996123
eval/Num Paths                                5
eval/Average Returns                       6192.47
eval/env_infos/final/reward_run Mean          6.65352
eval/env_infos/final/reward_run Std           0.6071
eval/env_infos/final/reward_run Max           7.70486
eval/env_infos/final/reward_run Min           5.94047
eval/env_infos/initial/reward_run Mean       -0.292056
eval/env_infos/initial/reward_run Std         0.288152
eval/env_infos/initial/reward_run Max         0.238792
eval/env_infos/initial/reward_run Min        -0.526724
eval/env_infos/reward_run Mean                6.60344
eval/env_infos/reward_run Std                 1.31163
eval/env_infos/reward_run Max                 9.36184
eval/env_infos/reward_run Min                -0.526724
eval/env_infos/final/reward_ctrl Mean        -0.452014
eval/env_infos/final/reward_ctrl Std          0.0224156
eval/env_infos/final/reward_ctrl Max         -0.419374
eval/env_infos/final/reward_ctrl Min         -0.486941
eval/env_infos/initial/reward_ctrl Mean      -0.186398
eval/env_infos/initial/reward_ctrl Std        0.0144527
eval/env_infos/initial/reward_ctrl Max       -0.164508
eval/env_infos/initial/reward_ctrl Min       -0.20794
eval/env_infos/reward_ctrl Mean              -0.410974
eval/env_infos/reward_ctrl Std                0.090495
eval/env_infos/reward_ctrl Max               -0.0767392
eval/env_infos/reward_ctrl Min               -0.582806
time/data storing (s)                         0.00448278
time/evaluation sampling (s)                  2.02166
time/exploration sampling (s)                 0.534309
time/logging (s)                              0.0138272
time/sac training (s)                         7.41606
time/saving (s)                               0.00377379
time/training (s)                             3.4447e-05
time/epoch (s)                                9.99415
time/total (s)                             3980.06
Epoch                                       376
---------------------------------------  ---------------
2021-11-24 01:35:45.977824 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 377 finished
---------------------------------------  ---------------
epoch                                       377
replay_buffer/size                       379000
trainer/num train calls                  378000
trainer/QF1 Loss                              7.07048
trainer/QF2 Loss                              6.7528
trainer/Policy Loss                        -403.329
trainer/Q1 Predictions Mean                 403.893
trainer/Q1 Predictions Std                   87.3896
trainer/Q1 Predictions Max                  468.817
trainer/Q1 Predictions Min                   18.6481
trainer/Q2 Predictions Mean                 403.909
trainer/Q2 Predictions Std                   87.2613
trainer/Q2 Predictions Max                  467.833
trainer/Q2 Predictions Min                   19.0859
trainer/Q Targets Mean                      404.091
trainer/Q Targets Std                        87.3496
trainer/Q Targets Max                       468.389
trainer/Q Targets Min                        19.4172
trainer/Log Pis Mean                          6.34472
trainer/Log Pis Std                           4.18045
trainer/Log Pis Max                          15.9925
trainer/Log Pis Min                          -5.795
trainer/policy/mean Mean                      0.0730074
trainer/policy/mean Std                       0.776742
trainer/policy/mean Max                       0.999002
trainer/policy/mean Min                      -0.9993
trainer/policy/normal/std Mean                0.435962
trainer/policy/normal/std Std                 0.142286
trainer/policy/normal/std Max                 0.904975
trainer/policy/normal/std Min                 0.0590511
trainer/policy/normal/log_std Mean           -0.905117
trainer/policy/normal/log_std Std             0.432271
trainer/policy/normal/log_std Max            -0.0998476
trainer/policy/normal/log_std Min            -2.82935
trainer/Alpha                                 0.146599
trainer/Alpha Loss                            0.661882
expl/num steps total                     379000
expl/num paths total                        379
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.87754
expl/Rewards Std                              1.27182
expl/Rewards Max                              8.19378
expl/Rewards Min                             -0.71975
expl/Returns Mean                          5877.54
expl/Returns Std                              0
expl/Returns Max                           5877.54
expl/Returns Min                           5877.54
expl/Actions Mean                             0.0868117
expl/Actions Std                              0.798309
expl/Actions Max                              0.99937
expl/Actions Min                             -0.999743
expl/Num Paths                                1
expl/Average Returns                       5877.54
expl/env_infos/final/reward_run Mean          6.4665
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.4665
expl/env_infos/final/reward_run Min           6.4665
expl/env_infos/initial/reward_run Mean       -0.431748
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.431748
expl/env_infos/initial/reward_run Min        -0.431748
expl/env_infos/reward_run Mean                6.26444
expl/env_infos/reward_run Std                 1.2705
expl/env_infos/reward_run Max                 8.69577
expl/env_infos/reward_run Min                -0.431748
expl/env_infos/final/reward_ctrl Mean        -0.141715
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.141715
expl/env_infos/final/reward_ctrl Min         -0.141715
expl/env_infos/initial/reward_ctrl Mean      -0.288002
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.288002
expl/env_infos/initial/reward_ctrl Min       -0.288002
expl/env_infos/reward_ctrl Mean              -0.3869
expl/env_infos/reward_ctrl Std                0.0926126
expl/env_infos/reward_ctrl Max               -0.0667176
expl/env_infos/reward_ctrl Min               -0.570912
eval/num steps total                          1.89e+06
eval/num paths total                       1890
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.1343
eval/Rewards Std                              1.28496
eval/Rewards Max                              8.52711
eval/Rewards Min                             -0.890331
eval/Returns Mean                          6134.3
eval/Returns Std                             60.4801
eval/Returns Max                           6237.49
eval/Returns Min                           6054.81
eval/Actions Mean                             0.0868715
eval/Actions Std                              0.813983
eval/Actions Max                              0.995525
eval/Actions Min                             -0.995061
eval/Num Paths                                5
eval/Average Returns                       6134.3
eval/env_infos/final/reward_run Mean          6.92976
eval/env_infos/final/reward_run Std           1.03778
eval/env_infos/final/reward_run Max           7.98455
eval/env_infos/final/reward_run Min           5.08672
eval/env_infos/initial/reward_run Mean       -0.531244
eval/env_infos/initial/reward_run Std         0.0964448
eval/env_infos/initial/reward_run Max        -0.46312
eval/env_infos/initial/reward_run Min        -0.716616
eval/env_infos/reward_run Mean                6.53637
eval/env_infos/reward_run Std                 1.2854
eval/env_infos/reward_run Max                 9.04165
eval/env_infos/reward_run Min                -0.716616
eval/env_infos/final/reward_ctrl Mean        -0.415934
eval/env_infos/final/reward_ctrl Std          0.0904762
eval/env_infos/final/reward_ctrl Max         -0.242392
eval/env_infos/final/reward_ctrl Min         -0.500648
eval/env_infos/initial/reward_ctrl Mean      -0.182883
eval/env_infos/initial/reward_ctrl Std        0.0290686
eval/env_infos/initial/reward_ctrl Max       -0.149387
eval/env_infos/initial/reward_ctrl Min       -0.229343
eval/env_infos/reward_ctrl Mean              -0.402069
eval/env_infos/reward_ctrl Std                0.0886793
eval/env_infos/reward_ctrl Max               -0.0721872
eval/env_infos/reward_ctrl Min               -0.576917
time/data storing (s)                         0.00447557
time/evaluation sampling (s)                  2.02552
time/exploration sampling (s)                 0.530349
time/logging (s)                              0.0138521
time/sac training (s)                         7.43187
time/saving (s)                               0.00377543
time/training (s)                             3.5134e-05
time/epoch (s)                               10.0099
time/total (s)                             3990.35
Epoch                                       377
---------------------------------------  ---------------
2021-11-24 01:35:56.277086 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 378 finished
---------------------------------------  ---------------
epoch                                       378
replay_buffer/size                       380000
trainer/num train calls                  379000
trainer/QF1 Loss                              5.59982
trainer/QF2 Loss                              5.2868
trainer/Policy Loss                        -398.668
trainer/Q1 Predictions Mean                 399.329
trainer/Q1 Predictions Std                  100.03
trainer/Q1 Predictions Max                  472.213
trainer/Q1 Predictions Min                   21.1015
trainer/Q2 Predictions Mean                 399.616
trainer/Q2 Predictions Std                  100.09
trainer/Q2 Predictions Max                  472.292
trainer/Q2 Predictions Min                   20.6476
trainer/Q Targets Mean                      399.555
trainer/Q Targets Std                       100.132
trainer/Q Targets Max                       475.97
trainer/Q Targets Min                        21.3959
trainer/Log Pis Mean                          6.22592
trainer/Log Pis Std                           4.23641
trainer/Log Pis Max                          16.1099
trainer/Log Pis Min                          -3.93787
trainer/policy/mean Mean                      0.086517
trainer/policy/mean Std                       0.776938
trainer/policy/mean Max                       0.998648
trainer/policy/mean Min                      -0.997194
trainer/policy/normal/std Mean                0.438384
trainer/policy/normal/std Std                 0.143163
trainer/policy/normal/std Max                 0.897236
trainer/policy/normal/std Min                 0.0619686
trainer/policy/normal/log_std Mean           -0.900842
trainer/policy/normal/log_std Std             0.438678
trainer/policy/normal/log_std Max            -0.108436
trainer/policy/normal/log_std Min            -2.78113
trainer/Alpha                                 0.146961
trainer/Alpha Loss                            0.433215
expl/num steps total                     380000
expl/num paths total                        380
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.73623
expl/Rewards Std                              1.28625
expl/Rewards Max                              8.19441
expl/Rewards Min                             -0.523434
expl/Returns Mean                          5736.23
expl/Returns Std                              0
expl/Returns Max                           5736.23
expl/Returns Min                           5736.23
expl/Actions Mean                             0.0755543
expl/Actions Std                              0.792955
expl/Actions Max                              0.999577
expl/Actions Min                             -0.998383
expl/Num Paths                                1
expl/Average Returns                       5736.23
expl/env_infos/final/reward_run Mean          6.18287
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.18287
expl/env_infos/final/reward_run Min           6.18287
expl/env_infos/initial/reward_run Mean       -0.171196
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.171196
expl/env_infos/initial/reward_run Min        -0.171196
expl/env_infos/reward_run Mean                6.11693
expl/env_infos/reward_run Std                 1.27977
expl/env_infos/reward_run Max                 8.63211
expl/env_infos/reward_run Min                -0.318784
expl/env_infos/final/reward_ctrl Mean        -0.409423
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.409423
expl/env_infos/final/reward_ctrl Min         -0.409423
expl/env_infos/initial/reward_ctrl Mean      -0.177208
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.177208
expl/env_infos/initial/reward_ctrl Min       -0.177208
expl/env_infos/reward_ctrl Mean              -0.380691
expl/env_infos/reward_ctrl Std                0.088938
expl/env_infos/reward_ctrl Max               -0.125088
expl/env_infos/reward_ctrl Min               -0.583347
eval/num steps total                          1.895e+06
eval/num paths total                       1895
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.18492
eval/Rewards Std                              1.28577
eval/Rewards Max                              8.64987
eval/Rewards Min                             -0.753924
eval/Returns Mean                          6184.92
eval/Returns Std                             65.8246
eval/Returns Max                           6258.53
eval/Returns Min                           6073.35
eval/Actions Mean                             0.0737249
eval/Actions Std                              0.8145
eval/Actions Max                              0.997923
eval/Actions Min                             -0.996113
eval/Num Paths                                5
eval/Average Returns                       6184.92
eval/env_infos/final/reward_run Mean          6.63361
eval/env_infos/final/reward_run Std           1.08031
eval/env_infos/final/reward_run Max           8.46783
eval/env_infos/final/reward_run Min           5.32381
eval/env_infos/initial/reward_run Mean       -0.301639
eval/env_infos/initial/reward_run Std         0.182911
eval/env_infos/initial/reward_run Max        -0.0337386
eval/env_infos/initial/reward_run Min        -0.54099
eval/env_infos/reward_run Mean                6.58623
eval/env_infos/reward_run Std                 1.2816
eval/env_infos/reward_run Max                 9.18294
eval/env_infos/reward_run Min                -0.54099
eval/env_infos/final/reward_ctrl Mean        -0.470221
eval/env_infos/final/reward_ctrl Std          0.04796
eval/env_infos/final/reward_ctrl Max         -0.388207
eval/env_infos/final/reward_ctrl Min         -0.530655
eval/env_infos/initial/reward_ctrl Mean      -0.221159
eval/env_infos/initial/reward_ctrl Std        0.0151261
eval/env_infos/initial/reward_ctrl Max       -0.201467
eval/env_infos/initial/reward_ctrl Min       -0.242298
eval/env_infos/reward_ctrl Mean              -0.401308
eval/env_infos/reward_ctrl Std                0.08537
eval/env_infos/reward_ctrl Max               -0.107188
eval/env_infos/reward_ctrl Min               -0.580468
time/data storing (s)                         0.00450822
time/evaluation sampling (s)                  2.01532
time/exploration sampling (s)                 0.534992
time/logging (s)                              0.0136049
time/sac training (s)                         7.43006
time/saving (s)                               0.00376658
time/training (s)                             3.4544e-05
time/epoch (s)                               10.0023
time/total (s)                             4000.64
Epoch                                       378
---------------------------------------  ---------------
2021-11-24 01:36:06.690759 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 379 finished
---------------------------------------  ---------------
epoch                                       379
replay_buffer/size                       381000
trainer/num train calls                  380000
trainer/QF1 Loss                              4.34305
trainer/QF2 Loss                              4.92867
trainer/Policy Loss                        -399.653
trainer/Q1 Predictions Mean                 400.501
trainer/Q1 Predictions Std                   92.4009
trainer/Q1 Predictions Max                  470.43
trainer/Q1 Predictions Min                   20.5981
trainer/Q2 Predictions Mean                 400.479
trainer/Q2 Predictions Std                   92.4993
trainer/Q2 Predictions Max                  470.568
trainer/Q2 Predictions Min                   19.1507
trainer/Q Targets Mean                      400.569
trainer/Q Targets Std                        92.3501
trainer/Q Targets Max                       472.24
trainer/Q Targets Min                        20.1026
trainer/Log Pis Mean                          5.85395
trainer/Log Pis Std                           4.44394
trainer/Log Pis Max                          19.7215
trainer/Log Pis Min                          -4.07581
trainer/policy/mean Mean                      0.0720005
trainer/policy/mean Std                       0.77201
trainer/policy/mean Max                       0.994259
trainer/policy/mean Min                      -0.997107
trainer/policy/normal/std Mean                0.438873
trainer/policy/normal/std Std                 0.146788
trainer/policy/normal/std Max                 1.07457
trainer/policy/normal/std Min                 0.0615306
trainer/policy/normal/log_std Mean           -0.898192
trainer/policy/normal/log_std Std             0.427125
trainer/policy/normal/log_std Max             0.0719233
trainer/policy/normal/log_std Min            -2.78822
trainer/Alpha                                 0.145345
trainer/Alpha Loss                           -0.281684
expl/num steps total                     381000
expl/num paths total                        381
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.88346
expl/Rewards Std                              1.25141
expl/Rewards Max                              8.16533
expl/Rewards Min                             -0.615062
expl/Returns Mean                          5883.46
expl/Returns Std                              0
expl/Returns Max                           5883.46
expl/Returns Min                           5883.46
expl/Actions Mean                             0.10766
expl/Actions Std                              0.796068
expl/Actions Max                              0.999238
expl/Actions Min                             -0.999372
expl/Num Paths                                1
expl/Average Returns                       5883.46
expl/env_infos/final/reward_run Mean          7.12607
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.12607
expl/env_infos/final/reward_run Min           7.12607
expl/env_infos/initial/reward_run Mean       -0.402374
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.402374
expl/env_infos/initial/reward_run Min        -0.402374
expl/env_infos/reward_run Mean                6.27065
expl/env_infos/reward_run Std                 1.24332
expl/env_infos/reward_run Max                 8.65752
expl/env_infos/reward_run Min                -0.402374
expl/env_infos/final/reward_ctrl Mean        -0.273684
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.273684
expl/env_infos/final/reward_ctrl Min         -0.273684
expl/env_infos/initial/reward_ctrl Mean      -0.212688
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.212688
expl/env_infos/initial/reward_ctrl Min       -0.212688
expl/env_infos/reward_ctrl Mean              -0.387189
expl/env_infos/reward_ctrl Std                0.091715
expl/env_infos/reward_ctrl Max               -0.0838789
expl/env_infos/reward_ctrl Min               -0.582623
eval/num steps total                          1.9e+06
eval/num paths total                       1900
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.17038
eval/Rewards Std                              1.32876
eval/Rewards Max                              8.80312
eval/Rewards Min                             -0.626285
eval/Returns Mean                          6170.38
eval/Returns Std                            115.601
eval/Returns Max                           6312.18
eval/Returns Min                           6018.06
eval/Actions Mean                             0.103213
eval/Actions Std                              0.814589
eval/Actions Max                              0.995317
eval/Actions Min                             -0.995148
eval/Num Paths                                5
eval/Average Returns                       6170.38
eval/env_infos/final/reward_run Mean          7.45223
eval/env_infos/final/reward_run Std           0.622977
eval/env_infos/final/reward_run Max           8.35722
eval/env_infos/final/reward_run Min           6.67457
eval/env_infos/initial/reward_run Mean       -0.200892
eval/env_infos/initial/reward_run Std         0.321398
eval/env_infos/initial/reward_run Max         0.420486
eval/env_infos/initial/reward_run Min        -0.46142
eval/env_infos/reward_run Mean                6.5749
eval/env_infos/reward_run Std                 1.31907
eval/env_infos/reward_run Max                 9.35351
eval/env_infos/reward_run Min                -0.46142
eval/env_infos/final/reward_ctrl Mean        -0.399138
eval/env_infos/final/reward_ctrl Std          0.0924699
eval/env_infos/final/reward_ctrl Max         -0.245642
eval/env_infos/final/reward_ctrl Min         -0.513663
eval/env_infos/initial/reward_ctrl Mean      -0.171003
eval/env_infos/initial/reward_ctrl Std        0.038773
eval/env_infos/initial/reward_ctrl Max       -0.106037
eval/env_infos/initial/reward_ctrl Min       -0.226861
eval/env_infos/reward_ctrl Mean              -0.404525
eval/env_infos/reward_ctrl Std                0.090012
eval/env_infos/reward_ctrl Max               -0.0818333
eval/env_infos/reward_ctrl Min               -0.582221
time/data storing (s)                         0.00454132
time/evaluation sampling (s)                  2.00777
time/exploration sampling (s)                 0.535592
time/logging (s)                              0.0138134
time/sac training (s)                         7.54335
time/saving (s)                               0.00377612
time/training (s)                             3.5321e-05
time/epoch (s)                               10.1089
time/total (s)                             4011.04
Epoch                                       379
---------------------------------------  ---------------
2021-11-24 01:36:17.011314 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 380 finished
---------------------------------------  ---------------
epoch                                       380
replay_buffer/size                       382000
trainer/num train calls                  381000
trainer/QF1 Loss                              5.43751
trainer/QF2 Loss                              4.56755
trainer/Policy Loss                        -403.353
trainer/Q1 Predictions Mean                 404.268
trainer/Q1 Predictions Std                   92.0276
trainer/Q1 Predictions Max                  476.211
trainer/Q1 Predictions Min                   19.5682
trainer/Q2 Predictions Mean                 404.065
trainer/Q2 Predictions Std                   91.9893
trainer/Q2 Predictions Max                  476.316
trainer/Q2 Predictions Min                   19.7088
trainer/Q Targets Mean                      404.146
trainer/Q Targets Std                        92.2396
trainer/Q Targets Max                       478.818
trainer/Q Targets Min                        18.8424
trainer/Log Pis Mean                          6.09757
trainer/Log Pis Std                           4.19485
trainer/Log Pis Max                          17.0838
trainer/Log Pis Min                          -5.08012
trainer/policy/mean Mean                      0.083808
trainer/policy/mean Std                       0.778892
trainer/policy/mean Max                       0.99753
trainer/policy/mean Min                      -0.996046
trainer/policy/normal/std Mean                0.434376
trainer/policy/normal/std Std                 0.147687
trainer/policy/normal/std Max                 1.02647
trainer/policy/normal/std Min                 0.0674689
trainer/policy/normal/log_std Mean           -0.9133
trainer/policy/normal/log_std Std             0.443055
trainer/policy/normal/log_std Max             0.0261257
trainer/policy/normal/log_std Min            -2.69609
trainer/Alpha                                 0.146382
trainer/Alpha Loss                            0.187483
expl/num steps total                     382000
expl/num paths total                        382
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.69757
expl/Rewards Std                              1.21484
expl/Rewards Max                              8.09241
expl/Rewards Min                             -0.478908
expl/Returns Mean                          5697.57
expl/Returns Std                              0
expl/Returns Max                           5697.57
expl/Returns Min                           5697.57
expl/Actions Mean                             0.0947869
expl/Actions Std                              0.79202
expl/Actions Max                              0.999552
expl/Actions Min                             -0.999302
expl/Num Paths                                1
expl/Average Returns                       5697.57
expl/env_infos/final/reward_run Mean          6.92096
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.92096
expl/env_infos/final/reward_run Min           6.92096
expl/env_infos/initial/reward_run Mean       -0.339723
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.339723
expl/env_infos/initial/reward_run Min        -0.339723
expl/env_infos/reward_run Mean                6.07933
expl/env_infos/reward_run Std                 1.20629
expl/env_infos/reward_run Max                 8.63667
expl/env_infos/reward_run Min                -0.339723
expl/env_infos/final/reward_ctrl Mean        -0.217831
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.217831
expl/env_infos/final/reward_ctrl Min         -0.217831
expl/env_infos/initial/reward_ctrl Mean      -0.139186
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.139186
expl/env_infos/initial/reward_ctrl Min       -0.139186
expl/env_infos/reward_ctrl Mean              -0.381768
expl/env_infos/reward_ctrl Std                0.0933873
expl/env_infos/reward_ctrl Max               -0.0675863
expl/env_infos/reward_ctrl Min               -0.581667
eval/num steps total                          1.905e+06
eval/num paths total                       1905
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.24265
eval/Rewards Std                              1.29018
eval/Rewards Max                              8.56361
eval/Rewards Min                             -0.715409
eval/Returns Mean                          6242.65
eval/Returns Std                             93.4726
eval/Returns Max                           6330.37
eval/Returns Min                           6093.44
eval/Actions Mean                             0.0821769
eval/Actions Std                              0.814851
eval/Actions Max                              0.99561
eval/Actions Min                             -0.991981
eval/Num Paths                                5
eval/Average Returns                       6242.65
eval/env_infos/final/reward_run Mean          7.0229
eval/env_infos/final/reward_run Std           0.819068
eval/env_infos/final/reward_run Max           7.91702
eval/env_infos/final/reward_run Min           5.84739
eval/env_infos/initial/reward_run Mean       -0.193005
eval/env_infos/initial/reward_run Std         0.325817
eval/env_infos/initial/reward_run Max         0.317235
eval/env_infos/initial/reward_run Min        -0.510804
eval/env_infos/reward_run Mean                6.64509
eval/env_infos/reward_run Std                 1.28698
eval/env_infos/reward_run Max                 9.08072
eval/env_infos/reward_run Min                -0.510804
eval/env_infos/final/reward_ctrl Mean        -0.42356
eval/env_infos/final/reward_ctrl Std          0.0808259
eval/env_infos/final/reward_ctrl Max         -0.283561
eval/env_infos/final/reward_ctrl Min         -0.508741
eval/env_infos/initial/reward_ctrl Mean      -0.166546
eval/env_infos/initial/reward_ctrl Std        0.0453155
eval/env_infos/initial/reward_ctrl Max       -0.0818751
eval/env_infos/initial/reward_ctrl Min       -0.204605
eval/env_infos/reward_ctrl Mean              -0.402441
eval/env_infos/reward_ctrl Std                0.087693
eval/env_infos/reward_ctrl Max               -0.0588916
eval/env_infos/reward_ctrl Min               -0.57714
time/data storing (s)                         0.00448784
time/evaluation sampling (s)                  2.01175
time/exploration sampling (s)                 0.532971
time/logging (s)                              0.0138805
time/sac training (s)                         7.45689
time/saving (s)                               0.00378452
time/training (s)                             3.4265e-05
time/epoch (s)                               10.0238
time/total (s)                             4021.34
Epoch                                       380
---------------------------------------  ---------------
2021-11-24 01:36:27.276857 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 381 finished
---------------------------------------  ---------------
epoch                                       381
replay_buffer/size                       383000
trainer/num train calls                  382000
trainer/QF1 Loss                              5.01358
trainer/QF2 Loss                              5.03766
trainer/Policy Loss                        -402.976
trainer/Q1 Predictions Mean                 403.59
trainer/Q1 Predictions Std                   97.6599
trainer/Q1 Predictions Max                  472.292
trainer/Q1 Predictions Min                   21.4392
trainer/Q2 Predictions Mean                 403.725
trainer/Q2 Predictions Std                   97.7018
trainer/Q2 Predictions Max                  473.126
trainer/Q2 Predictions Min                   21.3115
trainer/Q Targets Mean                      403.565
trainer/Q Targets Std                        97.6177
trainer/Q Targets Max                       471.98
trainer/Q Targets Min                        19.4443
trainer/Log Pis Mean                          6.45006
trainer/Log Pis Std                           4.5298
trainer/Log Pis Max                          17.3771
trainer/Log Pis Min                          -6.77781
trainer/policy/mean Mean                      0.083957
trainer/policy/mean Std                       0.788435
trainer/policy/mean Max                       0.996117
trainer/policy/mean Min                      -0.997294
trainer/policy/normal/std Mean                0.441164
trainer/policy/normal/std Std                 0.141814
trainer/policy/normal/std Max                 1.02125
trainer/policy/normal/std Min                 0.074135
trainer/policy/normal/log_std Mean           -0.890009
trainer/policy/normal/log_std Std             0.420805
trainer/policy/normal/log_std Max             0.0210292
trainer/policy/normal/log_std Min            -2.60187
trainer/Alpha                                 0.146033
trainer/Alpha Loss                            0.865873
expl/num steps total                     383000
expl/num paths total                        383
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.92089
expl/Rewards Std                              1.29691
expl/Rewards Max                              8.38664
expl/Rewards Min                             -0.524244
expl/Returns Mean                          5920.89
expl/Returns Std                              0
expl/Returns Max                           5920.89
expl/Returns Min                           5920.89
expl/Actions Mean                             0.105827
expl/Actions Std                              0.802301
expl/Actions Max                              0.999395
expl/Actions Min                             -0.999964
expl/Num Paths                                1
expl/Average Returns                       5920.89
expl/env_infos/final/reward_run Mean          6.2141
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.2141
expl/env_infos/final/reward_run Min           6.2141
expl/env_infos/initial/reward_run Mean       -0.412975
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.412975
expl/env_infos/initial/reward_run Min        -0.412975
expl/env_infos/reward_run Mean                6.31382
expl/env_infos/reward_run Std                 1.29555
expl/env_infos/reward_run Max                 8.84071
expl/env_infos/reward_run Min                -0.412975
expl/env_infos/final/reward_ctrl Mean        -0.475131
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.475131
expl/env_infos/final/reward_ctrl Min         -0.475131
expl/env_infos/initial/reward_ctrl Mean      -0.111269
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.111269
expl/env_infos/initial/reward_ctrl Min       -0.111269
expl/env_infos/reward_ctrl Mean              -0.392932
expl/env_infos/reward_ctrl Std                0.0891156
expl/env_infos/reward_ctrl Max               -0.0926086
expl/env_infos/reward_ctrl Min               -0.581682
eval/num steps total                          1.91e+06
eval/num paths total                       1910
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.10423
eval/Rewards Std                              1.29213
eval/Rewards Max                              8.61552
eval/Rewards Min                             -0.819693
eval/Returns Mean                          6104.23
eval/Returns Std                             39.032
eval/Returns Max                           6136.11
eval/Returns Min                           6038.18
eval/Actions Mean                             0.0913273
eval/Actions Std                              0.819279
eval/Actions Max                              0.99824
eval/Actions Min                             -0.998816
eval/Num Paths                                5
eval/Average Returns                       6104.23
eval/env_infos/final/reward_run Mean          7.45787
eval/env_infos/final/reward_run Std           0.380359
eval/env_infos/final/reward_run Max           7.79832
eval/env_infos/final/reward_run Min           6.71446
eval/env_infos/initial/reward_run Mean       -0.0419135
eval/env_infos/initial/reward_run Std         0.545315
eval/env_infos/initial/reward_run Max         0.878874
eval/env_infos/initial/reward_run Min        -0.652176
eval/env_infos/reward_run Mean                6.51196
eval/env_infos/reward_run Std                 1.28905
eval/env_infos/reward_run Max                 9.13586
eval/env_infos/reward_run Min                -0.652176
eval/env_infos/final/reward_ctrl Mean        -0.336651
eval/env_infos/final/reward_ctrl Std          0.112405
eval/env_infos/final/reward_ctrl Max         -0.130462
eval/env_infos/final/reward_ctrl Min         -0.442863
eval/env_infos/initial/reward_ctrl Mean      -0.181802
eval/env_infos/initial/reward_ctrl Std        0.0248594
eval/env_infos/initial/reward_ctrl Max       -0.151329
eval/env_infos/initial/reward_ctrl Min       -0.226024
eval/env_infos/reward_ctrl Mean              -0.407736
eval/env_infos/reward_ctrl Std                0.0891497
eval/env_infos/reward_ctrl Max               -0.106987
eval/env_infos/reward_ctrl Min               -0.57431
time/data storing (s)                         0.00454963
time/evaluation sampling (s)                  1.99989
time/exploration sampling (s)                 0.523588
time/logging (s)                              0.0136112
time/sac training (s)                         7.42424
time/saving (s)                               0.00378275
time/training (s)                             3.5011e-05
time/epoch (s)                                9.9697
time/total (s)                             4031.59
Epoch                                       381
---------------------------------------  ---------------
2021-11-24 01:36:37.596112 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 382 finished
---------------------------------------  ---------------
epoch                                       382
replay_buffer/size                       384000
trainer/num train calls                  383000
trainer/QF1 Loss                              4.53109
trainer/QF2 Loss                              5.09919
trainer/Policy Loss                        -395.878
trainer/Q1 Predictions Mean                 396.495
trainer/Q1 Predictions Std                  102.518
trainer/Q1 Predictions Max                  478.245
trainer/Q1 Predictions Min                   22.0254
trainer/Q2 Predictions Mean                 396.784
trainer/Q2 Predictions Std                  102.624
trainer/Q2 Predictions Max                  478.156
trainer/Q2 Predictions Min                   22.2801
trainer/Q Targets Mean                      396.478
trainer/Q Targets Std                       102.591
trainer/Q Targets Max                       477.997
trainer/Q Targets Min                        22.0414
trainer/Log Pis Mean                          5.95807
trainer/Log Pis Std                           4.40038
trainer/Log Pis Max                          16.9101
trainer/Log Pis Min                          -5.69126
trainer/policy/mean Mean                      0.0746847
trainer/policy/mean Std                       0.7716
trainer/policy/mean Max                       0.997827
trainer/policy/mean Min                      -0.99503
trainer/policy/normal/std Mean                0.446167
trainer/policy/normal/std Std                 0.148153
trainer/policy/normal/std Max                 0.930137
trainer/policy/normal/std Min                 0.0678697
trainer/policy/normal/log_std Mean           -0.883437
trainer/policy/normal/log_std Std             0.435838
trainer/policy/normal/log_std Max            -0.0724231
trainer/policy/normal/log_std Min            -2.69017
trainer/Alpha                                 0.148323
trainer/Alpha Loss                           -0.0800231
expl/num steps total                     384000
expl/num paths total                        384
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00697
expl/Rewards Std                              1.26096
expl/Rewards Max                              8.48577
expl/Rewards Min                             -0.0175699
expl/Returns Mean                          6006.97
expl/Returns Std                              0
expl/Returns Max                           6006.97
expl/Returns Min                           6006.97
expl/Actions Mean                             0.0974538
expl/Actions Std                              0.802647
expl/Actions Max                              0.999792
expl/Actions Min                             -0.999557
expl/Num Paths                                1
expl/Average Returns                       6006.97
expl/env_infos/final/reward_run Mean          7.531
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.531
expl/env_infos/final/reward_run Min           7.531
expl/env_infos/initial/reward_run Mean        0.172871
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.172871
expl/env_infos/initial/reward_run Min         0.172871
expl/env_infos/reward_run Mean                6.39921
expl/env_infos/reward_run Std                 1.2504
expl/env_infos/reward_run Max                 8.88042
expl/env_infos/reward_run Min                 0.172871
expl/env_infos/final/reward_ctrl Mean        -0.426007
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.426007
expl/env_infos/final/reward_ctrl Min         -0.426007
expl/env_infos/initial/reward_ctrl Mean      -0.126352
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.126352
expl/env_infos/initial/reward_ctrl Min       -0.126352
expl/env_infos/reward_ctrl Mean              -0.392244
expl/env_infos/reward_ctrl Std                0.0905652
expl/env_infos/reward_ctrl Max               -0.118709
expl/env_infos/reward_ctrl Min               -0.576145
eval/num steps total                          1.915e+06
eval/num paths total                       1915
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.26506
eval/Rewards Std                              1.33329
eval/Rewards Max                              8.87361
eval/Rewards Min                             -0.771358
eval/Returns Mean                          6265.06
eval/Returns Std                             24.5733
eval/Returns Max                           6312.65
eval/Returns Min                           6245.78
eval/Actions Mean                             0.0929475
eval/Actions Std                              0.819589
eval/Actions Max                              0.996401
eval/Actions Min                             -0.997294
eval/Num Paths                                5
eval/Average Returns                       6265.06
eval/env_infos/final/reward_run Mean          7.036
eval/env_infos/final/reward_run Std           0.991483
eval/env_infos/final/reward_run Max           8.32986
eval/env_infos/final/reward_run Min           5.67882
eval/env_infos/initial/reward_run Mean       -0.370064
eval/env_infos/initial/reward_run Std         0.132935
eval/env_infos/initial/reward_run Max        -0.197525
eval/env_infos/initial/reward_run Min        -0.592358
eval/env_infos/reward_run Mean                6.67328
eval/env_infos/reward_run Std                 1.321
eval/env_infos/reward_run Max                 9.36533
eval/env_infos/reward_run Min                -0.592358
eval/env_infos/final/reward_ctrl Mean        -0.396396
eval/env_infos/final/reward_ctrl Std          0.0734251
eval/env_infos/final/reward_ctrl Max         -0.274705
eval/env_infos/final/reward_ctrl Min         -0.473285
eval/env_infos/initial/reward_ctrl Mean      -0.189052
eval/env_infos/initial/reward_ctrl Std        0.020993
eval/env_infos/initial/reward_ctrl Max       -0.163104
eval/env_infos/initial/reward_ctrl Min       -0.225421
eval/env_infos/reward_ctrl Mean              -0.408219
eval/env_infos/reward_ctrl Std                0.0903752
eval/env_infos/reward_ctrl Max               -0.106227
eval/env_infos/reward_ctrl Min               -0.5753
time/data storing (s)                         0.00450954
time/evaluation sampling (s)                  2.01813
time/exploration sampling (s)                 0.538411
time/logging (s)                              0.0135475
time/sac training (s)                         7.44507
time/saving (s)                               0.00375751
time/training (s)                             3.4691e-05
time/epoch (s)                               10.0235
time/total (s)                             4041.9
Epoch                                       382
---------------------------------------  ---------------
2021-11-24 01:36:47.907721 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 383 finished
---------------------------------------  ---------------
epoch                                       383
replay_buffer/size                       385000
trainer/num train calls                  384000
trainer/QF1 Loss                              5.89289
trainer/QF2 Loss                              5.39384
trainer/Policy Loss                        -389.998
trainer/Q1 Predictions Mean                 390.26
trainer/Q1 Predictions Std                  108.683
trainer/Q1 Predictions Max                  476.746
trainer/Q1 Predictions Min                   19.4553
trainer/Q2 Predictions Mean                 390.608
trainer/Q2 Predictions Std                  108.814
trainer/Q2 Predictions Max                  476.457
trainer/Q2 Predictions Min                   19.1201
trainer/Q Targets Mean                      390.797
trainer/Q Targets Std                       108.94
trainer/Q Targets Max                       478.574
trainer/Q Targets Min                        19.5477
trainer/Log Pis Mean                          5.89282
trainer/Log Pis Std                           4.66289
trainer/Log Pis Max                          18.5265
trainer/Log Pis Min                          -5.21298
trainer/policy/mean Mean                      0.0757601
trainer/policy/mean Std                       0.768
trainer/policy/mean Max                       0.995677
trainer/policy/mean Min                      -0.99182
trainer/policy/normal/std Mean                0.450291
trainer/policy/normal/std Std                 0.153098
trainer/policy/normal/std Max                 1.22671
trainer/policy/normal/std Min                 0.0707338
trainer/policy/normal/log_std Mean           -0.873588
trainer/policy/normal/log_std Std             0.428955
trainer/policy/normal/log_std Max             0.204334
trainer/policy/normal/log_std Min            -2.64883
trainer/Alpha                                 0.14822
trainer/Alpha Loss                           -0.204605
expl/num steps total                     385000
expl/num paths total                        385
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.01031
expl/Rewards Std                              1.28459
expl/Rewards Max                              8.32031
expl/Rewards Min                             -0.834537
expl/Returns Mean                          6010.31
expl/Returns Std                              0
expl/Returns Max                           6010.31
expl/Returns Min                           6010.31
expl/Actions Mean                             0.106903
expl/Actions Std                              0.81025
expl/Actions Max                              0.999794
expl/Actions Min                             -0.998687
expl/Num Paths                                1
expl/Average Returns                       6010.31
expl/env_infos/final/reward_run Mean          5.7376
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.7376
expl/env_infos/final/reward_run Min           5.7376
expl/env_infos/initial/reward_run Mean       -0.651988
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.651988
expl/env_infos/initial/reward_run Min        -0.651988
expl/env_infos/reward_run Mean                6.41107
expl/env_infos/reward_run Std                 1.27928
expl/env_infos/reward_run Max                 8.86435
expl/env_infos/reward_run Min                -0.651988
expl/env_infos/final/reward_ctrl Mean        -0.541594
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.541594
expl/env_infos/final/reward_ctrl Min         -0.541594
expl/env_infos/initial/reward_ctrl Mean      -0.182549
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.182549
expl/env_infos/initial/reward_ctrl Min       -0.182549
expl/env_infos/reward_ctrl Mean              -0.40076
expl/env_infos/reward_ctrl Std                0.0924211
expl/env_infos/reward_ctrl Max               -0.105124
expl/env_infos/reward_ctrl Min               -0.566181
eval/num steps total                          1.92e+06
eval/num paths total                       1920
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.25211
eval/Rewards Std                              1.32524
eval/Rewards Max                              8.71819
eval/Rewards Min                             -0.662142
eval/Returns Mean                          6252.11
eval/Returns Std                             49.5147
eval/Returns Max                           6335.84
eval/Returns Min                           6193.93
eval/Actions Mean                             0.0981094
eval/Actions Std                              0.823794
eval/Actions Max                              0.996379
eval/Actions Min                             -0.994823
eval/Num Paths                                5
eval/Average Returns                       6252.11
eval/env_infos/final/reward_run Mean          7.27773
eval/env_infos/final/reward_run Std           0.529501
eval/env_infos/final/reward_run Max           8.24067
eval/env_infos/final/reward_run Min           6.83142
eval/env_infos/initial/reward_run Mean       -0.321824
eval/env_infos/initial/reward_run Std         0.0677983
eval/env_infos/initial/reward_run Max        -0.219097
eval/env_infos/initial/reward_run Min        -0.419707
eval/env_infos/reward_run Mean                6.66507
eval/env_infos/reward_run Std                 1.31791
eval/env_infos/reward_run Max                 9.27224
eval/env_infos/reward_run Min                -0.419707
eval/env_infos/final/reward_ctrl Mean        -0.484131
eval/env_infos/final/reward_ctrl Std          0.048186
eval/env_infos/final/reward_ctrl Max         -0.402397
eval/env_infos/final/reward_ctrl Min         -0.539505
eval/env_infos/initial/reward_ctrl Mean      -0.19551
eval/env_infos/initial/reward_ctrl Std        0.0465285
eval/env_infos/initial/reward_ctrl Max       -0.13453
eval/env_infos/initial/reward_ctrl Min       -0.256985
eval/env_infos/reward_ctrl Mean              -0.412958
eval/env_infos/reward_ctrl Std                0.0926402
eval/env_infos/reward_ctrl Max               -0.0461527
eval/env_infos/reward_ctrl Min               -0.570944
time/data storing (s)                         0.00444708
time/evaluation sampling (s)                  2.00482
time/exploration sampling (s)                 0.540099
time/logging (s)                              0.0135778
time/sac training (s)                         7.44972
time/saving (s)                               0.00374864
time/training (s)                             3.4037e-05
time/epoch (s)                               10.0164
time/total (s)                             4052.19
Epoch                                       383
---------------------------------------  ---------------
2021-11-24 01:36:58.186323 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 384 finished
---------------------------------------  ---------------
epoch                                       384
replay_buffer/size                       386000
trainer/num train calls                  385000
trainer/QF1 Loss                              5.92977
trainer/QF2 Loss                              5.96102
trainer/Policy Loss                        -393.84
trainer/Q1 Predictions Mean                 394.529
trainer/Q1 Predictions Std                  106.456
trainer/Q1 Predictions Max                  473.122
trainer/Q1 Predictions Min                   19.7923
trainer/Q2 Predictions Mean                 394.479
trainer/Q2 Predictions Std                  106.179
trainer/Q2 Predictions Max                  473.246
trainer/Q2 Predictions Min                   19.4639
trainer/Q Targets Mean                      394.686
trainer/Q Targets Std                       106.594
trainer/Q Targets Max                       473.725
trainer/Q Targets Min                        17.4156
trainer/Log Pis Mean                          6.25978
trainer/Log Pis Std                           4.25202
trainer/Log Pis Max                          17.0815
trainer/Log Pis Min                          -5.80558
trainer/policy/mean Mean                      0.0654008
trainer/policy/mean Std                       0.78355
trainer/policy/mean Max                       0.994126
trainer/policy/mean Min                      -0.996736
trainer/policy/normal/std Mean                0.446717
trainer/policy/normal/std Std                 0.143589
trainer/policy/normal/std Max                 0.881086
trainer/policy/normal/std Min                 0.0637624
trainer/policy/normal/log_std Mean           -0.875192
trainer/policy/normal/log_std Std             0.411917
trainer/policy/normal/log_std Max            -0.1266
trainer/policy/normal/log_std Min            -2.75259
trainer/Alpha                                 0.148893
trainer/Alpha Loss                            0.494755
expl/num steps total                     386000
expl/num paths total                        386
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.74748
expl/Rewards Std                              1.27099
expl/Rewards Max                              8.13303
expl/Rewards Min                             -0.640406
expl/Returns Mean                          5747.48
expl/Returns Std                              0
expl/Returns Max                           5747.48
expl/Returns Min                           5747.48
expl/Actions Mean                             0.0988977
expl/Actions Std                              0.797159
expl/Actions Max                              0.999252
expl/Actions Min                             -0.999238
expl/Num Paths                                1
expl/Average Returns                       5747.48
expl/env_infos/final/reward_run Mean          5.50867
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.50867
expl/env_infos/final/reward_run Min           5.50867
expl/env_infos/initial/reward_run Mean       -0.401962
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.401962
expl/env_infos/initial/reward_run Min        -0.401962
expl/env_infos/reward_run Mean                6.13463
expl/env_infos/reward_run Std                 1.26598
expl/env_infos/reward_run Max                 8.53329
expl/env_infos/reward_run Min                -0.401962
expl/env_infos/final/reward_ctrl Mean        -0.272071
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.272071
expl/env_infos/final/reward_ctrl Min         -0.272071
expl/env_infos/initial/reward_ctrl Mean      -0.238443
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.238443
expl/env_infos/initial/reward_ctrl Min       -0.238443
expl/env_infos/reward_ctrl Mean              -0.387146
expl/env_infos/reward_ctrl Std                0.0886075
expl/env_infos/reward_ctrl Max               -0.0570518
expl/env_infos/reward_ctrl Min               -0.570776
eval/num steps total                          1.925e+06
eval/num paths total                       1925
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.27898
eval/Rewards Std                              1.32499
eval/Rewards Max                              8.65875
eval/Rewards Min                             -0.732235
eval/Returns Mean                          6278.98
eval/Returns Std                             60.9075
eval/Returns Max                           6347.17
eval/Returns Min                           6203.74
eval/Actions Mean                             0.084236
eval/Actions Std                              0.820029
eval/Actions Max                              0.995698
eval/Actions Min                             -0.995673
eval/Num Paths                                5
eval/Average Returns                       6278.98
eval/env_infos/final/reward_run Mean          7.65841
eval/env_infos/final/reward_run Std           0.653651
eval/env_infos/final/reward_run Max           8.57106
eval/env_infos/final/reward_run Min           6.58879
eval/env_infos/initial/reward_run Mean       -0.245198
eval/env_infos/initial/reward_run Std         0.333721
eval/env_infos/initial/reward_run Max         0.404208
eval/env_infos/initial/reward_run Min        -0.508588
eval/env_infos/reward_run Mean                6.68671
eval/env_infos/reward_run Std                 1.31978
eval/env_infos/reward_run Max                 9.18372
eval/env_infos/reward_run Min                -0.508588
eval/env_infos/final/reward_ctrl Mean        -0.393797
eval/env_infos/final/reward_ctrl Std          0.0782936
eval/env_infos/final/reward_ctrl Max         -0.303761
eval/env_infos/final/reward_ctrl Min         -0.536132
eval/env_infos/initial/reward_ctrl Mean      -0.1935
eval/env_infos/initial/reward_ctrl Std        0.0294482
eval/env_infos/initial/reward_ctrl Max       -0.147081
eval/env_infos/initial/reward_ctrl Min       -0.239184
eval/env_infos/reward_ctrl Mean              -0.407726
eval/env_infos/reward_ctrl Std                0.0827664
eval/env_infos/reward_ctrl Max               -0.100283
eval/env_infos/reward_ctrl Min               -0.573117
time/data storing (s)                         0.00448938
time/evaluation sampling (s)                  1.97817
time/exploration sampling (s)                 0.523261
time/logging (s)                              0.0136044
time/sac training (s)                         7.45778
time/saving (s)                               0.0037765
time/training (s)                             3.36e-05
time/epoch (s)                                9.98111
time/total (s)                             4062.46
Epoch                                       384
---------------------------------------  ---------------
2021-11-24 01:37:08.464524 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 385 finished
---------------------------------------  ---------------
epoch                                       385
replay_buffer/size                       387000
trainer/num train calls                  386000
trainer/QF1 Loss                              6.94156
trainer/QF2 Loss                              5.64893
trainer/Policy Loss                        -403.835
trainer/Q1 Predictions Mean                 404.499
trainer/Q1 Predictions Std                   91.8911
trainer/Q1 Predictions Max                  479.825
trainer/Q1 Predictions Min                   19.5981
trainer/Q2 Predictions Mean                 404.453
trainer/Q2 Predictions Std                   91.8038
trainer/Q2 Predictions Max                  479.317
trainer/Q2 Predictions Min                   18.2619
trainer/Q Targets Mean                      404.185
trainer/Q Targets Std                        91.9552
trainer/Q Targets Max                       479.653
trainer/Q Targets Min                        18.0987
trainer/Log Pis Mean                          5.58017
trainer/Log Pis Std                           4.29024
trainer/Log Pis Max                          17.4149
trainer/Log Pis Min                          -6.2305
trainer/policy/mean Mean                      0.090721
trainer/policy/mean Std                       0.764544
trainer/policy/mean Max                       0.994982
trainer/policy/mean Min                      -0.997448
trainer/policy/normal/std Mean                0.441126
trainer/policy/normal/std Std                 0.145384
trainer/policy/normal/std Max                 1.06865
trainer/policy/normal/std Min                 0.0659095
trainer/policy/normal/log_std Mean           -0.890781
trainer/policy/normal/log_std Std             0.420312
trainer/policy/normal/log_std Max             0.0664006
trainer/policy/normal/log_std Min            -2.71947
trainer/Alpha                                 0.147092
trainer/Alpha Loss                           -0.804697
expl/num steps total                     387000
expl/num paths total                        387
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.95763
expl/Rewards Std                              1.27719
expl/Rewards Max                              8.65424
expl/Rewards Min                             -0.919054
expl/Returns Mean                          5957.63
expl/Returns Std                              0
expl/Returns Max                           5957.63
expl/Returns Min                           5957.63
expl/Actions Mean                             0.109556
expl/Actions Std                              0.794684
expl/Actions Max                              0.999544
expl/Actions Min                             -0.999397
expl/Num Paths                                1
expl/Average Returns                       5957.63
expl/env_infos/final/reward_run Mean          7.06838
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.06838
expl/env_infos/final/reward_run Min           7.06838
expl/env_infos/initial/reward_run Mean       -0.724585
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.724585
expl/env_infos/initial/reward_run Min        -0.724585
expl/env_infos/reward_run Mean                6.34375
expl/env_infos/reward_run Std                 1.27558
expl/env_infos/reward_run Max                 9.04013
expl/env_infos/reward_run Min                -0.724585
expl/env_infos/final/reward_ctrl Mean        -0.254879
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.254879
expl/env_infos/final/reward_ctrl Min         -0.254879
expl/env_infos/initial/reward_ctrl Mean      -0.19447
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.19447
expl/env_infos/initial/reward_ctrl Min       -0.19447
expl/env_infos/reward_ctrl Mean              -0.386115
expl/env_infos/reward_ctrl Std                0.0853635
expl/env_infos/reward_ctrl Max               -0.0565323
expl/env_infos/reward_ctrl Min               -0.560141
eval/num steps total                          1.93e+06
eval/num paths total                       1930
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.27656
eval/Rewards Std                              1.29779
eval/Rewards Max                              8.74635
eval/Rewards Min                             -0.807754
eval/Returns Mean                          6276.56
eval/Returns Std                             30.7915
eval/Returns Max                           6316.87
eval/Returns Min                           6234.03
eval/Actions Mean                             0.100461
eval/Actions Std                              0.813858
eval/Actions Max                              0.996818
eval/Actions Min                             -0.995608
eval/Num Paths                                5
eval/Average Returns                       6276.56
eval/env_infos/final/reward_run Mean          7.62246
eval/env_infos/final/reward_run Std           0.524675
eval/env_infos/final/reward_run Max           8.11775
eval/env_infos/final/reward_run Min           6.66413
eval/env_infos/initial/reward_run Mean       -0.233198
eval/env_infos/initial/reward_run Std         0.590471
eval/env_infos/initial/reward_run Max         0.937027
eval/env_infos/initial/reward_run Min        -0.614288
eval/env_infos/reward_run Mean                6.68003
eval/env_infos/reward_run Std                 1.29395
eval/env_infos/reward_run Max                 9.29502
eval/env_infos/reward_run Min                -0.614288
eval/env_infos/final/reward_ctrl Mean        -0.382806
eval/env_infos/final/reward_ctrl Std          0.0924092
eval/env_infos/final/reward_ctrl Max         -0.22092
eval/env_infos/final/reward_ctrl Min         -0.462654
eval/env_infos/initial/reward_ctrl Mean      -0.174693
eval/env_infos/initial/reward_ctrl Std        0.0210294
eval/env_infos/initial/reward_ctrl Max       -0.153754
eval/env_infos/initial/reward_ctrl Min       -0.205835
eval/env_infos/reward_ctrl Mean              -0.403474
eval/env_infos/reward_ctrl Std                0.0839142
eval/env_infos/reward_ctrl Max               -0.06254
eval/env_infos/reward_ctrl Min               -0.571415
time/data storing (s)                         0.00453411
time/evaluation sampling (s)                  1.98743
time/exploration sampling (s)                 0.532656
time/logging (s)                              0.0136338
time/sac training (s)                         7.44081
time/saving (s)                               0.00375528
time/training (s)                             3.5175e-05
time/epoch (s)                                9.98286
time/total (s)                             4072.72
Epoch                                       385
---------------------------------------  ---------------
2021-11-24 01:37:18.759163 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 386 finished
---------------------------------------  ---------------
epoch                                       386
replay_buffer/size                       388000
trainer/num train calls                  387000
trainer/QF1 Loss                              8.28943
trainer/QF2 Loss                              8.10396
trainer/Policy Loss                        -403.038
trainer/Q1 Predictions Mean                 403.694
trainer/Q1 Predictions Std                   96.2299
trainer/Q1 Predictions Max                  474.219
trainer/Q1 Predictions Min                   20.0881
trainer/Q2 Predictions Mean                 403.793
trainer/Q2 Predictions Std                   96.1136
trainer/Q2 Predictions Max                  474.166
trainer/Q2 Predictions Min                   20.2764
trainer/Q Targets Mean                      402.843
trainer/Q Targets Std                        96.3307
trainer/Q Targets Max                       476.22
trainer/Q Targets Min                        20.3206
trainer/Log Pis Mean                          6.12756
trainer/Log Pis Std                           4.25383
trainer/Log Pis Max                          15.6106
trainer/Log Pis Min                          -5.77129
trainer/policy/mean Mean                      0.0749668
trainer/policy/mean Std                       0.776268
trainer/policy/mean Max                       0.999359
trainer/policy/mean Min                      -0.997953
trainer/policy/normal/std Mean                0.434502
trainer/policy/normal/std Std                 0.148539
trainer/policy/normal/std Max                 1.90136
trainer/policy/normal/std Min                 0.0769011
trainer/policy/normal/log_std Mean           -0.907186
trainer/policy/normal/log_std Std             0.419262
trainer/policy/normal/log_std Max             0.642568
trainer/policy/normal/log_std Min            -2.56524
trainer/Alpha                                 0.146803
trainer/Alpha Loss                            0.244736
expl/num steps total                     388000
expl/num paths total                        388
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.7066
expl/Rewards Std                              1.24226
expl/Rewards Max                              8.18381
expl/Rewards Min                             -0.537783
expl/Returns Mean                          5706.6
expl/Returns Std                              0
expl/Returns Max                           5706.6
expl/Returns Min                           5706.6
expl/Actions Mean                             0.110054
expl/Actions Std                              0.793494
expl/Actions Max                              0.999016
expl/Actions Min                             -0.998912
expl/Num Paths                                1
expl/Average Returns                       5706.6
expl/env_infos/final/reward_run Mean          7.58646
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.58646
expl/env_infos/final/reward_run Min           7.58646
expl/env_infos/initial/reward_run Mean       -0.33076
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.33076
expl/env_infos/initial/reward_run Min        -0.33076
expl/env_infos/reward_run Mean                6.09165
expl/env_infos/reward_run Std                 1.23353
expl/env_infos/reward_run Max                 8.60666
expl/env_infos/reward_run Min                -0.33076
expl/env_infos/final/reward_ctrl Mean        -0.405096
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.405096
expl/env_infos/final/reward_ctrl Min         -0.405096
expl/env_infos/initial/reward_ctrl Mean      -0.207023
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.207023
expl/env_infos/initial/reward_ctrl Min       -0.207023
expl/env_infos/reward_ctrl Mean              -0.385047
expl/env_infos/reward_ctrl Std                0.0872488
expl/env_infos/reward_ctrl Max               -0.0687136
expl/env_infos/reward_ctrl Min               -0.573769
eval/num steps total                          1.935e+06
eval/num paths total                       1935
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.25742
eval/Rewards Std                              1.32572
eval/Rewards Max                              8.95664
eval/Rewards Min                             -0.955915
eval/Returns Mean                          6257.42
eval/Returns Std                             79.0597
eval/Returns Max                           6375.08
eval/Returns Min                           6148.49
eval/Actions Mean                             0.0955186
eval/Actions Std                              0.817934
eval/Actions Max                              0.99764
eval/Actions Min                             -0.994433
eval/Num Paths                                5
eval/Average Returns                       6257.42
eval/env_infos/final/reward_run Mean          6.84969
eval/env_infos/final/reward_run Std           0.612432
eval/env_infos/final/reward_run Max           7.82761
eval/env_infos/final/reward_run Min           6.04379
eval/env_infos/initial/reward_run Mean       -0.213834
eval/env_infos/initial/reward_run Std         0.302624
eval/env_infos/initial/reward_run Max         0.300016
eval/env_infos/initial/reward_run Min        -0.555194
eval/env_infos/reward_run Mean                6.6643
eval/env_infos/reward_run Std                 1.31716
eval/env_infos/reward_run Max                 9.44634
eval/env_infos/reward_run Min                -0.555194
eval/env_infos/final/reward_ctrl Mean        -0.458085
eval/env_infos/final/reward_ctrl Std          0.0389673
eval/env_infos/final/reward_ctrl Max         -0.381048
eval/env_infos/final/reward_ctrl Min         -0.486453
eval/env_infos/initial/reward_ctrl Mean      -0.202562
eval/env_infos/initial/reward_ctrl Std        0.0502488
eval/env_infos/initial/reward_ctrl Max       -0.129235
eval/env_infos/initial/reward_ctrl Min       -0.271063
eval/env_infos/reward_ctrl Mean              -0.406884
eval/env_infos/reward_ctrl Std                0.0822148
eval/env_infos/reward_ctrl Max               -0.110627
eval/env_infos/reward_ctrl Min               -0.565517
time/data storing (s)                         0.00445771
time/evaluation sampling (s)                  2.00899
time/exploration sampling (s)                 0.534336
time/logging (s)                              0.0136304
time/sac training (s)                         7.4358
time/saving (s)                               0.00375381
time/training (s)                             3.429e-05
time/epoch (s)                               10.001
time/total (s)                             4083
Epoch                                       386
---------------------------------------  ---------------
2021-11-24 01:37:29.100171 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 387 finished
---------------------------------------  ---------------
epoch                                       387
replay_buffer/size                       389000
trainer/num train calls                  388000
trainer/QF1 Loss                              5.83161
trainer/QF2 Loss                              6.65352
trainer/Policy Loss                        -400.36
trainer/Q1 Predictions Mean                 400.926
trainer/Q1 Predictions Std                  100.912
trainer/Q1 Predictions Max                  479.975
trainer/Q1 Predictions Min                   19.9036
trainer/Q2 Predictions Mean                 400.993
trainer/Q2 Predictions Std                  100.789
trainer/Q2 Predictions Max                  478.447
trainer/Q2 Predictions Min                   19.7353
trainer/Q Targets Mean                      400.834
trainer/Q Targets Std                       101.039
trainer/Q Targets Max                       478.717
trainer/Q Targets Min                        18.2856
trainer/Log Pis Mean                          5.99588
trainer/Log Pis Std                           4.13512
trainer/Log Pis Max                          15.3548
trainer/Log Pis Min                          -6.28698
trainer/policy/mean Mean                      0.0835294
trainer/policy/mean Std                       0.777779
trainer/policy/mean Max                       0.998494
trainer/policy/mean Min                      -0.996375
trainer/policy/normal/std Mean                0.441638
trainer/policy/normal/std Std                 0.148311
trainer/policy/normal/std Max                 0.94586
trainer/policy/normal/std Min                 0.0640682
trainer/policy/normal/log_std Mean           -0.892588
trainer/policy/normal/log_std Std             0.430411
trainer/policy/normal/log_std Max            -0.0556604
trainer/policy/normal/log_std Min            -2.74781
trainer/Alpha                                 0.150423
trainer/Alpha Loss                           -0.00780036
expl/num steps total                     389000
expl/num paths total                        389
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.77267
expl/Rewards Std                              1.24264
expl/Rewards Max                              8.11283
expl/Rewards Min                             -0.867845
expl/Returns Mean                          5772.67
expl/Returns Std                              0
expl/Returns Max                           5772.67
expl/Returns Min                           5772.67
expl/Actions Mean                             0.0907811
expl/Actions Std                              0.794257
expl/Actions Max                              0.999686
expl/Actions Min                             -0.999282
expl/Num Paths                                1
expl/Average Returns                       5772.67
expl/env_infos/final/reward_run Mean          6.7127
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.7127
expl/env_infos/final/reward_run Min           6.7127
expl/env_infos/initial/reward_run Mean       -0.5683
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.5683
expl/env_infos/initial/reward_run Min        -0.5683
expl/env_infos/reward_run Mean                6.15612
expl/env_infos/reward_run Std                 1.23962
expl/env_infos/reward_run Max                 8.62854
expl/env_infos/reward_run Min                -0.5683
expl/env_infos/final/reward_ctrl Mean        -0.403222
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.403222
expl/env_infos/final/reward_ctrl Min         -0.403222
expl/env_infos/initial/reward_ctrl Mean      -0.299545
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.299545
expl/env_infos/initial/reward_ctrl Min       -0.299545
expl/env_infos/reward_ctrl Mean              -0.383451
expl/env_infos/reward_ctrl Std                0.0903301
expl/env_infos/reward_ctrl Max               -0.097995
expl/env_infos/reward_ctrl Min               -0.556868
eval/num steps total                          1.94e+06
eval/num paths total                       1940
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.28247
eval/Rewards Std                              1.3197
eval/Rewards Max                              8.76975
eval/Rewards Min                             -1.14718
eval/Returns Mean                          6282.47
eval/Returns Std                             44.2877
eval/Returns Max                           6339.72
eval/Returns Min                           6207.29
eval/Actions Mean                             0.0824318
eval/Actions Std                              0.814307
eval/Actions Max                              0.996285
eval/Actions Min                             -0.997507
eval/Num Paths                                5
eval/Average Returns                       6282.47
eval/env_infos/final/reward_run Mean          7.48817
eval/env_infos/final/reward_run Std           0.999835
eval/env_infos/final/reward_run Max           8.34927
eval/env_infos/final/reward_run Min           5.88293
eval/env_infos/initial/reward_run Mean       -0.541099
eval/env_infos/initial/reward_run Std         0.216482
eval/env_infos/initial/reward_run Max        -0.307702
eval/env_infos/initial/reward_run Min        -0.902464
eval/env_infos/reward_run Mean                6.68441
eval/env_infos/reward_run Std                 1.30925
eval/env_infos/reward_run Max                 9.23084
eval/env_infos/reward_run Min                -0.902464
eval/env_infos/final/reward_ctrl Mean        -0.425386
eval/env_infos/final/reward_ctrl Std          0.0151016
eval/env_infos/final/reward_ctrl Max         -0.402088
eval/env_infos/final/reward_ctrl Min         -0.443907
eval/env_infos/initial/reward_ctrl Mean      -0.196714
eval/env_infos/initial/reward_ctrl Std        0.0300497
eval/env_infos/initial/reward_ctrl Max       -0.166457
eval/env_infos/initial/reward_ctrl Min       -0.244716
eval/env_infos/reward_ctrl Mean              -0.401935
eval/env_infos/reward_ctrl Std                0.0879515
eval/env_infos/reward_ctrl Max               -0.0615874
eval/env_infos/reward_ctrl Min               -0.567373
time/data storing (s)                         0.00450368
time/evaluation sampling (s)                  2.04089
time/exploration sampling (s)                 0.531217
time/logging (s)                              0.0135916
time/sac training (s)                         7.45054
time/saving (s)                               0.00376646
time/training (s)                             3.5283e-05
time/epoch (s)                               10.0445
time/total (s)                             4093.33
Epoch                                       387
---------------------------------------  ---------------
2021-11-24 01:37:39.405333 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 388 finished
---------------------------------------  ---------------
epoch                                       388
replay_buffer/size                       390000
trainer/num train calls                  389000
trainer/QF1 Loss                              5.17889
trainer/QF2 Loss                              5.42075
trainer/Policy Loss                        -401.601
trainer/Q1 Predictions Mean                 401.991
trainer/Q1 Predictions Std                  100.738
trainer/Q1 Predictions Max                  474.31
trainer/Q1 Predictions Min                   20.2362
trainer/Q2 Predictions Mean                 402.046
trainer/Q2 Predictions Std                  100.668
trainer/Q2 Predictions Max                  473.141
trainer/Q2 Predictions Min                   19.7018
trainer/Q Targets Mean                      401.817
trainer/Q Targets Std                       100.56
trainer/Q Targets Max                       474.52
trainer/Q Targets Min                        19.703
trainer/Log Pis Mean                          5.81198
trainer/Log Pis Std                           4.19107
trainer/Log Pis Max                          15.9217
trainer/Log Pis Min                          -4.49732
trainer/policy/mean Mean                      0.0990333
trainer/policy/mean Std                       0.762446
trainer/policy/mean Max                       0.996342
trainer/policy/mean Min                      -0.995142
trainer/policy/normal/std Mean                0.438165
trainer/policy/normal/std Std                 0.151298
trainer/policy/normal/std Max                 0.994439
trainer/policy/normal/std Min                 0.0532738
trainer/policy/normal/log_std Mean           -0.910039
trainer/policy/normal/log_std Std             0.463441
trainer/policy/normal/log_std Max            -0.00557645
trainer/policy/normal/log_std Min            -2.93231
trainer/Alpha                                 0.149122
trainer/Alpha Loss                           -0.357799
expl/num steps total                     390000
expl/num paths total                        390
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.02064
expl/Rewards Std                              1.27377
expl/Rewards Max                              8.26387
expl/Rewards Min                             -0.617005
expl/Returns Mean                          6020.64
expl/Returns Std                              0
expl/Returns Max                           6020.64
expl/Returns Min                           6020.64
expl/Actions Mean                             0.123058
expl/Actions Std                              0.797298
expl/Actions Max                              0.999701
expl/Actions Min                             -0.999416
expl/Num Paths                                1
expl/Average Returns                       6020.64
expl/env_infos/final/reward_run Mean          6.22674
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.22674
expl/env_infos/final/reward_run Min           6.22674
expl/env_infos/initial/reward_run Mean       -0.401998
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.401998
expl/env_infos/initial/reward_run Min        -0.401998
expl/env_infos/reward_run Mean                6.41113
expl/env_infos/reward_run Std                 1.26723
expl/env_infos/reward_run Max                 8.79876
expl/env_infos/reward_run Min                -0.401998
expl/env_infos/final/reward_ctrl Mean        -0.417031
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.417031
expl/env_infos/final/reward_ctrl Min         -0.417031
expl/env_infos/initial/reward_ctrl Mean      -0.215007
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.215007
expl/env_infos/initial/reward_ctrl Min       -0.215007
expl/env_infos/reward_ctrl Mean              -0.390497
expl/env_infos/reward_ctrl Std                0.0941796
expl/env_infos/reward_ctrl Max               -0.0896542
expl/env_infos/reward_ctrl Min               -0.577335
eval/num steps total                          1.945e+06
eval/num paths total                       1945
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.38513
eval/Rewards Std                              1.3244
eval/Rewards Max                              8.80089
eval/Rewards Min                             -0.936048
eval/Returns Mean                          6385.13
eval/Returns Std                             81.3508
eval/Returns Max                           6468.17
eval/Returns Min                           6273.39
eval/Actions Mean                             0.116985
eval/Actions Std                              0.815223
eval/Actions Max                              0.995215
eval/Actions Min                             -0.993641
eval/Num Paths                                5
eval/Average Returns                       6385.13
eval/env_infos/final/reward_run Mean          7.2076
eval/env_infos/final/reward_run Std           0.788597
eval/env_infos/final/reward_run Max           8.11317
eval/env_infos/final/reward_run Min           6.07706
eval/env_infos/initial/reward_run Mean       -0.522294
eval/env_infos/initial/reward_run Std         0.155025
eval/env_infos/initial/reward_run Max        -0.31058
eval/env_infos/initial/reward_run Min        -0.751815
eval/env_infos/reward_run Mean                6.7921
eval/env_infos/reward_run Std                 1.31879
eval/env_infos/reward_run Max                 9.3372
eval/env_infos/reward_run Min                -0.751815
eval/env_infos/final/reward_ctrl Mean        -0.450864
eval/env_infos/final/reward_ctrl Std          0.0640438
eval/env_infos/final/reward_ctrl Max         -0.360644
eval/env_infos/final/reward_ctrl Min         -0.51856
eval/env_infos/initial/reward_ctrl Mean      -0.215685
eval/env_infos/initial/reward_ctrl Std        0.0431023
eval/env_infos/initial/reward_ctrl Max       -0.178604
eval/env_infos/initial/reward_ctrl Min       -0.291311
eval/env_infos/reward_ctrl Mean              -0.406964
eval/env_infos/reward_ctrl Std                0.0908765
eval/env_infos/reward_ctrl Max               -0.101413
eval/env_infos/reward_ctrl Min               -0.576628
time/data storing (s)                         0.0044762
time/evaluation sampling (s)                  2.01309
time/exploration sampling (s)                 0.538302
time/logging (s)                              0.0136614
time/sac training (s)                         7.43565
time/saving (s)                               0.0038444
time/training (s)                             3.4635e-05
time/epoch (s)                               10.0091
time/total (s)                             4103.62
Epoch                                       388
---------------------------------------  ---------------
2021-11-24 01:37:49.724686 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 389 finished
---------------------------------------  ---------------
epoch                                       389
replay_buffer/size                       391000
trainer/num train calls                  390000
trainer/QF1 Loss                              7.42586
trainer/QF2 Loss                              6.6478
trainer/Policy Loss                        -412.894
trainer/Q1 Predictions Mean                 413.528
trainer/Q1 Predictions Std                   72.0186
trainer/Q1 Predictions Max                  472.882
trainer/Q1 Predictions Min                   22.0245
trainer/Q2 Predictions Mean                 413.77
trainer/Q2 Predictions Std                   72.1423
trainer/Q2 Predictions Max                  473.775
trainer/Q2 Predictions Min                   21.6904
trainer/Q Targets Mean                      414.021
trainer/Q Targets Std                        72.235
trainer/Q Targets Max                       474.484
trainer/Q Targets Min                        22.3555
trainer/Log Pis Mean                          6.30142
trainer/Log Pis Std                           4.11589
trainer/Log Pis Max                          16.8106
trainer/Log Pis Min                          -5.86683
trainer/policy/mean Mean                      0.0999946
trainer/policy/mean Std                       0.783942
trainer/policy/mean Max                       0.99941
trainer/policy/mean Min                      -0.995654
trainer/policy/normal/std Mean                0.437546
trainer/policy/normal/std Std                 0.14096
trainer/policy/normal/std Max                 1.04303
trainer/policy/normal/std Min                 0.074505
trainer/policy/normal/log_std Mean           -0.898058
trainer/policy/normal/log_std Std             0.420464
trainer/policy/normal/log_std Max             0.0421339
trainer/policy/normal/log_std Min            -2.59689
trainer/Alpha                                 0.149565
trainer/Alpha Loss                            0.572705
expl/num steps total                     391000
expl/num paths total                        391
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.95385
expl/Rewards Std                              1.29738
expl/Rewards Max                              8.70631
expl/Rewards Min                             -0.756439
expl/Returns Mean                          5953.85
expl/Returns Std                              0
expl/Returns Max                           5953.85
expl/Returns Min                           5953.85
expl/Actions Mean                             0.102821
expl/Actions Std                              0.803283
expl/Actions Max                              0.999551
expl/Actions Min                             -0.999718
expl/Num Paths                                1
expl/Average Returns                       5953.85
expl/env_infos/final/reward_run Mean          7.86233
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.86233
expl/env_infos/final/reward_run Min           7.86233
expl/env_infos/initial/reward_run Mean       -0.5819
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.5819
expl/env_infos/initial/reward_run Min        -0.5819
expl/env_infos/reward_run Mean                6.34735
expl/env_infos/reward_run Std                 1.29055
expl/env_infos/reward_run Max                 9.19973
expl/env_infos/reward_run Min                -0.5819
expl/env_infos/final/reward_ctrl Mean        -0.338911
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.338911
expl/env_infos/final/reward_ctrl Min         -0.338911
expl/env_infos/initial/reward_ctrl Mean      -0.17454
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.17454
expl/env_infos/initial/reward_ctrl Min       -0.17454
expl/env_infos/reward_ctrl Mean              -0.393502
expl/env_infos/reward_ctrl Std                0.0886871
expl/env_infos/reward_ctrl Max               -0.0832806
expl/env_infos/reward_ctrl Min               -0.56494
eval/num steps total                          1.95e+06
eval/num paths total                       1950
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.25278
eval/Rewards Std                              1.3402
eval/Rewards Max                              8.73849
eval/Rewards Min                             -1.15525
eval/Returns Mean                          6252.78
eval/Returns Std                             22.18
eval/Returns Max                           6291.53
eval/Returns Min                           6222.97
eval/Actions Mean                             0.0993957
eval/Actions Std                              0.822362
eval/Actions Max                              0.996028
eval/Actions Min                             -0.997759
eval/Num Paths                                5
eval/Average Returns                       6252.78
eval/env_infos/final/reward_run Mean          7.07898
eval/env_infos/final/reward_run Std           0.906971
eval/env_infos/final/reward_run Max           7.91146
eval/env_infos/final/reward_run Min           5.90091
eval/env_infos/initial/reward_run Mean        0.0823288
eval/env_infos/initial/reward_run Std         0.446424
eval/env_infos/initial/reward_run Max         0.849858
eval/env_infos/initial/reward_run Min        -0.330798
eval/env_infos/reward_run Mean                6.66448
eval/env_infos/reward_run Std                 1.33044
eval/env_infos/reward_run Max                 9.27074
eval/env_infos/reward_run Min                -0.747385
eval/env_infos/final/reward_ctrl Mean        -0.423026
eval/env_infos/final/reward_ctrl Std          0.0601663
eval/env_infos/final/reward_ctrl Max         -0.355463
eval/env_infos/final/reward_ctrl Min         -0.533661
eval/env_infos/initial/reward_ctrl Mean      -0.161372
eval/env_infos/initial/reward_ctrl Std        0.0781814
eval/env_infos/initial/reward_ctrl Max       -0.0759189
eval/env_infos/initial/reward_ctrl Min       -0.277241
eval/env_infos/reward_ctrl Mean              -0.411695
eval/env_infos/reward_ctrl Std                0.0859919
eval/env_infos/reward_ctrl Max               -0.0526624
eval/env_infos/reward_ctrl Min               -0.56917
time/data storing (s)                         0.00449801
time/evaluation sampling (s)                  2.01389
time/exploration sampling (s)                 0.537254
time/logging (s)                              0.013652
time/sac training (s)                         7.45009
time/saving (s)                               0.0037968
time/training (s)                             3.4505e-05
time/epoch (s)                               10.0232
time/total (s)                             4113.93
Epoch                                       389
---------------------------------------  ---------------
2021-11-24 01:38:00.073928 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 390 finished
---------------------------------------  ---------------
epoch                                       390
replay_buffer/size                       392000
trainer/num train calls                  391000
trainer/QF1 Loss                              5.7981
trainer/QF2 Loss                              6.07143
trainer/Policy Loss                        -405.045
trainer/Q1 Predictions Mean                 405.682
trainer/Q1 Predictions Std                   95.5262
trainer/Q1 Predictions Max                  480.44
trainer/Q1 Predictions Min                   20.3102
trainer/Q2 Predictions Mean                 405.633
trainer/Q2 Predictions Std                   95.5123
trainer/Q2 Predictions Max                  480.617
trainer/Q2 Predictions Min                   19.7506
trainer/Q Targets Mean                      405.549
trainer/Q Targets Std                        95.5125
trainer/Q Targets Max                       478.124
trainer/Q Targets Min                        19.8941
trainer/Log Pis Mean                          5.96701
trainer/Log Pis Std                           4.43887
trainer/Log Pis Max                          16.0044
trainer/Log Pis Min                          -6.21943
trainer/policy/mean Mean                      0.0925919
trainer/policy/mean Std                       0.774962
trainer/policy/mean Max                       0.996936
trainer/policy/mean Min                      -0.995955
trainer/policy/normal/std Mean                0.443207
trainer/policy/normal/std Std                 0.144264
trainer/policy/normal/std Max                 1.01949
trainer/policy/normal/std Min                 0.0607695
trainer/policy/normal/log_std Mean           -0.886282
trainer/policy/normal/log_std Std             0.423485
trainer/policy/normal/log_std Max             0.0193034
trainer/policy/normal/log_std Min            -2.80067
trainer/Alpha                                 0.146694
trainer/Alpha Loss                           -0.0633221
expl/num steps total                     392000
expl/num paths total                        392
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.87235
expl/Rewards Std                              1.28039
expl/Rewards Max                              8.44114
expl/Rewards Min                             -0.549563
expl/Returns Mean                          5872.35
expl/Returns Std                              0
expl/Returns Max                           5872.35
expl/Returns Min                           5872.35
expl/Actions Mean                             0.0926684
expl/Actions Std                              0.801049
expl/Actions Max                              0.999454
expl/Actions Min                             -0.998943
expl/Num Paths                                1
expl/Average Returns                       5872.35
expl/env_infos/final/reward_run Mean          6.06564
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.06564
expl/env_infos/final/reward_run Min           6.06564
expl/env_infos/initial/reward_run Mean       -0.337467
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.337467
expl/env_infos/initial/reward_run Min        -0.337467
expl/env_infos/reward_run Mean                6.26251
expl/env_infos/reward_run Std                 1.27296
expl/env_infos/reward_run Max                 8.89305
expl/env_infos/reward_run Min                -0.337467
expl/env_infos/final/reward_ctrl Mean        -0.409785
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.409785
expl/env_infos/final/reward_ctrl Min         -0.409785
expl/env_infos/initial/reward_ctrl Mean      -0.212097
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.212097
expl/env_infos/initial/reward_ctrl Min       -0.212097
expl/env_infos/reward_ctrl Mean              -0.39016
expl/env_infos/reward_ctrl Std                0.0885667
expl/env_infos/reward_ctrl Max               -0.10336
expl/env_infos/reward_ctrl Min               -0.587336
eval/num steps total                          1.955e+06
eval/num paths total                       1955
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.3078
eval/Rewards Std                              1.36925
eval/Rewards Max                              8.82011
eval/Rewards Min                             -0.691986
eval/Returns Mean                          6307.8
eval/Returns Std                             68.7718
eval/Returns Max                           6392.51
eval/Returns Min                           6216.62
eval/Actions Mean                             0.087857
eval/Actions Std                              0.820054
eval/Actions Max                              0.995358
eval/Actions Min                             -0.997349
eval/Num Paths                                5
eval/Average Returns                       6307.8
eval/env_infos/final/reward_run Mean          6.95795
eval/env_infos/final/reward_run Std           1.05981
eval/env_infos/final/reward_run Max           8.23224
eval/env_infos/final/reward_run Min           5.60393
eval/env_infos/initial/reward_run Mean       -0.238568
eval/env_infos/initial/reward_run Std         0.136146
eval/env_infos/initial/reward_run Max         0.024628
eval/env_infos/initial/reward_run Min        -0.344809
eval/env_infos/reward_run Mean                6.71592
eval/env_infos/reward_run Std                 1.36319
eval/env_infos/reward_run Max                 9.33072
eval/env_infos/reward_run Min                -0.344809
eval/env_infos/final/reward_ctrl Mean        -0.455064
eval/env_infos/final/reward_ctrl Std          0.0496952
eval/env_infos/final/reward_ctrl Max         -0.362276
eval/env_infos/final/reward_ctrl Min         -0.507249
eval/env_infos/initial/reward_ctrl Mean      -0.16937
eval/env_infos/initial/reward_ctrl Std        0.0436313
eval/env_infos/initial/reward_ctrl Max       -0.117397
eval/env_infos/initial/reward_ctrl Min       -0.218097
eval/env_infos/reward_ctrl Mean              -0.408125
eval/env_infos/reward_ctrl Std                0.0845018
eval/env_infos/reward_ctrl Max               -0.0740581
eval/env_infos/reward_ctrl Min               -0.575716
time/data storing (s)                         0.00451715
time/evaluation sampling (s)                  2.01736
time/exploration sampling (s)                 0.541611
time/logging (s)                              0.0144797
time/sac training (s)                         7.46959
time/saving (s)                               0.00378424
time/training (s)                             3.4663e-05
time/epoch (s)                               10.0514
time/total (s)                             4124.26
Epoch                                       390
---------------------------------------  ---------------
2021-11-24 01:38:10.408265 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 391 finished
---------------------------------------  ---------------
epoch                                       391
replay_buffer/size                       393000
trainer/num train calls                  392000
trainer/QF1 Loss                              5.66122
trainer/QF2 Loss                              5.64703
trainer/Policy Loss                        -411.12
trainer/Q1 Predictions Mean                 412.024
trainer/Q1 Predictions Std                   88.5556
trainer/Q1 Predictions Max                  477.604
trainer/Q1 Predictions Min                   22.7786
trainer/Q2 Predictions Mean                 412.059
trainer/Q2 Predictions Std                   88.3793
trainer/Q2 Predictions Max                  477.827
trainer/Q2 Predictions Min                   24.3919
trainer/Q Targets Mean                      411.297
trainer/Q Targets Std                        88.3029
trainer/Q Targets Max                       478.807
trainer/Q Targets Min                        22.9119
trainer/Log Pis Mean                          6.2744
trainer/Log Pis Std                           4.42082
trainer/Log Pis Max                          18.7641
trainer/Log Pis Min                          -4.82831
trainer/policy/mean Mean                      0.109537
trainer/policy/mean Std                       0.781394
trainer/policy/mean Max                       0.995493
trainer/policy/mean Min                      -0.996686
trainer/policy/normal/std Mean                0.442782
trainer/policy/normal/std Std                 0.142362
trainer/policy/normal/std Max                 0.952569
trainer/policy/normal/std Min                 0.0686713
trainer/policy/normal/log_std Mean           -0.888181
trainer/policy/normal/log_std Std             0.429116
trainer/policy/normal/log_std Max            -0.0485927
trainer/policy/normal/log_std Min            -2.67842
trainer/Alpha                                 0.148727
trainer/Alpha Loss                            0.522911
expl/num steps total                     393000
expl/num paths total                        393
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.79458
expl/Rewards Std                              1.26191
expl/Rewards Max                              8.26568
expl/Rewards Min                             -0.546882
expl/Returns Mean                          5794.58
expl/Returns Std                              0
expl/Returns Max                           5794.58
expl/Returns Min                           5794.58
expl/Actions Mean                             0.107795
expl/Actions Std                              0.803512
expl/Actions Max                              0.999539
expl/Actions Min                             -0.999443
expl/Num Paths                                1
expl/Average Returns                       5794.58
expl/env_infos/final/reward_run Mean          7.31436
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.31436
expl/env_infos/final/reward_run Min           7.31436
expl/env_infos/initial/reward_run Mean       -0.198513
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.198513
expl/env_infos/initial/reward_run Min        -0.198513
expl/env_infos/reward_run Mean                6.18893
expl/env_infos/reward_run Std                 1.24852
expl/env_infos/reward_run Max                 8.7456
expl/env_infos/reward_run Min                -0.198513
expl/env_infos/final/reward_ctrl Mean        -0.369672
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.369672
expl/env_infos/final/reward_ctrl Min         -0.369672
expl/env_infos/initial/reward_ctrl Mean      -0.190633
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.190633
expl/env_infos/initial/reward_ctrl Min       -0.190633
expl/env_infos/reward_ctrl Mean              -0.394351
expl/env_infos/reward_ctrl Std                0.0939925
expl/env_infos/reward_ctrl Max               -0.101404
expl/env_infos/reward_ctrl Min               -0.576691
eval/num steps total                          1.96e+06
eval/num paths total                       1960
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.14518
eval/Rewards Std                              1.31377
eval/Rewards Max                              8.61171
eval/Rewards Min                             -0.920266
eval/Returns Mean                          6145.18
eval/Returns Std                             28.5581
eval/Returns Max                           6186.57
eval/Returns Min                           6112.15
eval/Actions Mean                             0.101739
eval/Actions Std                              0.815954
eval/Actions Max                              0.996851
eval/Actions Min                             -0.996838
eval/Num Paths                                5
eval/Average Returns                       6145.18
eval/env_infos/final/reward_run Mean          7.23002
eval/env_infos/final/reward_run Std           0.650885
eval/env_infos/final/reward_run Max           8.37326
eval/env_infos/final/reward_run Min           6.53293
eval/env_infos/initial/reward_run Mean       -0.337401
eval/env_infos/initial/reward_run Std         0.245212
eval/env_infos/initial/reward_run Max         0.0316752
eval/env_infos/initial/reward_run Min        -0.729844
eval/env_infos/reward_run Mean                6.55086
eval/env_infos/reward_run Std                 1.29889
eval/env_infos/reward_run Max                 9.15506
eval/env_infos/reward_run Min                -0.729844
eval/env_infos/final/reward_ctrl Mean        -0.390893
eval/env_infos/final/reward_ctrl Std          0.100773
eval/env_infos/final/reward_ctrl Max         -0.250934
eval/env_infos/final/reward_ctrl Min         -0.512587
eval/env_infos/initial/reward_ctrl Mean      -0.152831
eval/env_infos/initial/reward_ctrl Std        0.0352734
eval/env_infos/initial/reward_ctrl Max       -0.100364
eval/env_infos/initial/reward_ctrl Min       -0.190422
eval/env_infos/reward_ctrl Mean              -0.405679
eval/env_infos/reward_ctrl Std                0.0933271
eval/env_infos/reward_ctrl Max               -0.0625374
eval/env_infos/reward_ctrl Min               -0.581953
time/data storing (s)                         0.00452083
time/evaluation sampling (s)                  2.01723
time/exploration sampling (s)                 0.534139
time/logging (s)                              0.0144534
time/sac training (s)                         7.46387
time/saving (s)                               0.00381935
time/training (s)                             3.4446e-05
time/epoch (s)                               10.0381
time/total (s)                             4134.58
Epoch                                       391
---------------------------------------  ---------------
2021-11-24 01:38:20.847562 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 392 finished
---------------------------------------  ---------------
epoch                                       392
replay_buffer/size                       394000
trainer/num train calls                  393000
trainer/QF1 Loss                              9.33244
trainer/QF2 Loss                              7.18135
trainer/Policy Loss                        -407.793
trainer/Q1 Predictions Mean                 408.628
trainer/Q1 Predictions Std                   87.7875
trainer/Q1 Predictions Max                  479.765
trainer/Q1 Predictions Min                   20.8716
trainer/Q2 Predictions Mean                 407.897
trainer/Q2 Predictions Std                   87.8164
trainer/Q2 Predictions Max                  479.286
trainer/Q2 Predictions Min                   20.3165
trainer/Q Targets Mean                      407.736
trainer/Q Targets Std                        87.8003
trainer/Q Targets Max                       481.08
trainer/Q Targets Min                        20.8502
trainer/Log Pis Mean                          6.10525
trainer/Log Pis Std                           4.25909
trainer/Log Pis Max                          16.4821
trainer/Log Pis Min                          -6.43681
trainer/policy/mean Mean                      0.0880409
trainer/policy/mean Std                       0.778955
trainer/policy/mean Max                       0.999178
trainer/policy/mean Min                      -0.998106
trainer/policy/normal/std Mean                0.437443
trainer/policy/normal/std Std                 0.14474
trainer/policy/normal/std Max                 0.989862
trainer/policy/normal/std Min                 0.06483
trainer/policy/normal/log_std Mean           -0.900401
trainer/policy/normal/log_std Std             0.423908
trainer/policy/normal/log_std Max            -0.0101895
trainer/policy/normal/log_std Min            -2.73599
trainer/Alpha                                 0.149152
trainer/Alpha Loss                            0.200268
expl/num steps total                     394000
expl/num paths total                        394
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.79191
expl/Rewards Std                              1.24598
expl/Rewards Max                              7.98248
expl/Rewards Min                             -0.58781
expl/Returns Mean                          5791.91
expl/Returns Std                              0
expl/Returns Max                           5791.91
expl/Returns Min                           5791.91
expl/Actions Mean                             0.0982361
expl/Actions Std                              0.800008
expl/Actions Max                              0.999657
expl/Actions Min                             -0.999411
expl/Num Paths                                1
expl/Average Returns                       5791.91
expl/env_infos/final/reward_run Mean          6.0445
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.0445
expl/env_infos/final/reward_run Min           6.0445
expl/env_infos/initial/reward_run Mean       -0.403337
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.403337
expl/env_infos/initial/reward_run Min        -0.403337
expl/env_infos/reward_run Mean                6.18171
expl/env_infos/reward_run Std                 1.23368
expl/env_infos/reward_run Max                 8.48737
expl/env_infos/reward_run Min                -0.403337
expl/env_infos/final/reward_ctrl Mean        -0.440951
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.440951
expl/env_infos/final/reward_ctrl Min         -0.440951
expl/env_infos/initial/reward_ctrl Mean      -0.184473
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.184473
expl/env_infos/initial/reward_ctrl Min       -0.184473
expl/env_infos/reward_ctrl Mean              -0.389798
expl/env_infos/reward_ctrl Std                0.0919862
expl/env_infos/reward_ctrl Max               -0.0844101
expl/env_infos/reward_ctrl Min               -0.57556
eval/num steps total                          1.965e+06
eval/num paths total                       1965
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.27166
eval/Rewards Std                              1.32063
eval/Rewards Max                              8.8208
eval/Rewards Min                             -0.804349
eval/Returns Mean                          6271.66
eval/Returns Std                             70.2173
eval/Returns Max                           6376.55
eval/Returns Min                           6203.15
eval/Actions Mean                             0.0937847
eval/Actions Std                              0.819482
eval/Actions Max                              0.996105
eval/Actions Min                             -0.997565
eval/Num Paths                                5
eval/Average Returns                       6271.66
eval/env_infos/final/reward_run Mean          6.81555
eval/env_infos/final/reward_run Std           0.943171
eval/env_infos/final/reward_run Max           8.21697
eval/env_infos/final/reward_run Min           5.4674
eval/env_infos/initial/reward_run Mean       -0.407298
eval/env_infos/initial/reward_run Std         0.112971
eval/env_infos/initial/reward_run Max        -0.294428
eval/env_infos/initial/reward_run Min        -0.617619
eval/env_infos/reward_run Mean                6.67987
eval/env_infos/reward_run Std                 1.31013
eval/env_infos/reward_run Max                 9.37233
eval/env_infos/reward_run Min                -0.617619
eval/env_infos/final/reward_ctrl Mean        -0.424957
eval/env_infos/final/reward_ctrl Std          0.0531774
eval/env_infos/final/reward_ctrl Max         -0.351524
eval/env_infos/final/reward_ctrl Min         -0.486111
eval/env_infos/initial/reward_ctrl Mean      -0.223579
eval/env_infos/initial/reward_ctrl Std        0.0275517
eval/env_infos/initial/reward_ctrl Max       -0.18673
eval/env_infos/initial/reward_ctrl Min       -0.26722
eval/env_infos/reward_ctrl Mean              -0.408207
eval/env_infos/reward_ctrl Std                0.092127
eval/env_infos/reward_ctrl Max               -0.0986742
eval/env_infos/reward_ctrl Min               -0.581592
time/data storing (s)                         0.00448032
time/evaluation sampling (s)                  2.00818
time/exploration sampling (s)                 0.544382
time/logging (s)                              0.0145242
time/sac training (s)                         7.56463
time/saving (s)                               0.00376558
time/training (s)                             3.3273e-05
time/epoch (s)                               10.14
time/total (s)                             4145.01
Epoch                                       392
---------------------------------------  ---------------
2021-11-24 01:38:31.186586 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 393 finished
---------------------------------------  ---------------
epoch                                       393
replay_buffer/size                       395000
trainer/num train calls                  394000
trainer/QF1 Loss                              5.19419
trainer/QF2 Loss                              4.00514
trainer/Policy Loss                        -390.527
trainer/Q1 Predictions Mean                 390.863
trainer/Q1 Predictions Std                  114.133
trainer/Q1 Predictions Max                  477.351
trainer/Q1 Predictions Min                   19.6707
trainer/Q2 Predictions Mean                 391.397
trainer/Q2 Predictions Std                  114.373
trainer/Q2 Predictions Max                  477.052
trainer/Q2 Predictions Min                   19.6524
trainer/Q Targets Mean                      391.44
trainer/Q Targets Std                       114.269
trainer/Q Targets Max                       475.802
trainer/Q Targets Min                        19.3628
trainer/Log Pis Mean                          5.5646
trainer/Log Pis Std                           4.54825
trainer/Log Pis Max                          15.1328
trainer/Log Pis Min                          -6.59819
trainer/policy/mean Mean                      0.116262
trainer/policy/mean Std                       0.767971
trainer/policy/mean Max                       0.99617
trainer/policy/mean Min                      -0.997437
trainer/policy/normal/std Mean                0.462018
trainer/policy/normal/std Std                 0.160984
trainer/policy/normal/std Max                 1.01429
trainer/policy/normal/std Min                 0.0732024
trainer/policy/normal/log_std Mean           -0.853134
trainer/policy/normal/log_std Std             0.446108
trainer/policy/normal/log_std Max             0.0141899
trainer/policy/normal/log_std Min            -2.61453
trainer/Alpha                                 0.149491
trainer/Alpha Loss                           -0.827482
expl/num steps total                     395000
expl/num paths total                        395
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.91114
expl/Rewards Std                              1.23293
expl/Rewards Max                              8.14449
expl/Rewards Min                             -0.519542
expl/Returns Mean                          5911.14
expl/Returns Std                              0
expl/Returns Max                           5911.14
expl/Returns Min                           5911.14
expl/Actions Mean                             0.119057
expl/Actions Std                              0.800334
expl/Actions Max                              0.999203
expl/Actions Min                             -0.999453
expl/Num Paths                                1
expl/Average Returns                       5911.14
expl/env_infos/final/reward_run Mean          6.87983
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.87983
expl/env_infos/final/reward_run Min           6.87983
expl/env_infos/initial/reward_run Mean       -0.217599
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.217599
expl/env_infos/initial/reward_run Min        -0.217599
expl/env_infos/reward_run Mean                6.30396
expl/env_infos/reward_run Std                 1.22696
expl/env_infos/reward_run Max                 8.68651
expl/env_infos/reward_run Min                -0.217599
expl/env_infos/final/reward_ctrl Mean        -0.298754
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.298754
expl/env_infos/final/reward_ctrl Min         -0.298754
expl/env_infos/initial/reward_ctrl Mean      -0.301942
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.301942
expl/env_infos/initial/reward_ctrl Min       -0.301942
expl/env_infos/reward_ctrl Mean              -0.392825
expl/env_infos/reward_ctrl Std                0.0833821
expl/env_infos/reward_ctrl Max               -0.0805795
expl/env_infos/reward_ctrl Min               -0.580194
eval/num steps total                          1.97e+06
eval/num paths total                       1970
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.31615
eval/Rewards Std                              1.31865
eval/Rewards Max                              8.83624
eval/Rewards Min                             -0.757594
eval/Returns Mean                          6316.15
eval/Returns Std                             50.1379
eval/Returns Max                           6397.85
eval/Returns Min                           6262.6
eval/Actions Mean                             0.116686
eval/Actions Std                              0.82082
eval/Actions Max                              0.999259
eval/Actions Min                             -0.996473
eval/Num Paths                                5
eval/Average Returns                       6316.15
eval/env_infos/final/reward_run Mean          7.39132
eval/env_infos/final/reward_run Std           0.70708
eval/env_infos/final/reward_run Max           8.31369
eval/env_infos/final/reward_run Min           6.51834
eval/env_infos/initial/reward_run Mean       -0.324068
eval/env_infos/initial/reward_run Std         0.161131
eval/env_infos/initial/reward_run Max        -0.13807
eval/env_infos/initial/reward_run Min        -0.614641
eval/env_infos/reward_run Mean                6.72856
eval/env_infos/reward_run Std                 1.31343
eval/env_infos/reward_run Max                 9.34956
eval/env_infos/reward_run Min                -0.614641
eval/env_infos/final/reward_ctrl Mean        -0.46491
eval/env_infos/final/reward_ctrl Std          0.0646758
eval/env_infos/final/reward_ctrl Max         -0.342838
eval/env_infos/final/reward_ctrl Min         -0.518439
eval/env_infos/initial/reward_ctrl Mean      -0.179628
eval/env_infos/initial/reward_ctrl Std        0.0530656
eval/env_infos/initial/reward_ctrl Max       -0.124098
eval/env_infos/initial/reward_ctrl Min       -0.25681
eval/env_infos/reward_ctrl Mean              -0.412417
eval/env_infos/reward_ctrl Std                0.0871113
eval/env_infos/reward_ctrl Max               -0.0399272
eval/env_infos/reward_ctrl Min               -0.578616
time/data storing (s)                         0.00450786
time/evaluation sampling (s)                  2.02537
time/exploration sampling (s)                 0.52806
time/logging (s)                              0.0135931
time/sac training (s)                         7.46482
time/saving (s)                               0.00374832
time/training (s)                             3.3944e-05
time/epoch (s)                               10.0401
time/total (s)                             4155.33
Epoch                                       393
---------------------------------------  ---------------
2021-11-24 01:38:41.571206 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 394 finished
---------------------------------------  ---------------
epoch                                       394
replay_buffer/size                       396000
trainer/num train calls                  395000
trainer/QF1 Loss                              6.25826
trainer/QF2 Loss                              6.78487
trainer/Policy Loss                        -402.296
trainer/Q1 Predictions Mean                 403.122
trainer/Q1 Predictions Std                   95.3866
trainer/Q1 Predictions Max                  473.651
trainer/Q1 Predictions Min                   19.1569
trainer/Q2 Predictions Mean                 402.926
trainer/Q2 Predictions Std                   95.5062
trainer/Q2 Predictions Max                  474.87
trainer/Q2 Predictions Min                   18.9764
trainer/Q Targets Mean                      403.782
trainer/Q Targets Std                        95.7858
trainer/Q Targets Max                       477.958
trainer/Q Targets Min                        19.1198
trainer/Log Pis Mean                          5.78809
trainer/Log Pis Std                           4.45886
trainer/Log Pis Max                          14.9355
trainer/Log Pis Min                          -7.6363
trainer/policy/mean Mean                      0.0848687
trainer/policy/mean Std                       0.784003
trainer/policy/mean Max                       0.99604
trainer/policy/mean Min                      -0.993927
trainer/policy/normal/std Mean                0.446015
trainer/policy/normal/std Std                 0.143133
trainer/policy/normal/std Max                 0.923575
trainer/policy/normal/std Min                 0.074594
trainer/policy/normal/log_std Mean           -0.878562
trainer/policy/normal/log_std Std             0.419009
trainer/policy/normal/log_std Max            -0.0795035
trainer/policy/normal/log_std Min            -2.5957
trainer/Alpha                                 0.148878
trainer/Alpha Loss                           -0.403613
expl/num steps total                     396000
expl/num paths total                        396
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.92338
expl/Rewards Std                              1.29914
expl/Rewards Max                              8.63957
expl/Rewards Min                             -0.175603
expl/Returns Mean                          5923.38
expl/Returns Std                              0
expl/Returns Max                           5923.38
expl/Returns Min                           5923.38
expl/Actions Mean                             0.110265
expl/Actions Std                              0.801705
expl/Actions Max                              0.999408
expl/Actions Min                             -0.998109
expl/Num Paths                                1
expl/Average Returns                       5923.38
expl/env_infos/final/reward_run Mean          5.77047
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.77047
expl/env_infos/final/reward_run Min           5.77047
expl/env_infos/initial/reward_run Mean       -0.0491001
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0491001
expl/env_infos/initial/reward_run Min        -0.0491001
expl/env_infos/reward_run Mean                6.31632
expl/env_infos/reward_run Std                 1.29398
expl/env_infos/reward_run Max                 9.15337
expl/env_infos/reward_run Min                -0.0491001
expl/env_infos/final/reward_ctrl Mean        -0.491463
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.491463
expl/env_infos/final/reward_ctrl Min         -0.491463
expl/env_infos/initial/reward_ctrl Mean      -0.126503
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.126503
expl/env_infos/initial/reward_ctrl Min       -0.126503
expl/env_infos/reward_ctrl Mean              -0.392934
expl/env_infos/reward_ctrl Std                0.0869795
expl/env_infos/reward_ctrl Max               -0.117358
expl/env_infos/reward_ctrl Min               -0.563225
eval/num steps total                          1.975e+06
eval/num paths total                       1975
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.2475
eval/Rewards Std                              1.33284
eval/Rewards Max                              8.71053
eval/Rewards Min                             -0.696004
eval/Returns Mean                          6247.5
eval/Returns Std                             63.5019
eval/Returns Max                           6326.64
eval/Returns Min                           6153.34
eval/Actions Mean                             0.117302
eval/Actions Std                              0.820006
eval/Actions Max                              0.996382
eval/Actions Min                             -0.994565
eval/Num Paths                                5
eval/Average Returns                       6247.5
eval/env_infos/final/reward_run Mean          7.03438
eval/env_infos/final/reward_run Std           0.694653
eval/env_infos/final/reward_run Max           7.96791
eval/env_infos/final/reward_run Min           5.94095
eval/env_infos/initial/reward_run Mean       -0.132501
eval/env_infos/initial/reward_run Std         0.147017
eval/env_infos/initial/reward_run Max         0.14512
eval/env_infos/initial/reward_run Min        -0.27221
eval/env_infos/reward_run Mean                6.6592
eval/env_infos/reward_run Std                 1.33317
eval/env_infos/reward_run Max                 9.25659
eval/env_infos/reward_run Min                -0.308682
eval/env_infos/final/reward_ctrl Mean        -0.380705
eval/env_infos/final/reward_ctrl Std          0.0737834
eval/env_infos/final/reward_ctrl Max         -0.250181
eval/env_infos/final/reward_ctrl Min         -0.4629
eval/env_infos/initial/reward_ctrl Mean      -0.162613
eval/env_infos/initial/reward_ctrl Std        0.0451307
eval/env_infos/initial/reward_ctrl Max       -0.113644
eval/env_infos/initial/reward_ctrl Min       -0.235244
eval/env_infos/reward_ctrl Mean              -0.411701
eval/env_infos/reward_ctrl Std                0.0866671
eval/env_infos/reward_ctrl Max               -0.0621989
eval/env_infos/reward_ctrl Min               -0.573233
time/data storing (s)                         0.00451676
time/evaluation sampling (s)                  2.08117
time/exploration sampling (s)                 0.530136
time/logging (s)                              0.0141873
time/sac training (s)                         7.45385
time/saving (s)                               0.00378302
time/training (s)                             3.3752e-05
time/epoch (s)                               10.0877
time/total (s)                             4165.7
Epoch                                       394
---------------------------------------  ---------------
2021-11-24 01:38:51.835576 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 395 finished
---------------------------------------  ---------------
epoch                                       395
replay_buffer/size                       397000
trainer/num train calls                  396000
trainer/QF1 Loss                             12.0257
trainer/QF2 Loss                              9.61523
trainer/Policy Loss                        -410.607
trainer/Q1 Predictions Mean                 411.283
trainer/Q1 Predictions Std                   83.0075
trainer/Q1 Predictions Max                  481.932
trainer/Q1 Predictions Min                   22.0527
trainer/Q2 Predictions Mean                 411.575
trainer/Q2 Predictions Std                   83.0551
trainer/Q2 Predictions Max                  482.696
trainer/Q2 Predictions Min                   21.5302
trainer/Q Targets Mean                      410.875
trainer/Q Targets Std                        83.1302
trainer/Q Targets Max                       480.014
trainer/Q Targets Min                        21.3946
trainer/Log Pis Mean                          6.05768
trainer/Log Pis Std                           4.18365
trainer/Log Pis Max                          15.0655
trainer/Log Pis Min                          -6.21166
trainer/policy/mean Mean                      0.0925903
trainer/policy/mean Std                       0.782052
trainer/policy/mean Max                       0.99662
trainer/policy/mean Min                      -0.99666
trainer/policy/normal/std Mean                0.439641
trainer/policy/normal/std Std                 0.140702
trainer/policy/normal/std Max                 0.899679
trainer/policy/normal/std Min                 0.0755968
trainer/policy/normal/log_std Mean           -0.891944
trainer/policy/normal/log_std Std             0.415476
trainer/policy/normal/log_std Max            -0.105717
trainer/policy/normal/log_std Min            -2.58234
trainer/Alpha                                 0.149075
trainer/Alpha Loss                            0.109784
expl/num steps total                     397000
expl/num paths total                        397
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.87137
expl/Rewards Std                              1.24881
expl/Rewards Max                              8.45104
expl/Rewards Min                             -0.207925
expl/Returns Mean                          5871.37
expl/Returns Std                              0
expl/Returns Max                           5871.37
expl/Returns Min                           5871.37
expl/Actions Mean                             0.105877
expl/Actions Std                              0.798463
expl/Actions Max                              0.999511
expl/Actions Min                             -0.999185
expl/Num Paths                                1
expl/Average Returns                       5871.37
expl/env_infos/final/reward_run Mean          6.73161
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.73161
expl/env_infos/final/reward_run Min           6.73161
expl/env_infos/initial/reward_run Mean        0.032111
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.032111
expl/env_infos/initial/reward_run Min         0.032111
expl/env_infos/reward_run Mean                6.26062
expl/env_infos/reward_run Std                 1.24232
expl/env_infos/reward_run Max                 8.94737
expl/env_infos/reward_run Min                 0.032111
expl/env_infos/final/reward_ctrl Mean        -0.29606
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.29606
expl/env_infos/final/reward_ctrl Min         -0.29606
expl/env_infos/initial/reward_ctrl Mean      -0.240036
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.240036
expl/env_infos/initial/reward_ctrl Min       -0.240036
expl/env_infos/reward_ctrl Mean              -0.389252
expl/env_infos/reward_ctrl Std                0.0893901
expl/env_infos/reward_ctrl Max               -0.104386
expl/env_infos/reward_ctrl Min               -0.564801
eval/num steps total                          1.98e+06
eval/num paths total                       1980
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.34257
eval/Rewards Std                              1.34304
eval/Rewards Max                              8.96723
eval/Rewards Min                             -0.585563
eval/Returns Mean                          6342.57
eval/Returns Std                             85.3836
eval/Returns Max                           6482.31
eval/Returns Min                           6243.8
eval/Actions Mean                             0.105112
eval/Actions Std                              0.820984
eval/Actions Max                              0.99803
eval/Actions Min                             -0.997852
eval/Num Paths                                5
eval/Average Returns                       6342.57
eval/env_infos/final/reward_run Mean          7.18871
eval/env_infos/final/reward_run Std           0.657475
eval/env_infos/final/reward_run Max           8.06327
eval/env_infos/final/reward_run Min           6.27974
eval/env_infos/initial/reward_run Mean       -0.203449
eval/env_infos/initial/reward_run Std         0.100424
eval/env_infos/initial/reward_run Max        -0.0721802
eval/env_infos/initial/reward_run Min        -0.366531
eval/env_infos/reward_run Mean                6.75361
eval/env_infos/reward_run Std                 1.34036
eval/env_infos/reward_run Max                 9.47793
eval/env_infos/reward_run Min                -0.366531
eval/env_infos/final/reward_ctrl Mean        -0.375148
eval/env_infos/final/reward_ctrl Std          0.117069
eval/env_infos/final/reward_ctrl Max         -0.159832
eval/env_infos/final/reward_ctrl Min         -0.509606
eval/env_infos/initial/reward_ctrl Mean      -0.214813
eval/env_infos/initial/reward_ctrl Std        0.0279922
eval/env_infos/initial/reward_ctrl Max       -0.16049
eval/env_infos/initial/reward_ctrl Min       -0.240106
eval/env_infos/reward_ctrl Mean              -0.411038
eval/env_infos/reward_ctrl Std                0.0865711
eval/env_infos/reward_ctrl Max               -0.0840545
eval/env_infos/reward_ctrl Min               -0.568902
time/data storing (s)                         0.00454699
time/evaluation sampling (s)                  1.99969
time/exploration sampling (s)                 0.53226
time/logging (s)                              0.0140357
time/sac training (s)                         7.4154
time/saving (s)                               0.00374755
time/training (s)                             3.4046e-05
time/epoch (s)                                9.96971
time/total (s)                             4175.95
Epoch                                       395
---------------------------------------  ---------------
2021-11-24 01:39:02.084490 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 396 finished
---------------------------------------  ---------------
epoch                                       396
replay_buffer/size                       398000
trainer/num train calls                  397000
trainer/QF1 Loss                              5.98097
trainer/QF2 Loss                              5.19796
trainer/Policy Loss                        -411.995
trainer/Q1 Predictions Mean                 412.813
trainer/Q1 Predictions Std                   76.2203
trainer/Q1 Predictions Max                  475.907
trainer/Q1 Predictions Min                   21.7244
trainer/Q2 Predictions Mean                 412.612
trainer/Q2 Predictions Std                   75.9296
trainer/Q2 Predictions Max                  474.032
trainer/Q2 Predictions Min                   21.5471
trainer/Q Targets Mean                      412.951
trainer/Q Targets Std                        75.9679
trainer/Q Targets Max                       476.559
trainer/Q Targets Min                        21.5032
trainer/Log Pis Mean                          6.27677
trainer/Log Pis Std                           4.27587
trainer/Log Pis Max                          16.1095
trainer/Log Pis Min                          -5.95024
trainer/policy/mean Mean                      0.0803651
trainer/policy/mean Std                       0.793643
trainer/policy/mean Max                       0.995905
trainer/policy/mean Min                      -0.997968
trainer/policy/normal/std Mean                0.448401
trainer/policy/normal/std Std                 0.137081
trainer/policy/normal/std Max                 1.29285
trainer/policy/normal/std Min                 0.0722025
trainer/policy/normal/log_std Mean           -0.867802
trainer/policy/normal/log_std Std             0.406107
trainer/policy/normal/log_std Max             0.25685
trainer/policy/normal/log_std Min            -2.62828
trainer/Alpha                                 0.147514
trainer/Alpha Loss                            0.529691
expl/num steps total                     398000
expl/num paths total                        398
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.94511
expl/Rewards Std                              1.2559
expl/Rewards Max                              8.36082
expl/Rewards Min                             -0.379091
expl/Returns Mean                          5945.11
expl/Returns Std                              0
expl/Returns Max                           5945.11
expl/Returns Min                           5945.11
expl/Actions Mean                             0.116893
expl/Actions Std                              0.80214
expl/Actions Max                              0.999837
expl/Actions Min                             -0.999933
expl/Num Paths                                1
expl/Average Returns                       5945.11
expl/env_infos/final/reward_run Mean          8.25713
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.25713
expl/env_infos/final/reward_run Min           8.25713
expl/env_infos/initial/reward_run Mean       -0.206408
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.206408
expl/env_infos/initial/reward_run Min        -0.206408
expl/env_infos/reward_run Mean                6.33937
expl/env_infos/reward_run Std                 1.25057
expl/env_infos/reward_run Max                 8.71577
expl/env_infos/reward_run Min                -0.206408
expl/env_infos/final/reward_ctrl Mean        -0.454137
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.454137
expl/env_infos/final/reward_ctrl Min         -0.454137
expl/env_infos/initial/reward_ctrl Mean      -0.172683
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.172683
expl/env_infos/initial/reward_ctrl Min       -0.172683
expl/env_infos/reward_ctrl Mean              -0.394255
expl/env_infos/reward_ctrl Std                0.0898808
expl/env_infos/reward_ctrl Max               -0.131508
expl/env_infos/reward_ctrl Min               -0.579029
eval/num steps total                          1.985e+06
eval/num paths total                       1985
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.38596
eval/Rewards Std                              1.34185
eval/Rewards Max                              8.89117
eval/Rewards Min                             -0.662976
eval/Returns Mean                          6385.96
eval/Returns Std                             58.282
eval/Returns Max                           6482.6
eval/Returns Min                           6322.64
eval/Actions Mean                             0.109111
eval/Actions Std                              0.821552
eval/Actions Max                              0.996676
eval/Actions Min                             -0.997023
eval/Num Paths                                5
eval/Average Returns                       6385.96
eval/env_infos/final/reward_run Mean          7.19725
eval/env_infos/final/reward_run Std           0.72289
eval/env_infos/final/reward_run Max           8.13208
eval/env_infos/final/reward_run Min           6.2681
eval/env_infos/initial/reward_run Mean       -0.333513
eval/env_infos/initial/reward_run Std         0.112485
eval/env_infos/initial/reward_run Max        -0.131804
eval/env_infos/initial/reward_run Min        -0.458291
eval/env_infos/reward_run Mean                6.79808
eval/env_infos/reward_run Std                 1.33751
eval/env_infos/reward_run Max                 9.36273
eval/env_infos/reward_run Min                -0.458291
eval/env_infos/final/reward_ctrl Mean        -0.42422
eval/env_infos/final/reward_ctrl Std          0.0802887
eval/env_infos/final/reward_ctrl Max         -0.305192
eval/env_infos/final/reward_ctrl Min         -0.522828
eval/env_infos/initial/reward_ctrl Mean      -0.210079
eval/env_infos/initial/reward_ctrl Std        0.0352523
eval/env_infos/initial/reward_ctrl Max       -0.171737
eval/env_infos/initial/reward_ctrl Min       -0.261111
eval/env_infos/reward_ctrl Mean              -0.412111
eval/env_infos/reward_ctrl Std                0.0860627
eval/env_infos/reward_ctrl Max               -0.0733473
eval/env_infos/reward_ctrl Min               -0.571839
time/data storing (s)                         0.00451422
time/evaluation sampling (s)                  1.99991
time/exploration sampling (s)                 0.52579
time/logging (s)                              0.0138037
time/sac training (s)                         7.40783
time/saving (s)                               0.00375266
time/training (s)                             3.3963e-05
time/epoch (s)                                9.95563
time/total (s)                             4186.19
Epoch                                       396
---------------------------------------  ---------------
2021-11-24 01:39:12.431995 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 397 finished
---------------------------------------  ---------------
epoch                                       397
replay_buffer/size                       399000
trainer/num train calls                  398000
trainer/QF1 Loss                              5.25761
trainer/QF2 Loss                              4.33916
trainer/Policy Loss                        -415.815
trainer/Q1 Predictions Mean                 416.381
trainer/Q1 Predictions Std                   79.2311
trainer/Q1 Predictions Max                  477.41
trainer/Q1 Predictions Min                   22.0076
trainer/Q2 Predictions Mean                 416.595
trainer/Q2 Predictions Std                   79.1746
trainer/Q2 Predictions Max                  477.874
trainer/Q2 Predictions Min                   20.9986
trainer/Q Targets Mean                      417.039
trainer/Q Targets Std                        79.4523
trainer/Q Targets Max                       479.334
trainer/Q Targets Min                        20.7841
trainer/Log Pis Mean                          5.89455
trainer/Log Pis Std                           4.05504
trainer/Log Pis Max                          16.2926
trainer/Log Pis Min                          -5.69201
trainer/policy/mean Mean                      0.0796384
trainer/policy/mean Std                       0.78155
trainer/policy/mean Max                       0.994471
trainer/policy/mean Min                      -0.995762
trainer/policy/normal/std Mean                0.440628
trainer/policy/normal/std Std                 0.140212
trainer/policy/normal/std Max                 1.15311
trainer/policy/normal/std Min                 0.0599582
trainer/policy/normal/log_std Mean           -0.889785
trainer/policy/normal/log_std Std             0.418565
trainer/policy/normal/log_std Max             0.142462
trainer/policy/normal/log_std Min            -2.81411
trainer/Alpha                                 0.149895
trainer/Alpha Loss                           -0.20013
expl/num steps total                     399000
expl/num paths total                        399
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.91241
expl/Rewards Std                              1.23997
expl/Rewards Max                              8.23911
expl/Rewards Min                             -0.465462
expl/Returns Mean                          5912.41
expl/Returns Std                              0
expl/Returns Max                           5912.41
expl/Returns Min                           5912.41
expl/Actions Mean                             0.0873738
expl/Actions Std                              0.803226
expl/Actions Max                              0.999653
expl/Actions Min                             -0.999112
expl/Num Paths                                1
expl/Average Returns                       5912.41
expl/env_infos/final/reward_run Mean          4.86141
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.86141
expl/env_infos/final/reward_run Min           4.86141
expl/env_infos/initial/reward_run Mean       -0.157112
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.157112
expl/env_infos/initial/reward_run Min        -0.157112
expl/env_infos/reward_run Mean                6.30409
expl/env_infos/reward_run Std                 1.23809
expl/env_infos/reward_run Max                 8.79918
expl/env_infos/reward_run Min                -0.157112
expl/env_infos/final/reward_ctrl Mean        -0.352209
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.352209
expl/env_infos/final/reward_ctrl Min         -0.352209
expl/env_infos/initial/reward_ctrl Mean      -0.30835
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.30835
expl/env_infos/initial/reward_ctrl Min       -0.30835
expl/env_infos/reward_ctrl Mean              -0.391683
expl/env_infos/reward_ctrl Std                0.0905143
expl/env_infos/reward_ctrl Max               -0.108621
expl/env_infos/reward_ctrl Min               -0.580089
eval/num steps total                          1.99e+06
eval/num paths total                       1990
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.18813
eval/Rewards Std                              1.29443
eval/Rewards Max                              8.77923
eval/Rewards Min                             -0.844194
eval/Returns Mean                          6188.13
eval/Returns Std                             76.385
eval/Returns Max                           6301.89
eval/Returns Min                           6072.38
eval/Actions Mean                             0.0903662
eval/Actions Std                              0.816962
eval/Actions Max                              0.9959
eval/Actions Min                             -0.996612
eval/Num Paths                                5
eval/Average Returns                       6188.13
eval/env_infos/final/reward_run Mean          7.45721
eval/env_infos/final/reward_run Std           0.713876
eval/env_infos/final/reward_run Max           8.57518
eval/env_infos/final/reward_run Min           6.77474
eval/env_infos/initial/reward_run Mean       -0.134592
eval/env_infos/initial/reward_run Std         0.384017
eval/env_infos/initial/reward_run Max         0.483808
eval/env_infos/initial/reward_run Min        -0.571508
eval/env_infos/reward_run Mean                6.59348
eval/env_infos/reward_run Std                 1.28949
eval/env_infos/reward_run Max                 9.28636
eval/env_infos/reward_run Min                -0.571508
eval/env_infos/final/reward_ctrl Mean        -0.460109
eval/env_infos/final/reward_ctrl Std          0.0356288
eval/env_infos/final/reward_ctrl Max         -0.399919
eval/env_infos/final/reward_ctrl Min         -0.500822
eval/env_infos/initial/reward_ctrl Mean      -0.19063
eval/env_infos/initial/reward_ctrl Std        0.0628613
eval/env_infos/initial/reward_ctrl Max       -0.0967152
eval/env_infos/initial/reward_ctrl Min       -0.270783
eval/env_infos/reward_ctrl Mean              -0.405356
eval/env_infos/reward_ctrl Std                0.0869478
eval/env_infos/reward_ctrl Max               -0.0418666
eval/env_infos/reward_ctrl Min               -0.582038
time/data storing (s)                         0.0045149
time/evaluation sampling (s)                  2.00933
time/exploration sampling (s)                 0.529034
time/logging (s)                              0.0139118
time/sac training (s)                         7.49005
time/saving (s)                               0.0037584
time/training (s)                             3.3754e-05
time/epoch (s)                               10.0506
time/total (s)                             4196.52
Epoch                                       397
---------------------------------------  ---------------
2021-11-24 01:39:23.267638 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 398 finished
---------------------------------------  ---------------
epoch                                       398
replay_buffer/size                       400000
trainer/num train calls                  399000
trainer/QF1 Loss                              4.50754
trainer/QF2 Loss                              4.36395
trainer/Policy Loss                        -405.971
trainer/Q1 Predictions Mean                 406.89
trainer/Q1 Predictions Std                   92.5912
trainer/Q1 Predictions Max                  478.807
trainer/Q1 Predictions Min                   21.3299
trainer/Q2 Predictions Mean                 406.736
trainer/Q2 Predictions Std                   92.5407
trainer/Q2 Predictions Max                  477.773
trainer/Q2 Predictions Min                   20.4771
trainer/Q Targets Mean                      406.78
trainer/Q Targets Std                        92.594
trainer/Q Targets Max                       478.372
trainer/Q Targets Min                        19.3106
trainer/Log Pis Mean                          6.35741
trainer/Log Pis Std                           4.48223
trainer/Log Pis Max                          18.2344
trainer/Log Pis Min                          -4.26035
trainer/policy/mean Mean                      0.114168
trainer/policy/mean Std                       0.777884
trainer/policy/mean Max                       0.993372
trainer/policy/mean Min                      -0.994439
trainer/policy/normal/std Mean                0.445932
trainer/policy/normal/std Std                 0.147977
trainer/policy/normal/std Max                 0.941242
trainer/policy/normal/std Min                 0.0695087
trainer/policy/normal/log_std Mean           -0.882007
trainer/policy/normal/log_std Std             0.427678
trainer/policy/normal/log_std Max            -0.0605552
trainer/policy/normal/log_std Min            -2.6663
trainer/Alpha                                 0.150552
trainer/Alpha Loss                            0.676737
expl/num steps total                     400000
expl/num paths total                        400
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.81651
expl/Rewards Std                              1.28147
expl/Rewards Max                              8.17925
expl/Rewards Min                             -0.584775
expl/Returns Mean                          5816.51
expl/Returns Std                              0
expl/Returns Max                           5816.51
expl/Returns Min                           5816.51
expl/Actions Mean                             0.0978209
expl/Actions Std                              0.801103
expl/Actions Max                              0.99923
expl/Actions Min                             -0.999219
expl/Num Paths                                1
expl/Average Returns                       5816.51
expl/env_infos/final/reward_run Mean          5.33216
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.33216
expl/env_infos/final/reward_run Min           5.33216
expl/env_infos/initial/reward_run Mean       -0.342542
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.342542
expl/env_infos/initial/reward_run Min        -0.342542
expl/env_infos/reward_run Mean                6.20731
expl/env_infos/reward_run Std                 1.27305
expl/env_infos/reward_run Max                 8.67539
expl/env_infos/reward_run Min                -0.342542
expl/env_infos/final/reward_ctrl Mean        -0.386226
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.386226
expl/env_infos/final/reward_ctrl Min         -0.386226
expl/env_infos/initial/reward_ctrl Mean      -0.242233
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.242233
expl/env_infos/initial/reward_ctrl Min       -0.242233
expl/env_infos/reward_ctrl Mean              -0.390801
expl/env_infos/reward_ctrl Std                0.0930163
expl/env_infos/reward_ctrl Max               -0.0960329
expl/env_infos/reward_ctrl Min               -0.57765
eval/num steps total                          1.995e+06
eval/num paths total                       1995
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.22437
eval/Rewards Std                              1.2927
eval/Rewards Max                              8.55441
eval/Rewards Min                             -0.764189
eval/Returns Mean                          6224.37
eval/Returns Std                             66.7154
eval/Returns Max                           6307.59
eval/Returns Min                           6149.37
eval/Actions Mean                             0.101469
eval/Actions Std                              0.819957
eval/Actions Max                              0.996503
eval/Actions Min                             -0.996719
eval/Num Paths                                5
eval/Average Returns                       6224.37
eval/env_infos/final/reward_run Mean          6.51467
eval/env_infos/final/reward_run Std           0.927937
eval/env_infos/final/reward_run Max           7.82647
eval/env_infos/final/reward_run Min           5.42051
eval/env_infos/initial/reward_run Mean       -0.286562
eval/env_infos/initial/reward_run Std         0.141285
eval/env_infos/initial/reward_run Max        -0.169691
eval/env_infos/initial/reward_run Min        -0.559538
eval/env_infos/reward_run Mean                6.63394
eval/env_infos/reward_run Std                 1.28278
eval/env_infos/reward_run Max                 9.09048
eval/env_infos/reward_run Min                -0.559538
eval/env_infos/final/reward_ctrl Mean        -0.375987
eval/env_infos/final/reward_ctrl Std          0.119531
eval/env_infos/final/reward_ctrl Max         -0.169405
eval/env_infos/final/reward_ctrl Min         -0.494175
eval/env_infos/initial/reward_ctrl Mean      -0.177107
eval/env_infos/initial/reward_ctrl Std        0.0452743
eval/env_infos/initial/reward_ctrl Max       -0.121807
eval/env_infos/initial/reward_ctrl Min       -0.238429
eval/env_infos/reward_ctrl Mean              -0.409575
eval/env_infos/reward_ctrl Std                0.0930117
eval/env_infos/reward_ctrl Max               -0.0602815
eval/env_infos/reward_ctrl Min               -0.581073
time/data storing (s)                         0.00453704
time/evaluation sampling (s)                  2.09031
time/exploration sampling (s)                 0.710537
time/logging (s)                              0.013788
time/sac training (s)                         7.70321
time/saving (s)                               0.00384129
time/training (s)                             3.4748e-05
time/epoch (s)                               10.5263
time/total (s)                             4207.34
Epoch                                       398
---------------------------------------  ---------------
2021-11-24 01:39:33.991815 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 399 finished
---------------------------------------  ---------------
epoch                                       399
replay_buffer/size                       401000
trainer/num train calls                  400000
trainer/QF1 Loss                              6.39578
trainer/QF2 Loss                              6.55155
trainer/Policy Loss                        -399.814
trainer/Q1 Predictions Mean                 400.326
trainer/Q1 Predictions Std                  107.841
trainer/Q1 Predictions Max                  475.513
trainer/Q1 Predictions Min                   20.8449
trainer/Q2 Predictions Mean                 400.684
trainer/Q2 Predictions Std                  108.297
trainer/Q2 Predictions Max                  475.269
trainer/Q2 Predictions Min                   21.7079
trainer/Q Targets Mean                      400.727
trainer/Q Targets Std                       108.267
trainer/Q Targets Max                       476.405
trainer/Q Targets Min                        19.4732
trainer/Log Pis Mean                          6.08052
trainer/Log Pis Std                           4.55696
trainer/Log Pis Max                          17.6352
trainer/Log Pis Min                          -6.38053
trainer/policy/mean Mean                      0.0981546
trainer/policy/mean Std                       0.777957
trainer/policy/mean Max                       0.99935
trainer/policy/mean Min                      -0.997949
trainer/policy/normal/std Mean                0.4584
trainer/policy/normal/std Std                 0.150644
trainer/policy/normal/std Max                 0.936121
trainer/policy/normal/std Min                 0.0736221
trainer/policy/normal/log_std Mean           -0.85321
trainer/policy/normal/log_std Std             0.423688
trainer/policy/normal/log_std Max            -0.0660102
trainer/policy/normal/log_std Min            -2.60881
trainer/Alpha                                 0.151093
trainer/Alpha Loss                            0.152174
expl/num steps total                     401000
expl/num paths total                        401
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.74559
expl/Rewards Std                              1.24285
expl/Rewards Max                              8.2633
expl/Rewards Min                             -0.517354
expl/Returns Mean                          5745.59
expl/Returns Std                              0
expl/Returns Max                           5745.59
expl/Returns Min                           5745.59
expl/Actions Mean                             0.107717
expl/Actions Std                              0.794057
expl/Actions Max                              0.999617
expl/Actions Min                             -0.999642
expl/Num Paths                                1
expl/Average Returns                       5745.59
expl/env_infos/final/reward_run Mean          6.94609
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.94609
expl/env_infos/final/reward_run Min           6.94609
expl/env_infos/initial/reward_run Mean       -0.0338957
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0338957
expl/env_infos/initial/reward_run Min        -0.0338957
expl/env_infos/reward_run Mean                6.13087
expl/env_infos/reward_run Std                 1.23191
expl/env_infos/reward_run Max                 8.67005
expl/env_infos/reward_run Min                -0.0367356
expl/env_infos/final/reward_ctrl Mean        -0.199661
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.199661
expl/env_infos/final/reward_ctrl Min         -0.199661
expl/env_infos/initial/reward_ctrl Mean      -0.227822
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.227822
expl/env_infos/initial/reward_ctrl Min       -0.227822
expl/env_infos/reward_ctrl Mean              -0.385277
expl/env_infos/reward_ctrl Std                0.0940633
expl/env_infos/reward_ctrl Max               -0.0777595
expl/env_infos/reward_ctrl Min               -0.572689
eval/num steps total                          2e+06
eval/num paths total                       2000
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.18853
eval/Rewards Std                              1.30563
eval/Rewards Max                              8.64826
eval/Rewards Min                             -1.06347
eval/Returns Mean                          6188.53
eval/Returns Std                             41.1735
eval/Returns Max                           6260.89
eval/Returns Min                           6151.14
eval/Actions Mean                             0.103997
eval/Actions Std                              0.819638
eval/Actions Max                              0.997242
eval/Actions Min                             -0.998678
eval/Num Paths                                5
eval/Average Returns                       6188.53
eval/env_infos/final/reward_run Mean          6.10554
eval/env_infos/final/reward_run Std           0.789414
eval/env_infos/final/reward_run Max           7.54886
eval/env_infos/final/reward_run Min           5.34264
eval/env_infos/initial/reward_run Mean       -0.0341755
eval/env_infos/initial/reward_run Std         0.268723
eval/env_infos/initial/reward_run Max         0.297402
eval/env_infos/initial/reward_run Min        -0.441199
eval/env_infos/reward_run Mean                6.5981
eval/env_infos/reward_run Std                 1.29664
eval/env_infos/reward_run Max                 9.16673
eval/env_infos/reward_run Min                -0.672705
eval/env_infos/final/reward_ctrl Mean        -0.385371
eval/env_infos/final/reward_ctrl Std          0.0926252
eval/env_infos/final/reward_ctrl Max         -0.295906
eval/env_infos/final/reward_ctrl Min         -0.544381
eval/env_infos/initial/reward_ctrl Mean      -0.157013
eval/env_infos/initial/reward_ctrl Std        0.0340994
eval/env_infos/initial/reward_ctrl Max       -0.0946031
eval/env_infos/initial/reward_ctrl Min       -0.189117
eval/env_infos/reward_ctrl Mean              -0.409573
eval/env_infos/reward_ctrl Std                0.0903271
eval/env_infos/reward_ctrl Max               -0.0624424
eval/env_infos/reward_ctrl Min               -0.583226
time/data storing (s)                         0.00450352
time/evaluation sampling (s)                  2.06049
time/exploration sampling (s)                 0.523785
time/logging (s)                              0.0136587
time/sac training (s)                         7.80096
time/saving (s)                               0.0038162
time/training (s)                             3.5474e-05
time/epoch (s)                               10.4072
time/total (s)                             4218.05
Epoch                                       399
---------------------------------------  ---------------
2021-11-24 01:39:44.459856 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 400 finished
---------------------------------------  ---------------
epoch                                       400
replay_buffer/size                       402000
trainer/num train calls                  401000
trainer/QF1 Loss                              5.28208
trainer/QF2 Loss                              4.32028
trainer/Policy Loss                        -408.723
trainer/Q1 Predictions Mean                 409.498
trainer/Q1 Predictions Std                   90.2739
trainer/Q1 Predictions Max                  480.547
trainer/Q1 Predictions Min                   22.686
trainer/Q2 Predictions Mean                 409.443
trainer/Q2 Predictions Std                   90.1875
trainer/Q2 Predictions Max                  480.543
trainer/Q2 Predictions Min                   20.3732
trainer/Q Targets Mean                      409.176
trainer/Q Targets Std                        90.1477
trainer/Q Targets Max                       481.235
trainer/Q Targets Min                        19.8449
trainer/Log Pis Mean                          6.44097
trainer/Log Pis Std                           3.97164
trainer/Log Pis Max                          16.0521
trainer/Log Pis Min                          -5.50762
trainer/policy/mean Mean                      0.0839318
trainer/policy/mean Std                       0.784382
trainer/policy/mean Max                       0.998734
trainer/policy/mean Min                      -0.997105
trainer/policy/normal/std Mean                0.442122
trainer/policy/normal/std Std                 0.139808
trainer/policy/normal/std Max                 0.975476
trainer/policy/normal/std Min                 0.0783173
trainer/policy/normal/log_std Mean           -0.884407
trainer/policy/normal/log_std Std             0.408616
trainer/policy/normal/log_std Max            -0.0248296
trainer/policy/normal/log_std Min            -2.54699
trainer/Alpha                                 0.151639
trainer/Alpha Loss                            0.831774
expl/num steps total                     402000
expl/num paths total                        402
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.86181
expl/Rewards Std                              1.25751
expl/Rewards Max                              8.42224
expl/Rewards Min                             -0.583865
expl/Returns Mean                          5861.81
expl/Returns Std                              0
expl/Returns Max                           5861.81
expl/Returns Min                           5861.81
expl/Actions Mean                             0.096975
expl/Actions Std                              0.793671
expl/Actions Max                              0.999588
expl/Actions Min                             -0.999553
expl/Num Paths                                1
expl/Average Returns                       5861.81
expl/env_infos/final/reward_run Mean          6.03994
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.03994
expl/env_infos/final/reward_run Min           6.03994
expl/env_infos/initial/reward_run Mean       -0.316881
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.316881
expl/env_infos/initial/reward_run Min        -0.316881
expl/env_infos/reward_run Mean                6.24541
expl/env_infos/reward_run Std                 1.25145
expl/env_infos/reward_run Max                 8.89419
expl/env_infos/reward_run Min                -0.316881
expl/env_infos/final/reward_ctrl Mean        -0.228168
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.228168
expl/env_infos/final/reward_ctrl Min         -0.228168
expl/env_infos/initial/reward_ctrl Mean      -0.266984
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.266984
expl/env_infos/initial/reward_ctrl Min       -0.266984
expl/env_infos/reward_ctrl Mean              -0.383591
expl/env_infos/reward_ctrl Std                0.0872858
expl/env_infos/reward_ctrl Max               -0.110578
expl/env_infos/reward_ctrl Min               -0.569375
eval/num steps total                          2.005e+06
eval/num paths total                       2005
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.30135
eval/Rewards Std                              1.35559
eval/Rewards Max                              8.97937
eval/Rewards Min                             -0.756371
eval/Returns Mean                          6301.35
eval/Returns Std                             48.8779
eval/Returns Max                           6351.97
eval/Returns Min                           6214.66
eval/Actions Mean                             0.0906818
eval/Actions Std                              0.818339
eval/Actions Max                              0.99715
eval/Actions Min                             -0.997165
eval/Num Paths                                5
eval/Average Returns                       6301.35
eval/env_infos/final/reward_run Mean          7.03455
eval/env_infos/final/reward_run Std           0.67078
eval/env_infos/final/reward_run Max           8.18816
eval/env_infos/final/reward_run Min           6.434
eval/env_infos/initial/reward_run Mean       -0.283368
eval/env_infos/initial/reward_run Std         0.162403
eval/env_infos/initial/reward_run Max        -0.0916054
eval/env_infos/initial/reward_run Min        -0.541846
eval/env_infos/reward_run Mean                6.70809
eval/env_infos/reward_run Std                 1.34892
eval/env_infos/reward_run Max                 9.44841
eval/env_infos/reward_run Min                -0.541846
eval/env_infos/final/reward_ctrl Mean        -0.384698
eval/env_infos/final/reward_ctrl Std          0.0628729
eval/env_infos/final/reward_ctrl Max         -0.304561
eval/env_infos/final/reward_ctrl Min         -0.476486
eval/env_infos/initial/reward_ctrl Mean      -0.177135
eval/env_infos/initial/reward_ctrl Std        0.0547103
eval/env_infos/initial/reward_ctrl Max       -0.074892
eval/env_infos/initial/reward_ctrl Min       -0.218795
eval/env_infos/reward_ctrl Mean              -0.406742
eval/env_infos/reward_ctrl Std                0.0826198
eval/env_infos/reward_ctrl Max               -0.0688402
eval/env_infos/reward_ctrl Min               -0.570405
time/data storing (s)                         0.00450985
time/evaluation sampling (s)                  2.01912
time/exploration sampling (s)                 0.525185
time/logging (s)                              0.0137052
time/sac training (s)                         7.59852
time/saving (s)                               0.00383394
time/training (s)                             3.6655e-05
time/epoch (s)                               10.1649
time/total (s)                             4228.5
Epoch                                       400
---------------------------------------  ---------------
2021-11-24 01:39:54.915395 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 401 finished
---------------------------------------  ---------------
epoch                                       401
replay_buffer/size                       403000
trainer/num train calls                  402000
trainer/QF1 Loss                              6.06052
trainer/QF2 Loss                              4.49591
trainer/Policy Loss                        -405.957
trainer/Q1 Predictions Mean                 406.653
trainer/Q1 Predictions Std                   99.7622
trainer/Q1 Predictions Max                  481.812
trainer/Q1 Predictions Min                   21.6809
trainer/Q2 Predictions Mean                 406.562
trainer/Q2 Predictions Std                   99.6269
trainer/Q2 Predictions Max                  481.438
trainer/Q2 Predictions Min                   20.9909
trainer/Q Targets Mean                      406.482
trainer/Q Targets Std                       100.007
trainer/Q Targets Max                       483.786
trainer/Q Targets Min                        20.1137
trainer/Log Pis Mean                          6.03862
trainer/Log Pis Std                           4.00662
trainer/Log Pis Max                          14.6616
trainer/Log Pis Min                          -5.32544
trainer/policy/mean Mean                      0.0852295
trainer/policy/mean Std                       0.781763
trainer/policy/mean Max                       0.995012
trainer/policy/mean Min                      -0.998199
trainer/policy/normal/std Mean                0.443486
trainer/policy/normal/std Std                 0.148304
trainer/policy/normal/std Max                 0.946747
trainer/policy/normal/std Min                 0.0670269
trainer/policy/normal/log_std Mean           -0.889949
trainer/policy/normal/log_std Std             0.437752
trainer/policy/normal/log_std Max            -0.0547236
trainer/policy/normal/log_std Min            -2.70266
trainer/Alpha                                 0.149304
trainer/Alpha Loss                            0.0734548
expl/num steps total                     403000
expl/num paths total                        403
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.83675
expl/Rewards Std                              1.21244
expl/Rewards Max                              8.40455
expl/Rewards Min                             -0.676915
expl/Returns Mean                          5836.75
expl/Returns Std                              0
expl/Returns Max                           5836.75
expl/Returns Min                           5836.75
expl/Actions Mean                             0.0950952
expl/Actions Std                              0.789132
expl/Actions Max                              0.999642
expl/Actions Min                             -0.998663
expl/Num Paths                                1
expl/Average Returns                       5836.75
expl/env_infos/final/reward_run Mean          7.01436
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.01436
expl/env_infos/final/reward_run Min           7.01436
expl/env_infos/initial/reward_run Mean       -0.334445
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.334445
expl/env_infos/initial/reward_run Min        -0.334445
expl/env_infos/reward_run Mean                6.21581
expl/env_infos/reward_run Std                 1.20795
expl/env_infos/reward_run Max                 8.9333
expl/env_infos/reward_run Min                -0.334445
expl/env_infos/final/reward_ctrl Mean        -0.272032
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.272032
expl/env_infos/final/reward_ctrl Min         -0.272032
expl/env_infos/initial/reward_ctrl Mean      -0.183536
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.183536
expl/env_infos/initial/reward_ctrl Min       -0.183536
expl/env_infos/reward_ctrl Mean              -0.379064
expl/env_infos/reward_ctrl Std                0.0877698
expl/env_infos/reward_ctrl Max               -0.0620502
expl/env_infos/reward_ctrl Min               -0.556158
eval/num steps total                          2.01e+06
eval/num paths total                       2010
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.17346
eval/Rewards Std                              1.26999
eval/Rewards Max                              8.54679
eval/Rewards Min                             -1.01099
eval/Returns Mean                          6173.46
eval/Returns Std                             64.5134
eval/Returns Max                           6244.7
eval/Returns Min                           6080.17
eval/Actions Mean                             0.0896721
eval/Actions Std                              0.806549
eval/Actions Max                              0.994025
eval/Actions Min                             -0.994645
eval/Num Paths                                5
eval/Average Returns                       6173.46
eval/env_infos/final/reward_run Mean          7.59575
eval/env_infos/final/reward_run Std           0.628103
eval/env_infos/final/reward_run Max           8.47047
eval/env_infos/final/reward_run Min           6.63303
eval/env_infos/initial/reward_run Mean        0.0231913
eval/env_infos/initial/reward_run Std         0.266077
eval/env_infos/initial/reward_run Max         0.487283
eval/env_infos/initial/reward_run Min        -0.243634
eval/env_infos/reward_run Mean                6.5686
eval/env_infos/reward_run Std                 1.26659
eval/env_infos/reward_run Max                 9.00947
eval/env_infos/reward_run Min                -0.587212
eval/env_infos/final/reward_ctrl Mean        -0.340519
eval/env_infos/final/reward_ctrl Std          0.025411
eval/env_infos/final/reward_ctrl Max         -0.30306
eval/env_infos/final/reward_ctrl Min         -0.366625
eval/env_infos/initial/reward_ctrl Mean      -0.179705
eval/env_infos/initial/reward_ctrl Std        0.0522857
eval/env_infos/initial/reward_ctrl Max       -0.124546
eval/env_infos/initial/reward_ctrl Min       -0.253414
eval/env_infos/reward_ctrl Mean              -0.395138
eval/env_infos/reward_ctrl Std                0.0820287
eval/env_infos/reward_ctrl Max               -0.0927878
eval/env_infos/reward_ctrl Min               -0.574499
time/data storing (s)                         0.00451673
time/evaluation sampling (s)                  2.04942
time/exploration sampling (s)                 0.519986
time/logging (s)                              0.0143031
time/sac training (s)                         7.56249
time/saving (s)                               0.00387946
time/training (s)                             3.9621e-05
time/epoch (s)                               10.1546
time/total (s)                             4238.94
Epoch                                       401
---------------------------------------  ---------------
2021-11-24 01:40:05.464202 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 402 finished
---------------------------------------  ---------------
epoch                                       402
replay_buffer/size                       404000
trainer/num train calls                  403000
trainer/QF1 Loss                              5.04767
trainer/QF2 Loss                              3.80599
trainer/Policy Loss                        -408.187
trainer/Q1 Predictions Mean                 409.009
trainer/Q1 Predictions Std                   95.0551
trainer/Q1 Predictions Max                  478.624
trainer/Q1 Predictions Min                   22.786
trainer/Q2 Predictions Mean                 409.061
trainer/Q2 Predictions Std                   95.2475
trainer/Q2 Predictions Max                  478.325
trainer/Q2 Predictions Min                   21.9585
trainer/Q Targets Mean                      409.267
trainer/Q Targets Std                        95.2678
trainer/Q Targets Max                       477.217
trainer/Q Targets Min                        22.8032
trainer/Log Pis Mean                          5.88904
trainer/Log Pis Std                           4.1839
trainer/Log Pis Max                          15.5806
trainer/Log Pis Min                          -5.60499
trainer/policy/mean Mean                      0.0802039
trainer/policy/mean Std                       0.777504
trainer/policy/mean Max                       0.995348
trainer/policy/mean Min                      -0.996831
trainer/policy/normal/std Mean                0.442541
trainer/policy/normal/std Std                 0.151035
trainer/policy/normal/std Max                 0.994386
trainer/policy/normal/std Min                 0.0647648
trainer/policy/normal/log_std Mean           -0.894615
trainer/policy/normal/log_std Std             0.442579
trainer/policy/normal/log_std Max            -0.00562968
trainer/policy/normal/log_std Min            -2.73699
trainer/Alpha                                 0.148818
trainer/Alpha Loss                           -0.211384
expl/num steps total                     404000
expl/num paths total                        404
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.72326
expl/Rewards Std                              1.25092
expl/Rewards Max                              8.4904
expl/Rewards Min                             -0.394139
expl/Returns Mean                          5723.26
expl/Returns Std                              0
expl/Returns Max                           5723.26
expl/Returns Min                           5723.26
expl/Actions Mean                             0.0901714
expl/Actions Std                              0.79529
expl/Actions Max                              0.999795
expl/Actions Min                             -0.998936
expl/Num Paths                                1
expl/Average Returns                       5723.26
expl/env_infos/final/reward_run Mean          6.63057
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.63057
expl/env_infos/final/reward_run Min           6.63057
expl/env_infos/initial/reward_run Mean       -0.205006
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.205006
expl/env_infos/initial/reward_run Min        -0.205006
expl/env_infos/reward_run Mean                6.10763
expl/env_infos/reward_run Std                 1.2454
expl/env_infos/reward_run Max                 8.82501
expl/env_infos/reward_run Min                -0.205006
expl/env_infos/final/reward_ctrl Mean        -0.36888
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.36888
expl/env_infos/final/reward_ctrl Min         -0.36888
expl/env_infos/initial/reward_ctrl Mean      -0.189133
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.189133
expl/env_infos/initial/reward_ctrl Min       -0.189133
expl/env_infos/reward_ctrl Mean              -0.38437
expl/env_infos/reward_ctrl Std                0.0884248
expl/env_infos/reward_ctrl Max               -0.067638
expl/env_infos/reward_ctrl Min               -0.560962
eval/num steps total                          2.015e+06
eval/num paths total                       2015
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.35255
eval/Rewards Std                              1.34694
eval/Rewards Max                              8.95218
eval/Rewards Min                             -0.874428
eval/Returns Mean                          6352.55
eval/Returns Std                             55.4815
eval/Returns Max                           6451.61
eval/Returns Min                           6282.93
eval/Actions Mean                             0.0841048
eval/Actions Std                              0.820457
eval/Actions Max                              0.99586
eval/Actions Min                             -0.996036
eval/Num Paths                                5
eval/Average Returns                       6352.55
eval/env_infos/final/reward_run Mean          7.55952
eval/env_infos/final/reward_run Std           0.840022
eval/env_infos/final/reward_run Max           8.94781
eval/env_infos/final/reward_run Min           6.59675
eval/env_infos/initial/reward_run Mean       -0.302521
eval/env_infos/initial/reward_run Std         0.346941
eval/env_infos/initial/reward_run Max         0.342625
eval/env_infos/initial/reward_run Min        -0.671953
eval/env_infos/reward_run Mean                6.76068
eval/env_infos/reward_run Std                 1.34242
eval/env_infos/reward_run Max                 9.447
eval/env_infos/reward_run Min                -0.671953
eval/env_infos/final/reward_ctrl Mean        -0.456832
eval/env_infos/final/reward_ctrl Std          0.063242
eval/env_infos/final/reward_ctrl Max         -0.357801
eval/env_infos/final/reward_ctrl Min         -0.534436
eval/env_infos/initial/reward_ctrl Mean      -0.143369
eval/env_infos/initial/reward_ctrl Std        0.0419215
eval/env_infos/initial/reward_ctrl Max       -0.095953
eval/env_infos/initial/reward_ctrl Min       -0.202475
eval/env_infos/reward_ctrl Mean              -0.408134
eval/env_infos/reward_ctrl Std                0.0810373
eval/env_infos/reward_ctrl Max               -0.0749539
eval/env_infos/reward_ctrl Min               -0.5771
time/data storing (s)                         0.00454511
time/evaluation sampling (s)                  1.994
time/exploration sampling (s)                 0.542404
time/logging (s)                              0.0137057
time/sac training (s)                         7.68296
time/saving (s)                               0.00381778
time/training (s)                             3.562e-05
time/epoch (s)                               10.2415
time/total (s)                             4249.48
Epoch                                       402
---------------------------------------  ---------------
2021-11-24 01:40:15.858250 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 403 finished
---------------------------------------  ---------------
epoch                                       403
replay_buffer/size                       405000
trainer/num train calls                  404000
trainer/QF1 Loss                              5.62758
trainer/QF2 Loss                              5.29906
trainer/Policy Loss                        -400.105
trainer/Q1 Predictions Mean                 400.879
trainer/Q1 Predictions Std                  109.212
trainer/Q1 Predictions Max                  476.303
trainer/Q1 Predictions Min                   21.5803
trainer/Q2 Predictions Mean                 400.921
trainer/Q2 Predictions Std                  109.063
trainer/Q2 Predictions Max                  477.212
trainer/Q2 Predictions Min                   22.179
trainer/Q Targets Mean                      400.458
trainer/Q Targets Std                       108.84
trainer/Q Targets Max                       475.563
trainer/Q Targets Min                        22.7025
trainer/Log Pis Mean                          6.31726
trainer/Log Pis Std                           4.57121
trainer/Log Pis Max                          17.8063
trainer/Log Pis Min                          -5.47412
trainer/policy/mean Mean                      0.089827
trainer/policy/mean Std                       0.779372
trainer/policy/mean Max                       0.994544
trainer/policy/mean Min                      -0.998579
trainer/policy/normal/std Mean                0.451326
trainer/policy/normal/std Std                 0.147648
trainer/policy/normal/std Max                 1.05126
trainer/policy/normal/std Min                 0.0739739
trainer/policy/normal/log_std Mean           -0.867127
trainer/policy/normal/log_std Std             0.418167
trainer/policy/normal/log_std Max             0.0499913
trainer/policy/normal/log_std Min            -2.60404
trainer/Alpha                                 0.150905
trainer/Alpha Loss                            0.599965
expl/num steps total                     405000
expl/num paths total                        405
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.84687
expl/Rewards Std                              1.28922
expl/Rewards Max                              8.26582
expl/Rewards Min                             -0.829226
expl/Returns Mean                          5846.87
expl/Returns Std                              0
expl/Returns Max                           5846.87
expl/Returns Min                           5846.87
expl/Actions Mean                             0.0937541
expl/Actions Std                              0.802448
expl/Actions Max                              0.99924
expl/Actions Min                             -0.999894
expl/Num Paths                                1
expl/Average Returns                       5846.87
expl/env_infos/final/reward_run Mean          7.02628
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.02628
expl/env_infos/final/reward_run Min           7.02628
expl/env_infos/initial/reward_run Mean       -0.669665
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.669665
expl/env_infos/initial/reward_run Min        -0.669665
expl/env_infos/reward_run Mean                6.23849
expl/env_infos/reward_run Std                 1.28714
expl/env_infos/reward_run Max                 8.75434
expl/env_infos/reward_run Min                -0.669665
expl/env_infos/final/reward_ctrl Mean        -0.319359
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.319359
expl/env_infos/final/reward_ctrl Min         -0.319359
expl/env_infos/initial/reward_ctrl Mean      -0.159561
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.159561
expl/env_infos/initial/reward_ctrl Min       -0.159561
expl/env_infos/reward_ctrl Mean              -0.391628
expl/env_infos/reward_ctrl Std                0.0921097
expl/env_infos/reward_ctrl Max               -0.124776
expl/env_infos/reward_ctrl Min               -0.577443
eval/num steps total                          2.02e+06
eval/num paths total                       2020
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.20686
eval/Rewards Std                              1.31972
eval/Rewards Max                              8.80942
eval/Rewards Min                             -0.834963
eval/Returns Mean                          6206.86
eval/Returns Std                             60.8364
eval/Returns Max                           6311.07
eval/Returns Min                           6130.17
eval/Actions Mean                             0.0968003
eval/Actions Std                              0.822114
eval/Actions Max                              0.99719
eval/Actions Min                             -0.998774
eval/Num Paths                                5
eval/Average Returns                       6206.86
eval/env_infos/final/reward_run Mean          7.73967
eval/env_infos/final/reward_run Std           0.816343
eval/env_infos/final/reward_run Max           8.74086
eval/env_infos/final/reward_run Min           6.60065
eval/env_infos/initial/reward_run Mean       -0.410677
eval/env_infos/initial/reward_run Std         0.332332
eval/env_infos/initial/reward_run Max         0.250007
eval/env_infos/initial/reward_run Min        -0.624951
eval/env_infos/reward_run Mean                6.618
eval/env_infos/reward_run Std                 1.31452
eval/env_infos/reward_run Max                 9.35856
eval/env_infos/reward_run Min                -0.624951
eval/env_infos/final/reward_ctrl Mean        -0.46908
eval/env_infos/final/reward_ctrl Std          0.0627004
eval/env_infos/final/reward_ctrl Max         -0.366448
eval/env_infos/final/reward_ctrl Min         -0.529238
eval/env_infos/initial/reward_ctrl Mean      -0.208375
eval/env_infos/initial/reward_ctrl Std        0.0494105
eval/env_infos/initial/reward_ctrl Max       -0.13676
eval/env_infos/initial/reward_ctrl Min       -0.276795
eval/env_infos/reward_ctrl Mean              -0.411145
eval/env_infos/reward_ctrl Std                0.0903835
eval/env_infos/reward_ctrl Max               -0.0903294
eval/env_infos/reward_ctrl Min               -0.578873
time/data storing (s)                         0.00450479
time/evaluation sampling (s)                  2.01982
time/exploration sampling (s)                 0.533924
time/logging (s)                              0.013741
time/sac training (s)                         7.52106
time/saving (s)                               0.00379173
time/training (s)                             3.5083e-05
time/epoch (s)                               10.0969
time/total (s)                             4259.86
Epoch                                       403
---------------------------------------  ---------------
2021-11-24 01:40:26.247658 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 404 finished
---------------------------------------  ---------------
epoch                                       404
replay_buffer/size                       406000
trainer/num train calls                  405000
trainer/QF1 Loss                              5.11564
trainer/QF2 Loss                              4.86231
trainer/Policy Loss                        -407.293
trainer/Q1 Predictions Mean                 407.844
trainer/Q1 Predictions Std                   95.1745
trainer/Q1 Predictions Max                  474.727
trainer/Q1 Predictions Min                   20.8942
trainer/Q2 Predictions Mean                 408.067
trainer/Q2 Predictions Std                   95.1892
trainer/Q2 Predictions Max                  473.436
trainer/Q2 Predictions Min                   20.8541
trainer/Q Targets Mean                      407.922
trainer/Q Targets Std                        95.1227
trainer/Q Targets Max                       475.933
trainer/Q Targets Min                        20.4569
trainer/Log Pis Mean                          6.26677
trainer/Log Pis Std                           4.37152
trainer/Log Pis Max                          19.5249
trainer/Log Pis Min                          -5.57968
trainer/policy/mean Mean                      0.0765284
trainer/policy/mean Std                       0.784753
trainer/policy/mean Max                       0.993798
trainer/policy/mean Min                      -0.995711
trainer/policy/normal/std Mean                0.453251
trainer/policy/normal/std Std                 0.145716
trainer/policy/normal/std Max                 1.39919
trainer/policy/normal/std Min                 0.0585471
trainer/policy/normal/log_std Mean           -0.863893
trainer/policy/normal/log_std Std             0.427597
trainer/policy/normal/log_std Max             0.335895
trainer/policy/normal/log_std Min            -2.83792
trainer/Alpha                                 0.153763
trainer/Alpha Loss                            0.499486
expl/num steps total                     406000
expl/num paths total                        406
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.94875
expl/Rewards Std                              1.27116
expl/Rewards Max                              8.3273
expl/Rewards Min                             -0.501373
expl/Returns Mean                          5948.75
expl/Returns Std                              0
expl/Returns Max                           5948.75
expl/Returns Min                           5948.75
expl/Actions Mean                             0.099074
expl/Actions Std                              0.808974
expl/Actions Max                              0.999615
expl/Actions Min                             -0.998582
expl/Num Paths                                1
expl/Average Returns                       5948.75
expl/env_infos/final/reward_run Mean          5.67632
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.67632
expl/env_infos/final/reward_run Min           5.67632
expl/env_infos/initial/reward_run Mean       -0.265794
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.265794
expl/env_infos/initial/reward_run Min        -0.265794
expl/env_infos/reward_run Mean                6.34731
expl/env_infos/reward_run Std                 1.26232
expl/env_infos/reward_run Max                 8.87972
expl/env_infos/reward_run Min                -0.265794
expl/env_infos/final/reward_ctrl Mean        -0.406267
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.406267
expl/env_infos/final/reward_ctrl Min         -0.406267
expl/env_infos/initial/reward_ctrl Mean      -0.235579
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.235579
expl/env_infos/initial/reward_ctrl Min       -0.235579
expl/env_infos/reward_ctrl Mean              -0.398552
expl/env_infos/reward_ctrl Std                0.0883853
expl/env_infos/reward_ctrl Max               -0.107554
expl/env_infos/reward_ctrl Min               -0.578804
eval/num steps total                          2.025e+06
eval/num paths total                       2025
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.26177
eval/Rewards Std                              1.33694
eval/Rewards Max                              9.05885
eval/Rewards Min                             -0.928368
eval/Returns Mean                          6261.77
eval/Returns Std                             52.1374
eval/Returns Max                           6310.27
eval/Returns Min                           6167.33
eval/Actions Mean                             0.0935158
eval/Actions Std                              0.826665
eval/Actions Max                              0.995481
eval/Actions Min                             -0.997869
eval/Num Paths                                5
eval/Average Returns                       6261.77
eval/env_infos/final/reward_run Mean          6.63498
eval/env_infos/final/reward_run Std           0.146194
eval/env_infos/final/reward_run Max           6.8005
eval/env_infos/final/reward_run Min           6.38771
eval/env_infos/initial/reward_run Mean       -0.189895
eval/env_infos/initial/reward_run Std         0.448905
eval/env_infos/initial/reward_run Max         0.608629
eval/env_infos/initial/reward_run Min        -0.670843
eval/env_infos/reward_run Mean                6.67704
eval/env_infos/reward_run Std                 1.32696
eval/env_infos/reward_run Max                 9.57628
eval/env_infos/reward_run Min                -0.670843
eval/env_infos/final/reward_ctrl Mean        -0.486398
eval/env_infos/final/reward_ctrl Std          0.052421
eval/env_infos/final/reward_ctrl Max         -0.387118
eval/env_infos/final/reward_ctrl Min         -0.532493
eval/env_infos/initial/reward_ctrl Mean      -0.239987
eval/env_infos/initial/reward_ctrl Std        0.0160552
eval/env_infos/initial/reward_ctrl Max       -0.210285
eval/env_infos/initial/reward_ctrl Min       -0.257524
eval/env_infos/reward_ctrl Mean              -0.415272
eval/env_infos/reward_ctrl Std                0.0857787
eval/env_infos/reward_ctrl Max               -0.104505
eval/env_infos/reward_ctrl Min               -0.581337
time/data storing (s)                         0.00454639
time/evaluation sampling (s)                  1.99966
time/exploration sampling (s)                 0.539548
time/logging (s)                              0.0138793
time/sac training (s)                         7.52796
time/saving (s)                               0.00377436
time/training (s)                             3.465e-05
time/epoch (s)                               10.0894
time/total (s)                             4270.23
Epoch                                       404
---------------------------------------  ---------------
2021-11-24 01:40:36.616563 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 405 finished
---------------------------------------  ---------------
epoch                                       405
replay_buffer/size                       407000
trainer/num train calls                  406000
trainer/QF1 Loss                              5.44385
trainer/QF2 Loss                              5.67399
trainer/Policy Loss                        -404.033
trainer/Q1 Predictions Mean                 404.806
trainer/Q1 Predictions Std                   97.9165
trainer/Q1 Predictions Max                  480.266
trainer/Q1 Predictions Min                   22.3447
trainer/Q2 Predictions Mean                 404.498
trainer/Q2 Predictions Std                   97.6723
trainer/Q2 Predictions Max                  480.486
trainer/Q2 Predictions Min                   22.7871
trainer/Q Targets Mean                      404.364
trainer/Q Targets Std                        97.6158
trainer/Q Targets Max                       481.385
trainer/Q Targets Min                        22.6383
trainer/Log Pis Mean                          6.02235
trainer/Log Pis Std                           4.35597
trainer/Log Pis Max                          14.9277
trainer/Log Pis Min                          -4.05384
trainer/policy/mean Mean                      0.0936729
trainer/policy/mean Std                       0.776752
trainer/policy/mean Max                       0.99279
trainer/policy/mean Min                      -0.998458
trainer/policy/normal/std Mean                0.438901
trainer/policy/normal/std Std                 0.146266
trainer/policy/normal/std Max                 0.996307
trainer/policy/normal/std Min                 0.0743248
trainer/policy/normal/log_std Mean           -0.900638
trainer/policy/normal/log_std Std             0.436939
trainer/policy/normal/log_std Max            -0.00370024
trainer/policy/normal/log_std Min            -2.59931
trainer/Alpha                                 0.151061
trainer/Alpha Loss                            0.0422462
expl/num steps total                     407000
expl/num paths total                        407
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.78309
expl/Rewards Std                              1.27603
expl/Rewards Max                              8.58064
expl/Rewards Min                             -0.657444
expl/Returns Mean                          5783.09
expl/Returns Std                              0
expl/Returns Max                           5783.09
expl/Returns Min                           5783.09
expl/Actions Mean                             0.0862024
expl/Actions Std                              0.800913
expl/Actions Max                              0.999393
expl/Actions Min                             -0.999029
expl/Num Paths                                1
expl/Average Returns                       5783.09
expl/env_infos/final/reward_run Mean          5.65698
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.65698
expl/env_infos/final/reward_run Min           5.65698
expl/env_infos/initial/reward_run Mean       -0.399899
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.399899
expl/env_infos/initial/reward_run Min        -0.399899
expl/env_infos/reward_run Mean                6.17243
expl/env_infos/reward_run Std                 1.27575
expl/env_infos/reward_run Max                 9.02387
expl/env_infos/reward_run Min                -0.408165
expl/env_infos/final/reward_ctrl Mean        -0.405229
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.405229
expl/env_infos/final/reward_ctrl Min         -0.405229
expl/env_infos/initial/reward_ctrl Mean      -0.135459
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.135459
expl/env_infos/initial/reward_ctrl Min       -0.135459
expl/env_infos/reward_ctrl Mean              -0.389335
expl/env_infos/reward_ctrl Std                0.0869037
expl/env_infos/reward_ctrl Max               -0.0533257
expl/env_infos/reward_ctrl Min               -0.574434
eval/num steps total                          2.03e+06
eval/num paths total                       2030
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.35039
eval/Rewards Std                              1.33322
eval/Rewards Max                              8.92877
eval/Rewards Min                             -0.700799
eval/Returns Mean                          6350.39
eval/Returns Std                             29.7182
eval/Returns Max                           6406.11
eval/Returns Min                           6319.06
eval/Actions Mean                             0.0871102
eval/Actions Std                              0.825053
eval/Actions Max                              0.9955
eval/Actions Min                             -0.996777
eval/Num Paths                                5
eval/Average Returns                       6350.39
eval/env_infos/final/reward_run Mean          7.45922
eval/env_infos/final/reward_run Std           0.634305
eval/env_infos/final/reward_run Max           8.39782
eval/env_infos/final/reward_run Min           6.5176
eval/env_infos/initial/reward_run Mean       -0.19943
eval/env_infos/initial/reward_run Std         0.207708
eval/env_infos/initial/reward_run Max         0.0518036
eval/env_infos/initial/reward_run Min        -0.494082
eval/env_infos/reward_run Mean                6.76338
eval/env_infos/reward_run Std                 1.32855
eval/env_infos/reward_run Max                 9.43063
eval/env_infos/reward_run Min                -0.494082
eval/env_infos/final/reward_ctrl Mean        -0.383558
eval/env_infos/final/reward_ctrl Std          0.0602384
eval/env_infos/final/reward_ctrl Max         -0.292905
eval/env_infos/final/reward_ctrl Min         -0.462328
eval/env_infos/initial/reward_ctrl Mean      -0.222406
eval/env_infos/initial/reward_ctrl Std        0.0724142
eval/env_infos/initial/reward_ctrl Max       -0.0958654
eval/env_infos/initial/reward_ctrl Min       -0.302355
eval/env_infos/reward_ctrl Mean              -0.412981
eval/env_infos/reward_ctrl Std                0.0835308
eval/env_infos/reward_ctrl Max               -0.0958654
eval/env_infos/reward_ctrl Min               -0.577041
time/data storing (s)                         0.00455831
time/evaluation sampling (s)                  1.99775
time/exploration sampling (s)                 0.533383
time/logging (s)                              0.0136531
time/sac training (s)                         7.51716
time/saving (s)                               0.00382808
time/training (s)                             3.4773e-05
time/epoch (s)                               10.0704
time/total (s)                             4280.59
Epoch                                       405
---------------------------------------  ---------------
2021-11-24 01:40:47.097310 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 406 finished
---------------------------------------  ---------------
epoch                                       406
replay_buffer/size                       408000
trainer/num train calls                  407000
trainer/QF1 Loss                              7.21567
trainer/QF2 Loss                              6.29758
trainer/Policy Loss                        -409.07
trainer/Q1 Predictions Mean                 409.539
trainer/Q1 Predictions Std                   86.9659
trainer/Q1 Predictions Max                  479.66
trainer/Q1 Predictions Min                   21.5755
trainer/Q2 Predictions Mean                 409.566
trainer/Q2 Predictions Std                   87.1742
trainer/Q2 Predictions Max                  480.117
trainer/Q2 Predictions Min                   21.4533
trainer/Q Targets Mean                      409.562
trainer/Q Targets Std                        86.9366
trainer/Q Targets Max                       480.406
trainer/Q Targets Min                        22.2804
trainer/Log Pis Mean                          6.26989
trainer/Log Pis Std                           4.32088
trainer/Log Pis Max                          16.4174
trainer/Log Pis Min                          -5.90114
trainer/policy/mean Mean                      0.095161
trainer/policy/mean Std                       0.778118
trainer/policy/mean Max                       0.995109
trainer/policy/mean Min                      -0.997794
trainer/policy/normal/std Mean                0.450709
trainer/policy/normal/std Std                 0.148528
trainer/policy/normal/std Max                 1.01335
trainer/policy/normal/std Min                 0.0755705
trainer/policy/normal/log_std Mean           -0.870237
trainer/policy/normal/log_std Std             0.423589
trainer/policy/normal/log_std Max             0.0132629
trainer/policy/normal/log_std Min            -2.58269
trainer/Alpha                                 0.152808
trainer/Alpha Loss                            0.507009
expl/num steps total                     408000
expl/num paths total                        408
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.84703
expl/Rewards Std                              1.27949
expl/Rewards Max                              8.48606
expl/Rewards Min                             -0.45848
expl/Returns Mean                          5847.03
expl/Returns Std                              0
expl/Returns Max                           5847.03
expl/Returns Min                           5847.03
expl/Actions Mean                             0.105549
expl/Actions Std                              0.801525
expl/Actions Max                              0.999143
expl/Actions Min                             -0.999602
expl/Num Paths                                1
expl/Average Returns                       5847.03
expl/env_infos/final/reward_run Mean          8.13352
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.13352
expl/env_infos/final/reward_run Min           8.13352
expl/env_infos/initial/reward_run Mean       -0.21696
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.21696
expl/env_infos/initial/reward_run Min        -0.21696
expl/env_infos/reward_run Mean                6.23918
expl/env_infos/reward_run Std                 1.27077
expl/env_infos/reward_run Max                 9.00443
expl/env_infos/reward_run Min                -0.21696
expl/env_infos/final/reward_ctrl Mean        -0.379549
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.379549
expl/env_infos/final/reward_ctrl Min         -0.379549
expl/env_infos/initial/reward_ctrl Mean      -0.24152
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.24152
expl/env_infos/initial/reward_ctrl Min       -0.24152
expl/env_infos/reward_ctrl Mean              -0.39215
expl/env_infos/reward_ctrl Std                0.0925531
expl/env_infos/reward_ctrl Max               -0.0609301
expl/env_infos/reward_ctrl Min               -0.577191
eval/num steps total                          2.035e+06
eval/num paths total                       2035
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.22663
eval/Rewards Std                              1.33964
eval/Rewards Max                              8.83986
eval/Rewards Min                             -0.926892
eval/Returns Mean                          6226.63
eval/Returns Std                             68.5295
eval/Returns Max                           6300.22
eval/Returns Min                           6132.74
eval/Actions Mean                             0.0996639
eval/Actions Std                              0.821346
eval/Actions Max                              0.997175
eval/Actions Min                             -0.998494
eval/Num Paths                                5
eval/Average Returns                       6226.63
eval/env_infos/final/reward_run Mean          7.49324
eval/env_infos/final/reward_run Std           0.943689
eval/env_infos/final/reward_run Max           8.26091
eval/env_infos/final/reward_run Min           6.10719
eval/env_infos/initial/reward_run Mean       -0.47572
eval/env_infos/initial/reward_run Std         0.155189
eval/env_infos/initial/reward_run Max        -0.317379
eval/env_infos/initial/reward_run Min        -0.748136
eval/env_infos/reward_run Mean                6.63735
eval/env_infos/reward_run Std                 1.32918
eval/env_infos/reward_run Max                 9.36344
eval/env_infos/reward_run Min                -0.748136
eval/env_infos/final/reward_ctrl Mean        -0.417488
eval/env_infos/final/reward_ctrl Std          0.0505015
eval/env_infos/final/reward_ctrl Max         -0.332136
eval/env_infos/final/reward_ctrl Min         -0.483748
eval/env_infos/initial/reward_ctrl Mean      -0.201381
eval/env_infos/initial/reward_ctrl Std        0.0384461
eval/env_infos/initial/reward_ctrl Max       -0.137929
eval/env_infos/initial/reward_ctrl Min       -0.243354
eval/env_infos/reward_ctrl Mean              -0.410726
eval/env_infos/reward_ctrl Std                0.086427
eval/env_infos/reward_ctrl Max               -0.0920115
eval/env_infos/reward_ctrl Min               -0.579471
time/data storing (s)                         0.00445804
time/evaluation sampling (s)                  2.02201
time/exploration sampling (s)                 0.610381
time/logging (s)                              0.0137334
time/sac training (s)                         7.527
time/saving (s)                               0.00380017
time/training (s)                             3.4233e-05
time/epoch (s)                               10.1814
time/total (s)                             4291.05
Epoch                                       406
---------------------------------------  ---------------
2021-11-24 01:40:57.539055 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 407 finished
---------------------------------------  ---------------
epoch                                       407
replay_buffer/size                       409000
trainer/num train calls                  408000
trainer/QF1 Loss                             11.7976
trainer/QF2 Loss                              7.21591
trainer/Policy Loss                        -407.188
trainer/Q1 Predictions Mean                 407.898
trainer/Q1 Predictions Std                   93.3269
trainer/Q1 Predictions Max                  482.228
trainer/Q1 Predictions Min                   23.0043
trainer/Q2 Predictions Mean                 407.895
trainer/Q2 Predictions Std                   93.593
trainer/Q2 Predictions Max                  482.575
trainer/Q2 Predictions Min                   22.5068
trainer/Q Targets Mean                      407.7
trainer/Q Targets Std                        93.5999
trainer/Q Targets Max                       482.749
trainer/Q Targets Min                        22.5679
trainer/Log Pis Mean                          5.89659
trainer/Log Pis Std                           4.36218
trainer/Log Pis Max                          16.266
trainer/Log Pis Min                          -5.982
trainer/policy/mean Mean                      0.0706959
trainer/policy/mean Std                       0.787516
trainer/policy/mean Max                       0.994906
trainer/policy/mean Min                      -0.99839
trainer/policy/normal/std Mean                0.447314
trainer/policy/normal/std Std                 0.142124
trainer/policy/normal/std Max                 0.915445
trainer/policy/normal/std Min                 0.0678974
trainer/policy/normal/log_std Mean           -0.875379
trainer/policy/normal/log_std Std             0.421022
trainer/policy/normal/log_std Max            -0.0883452
trainer/policy/normal/log_std Min            -2.68976
trainer/Alpha                                 0.15304
trainer/Alpha Loss                           -0.194107
expl/num steps total                     409000
expl/num paths total                        409
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.93682
expl/Rewards Std                              1.27767
expl/Rewards Max                              8.60482
expl/Rewards Min                             -0.497895
expl/Returns Mean                          5936.82
expl/Returns Std                              0
expl/Returns Max                           5936.82
expl/Returns Min                           5936.82
expl/Actions Mean                             0.10677
expl/Actions Std                              0.799124
expl/Actions Max                              0.999585
expl/Actions Min                             -0.998362
expl/Num Paths                                1
expl/Average Returns                       5936.82
expl/env_infos/final/reward_run Mean          6.25064
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.25064
expl/env_infos/final/reward_run Min           6.25064
expl/env_infos/initial/reward_run Mean        0.10671
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.10671
expl/env_infos/initial/reward_run Min         0.10671
expl/env_infos/reward_run Mean                6.32682
expl/env_infos/reward_run Std                 1.26675
expl/env_infos/reward_run Max                 9.09749
expl/env_infos/reward_run Min                -0.157781
expl/env_infos/final/reward_ctrl Mean        -0.339141
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.339141
expl/env_infos/final/reward_ctrl Min         -0.339141
expl/env_infos/initial/reward_ctrl Mean      -0.172828
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.172828
expl/env_infos/initial/reward_ctrl Min       -0.172828
expl/env_infos/reward_ctrl Mean              -0.389999
expl/env_infos/reward_ctrl Std                0.087935
expl/env_infos/reward_ctrl Max               -0.0652326
expl/env_infos/reward_ctrl Min               -0.57854
eval/num steps total                          2.04e+06
eval/num paths total                       2040
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.29052
eval/Rewards Std                              1.34073
eval/Rewards Max                              8.72545
eval/Rewards Min                             -0.995542
eval/Returns Mean                          6290.52
eval/Returns Std                             63.6178
eval/Returns Max                           6368.29
eval/Returns Min                           6191.66
eval/Actions Mean                             0.10122
eval/Actions Std                              0.815824
eval/Actions Max                              0.995427
eval/Actions Min                             -0.99515
eval/Num Paths                                5
eval/Average Returns                       6290.52
eval/env_infos/final/reward_run Mean          6.67657
eval/env_infos/final/reward_run Std           1.38937
eval/env_infos/final/reward_run Max           8.31914
eval/env_infos/final/reward_run Min           4.69953
eval/env_infos/initial/reward_run Mean       -0.381381
eval/env_infos/initial/reward_run Std         0.377676
eval/env_infos/initial/reward_run Max         0.282846
eval/env_infos/initial/reward_run Min        -0.782422
eval/env_infos/reward_run Mean                6.69601
eval/env_infos/reward_run Std                 1.33274
eval/env_infos/reward_run Max                 9.25863
eval/env_infos/reward_run Min                -0.782422
eval/env_infos/final/reward_ctrl Mean        -0.449378
eval/env_infos/final/reward_ctrl Std          0.0494578
eval/env_infos/final/reward_ctrl Max         -0.414614
eval/env_infos/final/reward_ctrl Min         -0.54696
eval/env_infos/initial/reward_ctrl Mean      -0.150421
eval/env_infos/initial/reward_ctrl Std        0.0561856
eval/env_infos/initial/reward_ctrl Max       -0.0487263
eval/env_infos/initial/reward_ctrl Min       -0.21312
eval/env_infos/reward_ctrl Mean              -0.405488
eval/env_infos/reward_ctrl Std                0.0859747
eval/env_infos/reward_ctrl Max               -0.0485901
eval/env_infos/reward_ctrl Min               -0.577177
time/data storing (s)                         0.00451769
time/evaluation sampling (s)                  2.01043
time/exploration sampling (s)                 0.521202
time/logging (s)                              0.0137162
time/sac training (s)                         7.58217
time/saving (s)                               0.0038302
time/training (s)                             3.4612e-05
time/epoch (s)                               10.1359
time/total (s)                             4301.48
Epoch                                       407
---------------------------------------  ---------------
2021-11-24 01:41:08.140686 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 408 finished
---------------------------------------  ----------------
epoch                                       408
replay_buffer/size                       410000
trainer/num train calls                  409000
trainer/QF1 Loss                              7.1912
trainer/QF2 Loss                              6.9638
trainer/Policy Loss                        -399.103
trainer/Q1 Predictions Mean                 399.746
trainer/Q1 Predictions Std                  111.173
trainer/Q1 Predictions Max                  479.536
trainer/Q1 Predictions Min                   20.8708
trainer/Q2 Predictions Mean                 399.638
trainer/Q2 Predictions Std                  111.169
trainer/Q2 Predictions Max                  479.29
trainer/Q2 Predictions Min                   22.3961
trainer/Q Targets Mean                      399.757
trainer/Q Targets Std                       111.163
trainer/Q Targets Max                       480.87
trainer/Q Targets Min                        21.5474
trainer/Log Pis Mean                          5.9869
trainer/Log Pis Std                           4.57692
trainer/Log Pis Max                          17.8579
trainer/Log Pis Min                          -6.65481
trainer/policy/mean Mean                      0.0787208
trainer/policy/mean Std                       0.764439
trainer/policy/mean Max                       0.99872
trainer/policy/mean Min                      -0.996588
trainer/policy/normal/std Mean                0.44629
trainer/policy/normal/std Std                 0.153232
trainer/policy/normal/std Max                 0.920702
trainer/policy/normal/std Min                 0.0596171
trainer/policy/normal/log_std Mean           -0.886207
trainer/policy/normal/log_std Std             0.441377
trainer/policy/normal/log_std Max            -0.0826183
trainer/policy/normal/log_std Min            -2.81981
trainer/Alpha                                 0.151919
trainer/Alpha Loss                           -0.024681
expl/num steps total                     410000
expl/num paths total                        410
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.81467
expl/Rewards Std                              1.31686
expl/Rewards Max                              8.4452
expl/Rewards Min                             -0.58638
expl/Returns Mean                          5814.67
expl/Returns Std                              0
expl/Returns Max                           5814.67
expl/Returns Min                           5814.67
expl/Actions Mean                             0.0845083
expl/Actions Std                              0.801598
expl/Actions Max                              0.999516
expl/Actions Min                             -0.999507
expl/Num Paths                                1
expl/Average Returns                       5814.67
expl/env_infos/final/reward_run Mean          6.28239
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.28239
expl/env_infos/final/reward_run Min           6.28239
expl/env_infos/initial/reward_run Mean       -0.328351
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.328351
expl/env_infos/initial/reward_run Min        -0.328351
expl/env_infos/reward_run Mean                6.20449
expl/env_infos/reward_run Std                 1.31435
expl/env_infos/reward_run Max                 8.8823
expl/env_infos/reward_run Min                -0.328351
expl/env_infos/final/reward_ctrl Mean        -0.302591
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.302591
expl/env_infos/final/reward_ctrl Min         -0.302591
expl/env_infos/initial/reward_ctrl Mean      -0.0658707
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.0658707
expl/env_infos/initial/reward_ctrl Min       -0.0658707
expl/env_infos/reward_ctrl Mean              -0.389821
expl/env_infos/reward_ctrl Std                0.0934847
expl/env_infos/reward_ctrl Max               -0.0489239
expl/env_infos/reward_ctrl Min               -0.579874
eval/num steps total                          2.045e+06
eval/num paths total                       2045
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.22706
eval/Rewards Std                              1.31804
eval/Rewards Max                              8.63728
eval/Rewards Min                             -0.886002
eval/Returns Mean                          6227.06
eval/Returns Std                             59.1571
eval/Returns Max                           6302.59
eval/Returns Min                           6157.07
eval/Actions Mean                             0.0828547
eval/Actions Std                              0.818925
eval/Actions Max                              0.994243
eval/Actions Min                             -0.997098
eval/Num Paths                                5
eval/Average Returns                       6227.06
eval/env_infos/final/reward_run Mean          6.92726
eval/env_infos/final/reward_run Std           0.778443
eval/env_infos/final/reward_run Max           8.25709
eval/env_infos/final/reward_run Min           6.16276
eval/env_infos/initial/reward_run Mean       -0.572065
eval/env_infos/initial/reward_run Std         0.0736612
eval/env_infos/initial/reward_run Max        -0.49797
eval/env_infos/initial/reward_run Min        -0.665341
eval/env_infos/reward_run Mean                6.63356
eval/env_infos/reward_run Std                 1.30904
eval/env_infos/reward_run Max                 9.1215
eval/env_infos/reward_run Min                -0.665341
eval/env_infos/final/reward_ctrl Mean        -0.410729
eval/env_infos/final/reward_ctrl Std          0.0354029
eval/env_infos/final/reward_ctrl Max         -0.355007
eval/env_infos/final/reward_ctrl Min         -0.460132
eval/env_infos/initial/reward_ctrl Mean      -0.211018
eval/env_infos/initial/reward_ctrl Std        0.053641
eval/env_infos/initial/reward_ctrl Max       -0.14317
eval/env_infos/initial/reward_ctrl Min       -0.299129
eval/env_infos/reward_ctrl Mean              -0.406502
eval/env_infos/reward_ctrl Std                0.0887784
eval/env_infos/reward_ctrl Max               -0.0705536
eval/env_infos/reward_ctrl Min               -0.579975
time/data storing (s)                         0.00449491
time/evaluation sampling (s)                  2.06102
time/exploration sampling (s)                 0.534199
time/logging (s)                              0.0137466
time/sac training (s)                         7.67446
time/saving (s)                               0.0037794
time/training (s)                             3.41299e-05
time/epoch (s)                               10.2917
time/total (s)                             4312.07
Epoch                                       408
---------------------------------------  ----------------
2021-11-24 01:41:18.448276 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 409 finished
---------------------------------------  ---------------
epoch                                       409
replay_buffer/size                       411000
trainer/num train calls                  410000
trainer/QF1 Loss                              4.62381
trainer/QF2 Loss                              5.0724
trainer/Policy Loss                        -403.481
trainer/Q1 Predictions Mean                 404.146
trainer/Q1 Predictions Std                   98.4483
trainer/Q1 Predictions Max                  482.189
trainer/Q1 Predictions Min                   24.3011
trainer/Q2 Predictions Mean                 403.557
trainer/Q2 Predictions Std                   98.4091
trainer/Q2 Predictions Max                  479.74
trainer/Q2 Predictions Min                   23.7697
trainer/Q Targets Mean                      403.62
trainer/Q Targets Std                        98.3464
trainer/Q Targets Max                       480.469
trainer/Q Targets Min                        22.0687
trainer/Log Pis Mean                          6.18116
trainer/Log Pis Std                           4.52347
trainer/Log Pis Max                          17.787
trainer/Log Pis Min                          -6.28798
trainer/policy/mean Mean                      0.0919363
trainer/policy/mean Std                       0.771351
trainer/policy/mean Max                       0.994659
trainer/policy/mean Min                      -0.997394
trainer/policy/normal/std Mean                0.439234
trainer/policy/normal/std Std                 0.149757
trainer/policy/normal/std Max                 0.961292
trainer/policy/normal/std Min                 0.0694531
trainer/policy/normal/log_std Mean           -0.904636
trainer/policy/normal/log_std Std             0.452651
trainer/policy/normal/log_std Max            -0.0394767
trainer/policy/normal/log_std Min            -2.6671
trainer/Alpha                                 0.151813
trainer/Alpha Loss                            0.341515
expl/num steps total                     411000
expl/num paths total                        411
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.68312
expl/Rewards Std                              1.25611
expl/Rewards Max                              8.17378
expl/Rewards Min                             -0.889736
expl/Returns Mean                          5683.12
expl/Returns Std                              0
expl/Returns Max                           5683.12
expl/Returns Min                           5683.12
expl/Actions Mean                             0.0887375
expl/Actions Std                              0.794308
expl/Actions Max                              0.999154
expl/Actions Min                             -0.999446
expl/Num Paths                                1
expl/Average Returns                       5683.12
expl/env_infos/final/reward_run Mean          7.9704
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.9704
expl/env_infos/final/reward_run Min           7.9704
expl/env_infos/initial/reward_run Mean       -0.344438
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.344438
expl/env_infos/initial/reward_run Min        -0.344438
expl/env_infos/reward_run Mean                6.0664
expl/env_infos/reward_run Std                 1.24595
expl/env_infos/reward_run Max                 8.61792
expl/env_infos/reward_run Min                -0.612004
expl/env_infos/final/reward_ctrl Mean        -0.493259
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.493259
expl/env_infos/final/reward_ctrl Min         -0.493259
expl/env_infos/initial/reward_ctrl Mean      -0.299304
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.299304
expl/env_infos/initial/reward_ctrl Min       -0.299304
expl/env_infos/reward_ctrl Mean              -0.38328
expl/env_infos/reward_ctrl Std                0.0940024
expl/env_infos/reward_ctrl Max               -0.0825759
expl/env_infos/reward_ctrl Min               -0.57627
eval/num steps total                          2.05e+06
eval/num paths total                       2050
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.37072
eval/Rewards Std                              1.33303
eval/Rewards Max                              8.84741
eval/Rewards Min                             -0.802875
eval/Returns Mean                          6370.72
eval/Returns Std                             51.6616
eval/Returns Max                           6427.58
eval/Returns Min                           6286.05
eval/Actions Mean                             0.0892064
eval/Actions Std                              0.820494
eval/Actions Max                              0.995744
eval/Actions Min                             -0.997045
eval/Num Paths                                5
eval/Average Returns                       6370.72
eval/env_infos/final/reward_run Mean          6.76555
eval/env_infos/final/reward_run Std           0.68404
eval/env_infos/final/reward_run Max           7.64866
eval/env_infos/final/reward_run Min           6.02104
eval/env_infos/initial/reward_run Mean       -0.133988
eval/env_infos/initial/reward_run Std         0.278595
eval/env_infos/initial/reward_run Max         0.395796
eval/env_infos/initial/reward_run Min        -0.364565
eval/env_infos/reward_run Mean                6.77942
eval/env_infos/reward_run Std                 1.32532
eval/env_infos/reward_run Max                 9.37825
eval/env_infos/reward_run Min                -0.436537
eval/env_infos/final/reward_ctrl Mean        -0.397779
eval/env_infos/final/reward_ctrl Std          0.0593244
eval/env_infos/final/reward_ctrl Max         -0.295112
eval/env_infos/final/reward_ctrl Min         -0.46494
eval/env_infos/initial/reward_ctrl Mean      -0.223239
eval/env_infos/initial/reward_ctrl Std        0.0315647
eval/env_infos/initial/reward_ctrl Max       -0.174293
eval/env_infos/initial/reward_ctrl Min       -0.258356
eval/env_infos/reward_ctrl Mean              -0.408701
eval/env_infos/reward_ctrl Std                0.0902842
eval/env_infos/reward_ctrl Max               -0.0916569
eval/env_infos/reward_ctrl Min               -0.576178
time/data storing (s)                         0.00448673
time/evaluation sampling (s)                  2.09082
time/exploration sampling (s)                 0.528981
time/logging (s)                              0.0138692
time/sac training (s)                         7.37163
time/saving (s)                               0.00375828
time/training (s)                             3.4961e-05
time/epoch (s)                               10.0136
time/total (s)                             4322.36
Epoch                                       409
---------------------------------------  ---------------
2021-11-24 01:41:28.642773 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 410 finished
---------------------------------------  ---------------
epoch                                       410
replay_buffer/size                       412000
trainer/num train calls                  411000
trainer/QF1 Loss                              6.50022
trainer/QF2 Loss                              6.38241
trainer/Policy Loss                        -417.247
trainer/Q1 Predictions Mean                 418
trainer/Q1 Predictions Std                   85.654
trainer/Q1 Predictions Max                  478.87
trainer/Q1 Predictions Min                   23.1404
trainer/Q2 Predictions Mean                 417.937
trainer/Q2 Predictions Std                   85.7039
trainer/Q2 Predictions Max                  480.699
trainer/Q2 Predictions Min                   22.8126
trainer/Q Targets Mean                      417.959
trainer/Q Targets Std                        85.7336
trainer/Q Targets Max                       480.201
trainer/Q Targets Min                        22.529
trainer/Log Pis Mean                          6.73605
trainer/Log Pis Std                           4.05761
trainer/Log Pis Max                          17.9647
trainer/Log Pis Min                          -4.05183
trainer/policy/mean Mean                      0.0904167
trainer/policy/mean Std                       0.793496
trainer/policy/mean Max                       0.99639
trainer/policy/mean Min                      -0.999147
trainer/policy/normal/std Mean                0.442859
trainer/policy/normal/std Std                 0.137543
trainer/policy/normal/std Max                 0.943934
trainer/policy/normal/std Min                 0.0721428
trainer/policy/normal/log_std Mean           -0.882502
trainer/policy/normal/log_std Std             0.412208
trainer/policy/normal/log_std Max            -0.0576991
trainer/policy/normal/log_std Min            -2.62911
trainer/Alpha                                 0.152526
trainer/Alpha Loss                            1.38409
expl/num steps total                     412000
expl/num paths total                        412
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.67036
expl/Rewards Std                              1.24896
expl/Rewards Max                              8.16804
expl/Rewards Min                             -0.541941
expl/Returns Mean                          5670.36
expl/Returns Std                              0
expl/Returns Max                           5670.36
expl/Returns Min                           5670.36
expl/Actions Mean                             0.0935812
expl/Actions Std                              0.793468
expl/Actions Max                              0.999832
expl/Actions Min                             -0.999406
expl/Num Paths                                1
expl/Average Returns                       5670.36
expl/env_infos/final/reward_run Mean          6.33044
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.33044
expl/env_infos/final/reward_run Min           6.33044
expl/env_infos/initial/reward_run Mean       -0.264591
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.264591
expl/env_infos/initial/reward_run Min        -0.264591
expl/env_infos/reward_run Mean                6.05337
expl/env_infos/reward_run Std                 1.24332
expl/env_infos/reward_run Max                 8.59123
expl/env_infos/reward_run Min                -0.264591
expl/env_infos/final/reward_ctrl Mean        -0.36187
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.36187
expl/env_infos/final/reward_ctrl Min         -0.36187
expl/env_infos/initial/reward_ctrl Mean      -0.27735
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.27735
expl/env_infos/initial/reward_ctrl Min       -0.27735
expl/env_infos/reward_ctrl Mean              -0.38301
expl/env_infos/reward_ctrl Std                0.090959
expl/env_infos/reward_ctrl Max               -0.127643
expl/env_infos/reward_ctrl Min               -0.580895
eval/num steps total                          2.055e+06
eval/num paths total                       2055
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.27998
eval/Rewards Std                              1.33196
eval/Rewards Max                              8.83603
eval/Rewards Min                             -0.791777
eval/Returns Mean                          6279.98
eval/Returns Std                             45.7245
eval/Returns Max                           6342.63
eval/Returns Min                           6218.42
eval/Actions Mean                             0.0895696
eval/Actions Std                              0.816447
eval/Actions Max                              0.999448
eval/Actions Min                             -0.997784
eval/Num Paths                                5
eval/Average Returns                       6279.98
eval/env_infos/final/reward_run Mean          6.73606
eval/env_infos/final/reward_run Std           1.43522
eval/env_infos/final/reward_run Max           8.53901
eval/env_infos/final/reward_run Min           4.9786
eval/env_infos/initial/reward_run Mean       -0.201434
eval/env_infos/initial/reward_run Std         0.2317
eval/env_infos/initial/reward_run Max         0.168666
eval/env_infos/initial/reward_run Min        -0.537547
eval/env_infos/reward_run Mean                6.68474
eval/env_infos/reward_run Std                 1.32392
eval/env_infos/reward_run Max                 9.32516
eval/env_infos/reward_run Min                -0.537547
eval/env_infos/final/reward_ctrl Mean        -0.441247
eval/env_infos/final/reward_ctrl Std          0.0421212
eval/env_infos/final/reward_ctrl Max         -0.398674
eval/env_infos/final/reward_ctrl Min         -0.497667
eval/env_infos/initial/reward_ctrl Mean      -0.160501
eval/env_infos/initial/reward_ctrl Std        0.0513506
eval/env_infos/initial/reward_ctrl Max       -0.110634
eval/env_infos/initial/reward_ctrl Min       -0.25423
eval/env_infos/reward_ctrl Mean              -0.404765
eval/env_infos/reward_ctrl Std                0.0866402
eval/env_infos/reward_ctrl Max               -0.0621991
eval/env_infos/reward_ctrl Min               -0.578605
time/data storing (s)                         0.00448045
time/evaluation sampling (s)                  1.97185
time/exploration sampling (s)                 0.517928
time/logging (s)                              0.0136028
time/sac training (s)                         7.38552
time/saving (s)                               0.00377187
time/training (s)                             3.397e-05
time/epoch (s)                                9.89719
time/total (s)                             4332.54
Epoch                                       410
---------------------------------------  ---------------
2021-11-24 01:41:38.820545 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 411 finished
---------------------------------------  ---------------
epoch                                       411
replay_buffer/size                       413000
trainer/num train calls                  412000
trainer/QF1 Loss                              6.31588
trainer/QF2 Loss                              7.02721
trainer/Policy Loss                        -414.079
trainer/Q1 Predictions Mean                 414.447
trainer/Q1 Predictions Std                   83.2896
trainer/Q1 Predictions Max                  481.798
trainer/Q1 Predictions Min                   21.5734
trainer/Q2 Predictions Mean                 414.458
trainer/Q2 Predictions Std                   83.3937
trainer/Q2 Predictions Max                  482.183
trainer/Q2 Predictions Min                   23.1827
trainer/Q Targets Mean                      413.765
trainer/Q Targets Std                        83.344
trainer/Q Targets Max                       480.647
trainer/Q Targets Min                        22.5078
trainer/Log Pis Mean                          6.1403
trainer/Log Pis Std                           4.26899
trainer/Log Pis Max                          18.194
trainer/Log Pis Min                          -5.0784
trainer/policy/mean Mean                      0.0990782
trainer/policy/mean Std                       0.78264
trainer/policy/mean Max                       0.995749
trainer/policy/mean Min                      -0.997575
trainer/policy/normal/std Mean                0.442685
trainer/policy/normal/std Std                 0.142566
trainer/policy/normal/std Max                 0.90975
trainer/policy/normal/std Min                 0.0816993
trainer/policy/normal/log_std Mean           -0.886334
trainer/policy/normal/log_std Std             0.419162
trainer/policy/normal/log_std Max            -0.0945853
trainer/policy/normal/log_std Min            -2.50471
trainer/Alpha                                 0.151751
trainer/Alpha Loss                            0.26453
expl/num steps total                     413000
expl/num paths total                        413
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.90646
expl/Rewards Std                              1.25495
expl/Rewards Max                              8.67632
expl/Rewards Min                             -0.311385
expl/Returns Mean                          5906.46
expl/Returns Std                              0
expl/Returns Max                           5906.46
expl/Returns Min                           5906.46
expl/Actions Mean                             0.104842
expl/Actions Std                              0.801277
expl/Actions Max                              0.999568
expl/Actions Min                             -0.999383
expl/Num Paths                                1
expl/Average Returns                       5906.46
expl/env_infos/final/reward_run Mean          7.21046
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.21046
expl/env_infos/final/reward_run Min           7.21046
expl/env_infos/initial/reward_run Mean       -0.188605
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.188605
expl/env_infos/initial/reward_run Min        -0.188605
expl/env_infos/reward_run Mean                6.29828
expl/env_infos/reward_run Std                 1.25145
expl/env_infos/reward_run Max                 9.12184
expl/env_infos/reward_run Min                -0.188605
expl/env_infos/final/reward_ctrl Mean        -0.304395
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.304395
expl/env_infos/final/reward_ctrl Min         -0.304395
expl/env_infos/initial/reward_ctrl Mean      -0.120394
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.120394
expl/env_infos/initial/reward_ctrl Min       -0.120394
expl/env_infos/reward_ctrl Mean              -0.391822
expl/env_infos/reward_ctrl Std                0.0907477
expl/env_infos/reward_ctrl Max               -0.103047
expl/env_infos/reward_ctrl Min               -0.572589
eval/num steps total                          2.06e+06
eval/num paths total                       2060
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.24975
eval/Rewards Std                              1.34233
eval/Rewards Max                              8.60589
eval/Rewards Min                             -0.983207
eval/Returns Mean                          6249.75
eval/Returns Std                             64.4003
eval/Returns Max                           6343.8
eval/Returns Min                           6162.77
eval/Actions Mean                             0.0976201
eval/Actions Std                              0.819894
eval/Actions Max                              0.997139
eval/Actions Min                             -0.998775
eval/Num Paths                                5
eval/Average Returns                       6249.75
eval/env_infos/final/reward_run Mean          6.52413
eval/env_infos/final/reward_run Std           0.813316
eval/env_infos/final/reward_run Max           7.82947
eval/env_infos/final/reward_run Min           5.65766
eval/env_infos/initial/reward_run Mean       -0.320589
eval/env_infos/initial/reward_run Std         0.273098
eval/env_infos/initial/reward_run Max         0.0950208
eval/env_infos/initial/reward_run Min        -0.707796
eval/env_infos/reward_run Mean                6.65881
eval/env_infos/reward_run Std                 1.33875
eval/env_infos/reward_run Max                 9.10575
eval/env_infos/reward_run Min                -0.707796
eval/env_infos/final/reward_ctrl Mean        -0.413142
eval/env_infos/final/reward_ctrl Std          0.0588306
eval/env_infos/final/reward_ctrl Max         -0.324514
eval/env_infos/final/reward_ctrl Min         -0.496913
eval/env_infos/initial/reward_ctrl Mean      -0.176549
eval/env_infos/initial/reward_ctrl Std        0.0540049
eval/env_infos/initial/reward_ctrl Max       -0.117371
eval/env_infos/initial/reward_ctrl Min       -0.275411
eval/env_infos/reward_ctrl Mean              -0.409054
eval/env_infos/reward_ctrl Std                0.0874406
eval/env_infos/reward_ctrl Max               -0.0496179
eval/env_infos/reward_ctrl Min               -0.580823
time/data storing (s)                         0.00453234
time/evaluation sampling (s)                  1.97204
time/exploration sampling (s)                 0.52288
time/logging (s)                              0.0136371
time/sac training (s)                         7.36713
time/saving (s)                               0.00377223
time/training (s)                             3.4401e-05
time/epoch (s)                                9.88402
time/total (s)                             4342.7
Epoch                                       411
---------------------------------------  ---------------
2021-11-24 01:41:49.095217 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 412 finished
---------------------------------------  ---------------
epoch                                       412
replay_buffer/size                       414000
trainer/num train calls                  413000
trainer/QF1 Loss                              5.02761
trainer/QF2 Loss                              5.73728
trainer/Policy Loss                        -417.28
trainer/Q1 Predictions Mean                 417.734
trainer/Q1 Predictions Std                   79.3614
trainer/Q1 Predictions Max                  481.73
trainer/Q1 Predictions Min                   21.6616
trainer/Q2 Predictions Mean                 418.189
trainer/Q2 Predictions Std                   79.4479
trainer/Q2 Predictions Max                  482.704
trainer/Q2 Predictions Min                   23.8705
trainer/Q Targets Mean                      417.837
trainer/Q Targets Std                        79.5346
trainer/Q Targets Max                       480.848
trainer/Q Targets Min                        22.4495
trainer/Log Pis Mean                          6.27557
trainer/Log Pis Std                           3.88345
trainer/Log Pis Max                          15.8332
trainer/Log Pis Min                          -3.92281
trainer/policy/mean Mean                      0.071079
trainer/policy/mean Std                       0.784427
trainer/policy/mean Max                       0.996021
trainer/policy/mean Min                      -0.99829
trainer/policy/normal/std Mean                0.440531
trainer/policy/normal/std Std                 0.143121
trainer/policy/normal/std Max                 0.874224
trainer/policy/normal/std Min                 0.075367
trainer/policy/normal/log_std Mean           -0.89259
trainer/policy/normal/log_std Std             0.423826
trainer/policy/normal/log_std Max            -0.134419
trainer/policy/normal/log_std Min            -2.58539
trainer/Alpha                                 0.153916
trainer/Alpha Loss                            0.515694
expl/num steps total                     414000
expl/num paths total                        414
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.96657
expl/Rewards Std                              1.25739
expl/Rewards Max                              8.24567
expl/Rewards Min                             -1.04621
expl/Returns Mean                          5966.57
expl/Returns Std                              0
expl/Returns Max                           5966.57
expl/Returns Min                           5966.57
expl/Actions Mean                             0.099362
expl/Actions Std                              0.795064
expl/Actions Max                              0.999023
expl/Actions Min                             -0.998544
expl/Num Paths                                1
expl/Average Returns                       5966.57
expl/env_infos/final/reward_run Mean          7.65043
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.65043
expl/env_infos/final/reward_run Min           7.65043
expl/env_infos/initial/reward_run Mean       -0.76311
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.76311
expl/env_infos/initial/reward_run Min        -0.76311
expl/env_infos/reward_run Mean                6.35177
expl/env_infos/reward_run Std                 1.26072
expl/env_infos/reward_run Max                 8.79684
expl/env_infos/reward_run Min                -0.76311
expl/env_infos/final/reward_ctrl Mean        -0.460405
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.460405
expl/env_infos/final/reward_ctrl Min         -0.460405
expl/env_infos/initial/reward_ctrl Mean      -0.283101
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.283101
expl/env_infos/initial/reward_ctrl Min       -0.283101
expl/env_infos/reward_ctrl Mean              -0.3852
expl/env_infos/reward_ctrl Std                0.0862091
expl/env_infos/reward_ctrl Max               -0.117441
expl/env_infos/reward_ctrl Min               -0.566141
eval/num steps total                          2.065e+06
eval/num paths total                       2065
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.34666
eval/Rewards Std                              1.28885
eval/Rewards Max                              8.66129
eval/Rewards Min                             -0.979281
eval/Returns Mean                          6346.66
eval/Returns Std                             77.1471
eval/Returns Max                           6429.1
eval/Returns Min                           6207.53
eval/Actions Mean                             0.0961089
eval/Actions Std                              0.813601
eval/Actions Max                              0.99897
eval/Actions Min                             -0.995706
eval/Num Paths                                5
eval/Average Returns                       6346.66
eval/env_infos/final/reward_run Mean          7.65671
eval/env_infos/final/reward_run Std           0.663088
eval/env_infos/final/reward_run Max           8.57021
eval/env_infos/final/reward_run Min           6.86644
eval/env_infos/initial/reward_run Mean       -0.494866
eval/env_infos/initial/reward_run Std         0.184526
eval/env_infos/initial/reward_run Max        -0.235775
eval/env_infos/initial/reward_run Min        -0.742017
eval/env_infos/reward_run Mean                6.74937
eval/env_infos/reward_run Std                 1.29343
eval/env_infos/reward_run Max                 9.15596
eval/env_infos/reward_run Min                -0.742017
eval/env_infos/final/reward_ctrl Mean        -0.387153
eval/env_infos/final/reward_ctrl Std          0.123309
eval/env_infos/final/reward_ctrl Max         -0.224842
eval/env_infos/final/reward_ctrl Min         -0.553719
eval/env_infos/initial/reward_ctrl Mean      -0.199447
eval/env_infos/initial/reward_ctrl Std        0.0703127
eval/env_infos/initial/reward_ctrl Max       -0.0980963
eval/env_infos/initial/reward_ctrl Min       -0.267456
eval/env_infos/reward_ctrl Mean              -0.40271
eval/env_infos/reward_ctrl Std                0.0845406
eval/env_infos/reward_ctrl Max               -0.0856751
eval/env_infos/reward_ctrl Min               -0.566673
time/data storing (s)                         0.00451656
time/evaluation sampling (s)                  2.07193
time/exploration sampling (s)                 0.525046
time/logging (s)                              0.0138276
time/sac training (s)                         7.36047
time/saving (s)                               0.00384623
time/training (s)                             3.4099e-05
time/epoch (s)                                9.97967
time/total (s)                             4352.96
Epoch                                       412
---------------------------------------  ---------------
2021-11-24 01:41:59.401162 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 413 finished
---------------------------------------  ---------------
epoch                                       413
replay_buffer/size                       415000
trainer/num train calls                  414000
trainer/QF1 Loss                              5.70446
trainer/QF2 Loss                              6.88481
trainer/Policy Loss                        -416.396
trainer/Q1 Predictions Mean                 417.092
trainer/Q1 Predictions Std                   84.7827
trainer/Q1 Predictions Max                  477.296
trainer/Q1 Predictions Min                   20.8915
trainer/Q2 Predictions Mean                 417.131
trainer/Q2 Predictions Std                   84.7737
trainer/Q2 Predictions Max                  478.426
trainer/Q2 Predictions Min                   20.9358
trainer/Q Targets Mean                      416.864
trainer/Q Targets Std                        84.8063
trainer/Q Targets Max                       478.551
trainer/Q Targets Min                        20.7302
trainer/Log Pis Mean                          6.46545
trainer/Log Pis Std                           4.42896
trainer/Log Pis Max                          16.6856
trainer/Log Pis Min                          -5.36703
trainer/policy/mean Mean                      0.112086
trainer/policy/mean Std                       0.781123
trainer/policy/mean Max                       0.996672
trainer/policy/mean Min                      -0.995212
trainer/policy/normal/std Mean                0.434694
trainer/policy/normal/std Std                 0.145045
trainer/policy/normal/std Max                 1.01948
trainer/policy/normal/std Min                 0.0601845
trainer/policy/normal/log_std Mean           -0.911167
trainer/policy/normal/log_std Std             0.440358
trainer/policy/normal/log_std Max             0.019288
trainer/policy/normal/log_std Min            -2.81034
trainer/Alpha                                 0.15276
trainer/Alpha Loss                            0.874522
expl/num steps total                     415000
expl/num paths total                        415
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.77833
expl/Rewards Std                              1.23594
expl/Rewards Max                              8.24705
expl/Rewards Min                             -0.436692
expl/Returns Mean                          5778.33
expl/Returns Std                              0
expl/Returns Max                           5778.33
expl/Returns Min                           5778.33
expl/Actions Mean                             0.103329
expl/Actions Std                              0.801296
expl/Actions Max                              0.999326
expl/Actions Min                             -0.999105
expl/Num Paths                                1
expl/Average Returns                       5778.33
expl/env_infos/final/reward_run Mean          5.15934
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.15934
expl/env_infos/final/reward_run Min           5.15934
expl/env_infos/initial/reward_run Mean       -0.147377
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.147377
expl/env_infos/initial/reward_run Min        -0.147377
expl/env_infos/reward_run Mean                6.16998
expl/env_infos/reward_run Std                 1.23419
expl/env_infos/reward_run Max                 8.71942
expl/env_infos/reward_run Min                -0.147377
expl/env_infos/final/reward_ctrl Mean        -0.48949
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.48949
expl/env_infos/final/reward_ctrl Min         -0.48949
expl/env_infos/initial/reward_ctrl Mean      -0.289314
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.289314
expl/env_infos/initial/reward_ctrl Min       -0.289314
expl/env_infos/reward_ctrl Mean              -0.391651
expl/env_infos/reward_ctrl Std                0.0982555
expl/env_infos/reward_ctrl Max               -0.0907952
expl/env_infos/reward_ctrl Min               -0.579586
eval/num steps total                          2.07e+06
eval/num paths total                       2070
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.29612
eval/Rewards Std                              1.30192
eval/Rewards Max                              8.83813
eval/Rewards Min                             -0.647632
eval/Returns Mean                          6296.12
eval/Returns Std                             65.57
eval/Returns Max                           6363.65
eval/Returns Min                           6186.19
eval/Actions Mean                             0.0993998
eval/Actions Std                              0.820808
eval/Actions Max                              0.996346
eval/Actions Min                             -0.997092
eval/Num Paths                                5
eval/Average Returns                       6296.12
eval/env_infos/final/reward_run Mean          7.19515
eval/env_infos/final/reward_run Std           0.89532
eval/env_infos/final/reward_run Max           8.25781
eval/env_infos/final/reward_run Min           6.06105
eval/env_infos/initial/reward_run Mean       -0.276295
eval/env_infos/initial/reward_run Std         0.124018
eval/env_infos/initial/reward_run Max        -0.127036
eval/env_infos/initial/reward_run Min        -0.448287
eval/env_infos/reward_run Mean                6.70629
eval/env_infos/reward_run Std                 1.30033
eval/env_infos/reward_run Max                 9.38296
eval/env_infos/reward_run Min                -0.448287
eval/env_infos/final/reward_ctrl Mean        -0.484972
eval/env_infos/final/reward_ctrl Std          0.0417711
eval/env_infos/final/reward_ctrl Max         -0.425254
eval/env_infos/final/reward_ctrl Min         -0.544554
eval/env_infos/initial/reward_ctrl Mean      -0.191478
eval/env_infos/initial/reward_ctrl Std        0.0705601
eval/env_infos/initial/reward_ctrl Max       -0.103553
eval/env_infos/initial/reward_ctrl Min       -0.272749
eval/env_infos/reward_ctrl Mean              -0.410163
eval/env_infos/reward_ctrl Std                0.0958948
eval/env_infos/reward_ctrl Max               -0.0653822
eval/env_infos/reward_ctrl Min               -0.58051
time/data storing (s)                         0.00449214
time/evaluation sampling (s)                  1.97339
time/exploration sampling (s)                 0.591102
time/logging (s)                              0.0144157
time/sac training (s)                         7.42306
time/saving (s)                               0.00522969
time/training (s)                             3.4352e-05
time/epoch (s)                               10.0117
time/total (s)                             4363.26
Epoch                                       413
---------------------------------------  ---------------
2021-11-24 01:42:09.631669 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 414 finished
---------------------------------------  ---------------
epoch                                       414
replay_buffer/size                       416000
trainer/num train calls                  415000
trainer/QF1 Loss                              5.72844
trainer/QF2 Loss                              4.92714
trainer/Policy Loss                        -406.359
trainer/Q1 Predictions Mean                 406.736
trainer/Q1 Predictions Std                   96.2692
trainer/Q1 Predictions Max                  486.968
trainer/Q1 Predictions Min                   23.1147
trainer/Q2 Predictions Mean                 407.054
trainer/Q2 Predictions Std                   96.4667
trainer/Q2 Predictions Max                  485.999
trainer/Q2 Predictions Min                   22.8113
trainer/Q Targets Mean                      407.018
trainer/Q Targets Std                        96.0909
trainer/Q Targets Max                       484.314
trainer/Q Targets Min                        23.1313
trainer/Log Pis Mean                          5.4573
trainer/Log Pis Std                           4.02862
trainer/Log Pis Max                          15.1285
trainer/Log Pis Min                          -5.01608
trainer/policy/mean Mean                      0.104786
trainer/policy/mean Std                       0.76927
trainer/policy/mean Max                       0.9981
trainer/policy/mean Min                      -0.997003
trainer/policy/normal/std Mean                0.44446
trainer/policy/normal/std Std                 0.143763
trainer/policy/normal/std Max                 0.974218
trainer/policy/normal/std Min                 0.0800764
trainer/policy/normal/log_std Mean           -0.883786
trainer/policy/normal/log_std Std             0.424515
trainer/policy/normal/log_std Max            -0.0261198
trainer/policy/normal/log_std Min            -2.52477
trainer/Alpha                                 0.155204
trainer/Alpha Loss                           -1.01106
expl/num steps total                     416000
expl/num paths total                        416
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.04394
expl/Rewards Std                              1.26579
expl/Rewards Max                              8.74395
expl/Rewards Min                             -0.194159
expl/Returns Mean                          6043.94
expl/Returns Std                              0
expl/Returns Max                           6043.94
expl/Returns Min                           6043.94
expl/Actions Mean                             0.117054
expl/Actions Std                              0.79808
expl/Actions Max                              0.999792
expl/Actions Min                             -0.999472
expl/Num Paths                                1
expl/Average Returns                       6043.94
expl/env_infos/final/reward_run Mean          6.10275
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.10275
expl/env_infos/final/reward_run Min           6.10275
expl/env_infos/initial/reward_run Mean        0.0636975
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0636975
expl/env_infos/initial/reward_run Min         0.0636975
expl/env_infos/reward_run Mean                6.43432
expl/env_infos/reward_run Std                 1.26423
expl/env_infos/reward_run Max                 9.24405
expl/env_infos/reward_run Min                 0.0636975
expl/env_infos/final/reward_ctrl Mean        -0.388752
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.388752
expl/env_infos/final/reward_ctrl Min         -0.388752
expl/env_infos/initial/reward_ctrl Mean      -0.071389
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.071389
expl/env_infos/initial/reward_ctrl Min       -0.071389
expl/env_infos/reward_ctrl Mean              -0.39038
expl/env_infos/reward_ctrl Std                0.0902298
expl/env_infos/reward_ctrl Max               -0.071389
expl/env_infos/reward_ctrl Min               -0.569395
eval/num steps total                          2.075e+06
eval/num paths total                       2075
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.39324
eval/Rewards Std                              1.34493
eval/Rewards Max                              8.94345
eval/Rewards Min                             -0.944643
eval/Returns Mean                          6393.24
eval/Returns Std                             63.2375
eval/Returns Max                           6486.09
eval/Returns Min                           6314.12
eval/Actions Mean                             0.122056
eval/Actions Std                              0.816052
eval/Actions Max                              0.995766
eval/Actions Min                             -0.997845
eval/Num Paths                                5
eval/Average Returns                       6393.24
eval/env_infos/final/reward_run Mean          7.46752
eval/env_infos/final/reward_run Std           0.508904
eval/env_infos/final/reward_run Max           8.02759
eval/env_infos/final/reward_run Min           6.88385
eval/env_infos/initial/reward_run Mean       -0.43745
eval/env_infos/initial/reward_run Std         0.160909
eval/env_infos/initial/reward_run Max        -0.192247
eval/env_infos/initial/reward_run Min        -0.677553
eval/env_infos/reward_run Mean                6.80174
eval/env_infos/reward_run Std                 1.34136
eval/env_infos/reward_run Max                 9.44336
eval/env_infos/reward_run Min                -0.677553
eval/env_infos/final/reward_ctrl Mean        -0.426331
eval/env_infos/final/reward_ctrl Std          0.0464364
eval/env_infos/final/reward_ctrl Max         -0.340062
eval/env_infos/final/reward_ctrl Min         -0.471017
eval/env_infos/initial/reward_ctrl Mean      -0.190113
eval/env_infos/initial/reward_ctrl Std        0.0416349
eval/env_infos/initial/reward_ctrl Max       -0.147021
eval/env_infos/initial/reward_ctrl Min       -0.26709
eval/env_infos/reward_ctrl Mean              -0.408503
eval/env_infos/reward_ctrl Std                0.0853025
eval/env_infos/reward_ctrl Max               -0.0845246
eval/env_infos/reward_ctrl Min               -0.574829
time/data storing (s)                         0.00449547
time/evaluation sampling (s)                  1.98383
time/exploration sampling (s)                 0.532488
time/logging (s)                              0.0138032
time/sac training (s)                         7.39637
time/saving (s)                               0.00375558
time/training (s)                             3.4772e-05
time/epoch (s)                                9.93478
time/total (s)                             4373.47
Epoch                                       414
---------------------------------------  ---------------
2021-11-24 01:42:19.854640 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 415 finished
---------------------------------------  ---------------
epoch                                       415
replay_buffer/size                       417000
trainer/num train calls                  416000
trainer/QF1 Loss                              3.89754
trainer/QF2 Loss                              4.06131
trainer/Policy Loss                        -406.217
trainer/Q1 Predictions Mean                 407.007
trainer/Q1 Predictions Std                  105.236
trainer/Q1 Predictions Max                  479.578
trainer/Q1 Predictions Min                   22.8265
trainer/Q2 Predictions Mean                 406.833
trainer/Q2 Predictions Std                  105.282
trainer/Q2 Predictions Max                  478.085
trainer/Q2 Predictions Min                   22.4004
trainer/Q Targets Mean                      406.974
trainer/Q Targets Std                       105.164
trainer/Q Targets Max                       479.608
trainer/Q Targets Min                        22.8315
trainer/Log Pis Mean                          6.07621
trainer/Log Pis Std                           4.73659
trainer/Log Pis Max                          16.3428
trainer/Log Pis Min                          -6.16611
trainer/policy/mean Mean                      0.105765
trainer/policy/mean Std                       0.768675
trainer/policy/mean Max                       0.994368
trainer/policy/mean Min                      -0.996089
trainer/policy/normal/std Mean                0.445464
trainer/policy/normal/std Std                 0.150557
trainer/policy/normal/std Max                 0.905136
trainer/policy/normal/std Min                 0.067996
trainer/policy/normal/log_std Mean           -0.888998
trainer/policy/normal/log_std Std             0.448574
trainer/policy/normal/log_std Max            -0.0996703
trainer/policy/normal/log_std Min            -2.68831
trainer/Alpha                                 0.153729
trainer/Alpha Loss                            0.142714
expl/num steps total                     417000
expl/num paths total                        417
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.90117
expl/Rewards Std                              1.23276
expl/Rewards Max                              8.30279
expl/Rewards Min                             -0.521801
expl/Returns Mean                          5901.17
expl/Returns Std                              0
expl/Returns Max                           5901.17
expl/Returns Min                           5901.17
expl/Actions Mean                             0.103238
expl/Actions Std                              0.807581
expl/Actions Max                              0.999011
expl/Actions Min                             -0.999417
expl/Num Paths                                1
expl/Average Returns                       5901.17
expl/env_infos/final/reward_run Mean          6.74873
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.74873
expl/env_infos/final/reward_run Min           6.74873
expl/env_infos/initial/reward_run Mean       -0.241333
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.241333
expl/env_infos/initial/reward_run Min        -0.241333
expl/env_infos/reward_run Mean                6.29888
expl/env_infos/reward_run Std                 1.22168
expl/env_infos/reward_run Max                 8.76725
expl/env_infos/reward_run Min                -0.241333
expl/env_infos/final/reward_ctrl Mean        -0.29489
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.29489
expl/env_infos/final/reward_ctrl Min         -0.29489
expl/env_infos/initial/reward_ctrl Mean      -0.280468
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.280468
expl/env_infos/initial/reward_ctrl Min       -0.280468
expl/env_infos/reward_ctrl Mean              -0.397707
expl/env_infos/reward_ctrl Std                0.0886391
expl/env_infos/reward_ctrl Max               -0.123589
expl/env_infos/reward_ctrl Min               -0.583705
eval/num steps total                          2.08e+06
eval/num paths total                       2080
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.43736
eval/Rewards Std                              1.31647
eval/Rewards Max                              9.00774
eval/Rewards Min                             -0.674979
eval/Returns Mean                          6437.36
eval/Returns Std                             83.7452
eval/Returns Max                           6539.66
eval/Returns Min                           6334.21
eval/Actions Mean                             0.0939831
eval/Actions Std                              0.82745
eval/Actions Max                              0.995534
eval/Actions Min                             -0.997745
eval/Num Paths                                5
eval/Average Returns                       6437.36
eval/env_infos/final/reward_run Mean          6.69346
eval/env_infos/final/reward_run Std           0.858724
eval/env_infos/final/reward_run Max           7.51464
eval/env_infos/final/reward_run Min           5.62913
eval/env_infos/initial/reward_run Mean       -0.236274
eval/env_infos/initial/reward_run Std         0.282198
eval/env_infos/initial/reward_run Max         0.291873
eval/env_infos/initial/reward_run Min        -0.541195
eval/env_infos/reward_run Mean                6.85347
eval/env_infos/reward_run Std                 1.30898
eval/env_infos/reward_run Max                 9.55632
eval/env_infos/reward_run Min                -0.541195
eval/env_infos/final/reward_ctrl Mean        -0.464192
eval/env_infos/final/reward_ctrl Std          0.0558425
eval/env_infos/final/reward_ctrl Max         -0.404604
eval/env_infos/final/reward_ctrl Min         -0.54759
eval/env_infos/initial/reward_ctrl Mean      -0.185165
eval/env_infos/initial/reward_ctrl Std        0.0421357
eval/env_infos/initial/reward_ctrl Max       -0.133784
eval/env_infos/initial/reward_ctrl Min       -0.257448
eval/env_infos/reward_ctrl Mean              -0.416104
eval/env_infos/reward_ctrl Std                0.0881863
eval/env_infos/reward_ctrl Max               -0.0860512
eval/env_infos/reward_ctrl Min               -0.580306
time/data storing (s)                         0.00449219
time/evaluation sampling (s)                  1.99698
time/exploration sampling (s)                 0.520832
time/logging (s)                              0.0137956
time/sac training (s)                         7.38685
time/saving (s)                               0.00378513
time/training (s)                             3.3895e-05
time/epoch (s)                                9.92677
time/total (s)                             4383.68
Epoch                                       415
---------------------------------------  ---------------
2021-11-24 01:42:30.075862 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 416 finished
---------------------------------------  ---------------
epoch                                       416
replay_buffer/size                       418000
trainer/num train calls                  417000
trainer/QF1 Loss                              6.90033
trainer/QF2 Loss                              5.79465
trainer/Policy Loss                        -415.652
trainer/Q1 Predictions Mean                 416.443
trainer/Q1 Predictions Std                   87.2901
trainer/Q1 Predictions Max                  479.009
trainer/Q1 Predictions Min                   22.6219
trainer/Q2 Predictions Mean                 416.168
trainer/Q2 Predictions Std                   87.1399
trainer/Q2 Predictions Max                  478.361
trainer/Q2 Predictions Min                   23.0582
trainer/Q Targets Mean                      415.901
trainer/Q Targets Std                        87.1665
trainer/Q Targets Max                       478.573
trainer/Q Targets Min                        22.9642
trainer/Log Pis Mean                          6.00886
trainer/Log Pis Std                           4.29924
trainer/Log Pis Max                          17.6143
trainer/Log Pis Min                          -5.43057
trainer/policy/mean Mean                      0.0750276
trainer/policy/mean Std                       0.781804
trainer/policy/mean Max                       0.993981
trainer/policy/mean Min                      -0.999437
trainer/policy/normal/std Mean                0.44462
trainer/policy/normal/std Std                 0.142655
trainer/policy/normal/std Max                 0.910305
trainer/policy/normal/std Min                 0.0665368
trainer/policy/normal/log_std Mean           -0.879052
trainer/policy/normal/log_std Std             0.408277
trainer/policy/normal/log_std Max            -0.0939755
trainer/policy/normal/log_std Min            -2.71
trainer/Alpha                                 0.153089
trainer/Alpha Loss                            0.01663
expl/num steps total                     418000
expl/num paths total                        418
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.92072
expl/Rewards Std                              1.27141
expl/Rewards Max                              8.41766
expl/Rewards Min                             -0.652277
expl/Returns Mean                          5920.72
expl/Returns Std                              0
expl/Returns Max                           5920.72
expl/Returns Min                           5920.72
expl/Actions Mean                             0.111529
expl/Actions Std                              0.788898
expl/Actions Max                              0.99959
expl/Actions Min                             -0.998876
expl/Num Paths                                1
expl/Average Returns                       5920.72
expl/env_infos/final/reward_run Mean          6.29545
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.29545
expl/env_infos/final/reward_run Min           6.29545
expl/env_infos/initial/reward_run Mean       -0.51319
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.51319
expl/env_infos/initial/reward_run Min        -0.51319
expl/env_infos/reward_run Mean                6.3016
expl/env_infos/reward_run Std                 1.26052
expl/env_infos/reward_run Max                 8.89023
expl/env_infos/reward_run Min                -0.51319
expl/env_infos/final/reward_ctrl Mean        -0.438866
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.438866
expl/env_infos/final/reward_ctrl Min         -0.438866
expl/env_infos/initial/reward_ctrl Mean      -0.139087
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.139087
expl/env_infos/initial/reward_ctrl Min       -0.139087
expl/env_infos/reward_ctrl Mean              -0.380879
expl/env_infos/reward_ctrl Std                0.093721
expl/env_infos/reward_ctrl Max               -0.0256878
expl/env_infos/reward_ctrl Min               -0.574313
eval/num steps total                          2.085e+06
eval/num paths total                       2085
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.44139
eval/Rewards Std                              1.34492
eval/Rewards Max                              9.11867
eval/Rewards Min                             -0.977382
eval/Returns Mean                          6441.39
eval/Returns Std                             45.2591
eval/Returns Max                           6511.45
eval/Returns Min                           6386.99
eval/Actions Mean                             0.106993
eval/Actions Std                              0.814483
eval/Actions Max                              0.995413
eval/Actions Min                             -0.995474
eval/Num Paths                                5
eval/Average Returns                       6441.39
eval/env_infos/final/reward_run Mean          7.22616
eval/env_infos/final/reward_run Std           1.031
eval/env_infos/final/reward_run Max           9.03645
eval/env_infos/final/reward_run Min           6.04224
eval/env_infos/initial/reward_run Mean        0.191732
eval/env_infos/initial/reward_run Std         0.419246
eval/env_infos/initial/reward_run Max         0.875587
eval/env_infos/initial/reward_run Min        -0.241618
eval/env_infos/reward_run Mean                6.84629
eval/env_infos/reward_run Std                 1.3374
eval/env_infos/reward_run Max                 9.64089
eval/env_infos/reward_run Min                -0.532753
eval/env_infos/final/reward_ctrl Mean        -0.47029
eval/env_infos/final/reward_ctrl Std          0.0620215
eval/env_infos/final/reward_ctrl Max         -0.362557
eval/env_infos/final/reward_ctrl Min         -0.544836
eval/env_infos/initial/reward_ctrl Mean      -0.173608
eval/env_infos/initial/reward_ctrl Std        0.0937338
eval/env_infos/initial/reward_ctrl Max       -0.0667879
eval/env_infos/initial/reward_ctrl Min       -0.326107
eval/env_infos/reward_ctrl Mean              -0.404898
eval/env_infos/reward_ctrl Std                0.0891274
eval/env_infos/reward_ctrl Max               -0.0667879
eval/env_infos/reward_ctrl Min               -0.578505
time/data storing (s)                         0.00448538
time/evaluation sampling (s)                  2.00704
time/exploration sampling (s)                 0.534227
time/logging (s)                              0.0136958
time/sac training (s)                         7.36344
time/saving (s)                               0.00373461
time/training (s)                             3.909e-05
time/epoch (s)                                9.92666
time/total (s)                             4393.89
Epoch                                       416
---------------------------------------  ---------------
2021-11-24 01:42:40.459244 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 417 finished
---------------------------------------  ---------------
epoch                                       417
replay_buffer/size                       419000
trainer/num train calls                  418000
trainer/QF1 Loss                              7.66382
trainer/QF2 Loss                              7.55358
trainer/Policy Loss                        -413.938
trainer/Q1 Predictions Mean                 415.181
trainer/Q1 Predictions Std                   90.2932
trainer/Q1 Predictions Max                  479.714
trainer/Q1 Predictions Min                   22.0254
trainer/Q2 Predictions Mean                 414.588
trainer/Q2 Predictions Std                   90.1809
trainer/Q2 Predictions Max                  478.376
trainer/Q2 Predictions Min                   23.1919
trainer/Q Targets Mean                      414.98
trainer/Q Targets Std                        89.9144
trainer/Q Targets Max                       478.592
trainer/Q Targets Min                        23.3249
trainer/Log Pis Mean                          6.2755
trainer/Log Pis Std                           4.37252
trainer/Log Pis Max                          16.0042
trainer/Log Pis Min                          -5.38619
trainer/policy/mean Mean                      0.0644531
trainer/policy/mean Std                       0.787182
trainer/policy/mean Max                       0.994479
trainer/policy/mean Min                      -0.998434
trainer/policy/normal/std Mean                0.437745
trainer/policy/normal/std Std                 0.14289
trainer/policy/normal/std Max                 0.930334
trainer/policy/normal/std Min                 0.0681552
trainer/policy/normal/log_std Mean           -0.899467
trainer/policy/normal/log_std Std             0.427021
trainer/policy/normal/log_std Max            -0.0722113
trainer/policy/normal/log_std Min            -2.68597
trainer/Alpha                                 0.155332
trainer/Alpha Loss                            0.513043
expl/num steps total                     419000
expl/num paths total                        419
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.9761
expl/Rewards Std                              1.2708
expl/Rewards Max                              8.37273
expl/Rewards Min                             -0.82258
expl/Returns Mean                          5976.1
expl/Returns Std                              0
expl/Returns Max                           5976.1
expl/Returns Min                           5976.1
expl/Actions Mean                             0.0949945
expl/Actions Std                              0.801795
expl/Actions Max                              0.99946
expl/Actions Min                             -0.998902
expl/Num Paths                                1
expl/Average Returns                       5976.1
expl/env_infos/final/reward_run Mean          5.74804
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.74804
expl/env_infos/final/reward_run Min           5.74804
expl/env_infos/initial/reward_run Mean       -0.323671
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.323671
expl/env_infos/initial/reward_run Min        -0.323671
expl/env_infos/reward_run Mean                6.36724
expl/env_infos/reward_run Std                 1.26471
expl/env_infos/reward_run Max                 8.88056
expl/env_infos/reward_run Min                -0.382689
expl/env_infos/final/reward_ctrl Mean        -0.390344
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.390344
expl/env_infos/final/reward_ctrl Min         -0.390344
expl/env_infos/initial/reward_ctrl Mean      -0.159949
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.159949
expl/env_infos/initial/reward_ctrl Min       -0.159949
expl/env_infos/reward_ctrl Mean              -0.39114
expl/env_infos/reward_ctrl Std                0.0886766
expl/env_infos/reward_ctrl Max               -0.0986868
expl/env_infos/reward_ctrl Min               -0.575618
eval/num steps total                          2.09e+06
eval/num paths total                       2090
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.32186
eval/Rewards Std                              1.31309
eval/Rewards Max                              8.80466
eval/Rewards Min                             -0.847112
eval/Returns Mean                          6321.86
eval/Returns Std                             77.3422
eval/Returns Max                           6390.3
eval/Returns Min                           6198.51
eval/Actions Mean                             0.0879775
eval/Actions Std                              0.82055
eval/Actions Max                              0.99585
eval/Actions Min                             -0.996963
eval/Num Paths                                5
eval/Average Returns                       6321.86
eval/env_infos/final/reward_run Mean          7.19892
eval/env_infos/final/reward_run Std           1.17717
eval/env_infos/final/reward_run Max           8.20705
eval/env_infos/final/reward_run Min           5.36407
eval/env_infos/initial/reward_run Mean        0.0413648
eval/env_infos/initial/reward_run Std         0.477631
eval/env_infos/initial/reward_run Max         0.978061
eval/env_infos/initial/reward_run Min        -0.312039
eval/env_infos/reward_run Mean                6.73048
eval/env_infos/reward_run Std                 1.30847
eval/env_infos/reward_run Max                 9.35243
eval/env_infos/reward_run Min                -0.384111
eval/env_infos/final/reward_ctrl Mean        -0.448521
eval/env_infos/final/reward_ctrl Std          0.0680827
eval/env_infos/final/reward_ctrl Max         -0.358525
eval/env_infos/final/reward_ctrl Min         -0.553307
eval/env_infos/initial/reward_ctrl Mean      -0.26183
eval/env_infos/initial/reward_ctrl Std        0.0322584
eval/env_infos/initial/reward_ctrl Max       -0.229046
eval/env_infos/initial/reward_ctrl Min       -0.319551
eval/env_infos/reward_ctrl Mean              -0.408625
eval/env_infos/reward_ctrl Std                0.087843
eval/env_infos/reward_ctrl Max               -0.0677961
eval/env_infos/reward_ctrl Min               -0.578393
time/data storing (s)                         0.00451835
time/evaluation sampling (s)                  1.98859
time/exploration sampling (s)                 0.533343
time/logging (s)                              0.0136285
time/sac training (s)                         7.53856
time/saving (s)                               0.00376456
time/training (s)                             3.3789e-05
time/epoch (s)                               10.0824
time/total (s)                             4404.26
Epoch                                       417
---------------------------------------  ---------------
2021-11-24 01:42:50.672544 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 418 finished
---------------------------------------  ---------------
epoch                                       418
replay_buffer/size                       420000
trainer/num train calls                  419000
trainer/QF1 Loss                              6.04687
trainer/QF2 Loss                              6.67796
trainer/Policy Loss                        -411.9
trainer/Q1 Predictions Mean                 412.727
trainer/Q1 Predictions Std                   87.8424
trainer/Q1 Predictions Max                  479.128
trainer/Q1 Predictions Min                   21.6522
trainer/Q2 Predictions Mean                 412.429
trainer/Q2 Predictions Std                   87.5514
trainer/Q2 Predictions Max                  477.124
trainer/Q2 Predictions Min                   21.3388
trainer/Q Targets Mean                      412.518
trainer/Q Targets Std                        87.693
trainer/Q Targets Max                       476.741
trainer/Q Targets Min                        21.393
trainer/Log Pis Mean                          6.27759
trainer/Log Pis Std                           4.48431
trainer/Log Pis Max                          21.2131
trainer/Log Pis Min                          -6.84671
trainer/policy/mean Mean                      0.076389
trainer/policy/mean Std                       0.787597
trainer/policy/mean Max                       0.998604
trainer/policy/mean Min                      -0.997207
trainer/policy/normal/std Mean                0.447471
trainer/policy/normal/std Std                 0.146084
trainer/policy/normal/std Max                 0.917456
trainer/policy/normal/std Min                 0.0767593
trainer/policy/normal/log_std Mean           -0.876664
trainer/policy/normal/log_std Std             0.421453
trainer/policy/normal/log_std Max            -0.0861507
trainer/policy/normal/log_std Min            -2.56708
trainer/Alpha                                 0.154011
trainer/Alpha Loss                            0.519297
expl/num steps total                     420000
expl/num paths total                        420
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.81227
expl/Rewards Std                              1.27547
expl/Rewards Max                              8.37905
expl/Rewards Min                             -0.722466
expl/Returns Mean                          5812.27
expl/Returns Std                              0
expl/Returns Max                           5812.27
expl/Returns Min                           5812.27
expl/Actions Mean                             0.0966911
expl/Actions Std                              0.804108
expl/Actions Max                              0.999675
expl/Actions Min                             -0.999797
expl/Num Paths                                1
expl/Average Returns                       5812.27
expl/env_infos/final/reward_run Mean          4.24955
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.24955
expl/env_infos/final/reward_run Min           4.24955
expl/env_infos/initial/reward_run Mean       -0.0824753
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0824753
expl/env_infos/initial/reward_run Min        -0.0824753
expl/env_infos/reward_run Mean                6.20583
expl/env_infos/reward_run Std                 1.26281
expl/env_infos/reward_run Max                 8.76462
expl/env_infos/reward_run Min                -0.372254
expl/env_infos/final/reward_ctrl Mean        -0.503514
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.503514
expl/env_infos/final/reward_ctrl Min         -0.503514
expl/env_infos/initial/reward_ctrl Mean      -0.134055
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.134055
expl/env_infos/initial/reward_ctrl Min       -0.134055
expl/env_infos/reward_ctrl Mean              -0.393563
expl/env_infos/reward_ctrl Std                0.0866647
expl/env_infos/reward_ctrl Max               -0.0831169
expl/env_infos/reward_ctrl Min               -0.570956
eval/num steps total                          2.095e+06
eval/num paths total                       2095
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.34097
eval/Rewards Std                              1.32737
eval/Rewards Max                              8.98569
eval/Rewards Min                             -0.841358
eval/Returns Mean                          6340.97
eval/Returns Std                             67.9465
eval/Returns Max                           6417.63
eval/Returns Min                           6213.45
eval/Actions Mean                             0.09085
eval/Actions Std                              0.826104
eval/Actions Max                              0.996913
eval/Actions Min                             -0.998782
eval/Num Paths                                5
eval/Average Returns                       6340.97
eval/env_infos/final/reward_run Mean          6.80045
eval/env_infos/final/reward_run Std           0.6857
eval/env_infos/final/reward_run Max           8.05694
eval/env_infos/final/reward_run Min           6.18803
eval/env_infos/initial/reward_run Mean       -0.146451
eval/env_infos/initial/reward_run Std         0.158859
eval/env_infos/initial/reward_run Max         0.0130381
eval/env_infos/initial/reward_run Min        -0.442585
eval/env_infos/reward_run Mean                6.75539
eval/env_infos/reward_run Std                 1.31932
eval/env_infos/reward_run Max                 9.50485
eval/env_infos/reward_run Min                -0.622354
eval/env_infos/final/reward_ctrl Mean        -0.44785
eval/env_infos/final/reward_ctrl Std          0.041053
eval/env_infos/final/reward_ctrl Max         -0.368687
eval/env_infos/final/reward_ctrl Min         -0.484184
eval/env_infos/initial/reward_ctrl Mean      -0.209775
eval/env_infos/initial/reward_ctrl Std        0.0624272
eval/env_infos/initial/reward_ctrl Max       -0.113747
eval/env_infos/initial/reward_ctrl Min       -0.286797
eval/env_infos/reward_ctrl Mean              -0.414421
eval/env_infos/reward_ctrl Std                0.0836703
eval/env_infos/reward_ctrl Max               -0.103268
eval/env_infos/reward_ctrl Min               -0.583067
time/data storing (s)                         0.00446483
time/evaluation sampling (s)                  1.98735
time/exploration sampling (s)                 0.53487
time/logging (s)                              0.0138224
time/sac training (s)                         7.37562
time/saving (s)                               0.00376611
time/training (s)                             3.4054e-05
time/epoch (s)                                9.91993
time/total (s)                             4414.46
Epoch                                       418
---------------------------------------  ---------------
2021-11-24 01:43:00.890482 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 419 finished
---------------------------------------  ---------------
epoch                                       419
replay_buffer/size                       421000
trainer/num train calls                  420000
trainer/QF1 Loss                              4.86253
trainer/QF2 Loss                              5.69265
trainer/Policy Loss                        -407.681
trainer/Q1 Predictions Mean                 408.344
trainer/Q1 Predictions Std                   96.0214
trainer/Q1 Predictions Max                  479.491
trainer/Q1 Predictions Min                   19.2739
trainer/Q2 Predictions Mean                 408.447
trainer/Q2 Predictions Std                   96.1046
trainer/Q2 Predictions Max                  481.985
trainer/Q2 Predictions Min                   19.8316
trainer/Q Targets Mean                      408.644
trainer/Q Targets Std                        96.2243
trainer/Q Targets Max                       485.684
trainer/Q Targets Min                        20.3404
trainer/Log Pis Mean                          5.83605
trainer/Log Pis Std                           4.38742
trainer/Log Pis Max                          15.8431
trainer/Log Pis Min                          -6.43718
trainer/policy/mean Mean                      0.0827712
trainer/policy/mean Std                       0.76745
trainer/policy/mean Max                       0.993298
trainer/policy/mean Min                      -0.998912
trainer/policy/normal/std Mean                0.442842
trainer/policy/normal/std Std                 0.157725
trainer/policy/normal/std Max                 0.971866
trainer/policy/normal/std Min                 0.0633443
trainer/policy/normal/log_std Mean           -0.898262
trainer/policy/normal/log_std Std             0.451635
trainer/policy/normal/log_std Max            -0.0285376
trainer/policy/normal/log_std Min            -2.75917
trainer/Alpha                                 0.153119
trainer/Alpha Loss                           -0.307657
expl/num steps total                     421000
expl/num paths total                        421
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.01534
expl/Rewards Std                              1.27245
expl/Rewards Max                              8.23811
expl/Rewards Min                             -0.576606
expl/Returns Mean                          6015.34
expl/Returns Std                              0
expl/Returns Max                           6015.34
expl/Returns Min                           6015.34
expl/Actions Mean                             0.0877404
expl/Actions Std                              0.803916
expl/Actions Max                              0.999468
expl/Actions Min                             -0.99928
expl/Num Paths                                1
expl/Average Returns                       6015.34
expl/env_infos/final/reward_run Mean          5.41856
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.41856
expl/env_infos/final/reward_run Min           5.41856
expl/env_infos/initial/reward_run Mean       -0.353844
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.353844
expl/env_infos/initial/reward_run Min        -0.353844
expl/env_infos/reward_run Mean                6.40773
expl/env_infos/reward_run Std                 1.2674
expl/env_infos/reward_run Max                 8.69536
expl/env_infos/reward_run Min                -0.353844
expl/env_infos/final/reward_ctrl Mean        -0.415599
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.415599
expl/env_infos/final/reward_ctrl Min         -0.415599
expl/env_infos/initial/reward_ctrl Mean      -0.222762
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.222762
expl/env_infos/initial/reward_ctrl Min       -0.222762
expl/env_infos/reward_ctrl Mean              -0.392388
expl/env_infos/reward_ctrl Std                0.0886526
expl/env_infos/reward_ctrl Max               -0.0885794
expl/env_infos/reward_ctrl Min               -0.564171
eval/num steps total                          2.1e+06
eval/num paths total                       2100
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.3022
eval/Rewards Std                              1.32
eval/Rewards Max                              8.86114
eval/Rewards Min                             -0.816291
eval/Returns Mean                          6302.2
eval/Returns Std                             71.2339
eval/Returns Max                           6403.38
eval/Returns Min                           6224.91
eval/Actions Mean                             0.0784019
eval/Actions Std                              0.820448
eval/Actions Max                              0.996039
eval/Actions Min                             -0.998735
eval/Num Paths                                5
eval/Average Returns                       6302.2
eval/env_infos/final/reward_run Mean          6.94053
eval/env_infos/final/reward_run Std           0.695382
eval/env_infos/final/reward_run Max           8.03378
eval/env_infos/final/reward_run Min           6.25932
eval/env_infos/initial/reward_run Mean       -0.218175
eval/env_infos/initial/reward_run Std         0.260654
eval/env_infos/initial/reward_run Max         0.18206
eval/env_infos/initial/reward_run Min        -0.632393
eval/env_infos/reward_run Mean                6.70976
eval/env_infos/reward_run Std                 1.31607
eval/env_infos/reward_run Max                 9.36458
eval/env_infos/reward_run Min                -0.632393
eval/env_infos/final/reward_ctrl Mean        -0.424684
eval/env_infos/final/reward_ctrl Std          0.0221368
eval/env_infos/final/reward_ctrl Max         -0.394439
eval/env_infos/final/reward_ctrl Min         -0.455121
eval/env_infos/initial/reward_ctrl Mean      -0.224073
eval/env_infos/initial/reward_ctrl Std        0.0663005
eval/env_infos/initial/reward_ctrl Max       -0.11375
eval/env_infos/initial/reward_ctrl Min       -0.293545
eval/env_infos/reward_ctrl Mean              -0.407569
eval/env_infos/reward_ctrl Std                0.0858815
eval/env_infos/reward_ctrl Max               -0.097864
eval/env_infos/reward_ctrl Min               -0.576974
time/data storing (s)                         0.00447915
time/evaluation sampling (s)                  1.99902
time/exploration sampling (s)                 0.530404
time/logging (s)                              0.0137566
time/sac training (s)                         7.3728
time/saving (s)                               0.0037441
time/training (s)                             3.3786e-05
time/epoch (s)                                9.92423
time/total (s)                             4424.66
Epoch                                       419
---------------------------------------  ---------------
2021-11-24 01:43:11.103173 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 420 finished
---------------------------------------  ---------------
epoch                                       420
replay_buffer/size                       422000
trainer/num train calls                  421000
trainer/QF1 Loss                              4.98246
trainer/QF2 Loss                              5.74697
trainer/Policy Loss                        -413.729
trainer/Q1 Predictions Mean                 414.732
trainer/Q1 Predictions Std                   92.3637
trainer/Q1 Predictions Max                  477.183
trainer/Q1 Predictions Min                   21.124
trainer/Q2 Predictions Mean                 414.279
trainer/Q2 Predictions Std                   92.3272
trainer/Q2 Predictions Max                  479.427
trainer/Q2 Predictions Min                   20.8449
trainer/Q Targets Mean                      414.595
trainer/Q Targets Std                        92.5414
trainer/Q Targets Max                       480.315
trainer/Q Targets Min                        19.6439
trainer/Log Pis Mean                          5.95837
trainer/Log Pis Std                           4.35635
trainer/Log Pis Max                          15.4133
trainer/Log Pis Min                          -5.08791
trainer/policy/mean Mean                      0.0824633
trainer/policy/mean Std                       0.783385
trainer/policy/mean Max                       0.999934
trainer/policy/mean Min                      -0.999038
trainer/policy/normal/std Mean                0.443121
trainer/policy/normal/std Std                 0.149728
trainer/policy/normal/std Max                 1.22815
trainer/policy/normal/std Min                 0.0633022
trainer/policy/normal/log_std Mean           -0.893776
trainer/policy/normal/log_std Std             0.447596
trainer/policy/normal/log_std Max             0.205506
trainer/policy/normal/log_std Min            -2.75983
trainer/Alpha                                 0.155661
trainer/Alpha Loss                           -0.0774297
expl/num steps total                     422000
expl/num paths total                        422
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00717
expl/Rewards Std                              1.2463
expl/Rewards Max                              8.36365
expl/Rewards Min                             -0.415044
expl/Returns Mean                          6007.17
expl/Returns Std                              0
expl/Returns Max                           6007.17
expl/Returns Min                           6007.17
expl/Actions Mean                             0.0994399
expl/Actions Std                              0.807659
expl/Actions Max                              0.999467
expl/Actions Min                             -0.999498
expl/Num Paths                                1
expl/Average Returns                       6007.17
expl/env_infos/final/reward_run Mean          7.55849
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.55849
expl/env_infos/final/reward_run Min           7.55849
expl/env_infos/initial/reward_run Mean        0.357071
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.357071
expl/env_infos/initial/reward_run Min         0.357071
expl/env_infos/reward_run Mean                6.4045
expl/env_infos/reward_run Std                 1.24146
expl/env_infos/reward_run Max                 8.86854
expl/env_infos/reward_run Min                 0.00432379
expl/env_infos/final/reward_ctrl Mean        -0.340619
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.340619
expl/env_infos/final/reward_ctrl Min         -0.340619
expl/env_infos/initial/reward_ctrl Mean      -0.218807
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.218807
expl/env_infos/initial/reward_ctrl Min       -0.218807
expl/env_infos/reward_ctrl Mean              -0.397321
expl/env_infos/reward_ctrl Std                0.0879843
expl/env_infos/reward_ctrl Max               -0.104879
expl/env_infos/reward_ctrl Min               -0.574348
eval/num steps total                          2.105e+06
eval/num paths total                       2105
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.36277
eval/Rewards Std                              1.31942
eval/Rewards Max                              8.74529
eval/Rewards Min                             -0.859742
eval/Returns Mean                          6362.77
eval/Returns Std                             58.8388
eval/Returns Max                           6474.85
eval/Returns Min                           6300.05
eval/Actions Mean                             0.0943087
eval/Actions Std                              0.824105
eval/Actions Max                              0.998082
eval/Actions Min                             -0.999793
eval/Num Paths                                5
eval/Average Returns                       6362.77
eval/env_infos/final/reward_run Mean          7.53896
eval/env_infos/final/reward_run Std           0.785373
eval/env_infos/final/reward_run Max           8.31926
eval/env_infos/final/reward_run Min           6.07589
eval/env_infos/initial/reward_run Mean        0.330811
eval/env_infos/initial/reward_run Std         0.600511
eval/env_infos/initial/reward_run Max         1.17375
eval/env_infos/initial/reward_run Min        -0.625937
eval/env_infos/reward_run Mean                6.7756
eval/env_infos/reward_run Std                 1.31214
eval/env_infos/reward_run Max                 9.24012
eval/env_infos/reward_run Min                -0.625937
eval/env_infos/final/reward_ctrl Mean        -0.433639
eval/env_infos/final/reward_ctrl Std          0.0520639
eval/env_infos/final/reward_ctrl Max         -0.37
eval/env_infos/final/reward_ctrl Min         -0.495205
eval/env_infos/initial/reward_ctrl Mean      -0.216908
eval/env_infos/initial/reward_ctrl Std        0.0671247
eval/env_infos/initial/reward_ctrl Max       -0.11677
eval/env_infos/initial/reward_ctrl Min       -0.308783
eval/env_infos/reward_ctrl Mean              -0.412826
eval/env_infos/reward_ctrl Std                0.0865894
eval/env_infos/reward_ctrl Max               -0.112703
eval/env_infos/reward_ctrl Min               -0.581458
time/data storing (s)                         0.0045196
time/evaluation sampling (s)                  1.99435
time/exploration sampling (s)                 0.534166
time/logging (s)                              0.0135918
time/sac training (s)                         7.36832
time/saving (s)                               0.00516528
time/training (s)                             3.3367e-05
time/epoch (s)                                9.92014
time/total (s)                             4434.86
Epoch                                       420
---------------------------------------  ---------------
2021-11-24 01:43:21.330178 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 421 finished
---------------------------------------  ---------------
epoch                                       421
replay_buffer/size                       423000
trainer/num train calls                  422000
trainer/QF1 Loss                              6.14566
trainer/QF2 Loss                              5.31445
trainer/Policy Loss                        -401.269
trainer/Q1 Predictions Mean                 401.82
trainer/Q1 Predictions Std                  103.798
trainer/Q1 Predictions Max                  476.472
trainer/Q1 Predictions Min                   20.8663
trainer/Q2 Predictions Mean                 402.192
trainer/Q2 Predictions Std                  103.884
trainer/Q2 Predictions Max                  476.119
trainer/Q2 Predictions Min                   20.6583
trainer/Q Targets Mean                      402.428
trainer/Q Targets Std                       103.992
trainer/Q Targets Max                       477.212
trainer/Q Targets Min                        21.0242
trainer/Log Pis Mean                          5.88392
trainer/Log Pis Std                           4.4185
trainer/Log Pis Max                          16.4539
trainer/Log Pis Min                          -5.91997
trainer/policy/mean Mean                      0.0661449
trainer/policy/mean Std                       0.780901
trainer/policy/mean Max                       0.996515
trainer/policy/mean Min                      -0.993075
trainer/policy/normal/std Mean                0.445491
trainer/policy/normal/std Std                 0.152059
trainer/policy/normal/std Max                 0.917776
trainer/policy/normal/std Min                 0.0698447
trainer/policy/normal/log_std Mean           -0.886238
trainer/policy/normal/log_std Std             0.437042
trainer/policy/normal/log_std Max            -0.0858021
trainer/policy/normal/log_std Min            -2.66148
trainer/Alpha                                 0.153316
trainer/Alpha Loss                           -0.217681
expl/num steps total                     423000
expl/num paths total                        423
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.9632
expl/Rewards Std                              1.29072
expl/Rewards Max                              8.30292
expl/Rewards Min                             -0.72885
expl/Returns Mean                          5963.2
expl/Returns Std                              0
expl/Returns Max                           5963.2
expl/Returns Min                           5963.2
expl/Actions Mean                             0.0991954
expl/Actions Std                              0.796348
expl/Actions Max                              0.999487
expl/Actions Min                             -0.999686
expl/Num Paths                                1
expl/Average Returns                       5963.2
expl/env_infos/final/reward_run Mean          6.55236
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.55236
expl/env_infos/final/reward_run Min           6.55236
expl/env_infos/initial/reward_run Mean       -0.506639
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.506639
expl/env_infos/initial/reward_run Min        -0.506639
expl/env_infos/reward_run Mean                6.3496
expl/env_infos/reward_run Std                 1.29166
expl/env_infos/reward_run Max                 8.7222
expl/env_infos/reward_run Min                -0.506639
expl/env_infos/final/reward_ctrl Mean        -0.39908
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.39908
expl/env_infos/final/reward_ctrl Min         -0.39908
expl/env_infos/initial/reward_ctrl Mean      -0.222211
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.222211
expl/env_infos/initial/reward_ctrl Min       -0.222211
expl/env_infos/reward_ctrl Mean              -0.386406
expl/env_infos/reward_ctrl Std                0.0872721
expl/env_infos/reward_ctrl Max               -0.0604557
expl/env_infos/reward_ctrl Min               -0.558522
eval/num steps total                          2.11e+06
eval/num paths total                       2110
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.39542
eval/Rewards Std                              1.31546
eval/Rewards Max                              8.79638
eval/Rewards Min                             -0.701101
eval/Returns Mean                          6395.42
eval/Returns Std                             67.4065
eval/Returns Max                           6527.49
eval/Returns Min                           6343.42
eval/Actions Mean                             0.0946243
eval/Actions Std                              0.821475
eval/Actions Max                              0.998527
eval/Actions Min                             -0.99714
eval/Num Paths                                5
eval/Average Returns                       6395.42
eval/env_infos/final/reward_run Mean          7.26861
eval/env_infos/final/reward_run Std           0.623851
eval/env_infos/final/reward_run Max           8.3002
eval/env_infos/final/reward_run Min           6.43743
eval/env_infos/initial/reward_run Mean       -0.215741
eval/env_infos/initial/reward_run Std         0.174395
eval/env_infos/initial/reward_run Max         0.00181853
eval/env_infos/initial/reward_run Min        -0.411609
eval/env_infos/reward_run Mean                6.80568
eval/env_infos/reward_run Std                 1.31557
eval/env_infos/reward_run Max                 9.28009
eval/env_infos/reward_run Min                -0.411609
eval/env_infos/final/reward_ctrl Mean        -0.372113
eval/env_infos/final/reward_ctrl Std          0.101022
eval/env_infos/final/reward_ctrl Max         -0.194756
eval/env_infos/final/reward_ctrl Min         -0.48182
eval/env_infos/initial/reward_ctrl Mean      -0.152402
eval/env_infos/initial/reward_ctrl Std        0.0439641
eval/env_infos/initial/reward_ctrl Max       -0.0998244
eval/env_infos/initial/reward_ctrl Min       -0.216428
eval/env_infos/reward_ctrl Mean              -0.410265
eval/env_infos/reward_ctrl Std                0.085338
eval/env_infos/reward_ctrl Max               -0.0920422
eval/env_infos/reward_ctrl Min               -0.573132
time/data storing (s)                         0.0044918
time/evaluation sampling (s)                  1.99699
time/exploration sampling (s)                 0.531588
time/logging (s)                              0.0137213
time/sac training (s)                         7.38264
time/saving (s)                               0.00376527
time/training (s)                             3.363e-05
time/epoch (s)                                9.93323
time/total (s)                             4445.07
Epoch                                       421
---------------------------------------  ---------------
2021-11-24 01:43:31.615944 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 422 finished
---------------------------------------  ---------------
epoch                                       422
replay_buffer/size                       424000
trainer/num train calls                  423000
trainer/QF1 Loss                              7.74281
trainer/QF2 Loss                             10.3347
trainer/Policy Loss                        -406.552
trainer/Q1 Predictions Mean                 407.58
trainer/Q1 Predictions Std                   99.7751
trainer/Q1 Predictions Max                  484.648
trainer/Q1 Predictions Min                   23.2288
trainer/Q2 Predictions Mean                 407.256
trainer/Q2 Predictions Std                   99.7369
trainer/Q2 Predictions Max                  483.93
trainer/Q2 Predictions Min                   23.127
trainer/Q Targets Mean                      407.767
trainer/Q Targets Std                        99.5525
trainer/Q Targets Max                       482.058
trainer/Q Targets Min                        22.3555
trainer/Log Pis Mean                          6.10743
trainer/Log Pis Std                           4.1666
trainer/Log Pis Max                          15.1168
trainer/Log Pis Min                          -5.20062
trainer/policy/mean Mean                      0.0896842
trainer/policy/mean Std                       0.784245
trainer/policy/mean Max                       0.994928
trainer/policy/mean Min                      -0.994715
trainer/policy/normal/std Mean                0.447902
trainer/policy/normal/std Std                 0.149364
trainer/policy/normal/std Max                 1.02152
trainer/policy/normal/std Min                 0.0643884
trainer/policy/normal/log_std Mean           -0.878286
trainer/policy/normal/log_std Std             0.430572
trainer/policy/normal/log_std Max             0.0212938
trainer/policy/normal/log_std Min            -2.74282
trainer/Alpha                                 0.154662
trainer/Alpha Loss                            0.200524
expl/num steps total                     424000
expl/num paths total                        424
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.86307
expl/Rewards Std                              1.3338
expl/Rewards Max                              8.40092
expl/Rewards Min                             -0.674603
expl/Returns Mean                          5863.07
expl/Returns Std                              0
expl/Returns Max                           5863.07
expl/Returns Min                           5863.07
expl/Actions Mean                             0.104852
expl/Actions Std                              0.795846
expl/Actions Max                              0.999568
expl/Actions Min                             -0.999402
expl/Num Paths                                1
expl/Average Returns                       5863.07
expl/env_infos/final/reward_run Mean          6.11372
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.11372
expl/env_infos/final/reward_run Min           6.11372
expl/env_infos/initial/reward_run Mean       -0.535322
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.535322
expl/env_infos/initial/reward_run Min        -0.535322
expl/env_infos/reward_run Mean                6.24969
expl/env_infos/reward_run Std                 1.33028
expl/env_infos/reward_run Max                 8.91302
expl/env_infos/reward_run Min                -0.535322
expl/env_infos/final/reward_ctrl Mean        -0.47001
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.47001
expl/env_infos/final/reward_ctrl Min         -0.47001
expl/env_infos/initial/reward_ctrl Mean      -0.139282
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.139282
expl/env_infos/initial/reward_ctrl Min       -0.139282
expl/env_infos/reward_ctrl Mean              -0.386619
expl/env_infos/reward_ctrl Std                0.0916086
expl/env_infos/reward_ctrl Max               -0.0753538
expl/env_infos/reward_ctrl Min               -0.57225
eval/num steps total                          2.115e+06
eval/num paths total                       2115
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.31948
eval/Rewards Std                              1.31797
eval/Rewards Max                              8.7946
eval/Rewards Min                             -0.683209
eval/Returns Mean                          6319.48
eval/Returns Std                             97.3812
eval/Returns Max                           6464.98
eval/Returns Min                           6205.17
eval/Actions Mean                             0.101585
eval/Actions Std                              0.814785
eval/Actions Max                              0.99759
eval/Actions Min                             -0.997597
eval/Num Paths                                5
eval/Average Returns                       6319.48
eval/env_infos/final/reward_run Mean          7.24404
eval/env_infos/final/reward_run Std           0.929427
eval/env_infos/final/reward_run Max           8.13675
eval/env_infos/final/reward_run Min           5.99014
eval/env_infos/initial/reward_run Mean       -0.234066
eval/env_infos/initial/reward_run Std         0.276886
eval/env_infos/initial/reward_run Max         0.291165
eval/env_infos/initial/reward_run Min        -0.522427
eval/env_infos/reward_run Mean                6.724
eval/env_infos/reward_run Std                 1.31082
eval/env_infos/reward_run Max                 9.3259
eval/env_infos/reward_run Min                -0.522427
eval/env_infos/final/reward_ctrl Mean        -0.413287
eval/env_infos/final/reward_ctrl Std          0.0634485
eval/env_infos/final/reward_ctrl Max         -0.320213
eval/env_infos/final/reward_ctrl Min         -0.493243
eval/env_infos/initial/reward_ctrl Mean      -0.212443
eval/env_infos/initial/reward_ctrl Std        0.0500737
eval/env_infos/initial/reward_ctrl Max       -0.160782
eval/env_infos/initial/reward_ctrl Min       -0.280589
eval/env_infos/reward_ctrl Mean              -0.404517
eval/env_infos/reward_ctrl Std                0.0920361
eval/env_infos/reward_ctrl Max               -0.0823413
eval/env_infos/reward_ctrl Min               -0.580938
time/data storing (s)                         0.00455108
time/evaluation sampling (s)                  1.99605
time/exploration sampling (s)                 0.523367
time/logging (s)                              0.013562
time/sac training (s)                         7.44802
time/saving (s)                               0.0037622
time/training (s)                             3.4616e-05
time/epoch (s)                                9.98935
time/total (s)                             4455.34
Epoch                                       422
---------------------------------------  ---------------
2021-11-24 01:43:41.827905 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 423 finished
---------------------------------------  ---------------
epoch                                       423
replay_buffer/size                       425000
trainer/num train calls                  424000
trainer/QF1 Loss                              5.23351
trainer/QF2 Loss                              5.23192
trainer/Policy Loss                        -416.296
trainer/Q1 Predictions Mean                 416.933
trainer/Q1 Predictions Std                   86.4251
trainer/Q1 Predictions Max                  476.555
trainer/Q1 Predictions Min                   18.5643
trainer/Q2 Predictions Mean                 417.069
trainer/Q2 Predictions Std                   86.3246
trainer/Q2 Predictions Max                  476.161
trainer/Q2 Predictions Min                   18.6278
trainer/Q Targets Mean                      416.824
trainer/Q Targets Std                        86.3924
trainer/Q Targets Max                       476.708
trainer/Q Targets Min                        17.9463
trainer/Log Pis Mean                          6.22797
trainer/Log Pis Std                           4.06501
trainer/Log Pis Max                          16.0095
trainer/Log Pis Min                          -7.27639
trainer/policy/mean Mean                      0.0862135
trainer/policy/mean Std                       0.787115
trainer/policy/mean Max                       0.999252
trainer/policy/mean Min                      -0.997019
trainer/policy/normal/std Mean                0.43824
trainer/policy/normal/std Std                 0.141994
trainer/policy/normal/std Max                 0.895685
trainer/policy/normal/std Min                 0.0723253
trainer/policy/normal/log_std Mean           -0.897488
trainer/policy/normal/log_std Std             0.423034
trainer/policy/normal/log_std Max            -0.110166
trainer/policy/normal/log_std Min            -2.62658
trainer/Alpha                                 0.154696
trainer/Alpha Loss                            0.425469
expl/num steps total                     425000
expl/num paths total                        425
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.82709
expl/Rewards Std                              1.2653
expl/Rewards Max                              8.46782
expl/Rewards Min                             -0.585666
expl/Returns Mean                          5827.09
expl/Returns Std                              0
expl/Returns Max                           5827.09
expl/Returns Min                           5827.09
expl/Actions Mean                             0.0846243
expl/Actions Std                              0.788035
expl/Actions Max                              0.99972
expl/Actions Min                             -0.999276
expl/Num Paths                                1
expl/Average Returns                       5827.09
expl/env_infos/final/reward_run Mean          6.27611
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.27611
expl/env_infos/final/reward_run Min           6.27611
expl/env_infos/initial/reward_run Mean        0.183623
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.183623
expl/env_infos/initial/reward_run Min         0.183623
expl/env_infos/reward_run Mean                6.20399
expl/env_infos/reward_run Std                 1.26664
expl/env_infos/reward_run Max                 8.98128
expl/env_infos/reward_run Min                -0.253292
expl/env_infos/final/reward_ctrl Mean        -0.212532
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.212532
expl/env_infos/final/reward_ctrl Min         -0.212532
expl/env_infos/initial/reward_ctrl Mean      -0.270501
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.270501
expl/env_infos/initial/reward_ctrl Min       -0.270501
expl/env_infos/reward_ctrl Mean              -0.376896
expl/env_infos/reward_ctrl Std                0.087291
expl/env_infos/reward_ctrl Max               -0.100735
expl/env_infos/reward_ctrl Min               -0.556067
eval/num steps total                          2.12e+06
eval/num paths total                       2120
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.18753
eval/Rewards Std                              1.30378
eval/Rewards Max                              8.88409
eval/Rewards Min                             -0.77303
eval/Returns Mean                          6187.53
eval/Returns Std                            126.155
eval/Returns Max                           6383.52
eval/Returns Min                           6071.89
eval/Actions Mean                             0.0888915
eval/Actions Std                              0.806255
eval/Actions Max                              0.996727
eval/Actions Min                             -0.996651
eval/Num Paths                                5
eval/Average Returns                       6187.53
eval/env_infos/final/reward_run Mean          7.24291
eval/env_infos/final/reward_run Std           0.816542
eval/env_infos/final/reward_run Max           8.10564
eval/env_infos/final/reward_run Min           5.79191
eval/env_infos/initial/reward_run Mean       -0.0347241
eval/env_infos/initial/reward_run Std         0.409467
eval/env_infos/initial/reward_run Max         0.555692
eval/env_infos/initial/reward_run Min        -0.607367
eval/env_infos/reward_run Mean                6.5823
eval/env_infos/reward_run Std                 1.30675
eval/env_infos/reward_run Max                 9.36855
eval/env_infos/reward_run Min                -0.607367
eval/env_infos/final/reward_ctrl Mean        -0.380016
eval/env_infos/final/reward_ctrl Std          0.0390393
eval/env_infos/final/reward_ctrl Max         -0.325332
eval/env_infos/final/reward_ctrl Min         -0.42997
eval/env_infos/initial/reward_ctrl Mean      -0.147269
eval/env_infos/initial/reward_ctrl Std        0.0562827
eval/env_infos/initial/reward_ctrl Max       -0.0508382
eval/env_infos/initial/reward_ctrl Min       -0.213476
eval/env_infos/reward_ctrl Mean              -0.39477
eval/env_infos/reward_ctrl Std                0.0809186
eval/env_infos/reward_ctrl Max               -0.0508382
eval/env_infos/reward_ctrl Min               -0.574925
time/data storing (s)                         0.00450026
time/evaluation sampling (s)                  1.97776
time/exploration sampling (s)                 0.513408
time/logging (s)                              0.0137409
time/sac training (s)                         7.40274
time/saving (s)                               0.00378039
time/training (s)                             3.4523e-05
time/epoch (s)                                9.91597
time/total (s)                             4465.54
Epoch                                       423
---------------------------------------  ---------------
2021-11-24 01:43:52.152658 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 424 finished
---------------------------------------  ---------------
epoch                                       424
replay_buffer/size                       426000
trainer/num train calls                  425000
trainer/QF1 Loss                              4.58763
trainer/QF2 Loss                              6.71725
trainer/Policy Loss                        -408.154
trainer/Q1 Predictions Mean                 409.076
trainer/Q1 Predictions Std                   97.2468
trainer/Q1 Predictions Max                  476.11
trainer/Q1 Predictions Min                   23.4348
trainer/Q2 Predictions Mean                 409.226
trainer/Q2 Predictions Std                   97.2433
trainer/Q2 Predictions Max                  478.125
trainer/Q2 Predictions Min                   21.7331
trainer/Q Targets Mean                      409.384
trainer/Q Targets Std                        97.4257
trainer/Q Targets Max                       477.137
trainer/Q Targets Min                        21.412
trainer/Log Pis Mean                          6.10516
trainer/Log Pis Std                           4.40481
trainer/Log Pis Max                          15.5125
trainer/Log Pis Min                          -5.59048
trainer/policy/mean Mean                      0.0850843
trainer/policy/mean Std                       0.78206
trainer/policy/mean Max                       0.99846
trainer/policy/mean Min                      -0.996042
trainer/policy/normal/std Mean                0.446955
trainer/policy/normal/std Std                 0.149819
trainer/policy/normal/std Max                 1.15482
trainer/policy/normal/std Min                 0.0693643
trainer/policy/normal/log_std Mean           -0.881481
trainer/policy/normal/log_std Std             0.435461
trainer/policy/normal/log_std Max             0.143942
trainer/policy/normal/log_std Min            -2.66838
trainer/Alpha                                 0.154418
trainer/Alpha Loss                            0.196454
expl/num steps total                     426000
expl/num paths total                        426
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11769
expl/Rewards Std                              1.25018
expl/Rewards Max                              8.92504
expl/Rewards Min                             -0.645804
expl/Returns Mean                          6117.69
expl/Returns Std                              0
expl/Returns Max                           6117.69
expl/Returns Min                           6117.69
expl/Actions Mean                             0.103936
expl/Actions Std                              0.803687
expl/Actions Max                              0.999772
expl/Actions Min                             -0.998875
expl/Num Paths                                1
expl/Average Returns                       6117.69
expl/env_infos/final/reward_run Mean          6.80917
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.80917
expl/env_infos/final/reward_run Min           6.80917
expl/env_infos/initial/reward_run Mean        0.0638128
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0638128
expl/env_infos/initial/reward_run Min         0.0638128
expl/env_infos/reward_run Mean                6.51172
expl/env_infos/reward_run Std                 1.24512
expl/env_infos/reward_run Max                 9.43972
expl/env_infos/reward_run Min                -0.168391
expl/env_infos/final/reward_ctrl Mean        -0.399642
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.399642
expl/env_infos/final/reward_ctrl Min         -0.399642
expl/env_infos/initial/reward_ctrl Mean      -0.125331
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.125331
expl/env_infos/initial/reward_ctrl Min       -0.125331
expl/env_infos/reward_ctrl Mean              -0.39403
expl/env_infos/reward_ctrl Std                0.0829731
expl/env_infos/reward_ctrl Max               -0.125331
expl/env_infos/reward_ctrl Min               -0.57864
eval/num steps total                          2.125e+06
eval/num paths total                       2125
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.41165
eval/Rewards Std                              1.32116
eval/Rewards Max                              8.93245
eval/Rewards Min                             -0.855716
eval/Returns Mean                          6411.65
eval/Returns Std                             65.9292
eval/Returns Max                           6489.79
eval/Returns Min                           6316.68
eval/Actions Mean                             0.0981862
eval/Actions Std                              0.814568
eval/Actions Max                              0.995858
eval/Actions Min                             -0.996101
eval/Num Paths                                5
eval/Average Returns                       6411.65
eval/env_infos/final/reward_run Mean          7.78294
eval/env_infos/final/reward_run Std           0.52485
eval/env_infos/final/reward_run Max           8.29282
eval/env_infos/final/reward_run Min           6.7871
eval/env_infos/initial/reward_run Mean       -0.4463
eval/env_infos/initial/reward_run Std         0.184998
eval/env_infos/initial/reward_run Max        -0.143431
eval/env_infos/initial/reward_run Min        -0.675936
eval/env_infos/reward_run Mean                6.81554
eval/env_infos/reward_run Std                 1.31627
eval/env_infos/reward_run Max                 9.43601
eval/env_infos/reward_run Min                -0.675936
eval/env_infos/final/reward_ctrl Mean        -0.355306
eval/env_infos/final/reward_ctrl Std          0.131327
eval/env_infos/final/reward_ctrl Max         -0.18831
eval/env_infos/final/reward_ctrl Min         -0.495396
eval/env_infos/initial/reward_ctrl Mean      -0.193726
eval/env_infos/initial/reward_ctrl Std        0.0262767
eval/env_infos/initial/reward_ctrl Max       -0.162205
eval/env_infos/initial/reward_ctrl Min       -0.229345
eval/env_infos/reward_ctrl Mean              -0.403897
eval/env_infos/reward_ctrl Std                0.0826027
eval/env_infos/reward_ctrl Max               -0.0991885
eval/env_infos/reward_ctrl Min               -0.577412
time/data storing (s)                         0.00448439
time/evaluation sampling (s)                  1.98728
time/exploration sampling (s)                 0.52838
time/logging (s)                              0.0138966
time/sac training (s)                         7.48936
time/saving (s)                               0.00384719
time/training (s)                             3.4937e-05
time/epoch (s)                               10.0273
time/total (s)                             4475.85
Epoch                                       424
---------------------------------------  ---------------
2021-11-24 01:44:02.665390 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 425 finished
---------------------------------------  ---------------
epoch                                       425
replay_buffer/size                       427000
trainer/num train calls                  426000
trainer/QF1 Loss                              7.38994
trainer/QF2 Loss                              8.16331
trainer/Policy Loss                        -411.013
trainer/Q1 Predictions Mean                 411.596
trainer/Q1 Predictions Std                   93.9799
trainer/Q1 Predictions Max                  484.441
trainer/Q1 Predictions Min                   20.9276
trainer/Q2 Predictions Mean                 411.948
trainer/Q2 Predictions Std                   94.3307
trainer/Q2 Predictions Max                  486.068
trainer/Q2 Predictions Min                   21.2261
trainer/Q Targets Mean                      412.414
trainer/Q Targets Std                        94.0744
trainer/Q Targets Max                       485.629
trainer/Q Targets Min                        20.3213
trainer/Log Pis Mean                          6.41177
trainer/Log Pis Std                           4.0443
trainer/Log Pis Max                          13.9506
trainer/Log Pis Min                         -10.7195
trainer/policy/mean Mean                      0.0604206
trainer/policy/mean Std                       0.797036
trainer/policy/mean Max                       0.997268
trainer/policy/mean Min                      -0.994288
trainer/policy/normal/std Mean                0.4413
trainer/policy/normal/std Std                 0.143297
trainer/policy/normal/std Max                 0.910818
trainer/policy/normal/std Min                 0.0674753
trainer/policy/normal/log_std Mean           -0.889663
trainer/policy/normal/log_std Std             0.420326
trainer/policy/normal/log_std Max            -0.0934118
trainer/policy/normal/log_std Min            -2.69599
trainer/Alpha                                 0.156245
trainer/Alpha Loss                            0.764374
expl/num steps total                     427000
expl/num paths total                        427
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.03302
expl/Rewards Std                              1.27394
expl/Rewards Max                              8.47918
expl/Rewards Min                             -0.124571
expl/Returns Mean                          6033.02
expl/Returns Std                              0
expl/Returns Max                           6033.02
expl/Returns Min                           6033.02
expl/Actions Mean                             0.0900784
expl/Actions Std                              0.797891
expl/Actions Max                              0.999465
expl/Actions Min                             -0.99939
expl/Num Paths                                1
expl/Average Returns                       6033.02
expl/env_infos/final/reward_run Mean          7.48449
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.48449
expl/env_infos/final/reward_run Min           7.48449
expl/env_infos/initial/reward_run Mean        0.115188
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.115188
expl/env_infos/initial/reward_run Min         0.115188
expl/env_infos/reward_run Mean                6.41986
expl/env_infos/reward_run Std                 1.27301
expl/env_infos/reward_run Max                 8.98321
expl/env_infos/reward_run Min                 0.115188
expl/env_infos/final/reward_ctrl Mean        -0.423552
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.423552
expl/env_infos/final/reward_ctrl Min         -0.423552
expl/env_infos/initial/reward_ctrl Mean      -0.239758
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.239758
expl/env_infos/initial/reward_ctrl Min       -0.239758
expl/env_infos/reward_ctrl Mean              -0.386846
expl/env_infos/reward_ctrl Std                0.0883215
expl/env_infos/reward_ctrl Max               -0.0974739
expl/env_infos/reward_ctrl Min               -0.576933
eval/num steps total                          2.13e+06
eval/num paths total                       2130
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.39252
eval/Rewards Std                              1.32669
eval/Rewards Max                              8.80334
eval/Rewards Min                             -0.897407
eval/Returns Mean                          6392.52
eval/Returns Std                             86.9502
eval/Returns Max                           6554.59
eval/Returns Min                           6299.86
eval/Actions Mean                             0.086233
eval/Actions Std                              0.81504
eval/Actions Max                              0.995026
eval/Actions Min                             -0.998233
eval/Num Paths                                5
eval/Average Returns                       6392.52
eval/env_infos/final/reward_run Mean          7.47209
eval/env_infos/final/reward_run Std           0.805435
eval/env_infos/final/reward_run Max           8.25482
eval/env_infos/final/reward_run Min           6.07639
eval/env_infos/initial/reward_run Mean       -0.0218126
eval/env_infos/initial/reward_run Std         0.378872
eval/env_infos/initial/reward_run Max         0.540624
eval/env_infos/initial/reward_run Min        -0.413295
eval/env_infos/reward_run Mean                6.79556
eval/env_infos/reward_run Std                 1.32515
eval/env_infos/reward_run Max                 9.25297
eval/env_infos/reward_run Min                -0.463313
eval/env_infos/final/reward_ctrl Mean        -0.447933
eval/env_infos/final/reward_ctrl Std          0.0849902
eval/env_infos/final/reward_ctrl Max         -0.284927
eval/env_infos/final/reward_ctrl Min         -0.526204
eval/env_infos/initial/reward_ctrl Mean      -0.168671
eval/env_infos/initial/reward_ctrl Std        0.05627
eval/env_infos/initial/reward_ctrl Max       -0.109277
eval/env_infos/initial/reward_ctrl Min       -0.258853
eval/env_infos/reward_ctrl Mean              -0.403036
eval/env_infos/reward_ctrl Std                0.0846623
eval/env_infos/reward_ctrl Max               -0.105187
eval/env_infos/reward_ctrl Min               -0.577532
time/data storing (s)                         0.00460532
time/evaluation sampling (s)                  2.02233
time/exploration sampling (s)                 0.535316
time/logging (s)                              0.0137175
time/sac training (s)                         7.62783
time/saving (s)                               0.0037959
time/training (s)                             3.4948e-05
time/epoch (s)                               10.2076
time/total (s)                             4486.35
Epoch                                       425
---------------------------------------  ---------------
2021-11-24 01:44:13.027030 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 426 finished
---------------------------------------  ---------------
epoch                                       426
replay_buffer/size                       428000
trainer/num train calls                  427000
trainer/QF1 Loss                              5.97533
trainer/QF2 Loss                              5.60182
trainer/Policy Loss                        -413.201
trainer/Q1 Predictions Mean                 413.541
trainer/Q1 Predictions Std                   96.8681
trainer/Q1 Predictions Max                  477.421
trainer/Q1 Predictions Min                   21.5292
trainer/Q2 Predictions Mean                 414.185
trainer/Q2 Predictions Std                   96.9706
trainer/Q2 Predictions Max                  478.163
trainer/Q2 Predictions Min                   20.4397
trainer/Q Targets Mean                      414.176
trainer/Q Targets Std                        97.1396
trainer/Q Targets Max                       478.781
trainer/Q Targets Min                        21.8052
trainer/Log Pis Mean                          6.50276
trainer/Log Pis Std                           4.22668
trainer/Log Pis Max                          15.6282
trainer/Log Pis Min                          -4.92267
trainer/policy/mean Mean                      0.0798319
trainer/policy/mean Std                       0.789593
trainer/policy/mean Max                       0.997327
trainer/policy/mean Min                      -0.995588
trainer/policy/normal/std Mean                0.444341
trainer/policy/normal/std Std                 0.144657
trainer/policy/normal/std Max                 0.94238
trainer/policy/normal/std Min                 0.0715992
trainer/policy/normal/log_std Mean           -0.885876
trainer/policy/normal/log_std Std             0.432878
trainer/policy/normal/log_std Max            -0.0593465
trainer/policy/normal/log_std Min            -2.63667
trainer/Alpha                                 0.152578
trainer/Alpha Loss                            0.945228
expl/num steps total                     428000
expl/num paths total                        428
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.94705
expl/Rewards Std                              1.25633
expl/Rewards Max                              8.54398
expl/Rewards Min                             -0.425256
expl/Returns Mean                          5947.05
expl/Returns Std                              0
expl/Returns Max                           5947.05
expl/Returns Min                           5947.05
expl/Actions Mean                             0.101722
expl/Actions Std                              0.80126
expl/Actions Max                              0.999803
expl/Actions Min                             -0.999202
expl/Num Paths                                1
expl/Average Returns                       5947.05
expl/env_infos/final/reward_run Mean          5.29951
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.29951
expl/env_infos/final/reward_run Min           5.29951
expl/env_infos/initial/reward_run Mean       -0.114717
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.114717
expl/env_infos/initial/reward_run Min        -0.114717
expl/env_infos/reward_run Mean                6.33847
expl/env_infos/reward_run Std                 1.24858
expl/env_infos/reward_run Max                 8.98975
expl/env_infos/reward_run Min                -0.114717
expl/env_infos/final/reward_ctrl Mean        -0.498716
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.498716
expl/env_infos/final/reward_ctrl Min         -0.498716
expl/env_infos/initial/reward_ctrl Mean      -0.310539
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.310539
expl/env_infos/initial/reward_ctrl Min       -0.310539
expl/env_infos/reward_ctrl Mean              -0.391419
expl/env_infos/reward_ctrl Std                0.0897892
expl/env_infos/reward_ctrl Max               -0.112342
expl/env_infos/reward_ctrl Min               -0.572903
eval/num steps total                          2.135e+06
eval/num paths total                       2135
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.43996
eval/Rewards Std                              1.31833
eval/Rewards Max                              8.86153
eval/Rewards Min                             -0.893236
eval/Returns Mean                          6439.96
eval/Returns Std                             65.1309
eval/Returns Max                           6522.86
eval/Returns Min                           6346.44
eval/Actions Mean                             0.0923139
eval/Actions Std                              0.821987
eval/Actions Max                              0.995849
eval/Actions Min                             -0.997611
eval/Num Paths                                5
eval/Average Returns                       6439.96
eval/env_infos/final/reward_run Mean          7.12895
eval/env_infos/final/reward_run Std           0.901332
eval/env_infos/final/reward_run Max           8.2154
eval/env_infos/final/reward_run Min           5.6143
eval/env_infos/initial/reward_run Mean       -0.0320467
eval/env_infos/initial/reward_run Std         0.344307
eval/env_infos/initial/reward_run Max         0.554273
eval/env_infos/initial/reward_run Min        -0.464238
eval/env_infos/reward_run Mean                6.85048
eval/env_infos/reward_run Std                 1.31095
eval/env_infos/reward_run Max                 9.37617
eval/env_infos/reward_run Min                -0.464238
eval/env_infos/final/reward_ctrl Mean        -0.391681
eval/env_infos/final/reward_ctrl Std          0.0488158
eval/env_infos/final/reward_ctrl Max         -0.319346
eval/env_infos/final/reward_ctrl Min         -0.457051
eval/env_infos/initial/reward_ctrl Mean      -0.229728
eval/env_infos/initial/reward_ctrl Std        0.0223108
eval/env_infos/initial/reward_ctrl Max       -0.210773
eval/env_infos/initial/reward_ctrl Min       -0.273046
eval/env_infos/reward_ctrl Mean              -0.410511
eval/env_infos/reward_ctrl Std                0.08663
eval/env_infos/reward_ctrl Max               -0.107511
eval/env_infos/reward_ctrl Min               -0.577124
time/data storing (s)                         0.0045338
time/evaluation sampling (s)                  1.99336
time/exploration sampling (s)                 0.536229
time/logging (s)                              0.0136379
time/sac training (s)                         7.51069
time/saving (s)                               0.00378131
time/training (s)                             3.4052e-05
time/epoch (s)                               10.0623
time/total (s)                             4496.69
Epoch                                       426
---------------------------------------  ---------------
2021-11-24 01:44:23.518914 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 427 finished
---------------------------------------  ---------------
epoch                                       427
replay_buffer/size                       429000
trainer/num train calls                  428000
trainer/QF1 Loss                              7.41659
trainer/QF2 Loss                              7.33838
trainer/Policy Loss                        -403.6
trainer/Q1 Predictions Mean                 403.943
trainer/Q1 Predictions Std                  105.056
trainer/Q1 Predictions Max                  485.984
trainer/Q1 Predictions Min                   19.3301
trainer/Q2 Predictions Mean                 404.278
trainer/Q2 Predictions Std                  105.38
trainer/Q2 Predictions Max                  486.267
trainer/Q2 Predictions Min                   19.7506
trainer/Q Targets Mean                      403.662
trainer/Q Targets Std                       105.181
trainer/Q Targets Max                       485.073
trainer/Q Targets Min                        19.5789
trainer/Log Pis Mean                          5.67689
trainer/Log Pis Std                           4.3097
trainer/Log Pis Max                          15.1847
trainer/Log Pis Min                          -5.68033
trainer/policy/mean Mean                      0.0941096
trainer/policy/mean Std                       0.766448
trainer/policy/mean Max                       0.994447
trainer/policy/mean Min                      -0.999742
trainer/policy/normal/std Mean                0.452747
trainer/policy/normal/std Std                 0.15437
trainer/policy/normal/std Max                 1.2079
trainer/policy/normal/std Min                 0.0671327
trainer/policy/normal/log_std Mean           -0.872588
trainer/policy/normal/log_std Std             0.446156
trainer/policy/normal/log_std Max             0.188883
trainer/policy/normal/log_std Min            -2.70108
trainer/Alpha                                 0.153389
trainer/Alpha Loss                           -0.605767
expl/num steps total                     429000
expl/num paths total                        429
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.05984
expl/Rewards Std                              1.25437
expl/Rewards Max                              8.27203
expl/Rewards Min                             -0.64989
expl/Returns Mean                          6059.84
expl/Returns Std                              0
expl/Returns Max                           6059.84
expl/Returns Min                           6059.84
expl/Actions Mean                             0.112272
expl/Actions Std                              0.802071
expl/Actions Max                              0.999853
expl/Actions Min                             -0.999711
expl/Num Paths                                1
expl/Average Returns                       6059.84
expl/env_infos/final/reward_run Mean          6.42961
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.42961
expl/env_infos/final/reward_run Min           6.42961
expl/env_infos/initial/reward_run Mean       -0.150979
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.150979
expl/env_infos/initial/reward_run Min        -0.150979
expl/env_infos/reward_run Mean                6.45339
expl/env_infos/reward_run Std                 1.24728
expl/env_infos/reward_run Max                 8.69962
expl/env_infos/reward_run Min                -0.245551
expl/env_infos/final/reward_ctrl Mean        -0.304032
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.304032
expl/env_infos/final/reward_ctrl Min         -0.304032
expl/env_infos/initial/reward_ctrl Mean      -0.196512
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.196512
expl/env_infos/initial/reward_ctrl Min       -0.196512
expl/env_infos/reward_ctrl Mean              -0.393553
expl/env_infos/reward_ctrl Std                0.0895903
expl/env_infos/reward_ctrl Max               -0.111034
expl/env_infos/reward_ctrl Min               -0.572063
eval/num steps total                          2.14e+06
eval/num paths total                       2140
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.397
eval/Rewards Std                              1.30981
eval/Rewards Max                              8.69268
eval/Rewards Min                             -0.562104
eval/Returns Mean                          6397
eval/Returns Std                             66.0512
eval/Returns Max                           6463.93
eval/Returns Min                           6289.26
eval/Actions Mean                             0.101291
eval/Actions Std                              0.819528
eval/Actions Max                              0.996346
eval/Actions Min                             -0.99756
eval/Num Paths                                5
eval/Average Returns                       6397
eval/env_infos/final/reward_run Mean          7.08838
eval/env_infos/final/reward_run Std           0.840726
eval/env_infos/final/reward_run Max           8.29305
eval/env_infos/final/reward_run Min           6.02802
eval/env_infos/initial/reward_run Mean       -0.226801
eval/env_infos/initial/reward_run Std         0.136566
eval/env_infos/initial/reward_run Max         0.00920564
eval/env_infos/initial/reward_run Min        -0.381452
eval/env_infos/reward_run Mean                6.80613
eval/env_infos/reward_run Std                 1.30277
eval/env_infos/reward_run Max                 9.15996
eval/env_infos/reward_run Min                -0.381452
eval/env_infos/final/reward_ctrl Mean        -0.398965
eval/env_infos/final/reward_ctrl Std          0.0603891
eval/env_infos/final/reward_ctrl Max         -0.318527
eval/env_infos/final/reward_ctrl Min         -0.48844
eval/env_infos/initial/reward_ctrl Mean      -0.183887
eval/env_infos/initial/reward_ctrl Std        0.0633223
eval/env_infos/initial/reward_ctrl Max       -0.0994073
eval/env_infos/initial/reward_ctrl Min       -0.266269
eval/env_infos/reward_ctrl Mean              -0.409132
eval/env_infos/reward_ctrl Std                0.0900714
eval/env_infos/reward_ctrl Max               -0.0701496
eval/env_infos/reward_ctrl Min               -0.574703
time/data storing (s)                         0.00458123
time/evaluation sampling (s)                  2.05851
time/exploration sampling (s)                 0.541851
time/logging (s)                              0.0136896
time/sac training (s)                         7.5693
time/saving (s)                               0.0037994
time/training (s)                             3.5114e-05
time/epoch (s)                               10.1918
time/total (s)                             4507.17
Epoch                                       427
---------------------------------------  ---------------
2021-11-24 01:44:33.899402 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 428 finished
---------------------------------------  ---------------
epoch                                       428
replay_buffer/size                       430000
trainer/num train calls                  429000
trainer/QF1 Loss                              6.68622
trainer/QF2 Loss                              4.82075
trainer/Policy Loss                        -408.235
trainer/Q1 Predictions Mean                 408.633
trainer/Q1 Predictions Std                  105.169
trainer/Q1 Predictions Max                  480.102
trainer/Q1 Predictions Min                   22.6114
trainer/Q2 Predictions Mean                 409.034
trainer/Q2 Predictions Std                  105.007
trainer/Q2 Predictions Max                  480.374
trainer/Q2 Predictions Min                   22.1045
trainer/Q Targets Mean                      409.396
trainer/Q Targets Std                       105.238
trainer/Q Targets Max                       477.439
trainer/Q Targets Min                        21.3799
trainer/Log Pis Mean                          5.65892
trainer/Log Pis Std                           4.22869
trainer/Log Pis Max                          14.9297
trainer/Log Pis Min                          -6.16448
trainer/policy/mean Mean                      0.103753
trainer/policy/mean Std                       0.765061
trainer/policy/mean Max                       0.995177
trainer/policy/mean Min                      -0.995883
trainer/policy/normal/std Mean                0.452068
trainer/policy/normal/std Std                 0.151852
trainer/policy/normal/std Max                 1.00224
trainer/policy/normal/std Min                 0.0743561
trainer/policy/normal/log_std Mean           -0.871758
trainer/policy/normal/log_std Std             0.439219
trainer/policy/normal/log_std Max             0.00223625
trainer/policy/normal/log_std Min            -2.59889
trainer/Alpha                                 0.153253
trainer/Alpha Loss                           -0.639745
expl/num steps total                     430000
expl/num paths total                        430
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.64645
expl/Rewards Std                              1.27095
expl/Rewards Max                              7.98428
expl/Rewards Min                             -0.817691
expl/Returns Mean                          5646.45
expl/Returns Std                              0
expl/Returns Max                           5646.45
expl/Returns Min                           5646.45
expl/Actions Mean                             0.102179
expl/Actions Std                              0.796791
expl/Actions Max                              0.999442
expl/Actions Min                             -0.999576
expl/Num Paths                                1
expl/Average Returns                       5646.45
expl/env_infos/final/reward_run Mean          6.85364
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.85364
expl/env_infos/final/reward_run Min           6.85364
expl/env_infos/initial/reward_run Mean       -0.604212
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.604212
expl/env_infos/initial/reward_run Min        -0.604212
expl/env_infos/reward_run Mean                6.03364
expl/env_infos/reward_run Std                 1.26426
expl/env_infos/reward_run Max                 8.54185
expl/env_infos/reward_run Min                -0.604212
expl/env_infos/final/reward_ctrl Mean        -0.331694
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.331694
expl/env_infos/final/reward_ctrl Min         -0.331694
expl/env_infos/initial/reward_ctrl Mean      -0.213479
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.213479
expl/env_infos/initial/reward_ctrl Min       -0.213479
expl/env_infos/reward_ctrl Mean              -0.38719
expl/env_infos/reward_ctrl Std                0.0949783
expl/env_infos/reward_ctrl Max               -0.0900562
expl/env_infos/reward_ctrl Min               -0.579475
eval/num steps total                          2.145e+06
eval/num paths total                       2145
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.23758
eval/Rewards Std                              1.3193
eval/Rewards Max                              8.75152
eval/Rewards Min                             -1.163
eval/Returns Mean                          6237.58
eval/Returns Std                            130.919
eval/Returns Max                           6367.67
eval/Returns Min                           5985.54
eval/Actions Mean                             0.0977033
eval/Actions Std                              0.820509
eval/Actions Max                              0.99963
eval/Actions Min                             -0.998518
eval/Num Paths                                5
eval/Average Returns                       6237.58
eval/env_infos/final/reward_run Mean          6.77779
eval/env_infos/final/reward_run Std           0.684141
eval/env_infos/final/reward_run Max           7.68546
eval/env_infos/final/reward_run Min           5.58772
eval/env_infos/initial/reward_run Mean       -0.184204
eval/env_infos/initial/reward_run Std         0.470225
eval/env_infos/initial/reward_run Max         0.691241
eval/env_infos/initial/reward_run Min        -0.707674
eval/env_infos/reward_run Mean                6.64725
eval/env_infos/reward_run Std                 1.31167
eval/env_infos/reward_run Max                 9.27157
eval/env_infos/reward_run Min                -0.707674
eval/env_infos/final/reward_ctrl Mean        -0.360478
eval/env_infos/final/reward_ctrl Std          0.0874596
eval/env_infos/final/reward_ctrl Max         -0.257087
eval/env_infos/final/reward_ctrl Min         -0.488109
eval/env_infos/initial/reward_ctrl Mean      -0.25283
eval/env_infos/initial/reward_ctrl Std        0.0442656
eval/env_infos/initial/reward_ctrl Max       -0.194526
eval/env_infos/initial/reward_ctrl Min       -0.301343
eval/env_infos/reward_ctrl Mean              -0.409669
eval/env_infos/reward_ctrl Std                0.0905113
eval/env_infos/reward_ctrl Max               -0.0827107
eval/env_infos/reward_ctrl Min               -0.578315
time/data storing (s)                         0.00448082
time/evaluation sampling (s)                  2.0121
time/exploration sampling (s)                 0.534334
time/logging (s)                              0.0137698
time/sac training (s)                         7.5144
time/saving (s)                               0.00378926
time/training (s)                             3.6216e-05
time/epoch (s)                               10.0829
time/total (s)                             4517.54
Epoch                                       428
---------------------------------------  ---------------
2021-11-24 01:44:44.388209 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 429 finished
---------------------------------------  ---------------
epoch                                       429
replay_buffer/size                       431000
trainer/num train calls                  430000
trainer/QF1 Loss                              4.69555
trainer/QF2 Loss                              4.55289
trainer/Policy Loss                        -415.295
trainer/Q1 Predictions Mean                 415.783
trainer/Q1 Predictions Std                   96.2378
trainer/Q1 Predictions Max                  491.721
trainer/Q1 Predictions Min                   23.2786
trainer/Q2 Predictions Mean                 416.366
trainer/Q2 Predictions Std                   96.2585
trainer/Q2 Predictions Max                  493.679
trainer/Q2 Predictions Min                   23.1832
trainer/Q Targets Mean                      415.476
trainer/Q Targets Std                        96.1737
trainer/Q Targets Max                       491.483
trainer/Q Targets Min                        20.938
trainer/Log Pis Mean                          5.82589
trainer/Log Pis Std                           4.09454
trainer/Log Pis Max                          15.0942
trainer/Log Pis Min                          -4.41118
trainer/policy/mean Mean                      0.0961585
trainer/policy/mean Std                       0.769229
trainer/policy/mean Max                       0.993014
trainer/policy/mean Min                      -0.997404
trainer/policy/normal/std Mean                0.439572
trainer/policy/normal/std Std                 0.144999
trainer/policy/normal/std Max                 0.899286
trainer/policy/normal/std Min                 0.0698815
trainer/policy/normal/log_std Mean           -0.895217
trainer/policy/normal/log_std Std             0.424867
trainer/policy/normal/log_std Max            -0.106154
trainer/policy/normal/log_std Min            -2.66095
trainer/Alpha                                 0.153386
trainer/Alpha Loss                           -0.326416
expl/num steps total                     431000
expl/num paths total                        431
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.01281
expl/Rewards Std                              1.27746
expl/Rewards Max                              8.1125
expl/Rewards Min                             -0.629215
expl/Returns Mean                          6012.81
expl/Returns Std                              0
expl/Returns Max                           6012.81
expl/Returns Min                           6012.81
expl/Actions Mean                             0.095553
expl/Actions Std                              0.794424
expl/Actions Max                              0.999418
expl/Actions Min                             -0.999056
expl/Num Paths                                1
expl/Average Returns                       6012.81
expl/env_infos/final/reward_run Mean          5.51767
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.51767
expl/env_infos/final/reward_run Min           5.51767
expl/env_infos/initial/reward_run Mean       -0.400391
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.400391
expl/env_infos/initial/reward_run Min        -0.400391
expl/env_infos/reward_run Mean                6.39695
expl/env_infos/reward_run Std                 1.26915
expl/env_infos/reward_run Max                 8.66539
expl/env_infos/reward_run Min                -0.400391
expl/env_infos/final/reward_ctrl Mean        -0.482507
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.482507
expl/env_infos/final/reward_ctrl Min         -0.482507
expl/env_infos/initial/reward_ctrl Mean      -0.228825
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.228825
expl/env_infos/initial/reward_ctrl Min       -0.228825
expl/env_infos/reward_ctrl Mean              -0.384143
expl/env_infos/reward_ctrl Std                0.0939306
expl/env_infos/reward_ctrl Max               -0.0998795
expl/env_infos/reward_ctrl Min               -0.575649
eval/num steps total                          2.15e+06
eval/num paths total                       2150
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.24538
eval/Rewards Std                              1.28817
eval/Rewards Max                              8.47246
eval/Rewards Min                             -0.825609
eval/Returns Mean                          6245.38
eval/Returns Std                             44.2161
eval/Returns Max                           6303.43
eval/Returns Min                           6176.39
eval/Actions Mean                             0.0926871
eval/Actions Std                              0.811494
eval/Actions Max                              0.995814
eval/Actions Min                             -0.997766
eval/Num Paths                                5
eval/Average Returns                       6245.38
eval/env_infos/final/reward_run Mean          7.00328
eval/env_infos/final/reward_run Std           0.626815
eval/env_infos/final/reward_run Max           8.17527
eval/env_infos/final/reward_run Min           6.29187
eval/env_infos/initial/reward_run Mean       -0.0584044
eval/env_infos/initial/reward_run Std         0.428961
eval/env_infos/initial/reward_run Max         0.648274
eval/env_infos/initial/reward_run Min        -0.508905
eval/env_infos/reward_run Mean                6.64565
eval/env_infos/reward_run Std                 1.27566
eval/env_infos/reward_run Max                 8.96453
eval/env_infos/reward_run Min                -0.508905
eval/env_infos/final/reward_ctrl Mean        -0.445443
eval/env_infos/final/reward_ctrl Std          0.0993475
eval/env_infos/final/reward_ctrl Max         -0.254536
eval/env_infos/final/reward_ctrl Min         -0.522534
eval/env_infos/initial/reward_ctrl Mean      -0.231155
eval/env_infos/initial/reward_ctrl Std        0.0789439
eval/env_infos/initial/reward_ctrl Max       -0.107351
eval/env_infos/initial/reward_ctrl Min       -0.316704
eval/env_infos/reward_ctrl Mean              -0.400268
eval/env_infos/reward_ctrl Std                0.090911
eval/env_infos/reward_ctrl Max               -0.0923134
eval/env_infos/reward_ctrl Min               -0.574318
time/data storing (s)                         0.00456903
time/evaluation sampling (s)                  2.06874
time/exploration sampling (s)                 0.532618
time/logging (s)                              0.0139883
time/sac training (s)                         7.56506
time/saving (s)                               0.00376735
time/training (s)                             3.478e-05
time/epoch (s)                               10.1888
time/total (s)                             4528.01
Epoch                                       429
---------------------------------------  ---------------
2021-11-24 01:44:54.943534 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 430 finished
---------------------------------------  ---------------
epoch                                       430
replay_buffer/size                       432000
trainer/num train calls                  431000
trainer/QF1 Loss                              5.59425
trainer/QF2 Loss                              5.8548
trainer/Policy Loss                        -407.389
trainer/Q1 Predictions Mean                 408.148
trainer/Q1 Predictions Std                  104.791
trainer/Q1 Predictions Max                  483.032
trainer/Q1 Predictions Min                   20.8863
trainer/Q2 Predictions Mean                 408.16
trainer/Q2 Predictions Std                  104.788
trainer/Q2 Predictions Max                  481.434
trainer/Q2 Predictions Min                   20.4373
trainer/Q Targets Mean                      407.852
trainer/Q Targets Std                       104.528
trainer/Q Targets Max                       479.846
trainer/Q Targets Min                        20.2754
trainer/Log Pis Mean                          5.89491
trainer/Log Pis Std                           4.66355
trainer/Log Pis Max                          16.6828
trainer/Log Pis Min                          -5.80418
trainer/policy/mean Mean                      0.0829305
trainer/policy/mean Std                       0.773444
trainer/policy/mean Max                       0.994358
trainer/policy/mean Min                      -0.995299
trainer/policy/normal/std Mean                0.449864
trainer/policy/normal/std Std                 0.15132
trainer/policy/normal/std Max                 0.956069
trainer/policy/normal/std Min                 0.0693322
trainer/policy/normal/log_std Mean           -0.876407
trainer/policy/normal/log_std Std             0.438601
trainer/policy/normal/log_std Max            -0.0449254
trainer/policy/normal/log_std Min            -2.66885
trainer/Alpha                                 0.154538
trainer/Alpha Loss                           -0.196231
expl/num steps total                     432000
expl/num paths total                        432
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.76054
expl/Rewards Std                              1.30454
expl/Rewards Max                              8.44804
expl/Rewards Min                             -0.560104
expl/Returns Mean                          5760.54
expl/Returns Std                              0
expl/Returns Max                           5760.54
expl/Returns Min                           5760.54
expl/Actions Mean                             0.107691
expl/Actions Std                              0.791068
expl/Actions Max                              0.998945
expl/Actions Min                             -0.99975
expl/Num Paths                                1
expl/Average Returns                       5760.54
expl/env_infos/final/reward_run Mean          6.80608
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.80608
expl/env_infos/final/reward_run Min           6.80608
expl/env_infos/initial/reward_run Mean       -0.344693
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.344693
expl/env_infos/initial/reward_run Min        -0.344693
expl/env_infos/reward_run Mean                6.14297
expl/env_infos/reward_run Std                 1.29649
expl/env_infos/reward_run Max                 8.93136
expl/env_infos/reward_run Min                -0.344693
expl/env_infos/final/reward_ctrl Mean        -0.382896
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.382896
expl/env_infos/final/reward_ctrl Min         -0.382896
expl/env_infos/initial/reward_ctrl Mean      -0.215411
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.215411
expl/env_infos/initial/reward_ctrl Min       -0.215411
expl/env_infos/reward_ctrl Mean              -0.382431
expl/env_infos/reward_ctrl Std                0.08957
expl/env_infos/reward_ctrl Max               -0.0633799
expl/env_infos/reward_ctrl Min               -0.569022
eval/num steps total                          2.155e+06
eval/num paths total                       2155
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.44315
eval/Rewards Std                              1.35579
eval/Rewards Max                              9.00367
eval/Rewards Min                             -0.830755
eval/Returns Mean                          6443.15
eval/Returns Std                             78.7135
eval/Returns Max                           6570.2
eval/Returns Min                           6347.67
eval/Actions Mean                             0.101619
eval/Actions Std                              0.818107
eval/Actions Max                              0.996617
eval/Actions Min                             -0.997873
eval/Num Paths                                5
eval/Average Returns                       6443.15
eval/env_infos/final/reward_run Mean          7.49854
eval/env_infos/final/reward_run Std           0.767359
eval/env_infos/final/reward_run Max           8.39039
eval/env_infos/final/reward_run Min           6.12624
eval/env_infos/initial/reward_run Mean       -0.212818
eval/env_infos/initial/reward_run Std         0.406347
eval/env_infos/initial/reward_run Max         0.568971
eval/env_infos/initial/reward_run Min        -0.533794
eval/env_infos/reward_run Mean                6.85093
eval/env_infos/reward_run Std                 1.3437
eval/env_infos/reward_run Max                 9.48982
eval/env_infos/reward_run Min                -0.533794
eval/env_infos/final/reward_ctrl Mean        -0.38127
eval/env_infos/final/reward_ctrl Std          0.0192976
eval/env_infos/final/reward_ctrl Max         -0.352631
eval/env_infos/final/reward_ctrl Min         -0.406675
eval/env_infos/initial/reward_ctrl Mean      -0.21201
eval/env_infos/initial/reward_ctrl Std        0.0491118
eval/env_infos/initial/reward_ctrl Max       -0.149405
eval/env_infos/initial/reward_ctrl Min       -0.266073
eval/env_infos/reward_ctrl Mean              -0.407775
eval/env_infos/reward_ctrl Std                0.0835043
eval/env_infos/reward_ctrl Max               -0.0474296
eval/env_infos/reward_ctrl Min               -0.580523
time/data storing (s)                         0.00451319
time/evaluation sampling (s)                  2.02398
time/exploration sampling (s)                 0.574848
time/logging (s)                              0.0137403
time/sac training (s)                         7.62889
time/saving (s)                               0.00378752
time/training (s)                             3.5359e-05
time/epoch (s)                               10.2498
time/total (s)                             4538.55
Epoch                                       430
---------------------------------------  ---------------
2021-11-24 01:45:05.249977 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 431 finished
---------------------------------------  ---------------
epoch                                       431
replay_buffer/size                       433000
trainer/num train calls                  432000
trainer/QF1 Loss                              6.11751
trainer/QF2 Loss                              6.21993
trainer/Policy Loss                        -409.49
trainer/Q1 Predictions Mean                 410.162
trainer/Q1 Predictions Std                   96.2781
trainer/Q1 Predictions Max                  486.995
trainer/Q1 Predictions Min                   21.6411
trainer/Q2 Predictions Mean                 409.791
trainer/Q2 Predictions Std                   96.2218
trainer/Q2 Predictions Max                  486.696
trainer/Q2 Predictions Min                   21.3509
trainer/Q Targets Mean                      409.915
trainer/Q Targets Std                        96.1119
trainer/Q Targets Max                       488.456
trainer/Q Targets Min                        21.152
trainer/Log Pis Mean                          6.05137
trainer/Log Pis Std                           4.44667
trainer/Log Pis Max                          15.3135
trainer/Log Pis Min                          -5.87781
trainer/policy/mean Mean                      0.086855
trainer/policy/mean Std                       0.775262
trainer/policy/mean Max                       0.998553
trainer/policy/mean Min                      -0.999617
trainer/policy/normal/std Mean                0.45153
trainer/policy/normal/std Std                 0.152535
trainer/policy/normal/std Max                 0.981208
trainer/policy/normal/std Min                 0.0676778
trainer/policy/normal/log_std Mean           -0.874378
trainer/policy/normal/log_std Std             0.445087
trainer/policy/normal/log_std Max            -0.018971
trainer/policy/normal/log_std Min            -2.693
trainer/Alpha                                 0.154539
trainer/Alpha Loss                            0.0959317
expl/num steps total                     433000
expl/num paths total                        433
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.92356
expl/Rewards Std                              1.24587
expl/Rewards Max                              8.33814
expl/Rewards Min                             -0.994566
expl/Returns Mean                          5923.56
expl/Returns Std                              0
expl/Returns Max                           5923.56
expl/Returns Min                           5923.56
expl/Actions Mean                             0.0978029
expl/Actions Std                              0.796983
expl/Actions Max                              0.999575
expl/Actions Min                             -0.999434
expl/Num Paths                                1
expl/Average Returns                       5923.56
expl/env_infos/final/reward_run Mean          7.8448
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.8448
expl/env_infos/final/reward_run Min           7.8448
expl/env_infos/initial/reward_run Mean       -0.749462
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.749462
expl/env_infos/initial/reward_run Min        -0.749462
expl/env_infos/reward_run Mean                6.3104
expl/env_infos/reward_run Std                 1.23376
expl/env_infos/reward_run Max                 8.87731
expl/env_infos/reward_run Min                -0.749462
expl/env_infos/final/reward_ctrl Mean        -0.408759
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.408759
expl/env_infos/final/reward_ctrl Min         -0.408759
expl/env_infos/initial/reward_ctrl Mean      -0.245104
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.245104
expl/env_infos/initial/reward_ctrl Min       -0.245104
expl/env_infos/reward_ctrl Mean              -0.386848
expl/env_infos/reward_ctrl Std                0.0924439
expl/env_infos/reward_ctrl Max               -0.0961504
expl/env_infos/reward_ctrl Min               -0.577774
eval/num steps total                          2.16e+06
eval/num paths total                       2160
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.38875
eval/Rewards Std                              1.3352
eval/Rewards Max                              8.87608
eval/Rewards Min                             -0.710314
eval/Returns Mean                          6388.75
eval/Returns Std                             57.797
eval/Returns Max                           6481.76
eval/Returns Min                           6306.33
eval/Actions Mean                             0.102032
eval/Actions Std                              0.821258
eval/Actions Max                              0.997051
eval/Actions Min                             -0.997507
eval/Num Paths                                5
eval/Average Returns                       6388.75
eval/env_infos/final/reward_run Mean          7.13361
eval/env_infos/final/reward_run Std           0.608789
eval/env_infos/final/reward_run Max           7.58996
eval/env_infos/final/reward_run Min           5.97398
eval/env_infos/initial/reward_run Mean       -0.282564
eval/env_infos/initial/reward_run Std         0.148438
eval/env_infos/initial/reward_run Max        -0.114353
eval/env_infos/initial/reward_run Min        -0.478472
eval/env_infos/reward_run Mean                6.79967
eval/env_infos/reward_run Std                 1.32577
eval/env_infos/reward_run Max                 9.34578
eval/env_infos/reward_run Min                -0.478472
eval/env_infos/final/reward_ctrl Mean        -0.401173
eval/env_infos/final/reward_ctrl Std          0.0631879
eval/env_infos/final/reward_ctrl Max         -0.313039
eval/env_infos/final/reward_ctrl Min         -0.475537
eval/env_infos/initial/reward_ctrl Mean      -0.227831
eval/env_infos/initial/reward_ctrl Std        0.0552318
eval/env_infos/initial/reward_ctrl Max       -0.158299
eval/env_infos/initial/reward_ctrl Min       -0.307819
eval/env_infos/reward_ctrl Mean              -0.410925
eval/env_infos/reward_ctrl Std                0.0872834
eval/env_infos/reward_ctrl Max               -0.0915795
eval/env_infos/reward_ctrl Min               -0.574492
time/data storing (s)                         0.00451925
time/evaluation sampling (s)                  2.06062
time/exploration sampling (s)                 0.535567
time/logging (s)                              0.0138364
time/sac training (s)                         7.39065
time/saving (s)                               0.00515218
time/training (s)                             3.4228e-05
time/epoch (s)                               10.0104
time/total (s)                             4548.84
Epoch                                       431
---------------------------------------  ---------------
2021-11-24 01:45:15.508439 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 432 finished
---------------------------------------  ----------------
epoch                                       432
replay_buffer/size                       434000
trainer/num train calls                  433000
trainer/QF1 Loss                              5.93764
trainer/QF2 Loss                              6.5907
trainer/Policy Loss                        -419.273
trainer/Q1 Predictions Mean                 420.242
trainer/Q1 Predictions Std                   79.7938
trainer/Q1 Predictions Max                  485.058
trainer/Q1 Predictions Min                   23.8627
trainer/Q2 Predictions Mean                 419.717
trainer/Q2 Predictions Std                   79.736
trainer/Q2 Predictions Max                  485.143
trainer/Q2 Predictions Min                   22.8663
trainer/Q Targets Mean                      419.971
trainer/Q Targets Std                        79.6702
trainer/Q Targets Max                       484.808
trainer/Q Targets Min                        22.828
trainer/Log Pis Mean                          6.05783
trainer/Log Pis Std                           4.32012
trainer/Log Pis Max                          15.6211
trainer/Log Pis Min                          -5.22525
trainer/policy/mean Mean                      0.0880872
trainer/policy/mean Std                       0.783262
trainer/policy/mean Max                       0.996485
trainer/policy/mean Min                      -0.993279
trainer/policy/normal/std Mean                0.440278
trainer/policy/normal/std Std                 0.139997
trainer/policy/normal/std Max                 1.00042
trainer/policy/normal/std Min                 0.073372
trainer/policy/normal/log_std Mean           -0.889812
trainer/policy/normal/log_std Std             0.413491
trainer/policy/normal/log_std Max             0.000420839
trainer/policy/normal/log_std Min            -2.61221
trainer/Alpha                                 0.153152
trainer/Alpha Loss                            0.108513
expl/num steps total                     434000
expl/num paths total                        434
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.03102
expl/Rewards Std                              1.31752
expl/Rewards Max                              8.34673
expl/Rewards Min                             -0.763499
expl/Returns Mean                          6031.02
expl/Returns Std                              0
expl/Returns Max                           6031.02
expl/Returns Min                           6031.02
expl/Actions Mean                             0.106348
expl/Actions Std                              0.806935
expl/Actions Max                              0.999234
expl/Actions Min                             -0.999765
expl/Num Paths                                1
expl/Average Returns                       6031.02
expl/env_infos/final/reward_run Mean          5.96241
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.96241
expl/env_infos/final/reward_run Min           5.96241
expl/env_infos/initial/reward_run Mean       -0.519099
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.519099
expl/env_infos/initial/reward_run Min        -0.519099
expl/env_infos/reward_run Mean                6.4285
expl/env_infos/reward_run Std                 1.30658
expl/env_infos/reward_run Max                 8.79298
expl/env_infos/reward_run Min                -0.519099
expl/env_infos/final/reward_ctrl Mean        -0.555891
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.555891
expl/env_infos/final/reward_ctrl Min         -0.555891
expl/env_infos/initial/reward_ctrl Mean      -0.244399
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.244399
expl/env_infos/initial/reward_ctrl Min       -0.244399
expl/env_infos/reward_ctrl Mean              -0.397472
expl/env_infos/reward_ctrl Std                0.091382
expl/env_infos/reward_ctrl Max               -0.116405
expl/env_infos/reward_ctrl Min               -0.577505
eval/num steps total                          2.165e+06
eval/num paths total                       2165
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.19358
eval/Rewards Std                              1.3045
eval/Rewards Max                              8.76126
eval/Rewards Min                             -0.81998
eval/Returns Mean                          6193.58
eval/Returns Std                             36.8294
eval/Returns Max                           6238.55
eval/Returns Min                           6127.05
eval/Actions Mean                             0.102206
eval/Actions Std                              0.818746
eval/Actions Max                              0.99908
eval/Actions Min                             -0.998365
eval/Num Paths                                5
eval/Average Returns                       6193.58
eval/env_infos/final/reward_run Mean          7.44161
eval/env_infos/final/reward_run Std           0.842814
eval/env_infos/final/reward_run Max           8.30679
eval/env_infos/final/reward_run Min           6.02627
eval/env_infos/initial/reward_run Mean       -0.37916
eval/env_infos/initial/reward_run Std         0.160831
eval/env_infos/initial/reward_run Max        -0.165767
eval/env_infos/initial/reward_run Min        -0.620999
eval/env_infos/reward_run Mean                6.60205
eval/env_infos/reward_run Std                 1.29349
eval/env_infos/reward_run Max                 9.31151
eval/env_infos/reward_run Min                -0.620999
eval/env_infos/final/reward_ctrl Mean        -0.393258
eval/env_infos/final/reward_ctrl Std          0.0682984
eval/env_infos/final/reward_ctrl Max         -0.307368
eval/env_infos/final/reward_ctrl Min         -0.503937
eval/env_infos/initial/reward_ctrl Mean      -0.230463
eval/env_infos/initial/reward_ctrl Std        0.0612168
eval/env_infos/initial/reward_ctrl Max       -0.125077
eval/env_infos/initial/reward_ctrl Min       -0.290956
eval/env_infos/reward_ctrl Mean              -0.408474
eval/env_infos/reward_ctrl Std                0.0897608
eval/env_infos/reward_ctrl Max               -0.102684
eval/env_infos/reward_ctrl Min               -0.578927
time/data storing (s)                         0.0044353
time/evaluation sampling (s)                  2.01633
time/exploration sampling (s)                 0.535924
time/logging (s)                              0.0138579
time/sac training (s)                         7.38861
time/saving (s)                               0.00378259
time/training (s)                             3.41421e-05
time/epoch (s)                                9.96298
time/total (s)                             4559.09
Epoch                                       432
---------------------------------------  ----------------
2021-11-24 01:45:25.767679 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 433 finished
---------------------------------------  ---------------
epoch                                       433
replay_buffer/size                       435000
trainer/num train calls                  434000
trainer/QF1 Loss                              7.1134
trainer/QF2 Loss                              7.29961
trainer/Policy Loss                        -398.954
trainer/Q1 Predictions Mean                 399.75
trainer/Q1 Predictions Std                  114.723
trainer/Q1 Predictions Max                  482.656
trainer/Q1 Predictions Min                   22.2959
trainer/Q2 Predictions Mean                 399.655
trainer/Q2 Predictions Std                  114.635
trainer/Q2 Predictions Max                  483.44
trainer/Q2 Predictions Min                   22.3611
trainer/Q Targets Mean                      400.023
trainer/Q Targets Std                       114.918
trainer/Q Targets Max                       483.533
trainer/Q Targets Min                        21.3573
trainer/Log Pis Mean                          6.12404
trainer/Log Pis Std                           4.33099
trainer/Log Pis Max                          19.3977
trainer/Log Pis Min                          -4.47254
trainer/policy/mean Mean                      0.0563893
trainer/policy/mean Std                       0.787481
trainer/policy/mean Max                       0.999304
trainer/policy/mean Min                      -0.995413
trainer/policy/normal/std Mean                0.462433
trainer/policy/normal/std Std                 0.151927
trainer/policy/normal/std Max                 1.08372
trainer/policy/normal/std Min                 0.0728429
trainer/policy/normal/log_std Mean           -0.84218
trainer/policy/normal/log_std Std             0.414964
trainer/policy/normal/log_std Max             0.0803965
trainer/policy/normal/log_std Min            -2.61945
trainer/Alpha                                 0.153216
trainer/Alpha Loss                            0.232685
expl/num steps total                     435000
expl/num paths total                        435
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.8326
expl/Rewards Std                              1.28859
expl/Rewards Max                              8.51382
expl/Rewards Min                             -0.593029
expl/Returns Mean                          5832.6
expl/Returns Std                              0
expl/Returns Max                           5832.6
expl/Returns Min                           5832.6
expl/Actions Mean                             0.104761
expl/Actions Std                              0.802834
expl/Actions Max                              0.999391
expl/Actions Min                             -0.999797
expl/Num Paths                                1
expl/Average Returns                       5832.6
expl/env_infos/final/reward_run Mean          5.5733
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.5733
expl/env_infos/final/reward_run Min           5.5733
expl/env_infos/initial/reward_run Mean       -0.42023
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.42023
expl/env_infos/initial/reward_run Min        -0.42023
expl/env_infos/reward_run Mean                6.22591
expl/env_infos/reward_run Std                 1.28134
expl/env_infos/reward_run Max                 8.84258
expl/env_infos/reward_run Min                -0.42023
expl/env_infos/final/reward_ctrl Mean        -0.454221
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.454221
expl/env_infos/final/reward_ctrl Min         -0.454221
expl/env_infos/initial/reward_ctrl Mean      -0.172799
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.172799
expl/env_infos/initial/reward_ctrl Min       -0.172799
expl/env_infos/reward_ctrl Mean              -0.393311
expl/env_infos/reward_ctrl Std                0.0877502
expl/env_infos/reward_ctrl Max               -0.113777
expl/env_infos/reward_ctrl Min               -0.578766
eval/num steps total                          2.17e+06
eval/num paths total                       2170
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.34289
eval/Rewards Std                              1.35573
eval/Rewards Max                              9.08256
eval/Rewards Min                             -0.847003
eval/Returns Mean                          6342.89
eval/Returns Std                             66.4699
eval/Returns Max                           6446.45
eval/Returns Min                           6269.99
eval/Actions Mean                             0.0951869
eval/Actions Std                              0.824269
eval/Actions Max                              0.999121
eval/Actions Min                             -0.998044
eval/Num Paths                                5
eval/Average Returns                       6342.89
eval/env_infos/final/reward_run Mean          7.68643
eval/env_infos/final/reward_run Std           0.90647
eval/env_infos/final/reward_run Max           8.55051
eval/env_infos/final/reward_run Min           6.14339
eval/env_infos/initial/reward_run Mean       -0.418015
eval/env_infos/initial/reward_run Std         0.150953
eval/env_infos/initial/reward_run Max        -0.200082
eval/env_infos/initial/reward_run Min        -0.635408
eval/env_infos/reward_run Mean                6.75597
eval/env_infos/reward_run Std                 1.34927
eval/env_infos/reward_run Max                 9.6068
eval/env_infos/reward_run Min                -0.635408
eval/env_infos/final/reward_ctrl Mean        -0.45164
eval/env_infos/final/reward_ctrl Std          0.0672089
eval/env_infos/final/reward_ctrl Max         -0.391419
eval/env_infos/final/reward_ctrl Min         -0.536523
eval/env_infos/initial/reward_ctrl Mean      -0.245343
eval/env_infos/initial/reward_ctrl Std        0.0374302
eval/env_infos/initial/reward_ctrl Max       -0.211596
eval/env_infos/initial/reward_ctrl Min       -0.314356
eval/env_infos/reward_ctrl Mean              -0.413088
eval/env_infos/reward_ctrl Std                0.0852926
eval/env_infos/reward_ctrl Max               -0.100686
eval/env_infos/reward_ctrl Min               -0.576542
time/data storing (s)                         0.00448563
time/evaluation sampling (s)                  2.00856
time/exploration sampling (s)                 0.534332
time/logging (s)                              0.0137758
time/sac training (s)                         7.39798
time/saving (s)                               0.00378334
time/training (s)                             3.459e-05
time/epoch (s)                                9.96295
time/total (s)                             4569.33
Epoch                                       433
---------------------------------------  ---------------
2021-11-24 01:45:36.008522 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 434 finished
---------------------------------------  ---------------
epoch                                       434
replay_buffer/size                       436000
trainer/num train calls                  435000
trainer/QF1 Loss                              5.18419
trainer/QF2 Loss                              4.91502
trainer/Policy Loss                        -419.293
trainer/Q1 Predictions Mean                 419.992
trainer/Q1 Predictions Std                   79.2704
trainer/Q1 Predictions Max                  484.516
trainer/Q1 Predictions Min                   23.687
trainer/Q2 Predictions Mean                 420
trainer/Q2 Predictions Std                   79.3639
trainer/Q2 Predictions Max                  484.398
trainer/Q2 Predictions Min                   23.8959
trainer/Q Targets Mean                      420.45
trainer/Q Targets Std                        79.4277
trainer/Q Targets Max                       485.25
trainer/Q Targets Min                        23.8682
trainer/Log Pis Mean                          6.31236
trainer/Log Pis Std                           4.16318
trainer/Log Pis Max                          16.9815
trainer/Log Pis Min                          -4.05815
trainer/policy/mean Mean                      0.0761292
trainer/policy/mean Std                       0.791209
trainer/policy/mean Max                       0.995898
trainer/policy/mean Min                      -0.997815
trainer/policy/normal/std Mean                0.440568
trainer/policy/normal/std Std                 0.143852
trainer/policy/normal/std Max                 1.15482
trainer/policy/normal/std Min                 0.0607893
trainer/policy/normal/log_std Mean           -0.892626
trainer/policy/normal/log_std Std             0.423405
trainer/policy/normal/log_std Max             0.143947
trainer/policy/normal/log_std Min            -2.80034
trainer/Alpha                                 0.151929
trainer/Alpha Loss                            0.588601
expl/num steps total                     436000
expl/num paths total                        436
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.01174
expl/Rewards Std                              1.26785
expl/Rewards Max                              8.38618
expl/Rewards Min                             -0.724926
expl/Returns Mean                          6011.74
expl/Returns Std                              0
expl/Returns Max                           6011.74
expl/Returns Min                           6011.74
expl/Actions Mean                             0.0813495
expl/Actions Std                              0.800289
expl/Actions Max                              0.999669
expl/Actions Min                             -0.998669
expl/Num Paths                                1
expl/Average Returns                       6011.74
expl/env_infos/final/reward_run Mean          7.43448
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.43448
expl/env_infos/final/reward_run Min           7.43448
expl/env_infos/initial/reward_run Mean       -0.474874
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.474874
expl/env_infos/initial/reward_run Min        -0.474874
expl/env_infos/reward_run Mean                6.39999
expl/env_infos/reward_run Std                 1.2618
expl/env_infos/reward_run Max                 8.81845
expl/env_infos/reward_run Min                -0.474874
expl/env_infos/final/reward_ctrl Mean        -0.394343
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.394343
expl/env_infos/final/reward_ctrl Min         -0.394343
expl/env_infos/initial/reward_ctrl Mean      -0.247161
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.247161
expl/env_infos/initial/reward_ctrl Min       -0.247161
expl/env_infos/reward_ctrl Mean              -0.388248
expl/env_infos/reward_ctrl Std                0.087484
expl/env_infos/reward_ctrl Max               -0.0876562
expl/env_infos/reward_ctrl Min               -0.573057
eval/num steps total                          2.175e+06
eval/num paths total                       2175
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.35247
eval/Rewards Std                              1.31354
eval/Rewards Max                              8.83563
eval/Rewards Min                             -0.882189
eval/Returns Mean                          6352.47
eval/Returns Std                             71.9285
eval/Returns Max                           6460.56
eval/Returns Min                           6270.97
eval/Actions Mean                             0.0793737
eval/Actions Std                              0.815616
eval/Actions Max                              0.995575
eval/Actions Min                             -0.997542
eval/Num Paths                                5
eval/Average Returns                       6352.47
eval/env_infos/final/reward_run Mean          6.91998
eval/env_infos/final/reward_run Std           0.906657
eval/env_infos/final/reward_run Max           7.89623
eval/env_infos/final/reward_run Min           5.48744
eval/env_infos/initial/reward_run Mean       -0.217084
eval/env_infos/initial/reward_run Std         0.379657
eval/env_infos/initial/reward_run Max         0.470991
eval/env_infos/initial/reward_run Min        -0.642359
eval/env_infos/reward_run Mean                6.75539
eval/env_infos/reward_run Std                 1.30336
eval/env_infos/reward_run Max                 9.29264
eval/env_infos/reward_run Min                -0.642359
eval/env_infos/final/reward_ctrl Mean        -0.448897
eval/env_infos/final/reward_ctrl Std          0.0356042
eval/env_infos/final/reward_ctrl Max         -0.398656
eval/env_infos/final/reward_ctrl Min         -0.504428
eval/env_infos/initial/reward_ctrl Mean      -0.218082
eval/env_infos/initial/reward_ctrl Std        0.0396154
eval/env_infos/initial/reward_ctrl Max       -0.14686
eval/env_infos/initial/reward_ctrl Min       -0.26398
eval/env_infos/reward_ctrl Mean              -0.402918
eval/env_infos/reward_ctrl Std                0.0851149
eval/env_infos/reward_ctrl Max               -0.100958
eval/env_infos/reward_ctrl Min               -0.578604
time/data storing (s)                         0.00447592
time/evaluation sampling (s)                  2.0121
time/exploration sampling (s)                 0.52228
time/logging (s)                              0.013887
time/sac training (s)                         7.39104
time/saving (s)                               0.00378296
time/training (s)                             3.4247e-05
time/epoch (s)                                9.9476
time/total (s)                             4579.56
Epoch                                       434
---------------------------------------  ---------------
2021-11-24 01:45:46.269012 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 435 finished
---------------------------------------  ---------------
epoch                                       435
replay_buffer/size                       437000
trainer/num train calls                  436000
trainer/QF1 Loss                              5.15501
trainer/QF2 Loss                              5.28099
trainer/Policy Loss                        -411.076
trainer/Q1 Predictions Mean                 411.795
trainer/Q1 Predictions Std                   96.525
trainer/Q1 Predictions Max                  482.291
trainer/Q1 Predictions Min                   21.5897
trainer/Q2 Predictions Mean                 411.874
trainer/Q2 Predictions Std                   96.6075
trainer/Q2 Predictions Max                  483.32
trainer/Q2 Predictions Min                   21.9928
trainer/Q Targets Mean                      411.564
trainer/Q Targets Std                        96.6633
trainer/Q Targets Max                       479.575
trainer/Q Targets Min                        21.8607
trainer/Log Pis Mean                          5.88403
trainer/Log Pis Std                           4.32528
trainer/Log Pis Max                          16.8282
trainer/Log Pis Min                          -5.56255
trainer/policy/mean Mean                      0.0757116
trainer/policy/mean Std                       0.781984
trainer/policy/mean Max                       0.996718
trainer/policy/mean Min                      -0.995873
trainer/policy/normal/std Mean                0.448376
trainer/policy/normal/std Std                 0.14926
trainer/policy/normal/std Max                 0.93619
trainer/policy/normal/std Min                 0.0710165
trainer/policy/normal/log_std Mean           -0.879035
trainer/policy/normal/log_std Std             0.437325
trainer/policy/normal/log_std Max            -0.0659371
trainer/policy/normal/log_std Min            -2.64484
trainer/Alpha                                 0.153887
trainer/Alpha Loss                           -0.217048
expl/num steps total                     437000
expl/num paths total                        437
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11038
expl/Rewards Std                              1.27432
expl/Rewards Max                              8.54383
expl/Rewards Min                             -0.953845
expl/Returns Mean                          6110.38
expl/Returns Std                              0
expl/Returns Max                           6110.38
expl/Returns Min                           6110.38
expl/Actions Mean                             0.0982736
expl/Actions Std                              0.800925
expl/Actions Max                              0.99962
expl/Actions Min                             -0.99925
expl/Num Paths                                1
expl/Average Returns                       6110.38
expl/env_infos/final/reward_run Mean          7.46377
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.46377
expl/env_infos/final/reward_run Min           7.46377
expl/env_infos/initial/reward_run Mean       -0.628574
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.628574
expl/env_infos/initial/reward_run Min        -0.628574
expl/env_infos/reward_run Mean                6.50107
expl/env_infos/reward_run Std                 1.27075
expl/env_infos/reward_run Max                 8.91287
expl/env_infos/reward_run Min                -0.628574
expl/env_infos/final/reward_ctrl Mean        -0.326972
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.326972
expl/env_infos/final/reward_ctrl Min         -0.326972
expl/env_infos/initial/reward_ctrl Mean      -0.325271
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.325271
expl/env_infos/initial/reward_ctrl Min       -0.325271
expl/env_infos/reward_ctrl Mean              -0.390683
expl/env_infos/reward_ctrl Std                0.0891156
expl/env_infos/reward_ctrl Max               -0.0683899
expl/env_infos/reward_ctrl Min               -0.577186
eval/num steps total                          2.18e+06
eval/num paths total                       2180
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.38696
eval/Rewards Std                              1.29492
eval/Rewards Max                              8.89575
eval/Rewards Min                             -0.771224
eval/Returns Mean                          6386.96
eval/Returns Std                             26.6893
eval/Returns Max                           6424.26
eval/Returns Min                           6346.06
eval/Actions Mean                             0.0981428
eval/Actions Std                              0.81838
eval/Actions Max                              0.99507
eval/Actions Min                             -0.997097
eval/Num Paths                                5
eval/Average Returns                       6386.96
eval/env_infos/final/reward_run Mean          7.2823
eval/env_infos/final/reward_run Std           0.615393
eval/env_infos/final/reward_run Max           8.36967
eval/env_infos/final/reward_run Min           6.64513
eval/env_infos/initial/reward_run Mean       -0.0135491
eval/env_infos/initial/reward_run Std         0.553585
eval/env_infos/initial/reward_run Max         1.06938
eval/env_infos/initial/reward_run Min        -0.44633
eval/env_infos/reward_run Mean                6.79459
eval/env_infos/reward_run Std                 1.29048
eval/env_infos/reward_run Max                 9.42884
eval/env_infos/reward_run Min                -0.44633
eval/env_infos/final/reward_ctrl Mean        -0.325444
eval/env_infos/final/reward_ctrl Std          0.0389968
eval/env_infos/final/reward_ctrl Max         -0.277575
eval/env_infos/final/reward_ctrl Min         -0.381262
eval/env_infos/initial/reward_ctrl Mean      -0.218441
eval/env_infos/initial/reward_ctrl Std        0.0572319
eval/env_infos/initial/reward_ctrl Max       -0.139461
eval/env_infos/initial/reward_ctrl Min       -0.28376
eval/env_infos/reward_ctrl Mean              -0.407626
eval/env_infos/reward_ctrl Std                0.0914857
eval/env_infos/reward_ctrl Max               -0.0619438
eval/env_infos/reward_ctrl Min               -0.575775
time/data storing (s)                         0.004493
time/evaluation sampling (s)                  2.00853
time/exploration sampling (s)                 0.534208
time/logging (s)                              0.0139004
time/sac training (s)                         7.39825
time/saving (s)                               0.00377675
time/training (s)                             3.4425e-05
time/epoch (s)                                9.96319
time/total (s)                             4589.8
Epoch                                       435
---------------------------------------  ---------------
2021-11-24 01:45:56.608809 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 436 finished
---------------------------------------  ---------------
epoch                                       436
replay_buffer/size                       438000
trainer/num train calls                  437000
trainer/QF1 Loss                              5.1327
trainer/QF2 Loss                              5.55167
trainer/Policy Loss                        -408.145
trainer/Q1 Predictions Mean                 408.86
trainer/Q1 Predictions Std                  105.224
trainer/Q1 Predictions Max                  485.834
trainer/Q1 Predictions Min                   21.0057
trainer/Q2 Predictions Mean                 408.954
trainer/Q2 Predictions Std                  105.314
trainer/Q2 Predictions Max                  483.553
trainer/Q2 Predictions Min                   21.3061
trainer/Q Targets Mean                      408.965
trainer/Q Targets Std                       105.22
trainer/Q Targets Max                       486.072
trainer/Q Targets Min                        21.7566
trainer/Log Pis Mean                          5.52774
trainer/Log Pis Std                           4.27337
trainer/Log Pis Max                          15.1278
trainer/Log Pis Min                          -4.32232
trainer/policy/mean Mean                      0.0827568
trainer/policy/mean Std                       0.763862
trainer/policy/mean Max                       0.995688
trainer/policy/mean Min                      -0.996909
trainer/policy/normal/std Mean                0.450589
trainer/policy/normal/std Std                 0.150665
trainer/policy/normal/std Max                 0.961347
trainer/policy/normal/std Min                 0.075353
trainer/policy/normal/log_std Mean           -0.872144
trainer/policy/normal/log_std Std             0.428003
trainer/policy/normal/log_std Max            -0.0394202
trainer/policy/normal/log_std Min            -2.58557
trainer/Alpha                                 0.155195
trainer/Alpha Loss                           -0.879858
expl/num steps total                     438000
expl/num paths total                        438
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.18898
expl/Rewards Std                              1.27117
expl/Rewards Max                              8.44501
expl/Rewards Min                             -0.639586
expl/Returns Mean                          6188.98
expl/Returns Std                              0
expl/Returns Max                           6188.98
expl/Returns Min                           6188.98
expl/Actions Mean                             0.103068
expl/Actions Std                              0.805882
expl/Actions Max                              0.999775
expl/Actions Min                             -0.999669
expl/Num Paths                                1
expl/Average Returns                       6188.98
expl/env_infos/final/reward_run Mean          6.343
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.343
expl/env_infos/final/reward_run Min           6.343
expl/env_infos/initial/reward_run Mean       -0.313889
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.313889
expl/env_infos/initial/reward_run Min        -0.313889
expl/env_infos/reward_run Mean                6.58502
expl/env_infos/reward_run Std                 1.26828
expl/env_infos/reward_run Max                 8.91836
expl/env_infos/reward_run Min                -0.313889
expl/env_infos/final/reward_ctrl Mean        -0.340797
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.340797
expl/env_infos/final/reward_ctrl Min         -0.340797
expl/env_infos/initial/reward_ctrl Mean      -0.325697
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.325697
expl/env_infos/initial/reward_ctrl Min       -0.325697
expl/env_infos/reward_ctrl Mean              -0.396042
expl/env_infos/reward_ctrl Std                0.0852608
expl/env_infos/reward_ctrl Max               -0.0614239
expl/env_infos/reward_ctrl Min               -0.577684
eval/num steps total                          2.185e+06
eval/num paths total                       2185
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.43412
eval/Rewards Std                              1.32152
eval/Rewards Max                              8.91718
eval/Rewards Min                             -1.08973
eval/Returns Mean                          6434.12
eval/Returns Std                             70.8308
eval/Returns Max                           6544.86
eval/Returns Min                           6329.61
eval/Actions Mean                             0.0979249
eval/Actions Std                              0.81944
eval/Actions Max                              0.998035
eval/Actions Min                             -0.997958
eval/Num Paths                                5
eval/Average Returns                       6434.12
eval/env_infos/final/reward_run Mean          8.09015
eval/env_infos/final/reward_run Std           0.334463
eval/env_infos/final/reward_run Max           8.58706
eval/env_infos/final/reward_run Min           7.70261
eval/env_infos/initial/reward_run Mean       -0.248852
eval/env_infos/initial/reward_run Std         0.571212
eval/env_infos/initial/reward_run Max         0.809144
eval/env_infos/initial/reward_run Min        -0.88135
eval/env_infos/reward_run Mean                6.84276
eval/env_infos/reward_run Std                 1.32145
eval/env_infos/reward_run Max                 9.40333
eval/env_infos/reward_run Min                -0.88135
eval/env_infos/final/reward_ctrl Mean        -0.421499
eval/env_infos/final/reward_ctrl Std          0.0748339
eval/env_infos/final/reward_ctrl Max         -0.289023
eval/env_infos/final/reward_ctrl Min         -0.507652
eval/env_infos/initial/reward_ctrl Mean      -0.209357
eval/env_infos/initial/reward_ctrl Std        0.0516819
eval/env_infos/initial/reward_ctrl Max       -0.13854
eval/env_infos/initial/reward_ctrl Min       -0.298167
eval/env_infos/reward_ctrl Mean              -0.408643
eval/env_infos/reward_ctrl Std                0.0824159
eval/env_infos/reward_ctrl Max               -0.0533746
eval/env_infos/reward_ctrl Min               -0.573672
time/data storing (s)                         0.00452318
time/evaluation sampling (s)                  2.00981
time/exploration sampling (s)                 0.53598
time/logging (s)                              0.013859
time/sac training (s)                         7.46775
time/saving (s)                               0.00379562
time/training (s)                             3.445e-05
time/epoch (s)                               10.0358
time/total (s)                             4600.13
Epoch                                       436
---------------------------------------  ---------------
2021-11-24 01:46:06.871024 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 437 finished
---------------------------------------  ---------------
epoch                                       437
replay_buffer/size                       439000
trainer/num train calls                  438000
trainer/QF1 Loss                              5.95933
trainer/QF2 Loss                              6.07282
trainer/Policy Loss                        -412.005
trainer/Q1 Predictions Mean                 413.15
trainer/Q1 Predictions Std                  105.201
trainer/Q1 Predictions Max                  488.576
trainer/Q1 Predictions Min                   23.8153
trainer/Q2 Predictions Mean                 412.941
trainer/Q2 Predictions Std                  105.111
trainer/Q2 Predictions Max                  487.416
trainer/Q2 Predictions Min                   22.7033
trainer/Q Targets Mean                      413.187
trainer/Q Targets Std                       105.144
trainer/Q Targets Max                       487.99
trainer/Q Targets Min                        22.0672
trainer/Log Pis Mean                          6.37266
trainer/Log Pis Std                           4.59927
trainer/Log Pis Max                          18.1248
trainer/Log Pis Min                          -4.59558
trainer/policy/mean Mean                      0.0868967
trainer/policy/mean Std                       0.790272
trainer/policy/mean Max                       0.992331
trainer/policy/mean Min                      -0.997588
trainer/policy/normal/std Mean                0.457078
trainer/policy/normal/std Std                 0.145977
trainer/policy/normal/std Max                 0.934481
trainer/policy/normal/std Min                 0.0720624
trainer/policy/normal/log_std Mean           -0.852336
trainer/policy/normal/log_std Std             0.413875
trainer/policy/normal/log_std Max            -0.0677645
trainer/policy/normal/log_std Min            -2.63022
trainer/Alpha                                 0.154801
trainer/Alpha Loss                            0.695239
expl/num steps total                     439000
expl/num paths total                        439
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.84566
expl/Rewards Std                              1.2203
expl/Rewards Max                              8.23246
expl/Rewards Min                             -0.641849
expl/Returns Mean                          5845.66
expl/Returns Std                              0
expl/Returns Max                           5845.66
expl/Returns Min                           5845.66
expl/Actions Mean                             0.109889
expl/Actions Std                              0.796816
expl/Actions Max                              0.999518
expl/Actions Min                             -0.999198
expl/Num Paths                                1
expl/Average Returns                       5845.66
expl/env_infos/final/reward_run Mean          6.67222
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.67222
expl/env_infos/final/reward_run Min           6.67222
expl/env_infos/initial/reward_run Mean       -0.397043
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.397043
expl/env_infos/initial/reward_run Min        -0.397043
expl/env_infos/reward_run Mean                6.23386
expl/env_infos/reward_run Std                 1.20989
expl/env_infos/reward_run Max                 8.70204
expl/env_infos/reward_run Min                -0.397043
expl/env_infos/final/reward_ctrl Mean        -0.220793
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.220793
expl/env_infos/final/reward_ctrl Min         -0.220793
expl/env_infos/initial/reward_ctrl Mean      -0.244806
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.244806
expl/env_infos/initial/reward_ctrl Min       -0.244806
expl/env_infos/reward_ctrl Mean              -0.388195
expl/env_infos/reward_ctrl Std                0.0934012
expl/env_infos/reward_ctrl Max               -0.0188769
expl/env_infos/reward_ctrl Min               -0.577611
eval/num steps total                          2.19e+06
eval/num paths total                       2190
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.31783
eval/Rewards Std                              1.30531
eval/Rewards Max                              8.89692
eval/Rewards Min                             -0.646029
eval/Returns Mean                          6317.83
eval/Returns Std                             83.515
eval/Returns Max                           6434.91
eval/Returns Min                           6181.32
eval/Actions Mean                             0.101354
eval/Actions Std                              0.819533
eval/Actions Max                              0.995534
eval/Actions Min                             -0.998502
eval/Num Paths                                5
eval/Average Returns                       6317.83
eval/env_infos/final/reward_run Mean          7.61471
eval/env_infos/final/reward_run Std           0.401511
eval/env_infos/final/reward_run Max           8.10199
eval/env_infos/final/reward_run Min           7.05644
eval/env_infos/initial/reward_run Mean       -0.329016
eval/env_infos/initial/reward_run Std         0.113562
eval/env_infos/initial/reward_run Max        -0.130327
eval/env_infos/initial/reward_run Min        -0.477786
eval/env_infos/reward_run Mean                6.72698
eval/env_infos/reward_run Std                 1.29434
eval/env_infos/reward_run Max                 9.3442
eval/env_infos/reward_run Min                -0.477786
eval/env_infos/final/reward_ctrl Mean        -0.435951
eval/env_infos/final/reward_ctrl Std          0.10624
eval/env_infos/final/reward_ctrl Max         -0.242172
eval/env_infos/final/reward_ctrl Min         -0.522459
eval/env_infos/initial/reward_ctrl Mean      -0.205674
eval/env_infos/initial/reward_ctrl Std        0.0697507
eval/env_infos/initial/reward_ctrl Max       -0.126547
eval/env_infos/initial/reward_ctrl Min       -0.305837
eval/env_infos/reward_ctrl Mean              -0.409144
eval/env_infos/reward_ctrl Std                0.0915351
eval/env_infos/reward_ctrl Max               -0.0328308
eval/env_infos/reward_ctrl Min               -0.580814
time/data storing (s)                         0.00450729
time/evaluation sampling (s)                  1.99531
time/exploration sampling (s)                 0.532182
time/logging (s)                              0.0137521
time/sac training (s)                         7.41628
time/saving (s)                               0.00376182
time/training (s)                             3.4107e-05
time/epoch (s)                                9.96583
time/total (s)                             4610.38
Epoch                                       437
---------------------------------------  ---------------
2021-11-24 01:46:17.136115 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 438 finished
---------------------------------------  ---------------
epoch                                       438
replay_buffer/size                       440000
trainer/num train calls                  439000
trainer/QF1 Loss                              5.02336
trainer/QF2 Loss                              6.3499
trainer/Policy Loss                        -415.748
trainer/Q1 Predictions Mean                 416.424
trainer/Q1 Predictions Std                   90.5123
trainer/Q1 Predictions Max                  485.991
trainer/Q1 Predictions Min                   23.8849
trainer/Q2 Predictions Mean                 416.433
trainer/Q2 Predictions Std                   90.3731
trainer/Q2 Predictions Max                  484.347
trainer/Q2 Predictions Min                   21.5123
trainer/Q Targets Mean                      416.212
trainer/Q Targets Std                        90.5201
trainer/Q Targets Max                       483.104
trainer/Q Targets Min                        20.8487
trainer/Log Pis Mean                          5.87843
trainer/Log Pis Std                           4.14218
trainer/Log Pis Max                          15.6484
trainer/Log Pis Min                          -5.00436
trainer/policy/mean Mean                      0.0673077
trainer/policy/mean Std                       0.778211
trainer/policy/mean Max                       0.99733
trainer/policy/mean Min                      -0.991748
trainer/policy/normal/std Mean                0.442525
trainer/policy/normal/std Std                 0.150149
trainer/policy/normal/std Max                 1.03715
trainer/policy/normal/std Min                 0.0746469
trainer/policy/normal/log_std Mean           -0.893922
trainer/policy/normal/log_std Std             0.440556
trainer/policy/normal/log_std Max             0.0364781
trainer/policy/normal/log_std Min            -2.59499
trainer/Alpha                                 0.155295
trainer/Alpha Loss                           -0.226407
expl/num steps total                     440000
expl/num paths total                        440
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.94958
expl/Rewards Std                              1.27885
expl/Rewards Max                              8.71235
expl/Rewards Min                             -0.596598
expl/Returns Mean                          5949.58
expl/Returns Std                              0
expl/Returns Max                           5949.58
expl/Returns Min                           5949.58
expl/Actions Mean                             0.0875081
expl/Actions Std                              0.796894
expl/Actions Max                              0.999844
expl/Actions Min                             -0.999101
expl/Num Paths                                1
expl/Average Returns                       5949.58
expl/env_infos/final/reward_run Mean          6.61051
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.61051
expl/env_infos/final/reward_run Min           6.61051
expl/env_infos/initial/reward_run Mean       -0.146077
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.146077
expl/env_infos/initial/reward_run Min        -0.146077
expl/env_infos/reward_run Mean                6.3352
expl/env_infos/reward_run Std                 1.26853
expl/env_infos/reward_run Max                 9.08175
expl/env_infos/reward_run Min                -0.146077
expl/env_infos/final/reward_ctrl Mean        -0.348701
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.348701
expl/env_infos/final/reward_ctrl Min         -0.348701
expl/env_infos/initial/reward_ctrl Mean      -0.280159
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.280159
expl/env_infos/initial/reward_ctrl Min       -0.280159
expl/env_infos/reward_ctrl Mean              -0.385619
expl/env_infos/reward_ctrl Std                0.0861288
expl/env_infos/reward_ctrl Max               -0.10765
expl/env_infos/reward_ctrl Min               -0.562157
eval/num steps total                          2.195e+06
eval/num paths total                       2195
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.48776
eval/Rewards Std                              1.36906
eval/Rewards Max                              9.11827
eval/Rewards Min                             -0.850246
eval/Returns Mean                          6487.76
eval/Returns Std                             57.3136
eval/Returns Max                           6572.16
eval/Returns Min                           6424.72
eval/Actions Mean                             0.0836704
eval/Actions Std                              0.819875
eval/Actions Max                              0.9969
eval/Actions Min                             -0.996942
eval/Num Paths                                5
eval/Average Returns                       6487.76
eval/env_infos/final/reward_run Mean          7.69318
eval/env_infos/final/reward_run Std           0.825454
eval/env_infos/final/reward_run Max           8.72111
eval/env_infos/final/reward_run Min           6.55882
eval/env_infos/initial/reward_run Mean       -0.325406
eval/env_infos/initial/reward_run Std         0.239305
eval/env_infos/initial/reward_run Max         0.0792933
eval/env_infos/initial/reward_run Min        -0.656414
eval/env_infos/reward_run Mean                6.89528
eval/env_infos/reward_run Std                 1.36588
eval/env_infos/reward_run Max                 9.53937
eval/env_infos/reward_run Min                -0.656414
eval/env_infos/final/reward_ctrl Mean        -0.377604
eval/env_infos/final/reward_ctrl Std          0.0857405
eval/env_infos/final/reward_ctrl Max         -0.260891
eval/env_infos/final/reward_ctrl Min         -0.516722
eval/env_infos/initial/reward_ctrl Mean      -0.191089
eval/env_infos/initial/reward_ctrl Std        0.0414084
eval/env_infos/initial/reward_ctrl Max       -0.144182
eval/env_infos/initial/reward_ctrl Min       -0.265265
eval/env_infos/reward_ctrl Mean              -0.407517
eval/env_infos/reward_ctrl Std                0.083972
eval/env_infos/reward_ctrl Max               -0.0776936
eval/env_infos/reward_ctrl Min               -0.575241
time/data storing (s)                         0.0045223
time/evaluation sampling (s)                  1.99094
time/exploration sampling (s)                 0.53959
time/logging (s)                              0.0136878
time/sac training (s)                         7.4143
time/saving (s)                               0.00510247
time/training (s)                             3.4142e-05
time/epoch (s)                                9.96817
time/total (s)                             4620.63
Epoch                                       438
---------------------------------------  ---------------
2021-11-24 01:46:27.412203 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 439 finished
---------------------------------------  ---------------
epoch                                       439
replay_buffer/size                       441000
trainer/num train calls                  440000
trainer/QF1 Loss                              7.75976
trainer/QF2 Loss                              6.99535
trainer/Policy Loss                        -406.881
trainer/Q1 Predictions Mean                 407.188
trainer/Q1 Predictions Std                  102.263
trainer/Q1 Predictions Max                  487.202
trainer/Q1 Predictions Min                   23.3096
trainer/Q2 Predictions Mean                 407.634
trainer/Q2 Predictions Std                  102.037
trainer/Q2 Predictions Max                  488.222
trainer/Q2 Predictions Min                   24.1396
trainer/Q Targets Mean                      406.813
trainer/Q Targets Std                       101.707
trainer/Q Targets Max                       485.189
trainer/Q Targets Min                        23.3451
trainer/Log Pis Mean                          5.99562
trainer/Log Pis Std                           4.32148
trainer/Log Pis Max                          25.4334
trainer/Log Pis Min                          -5.71016
trainer/policy/mean Mean                      0.0950945
trainer/policy/mean Std                       0.773672
trainer/policy/mean Max                       0.999859
trainer/policy/mean Min                      -0.995854
trainer/policy/normal/std Mean                0.445272
trainer/policy/normal/std Std                 0.150756
trainer/policy/normal/std Max                 1.35896
trainer/policy/normal/std Min                 0.0737262
trainer/policy/normal/log_std Mean           -0.885745
trainer/policy/normal/log_std Std             0.433277
trainer/policy/normal/log_std Max             0.306723
trainer/policy/normal/log_std Min            -2.6074
trainer/Alpha                                 0.154081
trainer/Alpha Loss                           -0.00819826
expl/num steps total                     441000
expl/num paths total                        441
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.01804
expl/Rewards Std                              1.25052
expl/Rewards Max                              8.39698
expl/Rewards Min                             -0.370932
expl/Returns Mean                          6018.04
expl/Returns Std                              0
expl/Returns Max                           6018.04
expl/Returns Min                           6018.04
expl/Actions Mean                             0.114416
expl/Actions Std                              0.799336
expl/Actions Max                              0.999383
expl/Actions Min                             -0.999085
expl/Num Paths                                1
expl/Average Returns                       6018.04
expl/env_infos/final/reward_run Mean          5.72907
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.72907
expl/env_infos/final/reward_run Min           5.72907
expl/env_infos/initial/reward_run Mean        0.0694654
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0694654
expl/env_infos/initial/reward_run Min         0.0694654
expl/env_infos/reward_run Mean                6.40925
expl/env_infos/reward_run Std                 1.2443
expl/env_infos/reward_run Max                 8.80882
expl/env_infos/reward_run Min                 0.0694654
expl/env_infos/final/reward_ctrl Mean        -0.533066
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.533066
expl/env_infos/final/reward_ctrl Min         -0.533066
expl/env_infos/initial/reward_ctrl Mean      -0.162985
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.162985
expl/env_infos/initial/reward_ctrl Min       -0.162985
expl/env_infos/reward_ctrl Mean              -0.391218
expl/env_infos/reward_ctrl Std                0.0878752
expl/env_infos/reward_ctrl Max               -0.100276
expl/env_infos/reward_ctrl Min               -0.56737
eval/num steps total                          2.2e+06
eval/num paths total                       2200
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.34057
eval/Rewards Std                              1.32946
eval/Rewards Max                              8.88427
eval/Rewards Min                             -0.616697
eval/Returns Mean                          6340.57
eval/Returns Std                            142.432
eval/Returns Max                           6476.31
eval/Returns Min                           6084.92
eval/Actions Mean                             0.107276
eval/Actions Std                              0.818647
eval/Actions Max                              0.998382
eval/Actions Min                             -0.997871
eval/Num Paths                                5
eval/Average Returns                       6340.57
eval/env_infos/final/reward_run Mean          7.01488
eval/env_infos/final/reward_run Std           0.873077
eval/env_infos/final/reward_run Max           8.45396
eval/env_infos/final/reward_run Min           6.16897
eval/env_infos/initial/reward_run Mean       -0.197274
eval/env_infos/initial/reward_run Std         0.201493
eval/env_infos/initial/reward_run Max         0.174333
eval/env_infos/initial/reward_run Min        -0.373371
eval/env_infos/reward_run Mean                6.74958
eval/env_infos/reward_run Std                 1.32484
eval/env_infos/reward_run Max                 9.32082
eval/env_infos/reward_run Min                -0.373371
eval/env_infos/final/reward_ctrl Mean        -0.446218
eval/env_infos/final/reward_ctrl Std          0.0507982
eval/env_infos/final/reward_ctrl Max         -0.375546
eval/env_infos/final/reward_ctrl Min         -0.519425
eval/env_infos/initial/reward_ctrl Mean      -0.196679
eval/env_infos/initial/reward_ctrl Std        0.0539381
eval/env_infos/initial/reward_ctrl Max       -0.126551
eval/env_infos/initial/reward_ctrl Min       -0.269628
eval/env_infos/reward_ctrl Mean              -0.409015
eval/env_infos/reward_ctrl Std                0.0825989
eval/env_infos/reward_ctrl Max               -0.0547332
eval/env_infos/reward_ctrl Min               -0.573194
time/data storing (s)                         0.00445718
time/evaluation sampling (s)                  2.01548
time/exploration sampling (s)                 0.532671
time/logging (s)                              0.0138823
time/sac training (s)                         7.41065
time/saving (s)                               0.00376832
time/training (s)                             3.5186e-05
time/epoch (s)                                9.98094
time/total (s)                             4630.89
Epoch                                       439
---------------------------------------  ---------------
2021-11-24 01:46:37.670543 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 440 finished
---------------------------------------  ---------------
epoch                                       440
replay_buffer/size                       442000
trainer/num train calls                  441000
trainer/QF1 Loss                              5.7816
trainer/QF2 Loss                              7.04433
trainer/Policy Loss                        -407.157
trainer/Q1 Predictions Mean                 408.028
trainer/Q1 Predictions Std                  100.757
trainer/Q1 Predictions Max                  484.769
trainer/Q1 Predictions Min                   20.6181
trainer/Q2 Predictions Mean                 407.607
trainer/Q2 Predictions Std                  100.799
trainer/Q2 Predictions Max                  483.865
trainer/Q2 Predictions Min                   20.5338
trainer/Q Targets Mean                      408.404
trainer/Q Targets Std                       100.903
trainer/Q Targets Max                       486.419
trainer/Q Targets Min                        21.4173
trainer/Log Pis Mean                          6.06433
trainer/Log Pis Std                           4.38357
trainer/Log Pis Max                          17.9937
trainer/Log Pis Min                          -4.65619
trainer/policy/mean Mean                      0.0919554
trainer/policy/mean Std                       0.776099
trainer/policy/mean Max                       0.997919
trainer/policy/mean Min                      -0.9982
trainer/policy/normal/std Mean                0.45101
trainer/policy/normal/std Std                 0.147098
trainer/policy/normal/std Max                 0.967575
trainer/policy/normal/std Min                 0.0673839
trainer/policy/normal/log_std Mean           -0.869793
trainer/policy/normal/log_std Std             0.427875
trainer/policy/normal/log_std Max            -0.0329627
trainer/policy/normal/log_std Min            -2.69735
trainer/Alpha                                 0.155778
trainer/Alpha Loss                            0.119616
expl/num steps total                     442000
expl/num paths total                        442
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.15929
expl/Rewards Std                              1.26778
expl/Rewards Max                              8.55613
expl/Rewards Min                             -0.56305
expl/Returns Mean                          6159.29
expl/Returns Std                              0
expl/Returns Max                           6159.29
expl/Returns Min                           6159.29
expl/Actions Mean                             0.118802
expl/Actions Std                              0.801957
expl/Actions Max                              0.999666
expl/Actions Min                             -0.999224
expl/Num Paths                                1
expl/Average Returns                       6159.29
expl/env_infos/final/reward_run Mean          7.67762
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.67762
expl/env_infos/final/reward_run Min           7.67762
expl/env_infos/initial/reward_run Mean       -0.290359
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.290359
expl/env_infos/initial/reward_run Min        -0.290359
expl/env_infos/reward_run Mean                6.55364
expl/env_infos/reward_run Std                 1.2639
expl/env_infos/reward_run Max                 9.03809
expl/env_infos/reward_run Min                -0.290359
expl/env_infos/final/reward_ctrl Mean        -0.419427
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.419427
expl/env_infos/final/reward_ctrl Min         -0.419427
expl/env_infos/initial/reward_ctrl Mean      -0.272691
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.272691
expl/env_infos/initial/reward_ctrl Min       -0.272691
expl/env_infos/reward_ctrl Mean              -0.394349
expl/env_infos/reward_ctrl Std                0.0847606
expl/env_infos/reward_ctrl Max               -0.134647
expl/env_infos/reward_ctrl Min               -0.56995
eval/num steps total                          2.205e+06
eval/num paths total                       2205
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.3742
eval/Rewards Std                              1.35305
eval/Rewards Max                              8.81228
eval/Rewards Min                             -1.0278
eval/Returns Mean                          6374.2
eval/Returns Std                             53.9855
eval/Returns Max                           6441.52
eval/Returns Min                           6284.04
eval/Actions Mean                             0.109161
eval/Actions Std                              0.81308
eval/Actions Max                              0.996105
eval/Actions Min                             -0.995527
eval/Num Paths                                5
eval/Average Returns                       6374.2
eval/env_infos/final/reward_run Mean          6.40241
eval/env_infos/final/reward_run Std           0.603706
eval/env_infos/final/reward_run Max           7.14855
eval/env_infos/final/reward_run Min           5.74333
eval/env_infos/initial/reward_run Mean       -0.0849367
eval/env_infos/initial/reward_run Std         0.381759
eval/env_infos/initial/reward_run Max         0.651033
eval/env_infos/initial/reward_run Min        -0.383202
eval/env_infos/reward_run Mean                6.77801
eval/env_infos/reward_run Std                 1.35055
eval/env_infos/reward_run Max                 9.36038
eval/env_infos/reward_run Min                -0.596322
eval/env_infos/final/reward_ctrl Mean        -0.446033
eval/env_infos/final/reward_ctrl Std          0.038385
eval/env_infos/final/reward_ctrl Max         -0.409842
eval/env_infos/final/reward_ctrl Min         -0.515895
eval/env_infos/initial/reward_ctrl Mean      -0.229041
eval/env_infos/initial/reward_ctrl Std        0.043815
eval/env_infos/initial/reward_ctrl Max       -0.168462
eval/env_infos/initial/reward_ctrl Min       -0.279974
eval/env_infos/reward_ctrl Mean              -0.403809
eval/env_infos/reward_ctrl Std                0.0807904
eval/env_infos/reward_ctrl Max               -0.0759494
eval/env_infos/reward_ctrl Min               -0.57499
time/data storing (s)                         0.00451511
time/evaluation sampling (s)                  1.99577
time/exploration sampling (s)                 0.53529
time/logging (s)                              0.0138429
time/sac training (s)                         7.40901
time/saving (s)                               0.00374124
time/training (s)                             3.4802e-05
time/epoch (s)                                9.9622
time/total (s)                             4641.13
Epoch                                       440
---------------------------------------  ---------------
2021-11-24 01:46:48.292018 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 441 finished
---------------------------------------  ---------------
epoch                                       441
replay_buffer/size                       443000
trainer/num train calls                  442000
trainer/QF1 Loss                              6.02075
trainer/QF2 Loss                              6.7952
trainer/Policy Loss                        -415.271
trainer/Q1 Predictions Mean                 415.714
trainer/Q1 Predictions Std                   93.2297
trainer/Q1 Predictions Max                  480.874
trainer/Q1 Predictions Min                   22.4501
trainer/Q2 Predictions Mean                 416.247
trainer/Q2 Predictions Std                   93.2501
trainer/Q2 Predictions Max                  482.277
trainer/Q2 Predictions Min                   22.6263
trainer/Q Targets Mean                      416.168
trainer/Q Targets Std                        93.2205
trainer/Q Targets Max                       483.584
trainer/Q Targets Min                        23.929
trainer/Log Pis Mean                          5.62049
trainer/Log Pis Std                           4.09837
trainer/Log Pis Max                          15.2304
trainer/Log Pis Min                          -6.29268
trainer/policy/mean Mean                      0.077176
trainer/policy/mean Std                       0.76181
trainer/policy/mean Max                       0.993565
trainer/policy/mean Min                      -0.996511
trainer/policy/normal/std Mean                0.433167
trainer/policy/normal/std Std                 0.152693
trainer/policy/normal/std Max                 0.915262
trainer/policy/normal/std Min                 0.066434
trainer/policy/normal/log_std Mean           -0.924245
trainer/policy/normal/log_std Std             0.468701
trainer/policy/normal/log_std Max            -0.0885449
trainer/policy/normal/log_std Min            -2.71155
trainer/Alpha                                 0.153769
trainer/Alpha Loss                           -0.710563
expl/num steps total                     443000
expl/num paths total                        443
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.95503
expl/Rewards Std                              1.27311
expl/Rewards Max                              8.54248
expl/Rewards Min                             -0.560659
expl/Returns Mean                          5955.03
expl/Returns Std                              0
expl/Returns Max                           5955.03
expl/Returns Min                           5955.03
expl/Actions Mean                             0.0852636
expl/Actions Std                              0.794322
expl/Actions Max                              0.999332
expl/Actions Min                             -0.999428
expl/Num Paths                                1
expl/Average Returns                       5955.03
expl/env_infos/final/reward_run Mean          5.86163
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.86163
expl/env_infos/final/reward_run Min           5.86163
expl/env_infos/initial/reward_run Mean       -0.248526
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.248526
expl/env_infos/initial/reward_run Min        -0.248526
expl/env_infos/reward_run Mean                6.33796
expl/env_infos/reward_run Std                 1.26542
expl/env_infos/reward_run Max                 9.0086
expl/env_infos/reward_run Min                -0.248526
expl/env_infos/final/reward_ctrl Mean        -0.52088
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.52088
expl/env_infos/final/reward_ctrl Min         -0.52088
expl/env_infos/initial/reward_ctrl Mean      -0.194546
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.194546
expl/env_infos/initial/reward_ctrl Min       -0.194546
expl/env_infos/reward_ctrl Mean              -0.382931
expl/env_infos/reward_ctrl Std                0.0870935
expl/env_infos/reward_ctrl Max               -0.039694
expl/env_infos/reward_ctrl Min               -0.567794
eval/num steps total                          2.21e+06
eval/num paths total                       2210
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.39572
eval/Rewards Std                              1.3483
eval/Rewards Max                              8.96963
eval/Rewards Min                             -0.892887
eval/Returns Mean                          6395.72
eval/Returns Std                             87.429
eval/Returns Max                           6483.24
eval/Returns Min                           6269.16
eval/Actions Mean                             0.0828947
eval/Actions Std                              0.817127
eval/Actions Max                              0.995098
eval/Actions Min                             -0.99819
eval/Num Paths                                5
eval/Average Returns                       6395.72
eval/env_infos/final/reward_run Mean          7.19851
eval/env_infos/final/reward_run Std           0.401046
eval/env_infos/final/reward_run Max           7.90744
eval/env_infos/final/reward_run Min           6.66964
eval/env_infos/initial/reward_run Mean       -0.401084
eval/env_infos/initial/reward_run Std         0.0995663
eval/env_infos/initial/reward_run Max        -0.254351
eval/env_infos/initial/reward_run Min        -0.520779
eval/env_infos/reward_run Mean                6.80046
eval/env_infos/reward_run Std                 1.34441
eval/env_infos/reward_run Max                 9.45763
eval/env_infos/reward_run Min                -0.630296
eval/env_infos/final/reward_ctrl Mean        -0.40054
eval/env_infos/final/reward_ctrl Std          0.068814
eval/env_infos/final/reward_ctrl Max         -0.279499
eval/env_infos/final/reward_ctrl Min         -0.491612
eval/env_infos/initial/reward_ctrl Mean      -0.186401
eval/env_infos/initial/reward_ctrl Std        0.0620149
eval/env_infos/initial/reward_ctrl Max       -0.109835
eval/env_infos/initial/reward_ctrl Min       -0.283213
eval/env_infos/reward_ctrl Mean              -0.404741
eval/env_infos/reward_ctrl Std                0.0847106
eval/env_infos/reward_ctrl Max               -0.0497167
eval/env_infos/reward_ctrl Min               -0.57314
time/data storing (s)                         0.00450707
time/evaluation sampling (s)                  1.99321
time/exploration sampling (s)                 0.533544
time/logging (s)                              0.0150655
time/sac training (s)                         7.73413
time/saving (s)                               0.00378375
time/training (s)                             3.5019e-05
time/epoch (s)                               10.2843
time/total (s)                             4651.74
Epoch                                       441
---------------------------------------  ---------------
2021-11-24 01:46:58.615296 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 442 finished
---------------------------------------  ---------------
epoch                                       442
replay_buffer/size                       444000
trainer/num train calls                  443000
trainer/QF1 Loss                              5.86302
trainer/QF2 Loss                              5.72825
trainer/Policy Loss                        -415.025
trainer/Q1 Predictions Mean                 415.95
trainer/Q1 Predictions Std                   96.4951
trainer/Q1 Predictions Max                  482.66
trainer/Q1 Predictions Min                   22.4679
trainer/Q2 Predictions Mean                 415.881
trainer/Q2 Predictions Std                   96.3839
trainer/Q2 Predictions Max                  484.222
trainer/Q2 Predictions Min                   22.4524
trainer/Q Targets Mean                      416.575
trainer/Q Targets Std                        96.6512
trainer/Q Targets Max                       485.521
trainer/Q Targets Min                        22.2128
trainer/Log Pis Mean                          5.8921
trainer/Log Pis Std                           4.04105
trainer/Log Pis Max                          14.6853
trainer/Log Pis Min                          -5.89054
trainer/policy/mean Mean                      0.109748
trainer/policy/mean Std                       0.772698
trainer/policy/mean Max                       0.996964
trainer/policy/mean Min                      -0.992655
trainer/policy/normal/std Mean                0.4464
trainer/policy/normal/std Std                 0.146
trainer/policy/normal/std Max                 0.886437
trainer/policy/normal/std Min                 0.0669257
trainer/policy/normal/log_std Mean           -0.881751
trainer/policy/normal/log_std Std             0.434206
trainer/policy/normal/log_std Max            -0.120545
trainer/policy/normal/log_std Min            -2.70417
trainer/Alpha                                 0.155138
trainer/Alpha Loss                           -0.201073
expl/num steps total                     444000
expl/num paths total                        444
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.69933
expl/Rewards Std                              1.20978
expl/Rewards Max                              8.22451
expl/Rewards Min                             -0.563144
expl/Returns Mean                          5699.33
expl/Returns Std                              0
expl/Returns Max                           5699.33
expl/Returns Min                           5699.33
expl/Actions Mean                             0.113018
expl/Actions Std                              0.792914
expl/Actions Max                              0.999313
expl/Actions Min                             -0.999898
expl/Num Paths                                1
expl/Average Returns                       5699.33
expl/env_infos/final/reward_run Mean          6.66907
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.66907
expl/env_infos/final/reward_run Min           6.66907
expl/env_infos/initial/reward_run Mean       -0.34903
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.34903
expl/env_infos/initial/reward_run Min        -0.34903
expl/env_infos/reward_run Mean                6.08422
expl/env_infos/reward_run Std                 1.19953
expl/env_infos/reward_run Max                 8.77884
expl/env_infos/reward_run Min                -0.34903
expl/env_infos/final/reward_ctrl Mean        -0.355608
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.355608
expl/env_infos/final/reward_ctrl Min         -0.355608
expl/env_infos/initial/reward_ctrl Mean      -0.214114
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.214114
expl/env_infos/initial/reward_ctrl Min       -0.214114
expl/env_infos/reward_ctrl Mean              -0.384891
expl/env_infos/reward_ctrl Std                0.087522
expl/env_infos/reward_ctrl Max               -0.10409
expl/env_infos/reward_ctrl Min               -0.56417
eval/num steps total                          2.215e+06
eval/num paths total                       2215
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.30331
eval/Rewards Std                              1.33489
eval/Rewards Max                              8.97204
eval/Rewards Min                             -0.821953
eval/Returns Mean                          6303.31
eval/Returns Std                             96.9405
eval/Returns Max                           6400.24
eval/Returns Min                           6122.63
eval/Actions Mean                             0.10488
eval/Actions Std                              0.812509
eval/Actions Max                              0.99592
eval/Actions Min                             -0.998987
eval/Num Paths                                5
eval/Average Returns                       6303.31
eval/env_infos/final/reward_run Mean          7.08222
eval/env_infos/final/reward_run Std           0.457314
eval/env_infos/final/reward_run Max           7.68615
eval/env_infos/final/reward_run Min           6.27642
eval/env_infos/initial/reward_run Mean       -0.42528
eval/env_infos/initial/reward_run Std         0.24007
eval/env_infos/initial/reward_run Max         0.00518455
eval/env_infos/initial/reward_run Min        -0.66595
eval/env_infos/reward_run Mean                6.70601
eval/env_infos/reward_run Std                 1.32893
eval/env_infos/reward_run Max                 9.44455
eval/env_infos/reward_run Min                -0.66595
eval/env_infos/final/reward_ctrl Mean        -0.391046
eval/env_infos/final/reward_ctrl Std          0.0904138
eval/env_infos/final/reward_ctrl Max         -0.250924
eval/env_infos/final/reward_ctrl Min         -0.498968
eval/env_infos/initial/reward_ctrl Mean      -0.169065
eval/env_infos/initial/reward_ctrl Std        0.0374642
eval/env_infos/initial/reward_ctrl Max       -0.122824
eval/env_infos/initial/reward_ctrl Min       -0.220259
eval/env_infos/reward_ctrl Mean              -0.402702
eval/env_infos/reward_ctrl Std                0.0866551
eval/env_infos/reward_ctrl Max               -0.0294744
eval/env_infos/reward_ctrl Min               -0.576674
time/data storing (s)                         0.00453428
time/evaluation sampling (s)                  2.00215
time/exploration sampling (s)                 0.536304
time/logging (s)                              0.0137012
time/sac training (s)                         7.46148
time/saving (s)                               0.00377202
time/training (s)                             3.4621e-05
time/epoch (s)                               10.022
time/total (s)                             4662.05
Epoch                                       442
---------------------------------------  ---------------
2021-11-24 01:47:08.891618 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 443 finished
---------------------------------------  ---------------
epoch                                       443
replay_buffer/size                       445000
trainer/num train calls                  444000
trainer/QF1 Loss                              5.3586
trainer/QF2 Loss                              5.08824
trainer/Policy Loss                        -414.126
trainer/Q1 Predictions Mean                 414.997
trainer/Q1 Predictions Std                   91.5698
trainer/Q1 Predictions Max                  485.198
trainer/Q1 Predictions Min                   20.171
trainer/Q2 Predictions Mean                 414.884
trainer/Q2 Predictions Std                   91.3874
trainer/Q2 Predictions Max                  484.483
trainer/Q2 Predictions Min                   20.6402
trainer/Q Targets Mean                      415.411
trainer/Q Targets Std                        91.4161
trainer/Q Targets Max                       484.095
trainer/Q Targets Min                        19.3539
trainer/Log Pis Mean                          5.73227
trainer/Log Pis Std                           4.02981
trainer/Log Pis Max                          14.4614
trainer/Log Pis Min                          -3.86007
trainer/policy/mean Mean                      0.113623
trainer/policy/mean Std                       0.767648
trainer/policy/mean Max                       0.998147
trainer/policy/mean Min                      -0.995092
trainer/policy/normal/std Mean                0.439261
trainer/policy/normal/std Std                 0.142308
trainer/policy/normal/std Max                 0.897085
trainer/policy/normal/std Min                 0.0666625
trainer/policy/normal/log_std Mean           -0.896187
trainer/policy/normal/log_std Std             0.428026
trainer/policy/normal/log_std Max            -0.108604
trainer/policy/normal/log_std Min            -2.70811
trainer/Alpha                                 0.155685
trainer/Alpha Loss                           -0.49795
expl/num steps total                     445000
expl/num paths total                        445
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.87178
expl/Rewards Std                              1.23714
expl/Rewards Max                              8.17235
expl/Rewards Min                             -0.736298
expl/Returns Mean                          5871.78
expl/Returns Std                              0
expl/Returns Max                           5871.78
expl/Returns Min                           5871.78
expl/Actions Mean                             0.129229
expl/Actions Std                              0.788756
expl/Actions Max                              0.999232
expl/Actions Min                             -0.999269
expl/Num Paths                                1
expl/Average Returns                       5871.78
expl/env_infos/final/reward_run Mean          6.82803
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.82803
expl/env_infos/final/reward_run Min           6.82803
expl/env_infos/initial/reward_run Mean       -0.601541
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.601541
expl/env_infos/initial/reward_run Min        -0.601541
expl/env_infos/reward_run Mean                6.25508
expl/env_infos/reward_run Std                 1.2287
expl/env_infos/reward_run Max                 8.59542
expl/env_infos/reward_run Min                -0.601541
expl/env_infos/final/reward_ctrl Mean        -0.38359
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.38359
expl/env_infos/final/reward_ctrl Min         -0.38359
expl/env_infos/initial/reward_ctrl Mean      -0.134757
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.134757
expl/env_infos/initial/reward_ctrl Min       -0.134757
expl/env_infos/reward_ctrl Mean              -0.383301
expl/env_infos/reward_ctrl Std                0.0908863
expl/env_infos/reward_ctrl Max               -0.097669
expl/env_infos/reward_ctrl Min               -0.5695
eval/num steps total                          2.22e+06
eval/num paths total                       2220
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.4713
eval/Rewards Std                              1.32852
eval/Rewards Max                              9.10164
eval/Rewards Min                             -0.810983
eval/Returns Mean                          6471.3
eval/Returns Std                             84.4647
eval/Returns Max                           6572.31
eval/Returns Min                           6363.53
eval/Actions Mean                             0.123937
eval/Actions Std                              0.814908
eval/Actions Max                              0.996673
eval/Actions Min                             -0.997375
eval/Num Paths                                5
eval/Average Returns                       6471.3
eval/env_infos/final/reward_run Mean          7.47165
eval/env_infos/final/reward_run Std           0.900818
eval/env_infos/final/reward_run Max           8.43459
eval/env_infos/final/reward_run Min           5.82808
eval/env_infos/initial/reward_run Mean       -0.411035
eval/env_infos/initial/reward_run Std         0.169527
eval/env_infos/initial/reward_run Max        -0.16931
eval/env_infos/initial/reward_run Min        -0.634759
eval/env_infos/reward_run Mean                6.87896
eval/env_infos/reward_run Std                 1.32186
eval/env_infos/reward_run Max                 9.58072
eval/env_infos/reward_run Min                -0.634759
eval/env_infos/final/reward_ctrl Mean        -0.429356
eval/env_infos/final/reward_ctrl Std          0.0980101
eval/env_infos/final/reward_ctrl Max         -0.246728
eval/env_infos/final/reward_ctrl Min         -0.524166
eval/env_infos/initial/reward_ctrl Mean      -0.215227
eval/env_infos/initial/reward_ctrl Std        0.0337813
eval/env_infos/initial/reward_ctrl Max       -0.176224
eval/env_infos/initial/reward_ctrl Min       -0.267984
eval/env_infos/reward_ctrl Mean              -0.407661
eval/env_infos/reward_ctrl Std                0.0856835
eval/env_infos/reward_ctrl Max               -0.0362403
eval/env_infos/reward_ctrl Min               -0.568202
time/data storing (s)                         0.00450854
time/evaluation sampling (s)                  2.00418
time/exploration sampling (s)                 0.533802
time/logging (s)                              0.0136647
time/sac training (s)                         7.41871
time/saving (s)                               0.00377106
time/training (s)                             3.7162e-05
time/epoch (s)                                9.97868
time/total (s)                             4672.31
Epoch                                       443
---------------------------------------  ---------------
2021-11-24 01:47:19.175446 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 444 finished
---------------------------------------  ---------------
epoch                                       444
replay_buffer/size                       446000
trainer/num train calls                  445000
trainer/QF1 Loss                              5.07583
trainer/QF2 Loss                              7.36758
trainer/Policy Loss                        -424.683
trainer/Q1 Predictions Mean                 425.367
trainer/Q1 Predictions Std                   75.6875
trainer/Q1 Predictions Max                  486.175
trainer/Q1 Predictions Min                   22.5212
trainer/Q2 Predictions Mean                 425.738
trainer/Q2 Predictions Std                   75.5812
trainer/Q2 Predictions Max                  486.95
trainer/Q2 Predictions Min                   23.1697
trainer/Q Targets Mean                      425.444
trainer/Q Targets Std                        75.6782
trainer/Q Targets Max                       487.081
trainer/Q Targets Min                        22.0462
trainer/Log Pis Mean                          6.47671
trainer/Log Pis Std                           3.88434
trainer/Log Pis Max                          15.4844
trainer/Log Pis Min                          -4.42116
trainer/policy/mean Mean                      0.0842252
trainer/policy/mean Std                       0.790221
trainer/policy/mean Max                       0.995052
trainer/policy/mean Min                      -0.997114
trainer/policy/normal/std Mean                0.439849
trainer/policy/normal/std Std                 0.139711
trainer/policy/normal/std Max                 1.01829
trainer/policy/normal/std Min                 0.0686938
trainer/policy/normal/log_std Mean           -0.892869
trainer/policy/normal/log_std Std             0.424025
trainer/policy/normal/log_std Max             0.0181258
trainer/policy/normal/log_std Min            -2.6781
trainer/Alpha                                 0.158128
trainer/Alpha Loss                            0.879224
expl/num steps total                     446000
expl/num paths total                        446
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.98411
expl/Rewards Std                              1.27363
expl/Rewards Max                              8.50957
expl/Rewards Min                             -0.465456
expl/Returns Mean                          5984.11
expl/Returns Std                              0
expl/Returns Max                           5984.11
expl/Returns Min                           5984.11
expl/Actions Mean                             0.0814495
expl/Actions Std                              0.796333
expl/Actions Max                              0.999177
expl/Actions Min                             -0.999932
expl/Num Paths                                1
expl/Average Returns                       5984.11
expl/env_infos/final/reward_run Mean          5.74406
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.74406
expl/env_infos/final/reward_run Min           5.74406
expl/env_infos/initial/reward_run Mean       -0.0938978
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0938978
expl/env_infos/initial/reward_run Min        -0.0938978
expl/env_infos/reward_run Mean                6.36858
expl/env_infos/reward_run Std                 1.2691
expl/env_infos/reward_run Max                 9.04258
expl/env_infos/reward_run Min                -0.0938978
expl/env_infos/final/reward_ctrl Mean        -0.344227
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.344227
expl/env_infos/final/reward_ctrl Min         -0.344227
expl/env_infos/initial/reward_ctrl Mean      -0.281894
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.281894
expl/env_infos/initial/reward_ctrl Min       -0.281894
expl/env_infos/reward_ctrl Mean              -0.384468
expl/env_infos/reward_ctrl Std                0.0851322
expl/env_infos/reward_ctrl Max               -0.0435622
expl/env_infos/reward_ctrl Min               -0.573306
eval/num steps total                          2.225e+06
eval/num paths total                       2225
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.44594
eval/Rewards Std                              1.34643
eval/Rewards Max                              9.02041
eval/Rewards Min                             -0.947137
eval/Returns Mean                          6445.94
eval/Returns Std                             59.9713
eval/Returns Max                           6512.86
eval/Returns Min                           6337.78
eval/Actions Mean                             0.0817598
eval/Actions Std                              0.815755
eval/Actions Max                              0.995295
eval/Actions Min                             -0.997527
eval/Num Paths                                5
eval/Average Returns                       6445.94
eval/env_infos/final/reward_run Mean          7.58975
eval/env_infos/final/reward_run Std           0.553695
eval/env_infos/final/reward_run Max           8.26433
eval/env_infos/final/reward_run Min           6.6917
eval/env_infos/initial/reward_run Mean       -0.154873
eval/env_infos/initial/reward_run Std         0.244177
eval/env_infos/initial/reward_run Max         0.253652
eval/env_infos/initial/reward_run Min        -0.397143
eval/env_infos/reward_run Mean                6.84922
eval/env_infos/reward_run Std                 1.34177
eval/env_infos/reward_run Max                 9.48998
eval/env_infos/reward_run Min                -0.42761
eval/env_infos/final/reward_ctrl Mean        -0.388195
eval/env_infos/final/reward_ctrl Std          0.0593464
eval/env_infos/final/reward_ctrl Max         -0.315783
eval/env_infos/final/reward_ctrl Min         -0.47811
eval/env_infos/initial/reward_ctrl Mean      -0.169463
eval/env_infos/initial/reward_ctrl Std        0.0235037
eval/env_infos/initial/reward_ctrl Max       -0.132512
eval/env_infos/initial/reward_ctrl Min       -0.205775
eval/env_infos/reward_ctrl Mean              -0.403284
eval/env_infos/reward_ctrl Std                0.081889
eval/env_infos/reward_ctrl Max               -0.0872942
eval/env_infos/reward_ctrl Min               -0.578792
time/data storing (s)                         0.00453305
time/evaluation sampling (s)                  1.99661
time/exploration sampling (s)                 0.5374
time/logging (s)                              0.0136172
time/sac training (s)                         7.43117
time/saving (s)                               0.00378677
time/training (s)                             3.4344e-05
time/epoch (s)                                9.98715
time/total (s)                             4682.58
Epoch                                       444
---------------------------------------  ---------------
2021-11-24 01:47:29.482520 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 445 finished
---------------------------------------  ---------------
epoch                                       445
replay_buffer/size                       447000
trainer/num train calls                  446000
trainer/QF1 Loss                              5.31821
trainer/QF2 Loss                              4.91159
trainer/Policy Loss                        -408.627
trainer/Q1 Predictions Mean                 408.748
trainer/Q1 Predictions Std                  104.359
trainer/Q1 Predictions Max                  483.726
trainer/Q1 Predictions Min                   22.5474
trainer/Q2 Predictions Mean                 409.28
trainer/Q2 Predictions Std                  104.409
trainer/Q2 Predictions Max                  484.145
trainer/Q2 Predictions Min                   20.8183
trainer/Q Targets Mean                      409.132
trainer/Q Targets Std                       104.178
trainer/Q Targets Max                       485.112
trainer/Q Targets Min                        21.818
trainer/Log Pis Mean                          5.76458
trainer/Log Pis Std                           4.51729
trainer/Log Pis Max                          16.4453
trainer/Log Pis Min                          -5.3592
trainer/policy/mean Mean                      0.0974585
trainer/policy/mean Std                       0.765056
trainer/policy/mean Max                       0.996469
trainer/policy/mean Min                      -0.998681
trainer/policy/normal/std Mean                0.446188
trainer/policy/normal/std Std                 0.14587
trainer/policy/normal/std Max                 0.877448
trainer/policy/normal/std Min                 0.0674601
trainer/policy/normal/log_std Mean           -0.879012
trainer/policy/normal/log_std Std             0.418279
trainer/policy/normal/log_std Max            -0.130738
trainer/policy/normal/log_std Min            -2.69622
trainer/Alpha                                 0.156149
trainer/Alpha Loss                           -0.437168
expl/num steps total                     447000
expl/num paths total                        447
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.77195
expl/Rewards Std                              1.22851
expl/Rewards Max                              8.23765
expl/Rewards Min                             -0.473952
expl/Returns Mean                          5771.95
expl/Returns Std                              0
expl/Returns Max                           5771.95
expl/Returns Min                           5771.95
expl/Actions Mean                             0.0974887
expl/Actions Std                              0.794693
expl/Actions Max                              0.999728
expl/Actions Min                             -0.999549
expl/Num Paths                                1
expl/Average Returns                       5771.95
expl/env_infos/final/reward_run Mean          5.97495
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.97495
expl/env_infos/final/reward_run Min           5.97495
expl/env_infos/initial/reward_run Mean       -0.196024
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.196024
expl/env_infos/initial/reward_run Min        -0.196024
expl/env_infos/reward_run Mean                6.15658
expl/env_infos/reward_run Std                 1.21559
expl/env_infos/reward_run Max                 8.52751
expl/env_infos/reward_run Min                -0.196024
expl/env_infos/final/reward_ctrl Mean        -0.45978
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.45978
expl/env_infos/final/reward_ctrl Min         -0.45978
expl/env_infos/initial/reward_ctrl Mean      -0.277928
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.277928
expl/env_infos/initial/reward_ctrl Min       -0.277928
expl/env_infos/reward_ctrl Mean              -0.384625
expl/env_infos/reward_ctrl Std                0.0898266
expl/env_infos/reward_ctrl Max               -0.0689707
expl/env_infos/reward_ctrl Min               -0.585107
eval/num steps total                          2.23e+06
eval/num paths total                       2230
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.21435
eval/Rewards Std                              1.30857
eval/Rewards Max                              8.94339
eval/Rewards Min                             -0.880119
eval/Returns Mean                          6214.35
eval/Returns Std                             47.1481
eval/Returns Max                           6258.5
eval/Returns Min                           6126.77
eval/Actions Mean                             0.0861058
eval/Actions Std                              0.81192
eval/Actions Max                              0.99627
eval/Actions Min                             -0.99885
eval/Num Paths                                5
eval/Average Returns                       6214.35
eval/env_infos/final/reward_run Mean          6.74986
eval/env_infos/final/reward_run Std           0.7608
eval/env_infos/final/reward_run Max           7.50192
eval/env_infos/final/reward_run Min           5.42301
eval/env_infos/initial/reward_run Mean       -0.128347
eval/env_infos/initial/reward_run Std         0.547076
eval/env_infos/initial/reward_run Max         0.811497
eval/env_infos/initial/reward_run Min        -0.697538
eval/env_infos/reward_run Mean                6.61432
eval/env_infos/reward_run Std                 1.29974
eval/env_infos/reward_run Max                 9.45763
eval/env_infos/reward_run Min                -0.697538
eval/env_infos/final/reward_ctrl Mean        -0.380427
eval/env_infos/final/reward_ctrl Std          0.0721824
eval/env_infos/final/reward_ctrl Max         -0.257729
eval/env_infos/final/reward_ctrl Min         -0.453476
eval/env_infos/initial/reward_ctrl Mean      -0.18922
eval/env_infos/initial/reward_ctrl Std        0.0237173
eval/env_infos/initial/reward_ctrl Max       -0.163423
eval/env_infos/initial/reward_ctrl Min       -0.232129
eval/env_infos/reward_ctrl Mean              -0.399977
eval/env_infos/reward_ctrl Std                0.0877827
eval/env_infos/reward_ctrl Max               -0.0623326
eval/env_infos/reward_ctrl Min               -0.579091
time/data storing (s)                         0.00451374
time/evaluation sampling (s)                  2.01398
time/exploration sampling (s)                 0.537365
time/logging (s)                              0.0136564
time/sac training (s)                         7.43651
time/saving (s)                               0.00376193
time/training (s)                             3.473e-05
time/epoch (s)                               10.0098
time/total (s)                             4692.87
Epoch                                       445
---------------------------------------  ---------------
2021-11-24 01:47:39.773932 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 446 finished
---------------------------------------  ---------------
epoch                                       446
replay_buffer/size                       448000
trainer/num train calls                  447000
trainer/QF1 Loss                              5.29976
trainer/QF2 Loss                              5.22799
trainer/Policy Loss                        -421.245
trainer/Q1 Predictions Mean                 422.171
trainer/Q1 Predictions Std                   84.2742
trainer/Q1 Predictions Max                  487.063
trainer/Q1 Predictions Min                   22.2217
trainer/Q2 Predictions Mean                 421.919
trainer/Q2 Predictions Std                   84.014
trainer/Q2 Predictions Max                  485.281
trainer/Q2 Predictions Min                   22.6369
trainer/Q Targets Mean                      421.946
trainer/Q Targets Std                        83.9861
trainer/Q Targets Max                       485.167
trainer/Q Targets Min                        23.0798
trainer/Log Pis Mean                          5.99525
trainer/Log Pis Std                           4.3145
trainer/Log Pis Max                          17.0536
trainer/Log Pis Min                          -6.02078
trainer/policy/mean Mean                      0.0898913
trainer/policy/mean Std                       0.779884
trainer/policy/mean Max                       0.999282
trainer/policy/mean Min                      -0.997813
trainer/policy/normal/std Mean                0.453717
trainer/policy/normal/std Std                 0.146806
trainer/policy/normal/std Max                 1.03074
trainer/policy/normal/std Min                 0.0701132
trainer/policy/normal/log_std Mean           -0.862311
trainer/policy/normal/log_std Std             0.422288
trainer/policy/normal/log_std Max             0.0302727
trainer/policy/normal/log_std Min            -2.65764
trainer/Alpha                                 0.154892
trainer/Alpha Loss                           -0.00886358
expl/num steps total                     448000
expl/num paths total                        448
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00986
expl/Rewards Std                              1.30858
expl/Rewards Max                              8.65144
expl/Rewards Min                             -0.343652
expl/Returns Mean                          6009.86
expl/Returns Std                              0
expl/Returns Max                           6009.86
expl/Returns Min                           6009.86
expl/Actions Mean                             0.110344
expl/Actions Std                              0.79439
expl/Actions Max                              0.999791
expl/Actions Min                             -0.999694
expl/Num Paths                                1
expl/Average Returns                       6009.86
expl/env_infos/final/reward_run Mean          6.42363
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.42363
expl/env_infos/final/reward_run Min           6.42363
expl/env_infos/initial/reward_run Mean       -0.217758
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.217758
expl/env_infos/initial/reward_run Min        -0.217758
expl/env_infos/reward_run Mean                6.3958
expl/env_infos/reward_run Std                 1.30892
expl/env_infos/reward_run Max                 9.19791
expl/env_infos/reward_run Min                -0.217758
expl/env_infos/final/reward_ctrl Mean        -0.436037
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.436037
expl/env_infos/final/reward_ctrl Min         -0.436037
expl/env_infos/initial/reward_ctrl Mean      -0.125894
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.125894
expl/env_infos/initial/reward_ctrl Min       -0.125894
expl/env_infos/reward_ctrl Mean              -0.385939
expl/env_infos/reward_ctrl Std                0.0925915
expl/env_infos/reward_ctrl Max               -0.0709048
expl/env_infos/reward_ctrl Min               -0.574013
eval/num steps total                          2.235e+06
eval/num paths total                       2235
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.36767
eval/Rewards Std                              1.31439
eval/Rewards Max                              8.85026
eval/Rewards Min                             -0.757221
eval/Returns Mean                          6367.67
eval/Returns Std                             59.2845
eval/Returns Max                           6448.43
eval/Returns Min                           6294.62
eval/Actions Mean                             0.100696
eval/Actions Std                              0.815425
eval/Actions Max                              0.996842
eval/Actions Min                             -0.996505
eval/Num Paths                                5
eval/Average Returns                       6367.67
eval/env_infos/final/reward_run Mean          7.63344
eval/env_infos/final/reward_run Std           0.71977
eval/env_infos/final/reward_run Max           8.92059
eval/env_infos/final/reward_run Min           6.77302
eval/env_infos/initial/reward_run Mean       -0.27741
eval/env_infos/initial/reward_run Std         0.252835
eval/env_infos/initial/reward_run Max         0.167087
eval/env_infos/initial/reward_run Min        -0.568932
eval/env_infos/reward_run Mean                6.7727
eval/env_infos/reward_run Std                 1.30993
eval/env_infos/reward_run Max                 9.32709
eval/env_infos/reward_run Min                -0.568932
eval/env_infos/final/reward_ctrl Mean        -0.377413
eval/env_infos/final/reward_ctrl Std          0.0837217
eval/env_infos/final/reward_ctrl Max         -0.267244
eval/env_infos/final/reward_ctrl Min         -0.48574
eval/env_infos/initial/reward_ctrl Mean      -0.157353
eval/env_infos/initial/reward_ctrl Std        0.0625127
eval/env_infos/initial/reward_ctrl Max       -0.0806311
eval/env_infos/initial/reward_ctrl Min       -0.251412
eval/env_infos/reward_ctrl Mean              -0.405034
eval/env_infos/reward_ctrl Std                0.0891717
eval/env_infos/reward_ctrl Max               -0.0806311
eval/env_infos/reward_ctrl Min               -0.580156
time/data storing (s)                         0.00454463
time/evaluation sampling (s)                  2.01501
time/exploration sampling (s)                 0.528124
time/logging (s)                              0.0136884
time/sac training (s)                         7.43147
time/saving (s)                               0.003764
time/training (s)                             3.4423e-05
time/epoch (s)                                9.99663
time/total (s)                             4703.15
Epoch                                       446
---------------------------------------  ---------------
2021-11-24 01:47:50.182959 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 447 finished
---------------------------------------  ---------------
epoch                                       447
replay_buffer/size                       449000
trainer/num train calls                  448000
trainer/QF1 Loss                              5.60533
trainer/QF2 Loss                              5.03069
trainer/Policy Loss                        -415.052
trainer/Q1 Predictions Mean                 415.788
trainer/Q1 Predictions Std                   91.5306
trainer/Q1 Predictions Max                  487.063
trainer/Q1 Predictions Min                   21.3307
trainer/Q2 Predictions Mean                 415.758
trainer/Q2 Predictions Std                   91.6762
trainer/Q2 Predictions Max                  487.34
trainer/Q2 Predictions Min                   23.4289
trainer/Q Targets Mean                      415.579
trainer/Q Targets Std                        91.513
trainer/Q Targets Max                       486.07
trainer/Q Targets Min                        20.5073
trainer/Log Pis Mean                          6.2085
trainer/Log Pis Std                           3.821
trainer/Log Pis Max                          16.2333
trainer/Log Pis Min                          -5.21501
trainer/policy/mean Mean                      0.0715351
trainer/policy/mean Std                       0.780674
trainer/policy/mean Max                       0.997911
trainer/policy/mean Min                      -0.992493
trainer/policy/normal/std Mean                0.434688
trainer/policy/normal/std Std                 0.143388
trainer/policy/normal/std Max                 0.987118
trainer/policy/normal/std Min                 0.0653966
trainer/policy/normal/log_std Mean           -0.90815
trainer/policy/normal/log_std Std             0.43092
trainer/policy/normal/log_std Max            -0.0129659
trainer/policy/normal/log_std Min            -2.72729
trainer/Alpha                                 0.1571
trainer/Alpha Loss                            0.385913
expl/num steps total                     449000
expl/num paths total                        449
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.029
expl/Rewards Std                              1.24592
expl/Rewards Max                              8.34048
expl/Rewards Min                             -0.432216
expl/Returns Mean                          6029
expl/Returns Std                              0
expl/Returns Max                           6029
expl/Returns Min                           6029
expl/Actions Mean                             0.101005
expl/Actions Std                              0.795474
expl/Actions Max                              0.999516
expl/Actions Min                             -0.998788
expl/Num Paths                                1
expl/Average Returns                       6029
expl/env_infos/final/reward_run Mean          6.97324
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.97324
expl/env_infos/final/reward_run Min           6.97324
expl/env_infos/initial/reward_run Mean        0.026378
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.026378
expl/env_infos/initial/reward_run Min         0.026378
expl/env_infos/reward_run Mean                6.41479
expl/env_infos/reward_run Std                 1.24412
expl/env_infos/reward_run Max                 8.86318
expl/env_infos/reward_run Min                -0.0652965
expl/env_infos/final/reward_ctrl Mean        -0.301529
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.301529
expl/env_infos/final/reward_ctrl Min         -0.301529
expl/env_infos/initial/reward_ctrl Mean      -0.207814
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.207814
expl/env_infos/initial/reward_ctrl Min       -0.207814
expl/env_infos/reward_ctrl Mean              -0.385789
expl/env_infos/reward_ctrl Std                0.0885395
expl/env_infos/reward_ctrl Max               -0.0463199
expl/env_infos/reward_ctrl Min               -0.580358
eval/num steps total                          2.24e+06
eval/num paths total                       2240
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.39114
eval/Rewards Std                              1.29881
eval/Rewards Max                              8.73733
eval/Rewards Min                             -0.741372
eval/Returns Mean                          6391.14
eval/Returns Std                             71.8057
eval/Returns Max                           6500.29
eval/Returns Min                           6311.89
eval/Actions Mean                             0.0974659
eval/Actions Std                              0.813417
eval/Actions Max                              0.996724
eval/Actions Min                             -0.997022
eval/Num Paths                                5
eval/Average Returns                       6391.14
eval/env_infos/final/reward_run Mean          7.3371
eval/env_infos/final/reward_run Std           1.47862
eval/env_infos/final/reward_run Max           9.14335
eval/env_infos/final/reward_run Min           5.50716
eval/env_infos/initial/reward_run Mean       -0.286473
eval/env_infos/initial/reward_run Std         0.221962
eval/env_infos/initial/reward_run Max        -0.0037182
eval/env_infos/initial/reward_run Min        -0.542783
eval/env_infos/reward_run Mean                6.79383
eval/env_infos/reward_run Std                 1.2973
eval/env_infos/reward_run Max                 9.24123
eval/env_infos/reward_run Min                -0.542783
eval/env_infos/final/reward_ctrl Mean        -0.433701
eval/env_infos/final/reward_ctrl Std          0.0773814
eval/env_infos/final/reward_ctrl Max         -0.308303
eval/env_infos/final/reward_ctrl Min         -0.517148
eval/env_infos/initial/reward_ctrl Mean      -0.221574
eval/env_infos/initial/reward_ctrl Std        0.0371048
eval/env_infos/initial/reward_ctrl Max       -0.163239
eval/env_infos/initial/reward_ctrl Min       -0.269374
eval/env_infos/reward_ctrl Mean              -0.402688
eval/env_infos/reward_ctrl Std                0.0847108
eval/env_infos/reward_ctrl Max               -0.0887818
eval/env_infos/reward_ctrl Min               -0.577777
time/data storing (s)                         0.00448404
time/evaluation sampling (s)                  2.01887
time/exploration sampling (s)                 0.532461
time/logging (s)                              0.013674
time/sac training (s)                         7.53861
time/saving (s)                               0.00377428
time/training (s)                             3.4716e-05
time/epoch (s)                               10.1119
time/total (s)                             4713.54
Epoch                                       447
---------------------------------------  ---------------
2021-11-24 01:48:00.535417 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 448 finished
---------------------------------------  ---------------
epoch                                       448
replay_buffer/size                       450000
trainer/num train calls                  449000
trainer/QF1 Loss                              7.28741
trainer/QF2 Loss                              7.1692
trainer/Policy Loss                        -415.576
trainer/Q1 Predictions Mean                 416.392
trainer/Q1 Predictions Std                   98.0655
trainer/Q1 Predictions Max                  494.29
trainer/Q1 Predictions Min                   22.4793
trainer/Q2 Predictions Mean                 416.498
trainer/Q2 Predictions Std                   97.9788
trainer/Q2 Predictions Max                  495.309
trainer/Q2 Predictions Min                   24.1902
trainer/Q Targets Mean                      416.297
trainer/Q Targets Std                        97.9915
trainer/Q Targets Max                       491.884
trainer/Q Targets Min                        22.8806
trainer/Log Pis Mean                          6.40954
trainer/Log Pis Std                           4.45374
trainer/Log Pis Max                          14.8831
trainer/Log Pis Min                          -5.11122
trainer/policy/mean Mean                      0.100617
trainer/policy/mean Std                       0.790826
trainer/policy/mean Max                       0.997735
trainer/policy/mean Min                      -0.999774
trainer/policy/normal/std Mean                0.452606
trainer/policy/normal/std Std                 0.147461
trainer/policy/normal/std Max                 0.936596
trainer/policy/normal/std Min                 0.0787659
trainer/policy/normal/log_std Mean           -0.864399
trainer/policy/normal/log_std Std             0.420063
trainer/policy/normal/log_std Max            -0.0655037
trainer/policy/normal/log_std Min            -2.54127
trainer/Alpha                                 0.158893
trainer/Alpha Loss                            0.753367
expl/num steps total                     450000
expl/num paths total                        450
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.0291
expl/Rewards Std                              1.32865
expl/Rewards Max                              8.47729
expl/Rewards Min                             -0.906442
expl/Returns Mean                          6029.1
expl/Returns Std                              0
expl/Returns Max                           6029.1
expl/Returns Min                           6029.1
expl/Actions Mean                             0.102683
expl/Actions Std                              0.799106
expl/Actions Max                              0.999712
expl/Actions Min                             -0.999453
expl/Num Paths                                1
expl/Average Returns                       6029.1
expl/env_infos/final/reward_run Mean          5.93105
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.93105
expl/env_infos/final/reward_run Min           5.93105
expl/env_infos/initial/reward_run Mean       -0.499506
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.499506
expl/env_infos/initial/reward_run Min        -0.499506
expl/env_infos/reward_run Mean                6.41856
expl/env_infos/reward_run Std                 1.31949
expl/env_infos/reward_run Max                 8.91223
expl/env_infos/reward_run Min                -0.499506
expl/env_infos/final/reward_ctrl Mean        -0.249386
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.249386
expl/env_infos/final/reward_ctrl Min         -0.249386
expl/env_infos/initial/reward_ctrl Mean      -0.276069
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.276069
expl/env_infos/initial/reward_ctrl Min       -0.276069
expl/env_infos/reward_ctrl Mean              -0.389469
expl/env_infos/reward_ctrl Std                0.0927263
expl/env_infos/reward_ctrl Max               -0.100304
expl/env_infos/reward_ctrl Min               -0.585232
eval/num steps total                          2.245e+06
eval/num paths total                       2245
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.27954
eval/Rewards Std                              1.325
eval/Rewards Max                              8.74739
eval/Rewards Min                             -0.785542
eval/Returns Mean                          6279.54
eval/Returns Std                             36.7379
eval/Returns Max                           6336.33
eval/Returns Min                           6240.98
eval/Actions Mean                             0.0949711
eval/Actions Std                              0.818241
eval/Actions Max                              0.997599
eval/Actions Min                             -0.998927
eval/Num Paths                                5
eval/Average Returns                       6279.54
eval/env_infos/final/reward_run Mean          7.15911
eval/env_infos/final/reward_run Std           1.24166
eval/env_infos/final/reward_run Max           8.69367
eval/env_infos/final/reward_run Min           4.98677
eval/env_infos/initial/reward_run Mean       -0.373166
eval/env_infos/initial/reward_run Std         0.218785
eval/env_infos/initial/reward_run Max         0.0363355
eval/env_infos/initial/reward_run Min        -0.562445
eval/env_infos/reward_run Mean                6.68666
eval/env_infos/reward_run Std                 1.31644
eval/env_infos/reward_run Max                 9.22263
eval/env_infos/reward_run Min                -0.562445
eval/env_infos/final/reward_ctrl Mean        -0.360694
eval/env_infos/final/reward_ctrl Std          0.115928
eval/env_infos/final/reward_ctrl Max         -0.212285
eval/env_infos/final/reward_ctrl Min         -0.524867
eval/env_infos/initial/reward_ctrl Mean      -0.189093
eval/env_infos/initial/reward_ctrl Std        0.041726
eval/env_infos/initial/reward_ctrl Max       -0.119488
eval/env_infos/initial/reward_ctrl Min       -0.230954
eval/env_infos/reward_ctrl Mean              -0.407123
eval/env_infos/reward_ctrl Std                0.0892254
eval/env_infos/reward_ctrl Max               -0.0770195
eval/env_infos/reward_ctrl Min               -0.577014
time/data storing (s)                         0.00449632
time/evaluation sampling (s)                  2.05569
time/exploration sampling (s)                 0.533948
time/logging (s)                              0.0136412
time/sac training (s)                         7.4451
time/saving (s)                               0.0037625
time/training (s)                             3.4602e-05
time/epoch (s)                               10.0567
time/total (s)                             4723.88
Epoch                                       448
---------------------------------------  ---------------
2021-11-24 01:48:10.839636 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 449 finished
---------------------------------------  ---------------
epoch                                       449
replay_buffer/size                       451000
trainer/num train calls                  450000
trainer/QF1 Loss                              5.50626
trainer/QF2 Loss                              4.24588
trainer/Policy Loss                        -404.163
trainer/Q1 Predictions Mean                 404.767
trainer/Q1 Predictions Std                  113.282
trainer/Q1 Predictions Max                  486.601
trainer/Q1 Predictions Min                   21.4631
trainer/Q2 Predictions Mean                 405.157
trainer/Q2 Predictions Std                  113.567
trainer/Q2 Predictions Max                  488.184
trainer/Q2 Predictions Min                   20.8551
trainer/Q Targets Mean                      405.061
trainer/Q Targets Std                       113.436
trainer/Q Targets Max                       489.718
trainer/Q Targets Min                        20.9456
trainer/Log Pis Mean                          5.7682
trainer/Log Pis Std                           4.67587
trainer/Log Pis Max                          15.2572
trainer/Log Pis Min                          -6.38801
trainer/policy/mean Mean                      0.0709691
trainer/policy/mean Std                       0.777639
trainer/policy/mean Max                       0.994009
trainer/policy/mean Min                      -0.998812
trainer/policy/normal/std Mean                0.458877
trainer/policy/normal/std Std                 0.146439
trainer/policy/normal/std Max                 0.988868
trainer/policy/normal/std Min                 0.0737473
trainer/policy/normal/log_std Mean           -0.847291
trainer/policy/normal/log_std Std             0.408796
trainer/policy/normal/log_std Max            -0.0111945
trainer/policy/normal/log_std Min            -2.60711
trainer/Alpha                                 0.158858
trainer/Alpha Loss                           -0.426443
expl/num steps total                     451000
expl/num paths total                        451
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.99155
expl/Rewards Std                              1.30541
expl/Rewards Max                              8.30212
expl/Rewards Min                             -0.546717
expl/Returns Mean                          5991.55
expl/Returns Std                              0
expl/Returns Max                           5991.55
expl/Returns Min                           5991.55
expl/Actions Mean                             0.0974308
expl/Actions Std                              0.798849
expl/Actions Max                              0.99983
expl/Actions Min                             -0.999664
expl/Num Paths                                1
expl/Average Returns                       5991.55
expl/env_infos/final/reward_run Mean          5.27613
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.27613
expl/env_infos/final/reward_run Min           5.27613
expl/env_infos/initial/reward_run Mean       -0.217434
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.217434
expl/env_infos/initial/reward_run Min        -0.217434
expl/env_infos/reward_run Mean                6.38015
expl/env_infos/reward_run Std                 1.30055
expl/env_infos/reward_run Max                 8.74056
expl/env_infos/reward_run Min                -0.217434
expl/env_infos/final/reward_ctrl Mean        -0.389923
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.389923
expl/env_infos/final/reward_ctrl Min         -0.389923
expl/env_infos/initial/reward_ctrl Mean      -0.273338
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.273338
expl/env_infos/initial/reward_ctrl Min       -0.273338
expl/env_infos/reward_ctrl Mean              -0.388592
expl/env_infos/reward_ctrl Std                0.0889812
expl/env_infos/reward_ctrl Max               -0.091298
expl/env_infos/reward_ctrl Min               -0.571064
eval/num steps total                          2.25e+06
eval/num paths total                       2250
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.44799
eval/Rewards Std                              1.33042
eval/Rewards Max                              9.05806
eval/Rewards Min                             -0.868221
eval/Returns Mean                          6447.99
eval/Returns Std                             56.6536
eval/Returns Max                           6555.16
eval/Returns Min                           6400.9
eval/Actions Mean                             0.0930681
eval/Actions Std                              0.817333
eval/Actions Max                              0.995311
eval/Actions Min                             -0.997021
eval/Num Paths                                5
eval/Average Returns                       6447.99
eval/env_infos/final/reward_run Mean          7.75225
eval/env_infos/final/reward_run Std           0.549316
eval/env_infos/final/reward_run Max           8.66001
eval/env_infos/final/reward_run Min           7.04644
eval/env_infos/initial/reward_run Mean       -0.262527
eval/env_infos/initial/reward_run Std         0.46648
eval/env_infos/initial/reward_run Max         0.604395
eval/env_infos/initial/reward_run Min        -0.665799
eval/env_infos/reward_run Mean                6.85401
eval/env_infos/reward_run Std                 1.32854
eval/env_infos/reward_run Max                 9.59722
eval/env_infos/reward_run Min                -0.665799
eval/env_infos/final/reward_ctrl Mean        -0.357418
eval/env_infos/final/reward_ctrl Std          0.0491924
eval/env_infos/final/reward_ctrl Max         -0.315648
eval/env_infos/final/reward_ctrl Min         -0.452473
eval/env_infos/initial/reward_ctrl Mean      -0.16638
eval/env_infos/initial/reward_ctrl Std        0.0371288
eval/env_infos/initial/reward_ctrl Max       -0.100414
eval/env_infos/initial/reward_ctrl Min       -0.202422
eval/env_infos/reward_ctrl Mean              -0.406017
eval/env_infos/reward_ctrl Std                0.0866771
eval/env_infos/reward_ctrl Max               -0.077397
eval/env_infos/reward_ctrl Min               -0.576534
time/data storing (s)                         0.00452831
time/evaluation sampling (s)                  2.01239
time/exploration sampling (s)                 0.534824
time/logging (s)                              0.0135947
time/sac training (s)                         7.43935
time/saving (s)                               0.00377838
time/training (s)                             3.4963e-05
time/epoch (s)                               10.0085
time/total (s)                             4734.17
Epoch                                       449
---------------------------------------  ---------------
2021-11-24 01:48:21.184383 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 450 finished
---------------------------------------  ---------------
epoch                                       450
replay_buffer/size                       452000
trainer/num train calls                  451000
trainer/QF1 Loss                              4.67777
trainer/QF2 Loss                              4.53007
trainer/Policy Loss                        -414.691
trainer/Q1 Predictions Mean                 415.507
trainer/Q1 Predictions Std                   92.4459
trainer/Q1 Predictions Max                  491.449
trainer/Q1 Predictions Min                   24.2451
trainer/Q2 Predictions Mean                 415.367
trainer/Q2 Predictions Std                   92.4433
trainer/Q2 Predictions Max                  491.858
trainer/Q2 Predictions Min                   24.1043
trainer/Q Targets Mean                      415.442
trainer/Q Targets Std                        92.4937
trainer/Q Targets Max                       495.444
trainer/Q Targets Min                        24.0534
trainer/Log Pis Mean                          6.01687
trainer/Log Pis Std                           4.29802
trainer/Log Pis Max                          19.1931
trainer/Log Pis Min                          -5.94775
trainer/policy/mean Mean                      0.0841945
trainer/policy/mean Std                       0.786574
trainer/policy/mean Max                       0.998362
trainer/policy/mean Min                      -0.995156
trainer/policy/normal/std Mean                0.454963
trainer/policy/normal/std Std                 0.149076
trainer/policy/normal/std Max                 1.52456
trainer/policy/normal/std Min                 0.0721248
trainer/policy/normal/log_std Mean           -0.860637
trainer/policy/normal/log_std Std             0.425925
trainer/policy/normal/log_std Max             0.421705
trainer/policy/normal/log_std Min            -2.62936
trainer/Alpha                                 0.15622
trainer/Alpha Loss                            0.0313206
expl/num steps total                     452000
expl/num paths total                        452
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.95919
expl/Rewards Std                              1.48704
expl/Rewards Max                              8.47642
expl/Rewards Min                             -0.878366
expl/Returns Mean                          5959.19
expl/Returns Std                              0
expl/Returns Max                           5959.19
expl/Returns Min                           5959.19
expl/Actions Mean                             0.082442
expl/Actions Std                              0.810111
expl/Actions Max                              0.999281
expl/Actions Min                             -0.998773
expl/Num Paths                                1
expl/Average Returns                       5959.19
expl/env_infos/final/reward_run Mean          7.69814
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.69814
expl/env_infos/final/reward_run Min           7.69814
expl/env_infos/initial/reward_run Mean        0.179131
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.179131
expl/env_infos/initial/reward_run Min         0.179131
expl/env_infos/reward_run Mean                6.35703
expl/env_infos/reward_run Std                 1.48898
expl/env_infos/reward_run Max                 9.00024
expl/env_infos/reward_run Min                -0.365865
expl/env_infos/final/reward_ctrl Mean        -0.409464
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.409464
expl/env_infos/final/reward_ctrl Min         -0.409464
expl/env_infos/initial/reward_ctrl Mean      -0.108547
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.108547
expl/env_infos/initial/reward_ctrl Min       -0.108547
expl/env_infos/reward_ctrl Mean              -0.397846
expl/env_infos/reward_ctrl Std                0.0864483
expl/env_infos/reward_ctrl Max               -0.094548
expl/env_infos/reward_ctrl Min               -0.571052
eval/num steps total                          2.255e+06
eval/num paths total                       2255
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.50107
eval/Rewards Std                              1.36955
eval/Rewards Max                              8.96528
eval/Rewards Min                             -0.912333
eval/Returns Mean                          6501.07
eval/Returns Std                             92.3816
eval/Returns Max                           6614.48
eval/Returns Min                           6395.3
eval/Actions Mean                             0.0981558
eval/Actions Std                              0.824065
eval/Actions Max                              0.996516
eval/Actions Min                             -0.996665
eval/Num Paths                                5
eval/Average Returns                       6501.07
eval/env_infos/final/reward_run Mean          7.15797
eval/env_infos/final/reward_run Std           0.761205
eval/env_infos/final/reward_run Max           8.00603
eval/env_infos/final/reward_run Min           6.24262
eval/env_infos/initial/reward_run Mean       -0.374251
eval/env_infos/initial/reward_run Std         0.157597
eval/env_infos/initial/reward_run Max        -0.171455
eval/env_infos/initial/reward_run Min        -0.633785
eval/env_infos/reward_run Mean                6.9143
eval/env_infos/reward_run Std                 1.36897
eval/env_infos/reward_run Max                 9.46537
eval/env_infos/reward_run Min                -0.633785
eval/env_infos/final/reward_ctrl Mean        -0.449396
eval/env_infos/final/reward_ctrl Std          0.0474238
eval/env_infos/final/reward_ctrl Max         -0.394837
eval/env_infos/final/reward_ctrl Min         -0.510512
eval/env_infos/initial/reward_ctrl Mean      -0.21717
eval/env_infos/initial/reward_ctrl Std        0.0444915
eval/env_infos/initial/reward_ctrl Max       -0.160919
eval/env_infos/initial/reward_ctrl Min       -0.285729
eval/env_infos/reward_ctrl Mean              -0.413231
eval/env_infos/reward_ctrl Std                0.0797419
eval/env_infos/reward_ctrl Max               -0.108218
eval/env_infos/reward_ctrl Min               -0.57183
time/data storing (s)                         0.00452983
time/evaluation sampling (s)                  2.01189
time/exploration sampling (s)                 0.538127
time/logging (s)                              0.0136379
time/sac training (s)                         7.47747
time/saving (s)                               0.00376528
time/training (s)                             3.4001e-05
time/epoch (s)                               10.0495
time/total (s)                             4744.5
Epoch                                       450
---------------------------------------  ---------------
2021-11-24 01:48:31.524235 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 451 finished
---------------------------------------  ---------------
epoch                                       451
replay_buffer/size                       453000
trainer/num train calls                  452000
trainer/QF1 Loss                              7.70904
trainer/QF2 Loss                              7.93514
trainer/Policy Loss                        -419.118
trainer/Q1 Predictions Mean                 420.029
trainer/Q1 Predictions Std                   84.8859
trainer/Q1 Predictions Max                  485.759
trainer/Q1 Predictions Min                   22.0143
trainer/Q2 Predictions Mean                 419.922
trainer/Q2 Predictions Std                   84.9124
trainer/Q2 Predictions Max                  486.279
trainer/Q2 Predictions Min                   21.7629
trainer/Q Targets Mean                      419.316
trainer/Q Targets Std                        84.7429
trainer/Q Targets Max                       487.214
trainer/Q Targets Min                        22.4368
trainer/Log Pis Mean                          5.98921
trainer/Log Pis Std                           4.10369
trainer/Log Pis Max                          18.0616
trainer/Log Pis Min                          -6.73984
trainer/policy/mean Mean                      0.0761798
trainer/policy/mean Std                       0.787414
trainer/policy/mean Max                       0.999635
trainer/policy/mean Min                      -0.997242
trainer/policy/normal/std Mean                0.446461
trainer/policy/normal/std Std                 0.14175
trainer/policy/normal/std Max                 0.926645
trainer/policy/normal/std Min                 0.0673707
trainer/policy/normal/log_std Mean           -0.87686
trainer/policy/normal/log_std Std             0.419104
trainer/policy/normal/log_std Max            -0.076185
trainer/policy/normal/log_std Min            -2.69754
trainer/Alpha                                 0.15623
trainer/Alpha Loss                           -0.0200371
expl/num steps total                     453000
expl/num paths total                        453
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.01416
expl/Rewards Std                              1.25024
expl/Rewards Max                              8.55201
expl/Rewards Min                             -0.701469
expl/Returns Mean                          6014.16
expl/Returns Std                              0
expl/Returns Max                           6014.16
expl/Returns Min                           6014.16
expl/Actions Mean                             0.0797157
expl/Actions Std                              0.80225
expl/Actions Max                              0.999215
expl/Actions Min                             -0.99942
expl/Num Paths                                1
expl/Average Returns                       6014.16
expl/env_infos/final/reward_run Mean          6.72546
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.72546
expl/env_infos/final/reward_run Min           6.72546
expl/env_infos/initial/reward_run Mean       -0.0511504
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0511504
expl/env_infos/initial/reward_run Min        -0.0511504
expl/env_infos/reward_run Mean                6.40413
expl/env_infos/reward_run Std                 1.24548
expl/env_infos/reward_run Max                 8.84692
expl/env_infos/reward_run Min                -0.293981
expl/env_infos/final/reward_ctrl Mean        -0.432748
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.432748
expl/env_infos/final/reward_ctrl Min         -0.432748
expl/env_infos/initial/reward_ctrl Mean      -0.297753
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.297753
expl/env_infos/initial/reward_ctrl Min       -0.297753
expl/env_infos/reward_ctrl Mean              -0.389975
expl/env_infos/reward_ctrl Std                0.0890878
expl/env_infos/reward_ctrl Max               -0.0871583
expl/env_infos/reward_ctrl Min               -0.565203
eval/num steps total                          2.26e+06
eval/num paths total                       2260
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.29209
eval/Rewards Std                              1.29642
eval/Rewards Max                              8.74243
eval/Rewards Min                             -0.684685
eval/Returns Mean                          6292.09
eval/Returns Std                             54.6986
eval/Returns Max                           6349.21
eval/Returns Min                           6216.51
eval/Actions Mean                             0.0831486
eval/Actions Std                              0.811518
eval/Actions Max                              0.99712
eval/Actions Min                             -0.999358
eval/Num Paths                                5
eval/Average Returns                       6292.09
eval/env_infos/final/reward_run Mean          6.94421
eval/env_infos/final/reward_run Std           0.527089
eval/env_infos/final/reward_run Max           7.79715
eval/env_infos/final/reward_run Min           6.15859
eval/env_infos/initial/reward_run Mean        0.105546
eval/env_infos/initial/reward_run Std         0.492066
eval/env_infos/initial/reward_run Max         1.0152
eval/env_infos/initial/reward_run Min        -0.463923
eval/env_infos/reward_run Mean                6.69137
eval/env_infos/reward_run Std                 1.29704
eval/env_infos/reward_run Max                 9.29878
eval/env_infos/reward_run Min                -0.463923
eval/env_infos/final/reward_ctrl Mean        -0.360966
eval/env_infos/final/reward_ctrl Std          0.0624465
eval/env_infos/final/reward_ctrl Max         -0.295378
eval/env_infos/final/reward_ctrl Min         -0.469124
eval/env_infos/initial/reward_ctrl Mean      -0.227691
eval/env_infos/initial/reward_ctrl Std        0.0978869
eval/env_infos/initial/reward_ctrl Max       -0.0933086
eval/env_infos/initial/reward_ctrl Min       -0.369884
eval/env_infos/reward_ctrl Mean              -0.399285
eval/env_infos/reward_ctrl Std                0.0872198
eval/env_infos/reward_ctrl Max               -0.0824542
eval/env_infos/reward_ctrl Min               -0.571698
time/data storing (s)                         0.00451389
time/evaluation sampling (s)                  2.01512
time/exploration sampling (s)                 0.538565
time/logging (s)                              0.0135652
time/sac training (s)                         7.46505
time/saving (s)                               0.00376406
time/training (s)                             3.5747e-05
time/epoch (s)                               10.0406
time/total (s)                             4754.82
Epoch                                       451
---------------------------------------  ---------------
2021-11-24 01:48:41.850071 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 452 finished
---------------------------------------  ---------------
epoch                                       452
replay_buffer/size                       454000
trainer/num train calls                  453000
trainer/QF1 Loss                              5.91509
trainer/QF2 Loss                              6.29935
trainer/Policy Loss                        -420.023
trainer/Q1 Predictions Mean                 420.752
trainer/Q1 Predictions Std                   77.6335
trainer/Q1 Predictions Max                  491.505
trainer/Q1 Predictions Min                   23.5601
trainer/Q2 Predictions Mean                 420.536
trainer/Q2 Predictions Std                   77.6904
trainer/Q2 Predictions Max                  490.989
trainer/Q2 Predictions Min                   22.7392
trainer/Q Targets Mean                      421.231
trainer/Q Targets Std                        77.81
trainer/Q Targets Max                       491.709
trainer/Q Targets Min                        22.9176
trainer/Log Pis Mean                          5.9152
trainer/Log Pis Std                           4.06398
trainer/Log Pis Max                          15.3505
trainer/Log Pis Min                          -6.4001
trainer/policy/mean Mean                      0.101035
trainer/policy/mean Std                       0.775619
trainer/policy/mean Max                       0.996488
trainer/policy/mean Min                      -0.996834
trainer/policy/normal/std Mean                0.435134
trainer/policy/normal/std Std                 0.140074
trainer/policy/normal/std Max                 1.08912
trainer/policy/normal/std Min                 0.0699755
trainer/policy/normal/log_std Mean           -0.905577
trainer/policy/normal/log_std Std             0.429582
trainer/policy/normal/log_std Max             0.0853656
trainer/policy/normal/log_std Min            -2.65961
trainer/Alpha                                 0.156229
trainer/Alpha Loss                           -0.157421
expl/num steps total                     454000
expl/num paths total                        454
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.15522
expl/Rewards Std                              1.28288
expl/Rewards Max                              8.67554
expl/Rewards Min                             -0.52249
expl/Returns Mean                          6155.22
expl/Returns Std                              0
expl/Returns Max                           6155.22
expl/Returns Min                           6155.22
expl/Actions Mean                             0.103966
expl/Actions Std                              0.795106
expl/Actions Max                              0.999646
expl/Actions Min                             -0.999435
expl/Num Paths                                1
expl/Average Returns                       6155.22
expl/env_infos/final/reward_run Mean          5.9141
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.9141
expl/env_infos/final/reward_run Min           5.9141
expl/env_infos/initial/reward_run Mean        0.293341
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.293341
expl/env_infos/initial/reward_run Min         0.293341
expl/env_infos/reward_run Mean                6.54102
expl/env_infos/reward_run Std                 1.2752
expl/env_infos/reward_run Max                 9.1135
expl/env_infos/reward_run Min                -0.0824535
expl/env_infos/final/reward_ctrl Mean        -0.383175
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.383175
expl/env_infos/final/reward_ctrl Min         -0.383175
expl/env_infos/initial/reward_ctrl Mean      -0.231916
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.231916
expl/env_infos/initial/reward_ctrl Min       -0.231916
expl/env_infos/reward_ctrl Mean              -0.385801
expl/env_infos/reward_ctrl Std                0.0863125
expl/env_infos/reward_ctrl Max               -0.0752037
expl/env_infos/reward_ctrl Min               -0.57064
eval/num steps total                          2.265e+06
eval/num paths total                       2265
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.3906
eval/Rewards Std                              1.33162
eval/Rewards Max                              8.94785
eval/Rewards Min                             -0.794378
eval/Returns Mean                          6390.6
eval/Returns Std                             39.5226
eval/Returns Max                           6440.47
eval/Returns Min                           6321.93
eval/Actions Mean                             0.101416
eval/Actions Std                              0.815296
eval/Actions Max                              0.997566
eval/Actions Min                             -0.997474
eval/Num Paths                                5
eval/Average Returns                       6390.6
eval/env_infos/final/reward_run Mean          7.14228
eval/env_infos/final/reward_run Std           1.31678
eval/env_infos/final/reward_run Max           8.88644
eval/env_infos/final/reward_run Min           5.33927
eval/env_infos/initial/reward_run Mean       -0.361688
eval/env_infos/initial/reward_run Std         0.153345
eval/env_infos/initial/reward_run Max        -0.220839
eval/env_infos/initial/reward_run Min        -0.559784
eval/env_infos/reward_run Mean                6.7956
eval/env_infos/reward_run Std                 1.3268
eval/env_infos/reward_run Max                 9.40648
eval/env_infos/reward_run Min                -0.559784
eval/env_infos/final/reward_ctrl Mean        -0.433891
eval/env_infos/final/reward_ctrl Std          0.0943526
eval/env_infos/final/reward_ctrl Max         -0.290303
eval/env_infos/final/reward_ctrl Min         -0.541278
eval/env_infos/initial/reward_ctrl Mean      -0.179629
eval/env_infos/initial/reward_ctrl Std        0.0304413
eval/env_infos/initial/reward_ctrl Max       -0.141152
eval/env_infos/initial/reward_ctrl Min       -0.231725
eval/env_infos/reward_ctrl Mean              -0.404995
eval/env_infos/reward_ctrl Std                0.0844453
eval/env_infos/reward_ctrl Max               -0.0415451
eval/env_infos/reward_ctrl Min               -0.576117
time/data storing (s)                         0.00449759
time/evaluation sampling (s)                  1.99638
time/exploration sampling (s)                 0.531297
time/logging (s)                              0.0136269
time/sac training (s)                         7.47846
time/saving (s)                               0.00377418
time/training (s)                             3.3947e-05
time/epoch (s)                               10.0281
time/total (s)                             4765.13
Epoch                                       452
---------------------------------------  ---------------
2021-11-24 01:48:52.131361 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 453 finished
---------------------------------------  ---------------
epoch                                       453
replay_buffer/size                       455000
trainer/num train calls                  454000
trainer/QF1 Loss                              5.73167
trainer/QF2 Loss                              5.23838
trainer/Policy Loss                        -421.696
trainer/Q1 Predictions Mean                 422.555
trainer/Q1 Predictions Std                   88.1951
trainer/Q1 Predictions Max                  485.551
trainer/Q1 Predictions Min                   22.0098
trainer/Q2 Predictions Mean                 422.647
trainer/Q2 Predictions Std                   88.3265
trainer/Q2 Predictions Max                  485.296
trainer/Q2 Predictions Min                   22.2282
trainer/Q Targets Mean                      423.04
trainer/Q Targets Std                        88.3285
trainer/Q Targets Max                       487.769
trainer/Q Targets Min                        22.3768
trainer/Log Pis Mean                          5.67349
trainer/Log Pis Std                           4.22948
trainer/Log Pis Max                          19.0776
trainer/Log Pis Min                          -5.90643
trainer/policy/mean Mean                      0.0781696
trainer/policy/mean Std                       0.779887
trainer/policy/mean Max                       0.999588
trainer/policy/mean Min                      -0.998052
trainer/policy/normal/std Mean                0.447992
trainer/policy/normal/std Std                 0.144085
trainer/policy/normal/std Max                 0.97271
trainer/policy/normal/std Min                 0.076071
trainer/policy/normal/log_std Mean           -0.87419
trainer/policy/normal/log_std Std             0.418726
trainer/policy/normal/log_std Max            -0.0276691
trainer/policy/normal/log_std Min            -2.57609
trainer/Alpha                                 0.157223
trainer/Alpha Loss                           -0.604078
expl/num steps total                     455000
expl/num paths total                        455
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11528
expl/Rewards Std                              1.28086
expl/Rewards Max                              8.63609
expl/Rewards Min                             -0.868413
expl/Returns Mean                          6115.28
expl/Returns Std                              0
expl/Returns Max                           6115.28
expl/Returns Min                           6115.28
expl/Actions Mean                             0.102963
expl/Actions Std                              0.80083
expl/Actions Max                              0.999513
expl/Actions Min                             -0.999547
expl/Num Paths                                1
expl/Average Returns                       6115.28
expl/env_infos/final/reward_run Mean          7.48648
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.48648
expl/env_infos/final/reward_run Min           7.48648
expl/env_infos/initial/reward_run Mean       -0.580772
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.580772
expl/env_infos/initial/reward_run Min        -0.580772
expl/env_infos/reward_run Mean                6.50644
expl/env_infos/reward_run Std                 1.27782
expl/env_infos/reward_run Max                 9.15306
expl/env_infos/reward_run Min                -0.580772
expl/env_infos/final/reward_ctrl Mean        -0.410095
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.410095
expl/env_infos/final/reward_ctrl Min         -0.410095
expl/env_infos/initial/reward_ctrl Mean      -0.287641
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.287641
expl/env_infos/initial/reward_ctrl Min       -0.287641
expl/env_infos/reward_ctrl Mean              -0.391158
expl/env_infos/reward_ctrl Std                0.0856824
expl/env_infos/reward_ctrl Max               -0.128355
expl/env_infos/reward_ctrl Min               -0.577393
eval/num steps total                          2.27e+06
eval/num paths total                       2270
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.5055
eval/Rewards Std                              1.31278
eval/Rewards Max                              9.04298
eval/Rewards Min                             -0.622811
eval/Returns Mean                          6505.5
eval/Returns Std                             89.7024
eval/Returns Max                           6594.55
eval/Returns Min                           6389.5
eval/Actions Mean                             0.102333
eval/Actions Std                              0.815683
eval/Actions Max                              0.996423
eval/Actions Min                             -0.997127
eval/Num Paths                                5
eval/Average Returns                       6505.5
eval/env_infos/final/reward_run Mean          7.14245
eval/env_infos/final/reward_run Std           0.710029
eval/env_infos/final/reward_run Max           8.18184
eval/env_infos/final/reward_run Min           6.0017
eval/env_infos/initial/reward_run Mean        0.119472
eval/env_infos/initial/reward_run Std         0.426321
eval/env_infos/initial/reward_run Max         0.831583
eval/env_infos/initial/reward_run Min        -0.46819
eval/env_infos/reward_run Mean                6.91098
eval/env_infos/reward_run Std                 1.30941
eval/env_infos/reward_run Max                 9.49308
eval/env_infos/reward_run Min                -0.46819
eval/env_infos/final/reward_ctrl Mean        -0.373161
eval/env_infos/final/reward_ctrl Std          0.116796
eval/env_infos/final/reward_ctrl Max         -0.199548
eval/env_infos/final/reward_ctrl Min         -0.528947
eval/env_infos/initial/reward_ctrl Mean      -0.167689
eval/env_infos/initial/reward_ctrl Std        0.0553105
eval/env_infos/initial/reward_ctrl Max       -0.0870463
eval/env_infos/initial/reward_ctrl Min       -0.243694
eval/env_infos/reward_ctrl Mean              -0.405486
eval/env_infos/reward_ctrl Std                0.0830816
eval/env_infos/reward_ctrl Max               -0.0711686
eval/env_infos/reward_ctrl Min               -0.576271
time/data storing (s)                         0.00453491
time/evaluation sampling (s)                  2.00884
time/exploration sampling (s)                 0.51708
time/logging (s)                              0.0136437
time/sac training (s)                         7.43522
time/saving (s)                               0.00378488
time/training (s)                             3.4494e-05
time/epoch (s)                                9.98314
time/total (s)                             4775.4
Epoch                                       453
---------------------------------------  ---------------
2021-11-24 01:49:02.430425 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 454 finished
---------------------------------------  ---------------
epoch                                       454
replay_buffer/size                       456000
trainer/num train calls                  455000
trainer/QF1 Loss                              3.5933
trainer/QF2 Loss                              3.63854
trainer/Policy Loss                        -421.931
trainer/Q1 Predictions Mean                 422.915
trainer/Q1 Predictions Std                   92.6549
trainer/Q1 Predictions Max                  488.919
trainer/Q1 Predictions Min                   22.6887
trainer/Q2 Predictions Mean                 422.857
trainer/Q2 Predictions Std                   92.6657
trainer/Q2 Predictions Max                  489.81
trainer/Q2 Predictions Min                   22.2309
trainer/Q Targets Mean                      422.684
trainer/Q Targets Std                        92.4918
trainer/Q Targets Max                       489.326
trainer/Q Targets Min                        22.6242
trainer/Log Pis Mean                          6.16694
trainer/Log Pis Std                           4.27628
trainer/Log Pis Max                          15.6135
trainer/Log Pis Min                          -4.99552
trainer/policy/mean Mean                      0.0535084
trainer/policy/mean Std                       0.788779
trainer/policy/mean Max                       0.994956
trainer/policy/mean Min                      -0.996605
trainer/policy/normal/std Mean                0.440338
trainer/policy/normal/std Std                 0.141245
trainer/policy/normal/std Max                 0.874521
trainer/policy/normal/std Min                 0.0624684
trainer/policy/normal/log_std Mean           -0.890775
trainer/policy/normal/log_std Std             0.416254
trainer/policy/normal/log_std Max            -0.134079
trainer/policy/normal/log_std Min            -2.77309
trainer/Alpha                                 0.158004
trainer/Alpha Loss                            0.308019
expl/num steps total                     456000
expl/num paths total                        456
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.91596
expl/Rewards Std                              1.27419
expl/Rewards Max                              8.58761
expl/Rewards Min                             -0.889138
expl/Returns Mean                          5915.96
expl/Returns Std                              0
expl/Returns Max                           5915.96
expl/Returns Min                           5915.96
expl/Actions Mean                             0.0863536
expl/Actions Std                              0.805133
expl/Actions Max                              0.999822
expl/Actions Min                             -0.999788
expl/Num Paths                                1
expl/Average Returns                       5915.96
expl/env_infos/final/reward_run Mean          6.88956
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.88956
expl/env_infos/final/reward_run Min           6.88956
expl/env_infos/initial/reward_run Mean       -0.620274
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.620274
expl/env_infos/initial/reward_run Min        -0.620274
expl/env_infos/reward_run Mean                6.30938
expl/env_infos/reward_run Std                 1.26965
expl/env_infos/reward_run Max                 9.03194
expl/env_infos/reward_run Min                -0.620274
expl/env_infos/final/reward_ctrl Mean        -0.323355
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.323355
expl/env_infos/final/reward_ctrl Min         -0.323355
expl/env_infos/initial/reward_ctrl Mean      -0.268863
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.268863
expl/env_infos/initial/reward_ctrl Min       -0.268863
expl/env_infos/reward_ctrl Mean              -0.393418
expl/env_infos/reward_ctrl Std                0.0884789
expl/env_infos/reward_ctrl Max               -0.11773
expl/env_infos/reward_ctrl Min               -0.578676
eval/num steps total                          2.275e+06
eval/num paths total                       2275
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.4422
eval/Rewards Std                              1.37645
eval/Rewards Max                              9.20543
eval/Rewards Min                             -0.811813
eval/Returns Mean                          6442.2
eval/Returns Std                            122.093
eval/Returns Max                           6608.82
eval/Returns Min                           6268.51
eval/Actions Mean                             0.0780513
eval/Actions Std                              0.824125
eval/Actions Max                              0.996436
eval/Actions Min                             -0.997379
eval/Num Paths                                5
eval/Average Returns                       6442.2
eval/env_infos/final/reward_run Mean          7.25759
eval/env_infos/final/reward_run Std           0.695976
eval/env_infos/final/reward_run Max           8.10932
eval/env_infos/final/reward_run Min           6.35902
eval/env_infos/initial/reward_run Mean       -0.413131
eval/env_infos/initial/reward_run Std         0.121365
eval/env_infos/initial/reward_run Max        -0.288024
eval/env_infos/initial/reward_run Min        -0.578351
eval/env_infos/reward_run Mean                6.85337
eval/env_infos/reward_run Std                 1.3744
eval/env_infos/reward_run Max                 9.66371
eval/env_infos/reward_run Min                -0.578351
eval/env_infos/final/reward_ctrl Mean        -0.363002
eval/env_infos/final/reward_ctrl Std          0.0948778
eval/env_infos/final/reward_ctrl Max         -0.190346
eval/env_infos/final/reward_ctrl Min         -0.466583
eval/env_infos/initial/reward_ctrl Mean      -0.219439
eval/env_infos/initial/reward_ctrl Std        0.0388635
eval/env_infos/initial/reward_ctrl Max       -0.163306
eval/env_infos/initial/reward_ctrl Min       -0.262942
eval/env_infos/reward_ctrl Mean              -0.411164
eval/env_infos/reward_ctrl Std                0.085464
eval/env_infos/reward_ctrl Max               -0.10034
eval/env_infos/reward_ctrl Min               -0.579494
time/data storing (s)                         0.0045274
time/evaluation sampling (s)                  2.01835
time/exploration sampling (s)                 0.540466
time/logging (s)                              0.0137336
time/sac training (s)                         7.42303
time/saving (s)                               0.00376591
time/training (s)                             3.5028e-05
time/epoch (s)                               10.0039
time/total (s)                             4785.68
Epoch                                       454
---------------------------------------  ---------------
2021-11-24 01:49:12.737646 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 455 finished
---------------------------------------  ---------------
epoch                                       455
replay_buffer/size                       457000
trainer/num train calls                  456000
trainer/QF1 Loss                              4.28278
trainer/QF2 Loss                             27.8213
trainer/Policy Loss                        -409.448
trainer/Q1 Predictions Mean                 409.853
trainer/Q1 Predictions Std                  107.56
trainer/Q1 Predictions Max                  483.42
trainer/Q1 Predictions Min                   20.2854
trainer/Q2 Predictions Mean                 410.193
trainer/Q2 Predictions Std                  106.789
trainer/Q2 Predictions Max                  483.817
trainer/Q2 Predictions Min                   21.24
trainer/Q Targets Mean                      410.455
trainer/Q Targets Std                       107.577
trainer/Q Targets Max                       485.457
trainer/Q Targets Min                        22.9912
trainer/Log Pis Mean                          6.29314
trainer/Log Pis Std                           4.23045
trainer/Log Pis Max                          17.7092
trainer/Log Pis Min                          -5.6176
trainer/policy/mean Mean                      0.0820282
trainer/policy/mean Std                       0.78886
trainer/policy/mean Max                       0.998685
trainer/policy/mean Min                      -0.996828
trainer/policy/normal/std Mean                0.449718
trainer/policy/normal/std Std                 0.143054
trainer/policy/normal/std Max                 0.92737
trainer/policy/normal/std Min                 0.0651792
trainer/policy/normal/log_std Mean           -0.870091
trainer/policy/normal/log_std Std             0.42201
trainer/policy/normal/log_std Max            -0.0754028
trainer/policy/normal/log_std Min            -2.73062
trainer/Alpha                                 0.157593
trainer/Alpha Loss                            0.541637
expl/num steps total                     457000
expl/num paths total                        457
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.92197
expl/Rewards Std                              1.2721
expl/Rewards Max                              8.25573
expl/Rewards Min                             -1.04268
expl/Returns Mean                          5921.97
expl/Returns Std                              0
expl/Returns Max                           5921.97
expl/Returns Min                           5921.97
expl/Actions Mean                             0.0841757
expl/Actions Std                              0.802271
expl/Actions Max                              0.999359
expl/Actions Min                             -0.998923
expl/Num Paths                                1
expl/Average Returns                       5921.97
expl/env_infos/final/reward_run Mean          5.12991
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.12991
expl/env_infos/final/reward_run Min           5.12991
expl/env_infos/initial/reward_run Mean        0.827114
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.827114
expl/env_infos/initial/reward_run Min         0.827114
expl/env_infos/reward_run Mean                6.31241
expl/env_infos/reward_run Std                 1.26645
expl/env_infos/reward_run Max                 8.75379
expl/env_infos/reward_run Min                -0.605944
expl/env_infos/final/reward_ctrl Mean        -0.439859
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.439859
expl/env_infos/final/reward_ctrl Min         -0.439859
expl/env_infos/initial/reward_ctrl Mean      -0.370012
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.370012
expl/env_infos/initial/reward_ctrl Min       -0.370012
expl/env_infos/reward_ctrl Mean              -0.390434
expl/env_infos/reward_ctrl Std                0.0873412
expl/env_infos/reward_ctrl Max               -0.0652191
expl/env_infos/reward_ctrl Min               -0.56525
eval/num steps total                          2.28e+06
eval/num paths total                       2280
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.38585
eval/Rewards Std                              1.32867
eval/Rewards Max                              8.90798
eval/Rewards Min                             -0.76823
eval/Returns Mean                          6385.85
eval/Returns Std                            120.134
eval/Returns Max                           6580.99
eval/Returns Min                           6235.11
eval/Actions Mean                             0.0802568
eval/Actions Std                              0.822218
eval/Actions Max                              0.99731
eval/Actions Min                             -0.997437
eval/Num Paths                                5
eval/Average Returns                       6385.85
eval/env_infos/final/reward_run Mean          8.07269
eval/env_infos/final/reward_run Std           0.59233
eval/env_infos/final/reward_run Max           8.89616
eval/env_infos/final/reward_run Min           7.10295
eval/env_infos/initial/reward_run Mean       -0.349397
eval/env_infos/initial/reward_run Std         0.11881
eval/env_infos/initial/reward_run Max        -0.186324
eval/env_infos/initial/reward_run Min        -0.540926
eval/env_infos/reward_run Mean                6.79534
eval/env_infos/reward_run Std                 1.32406
eval/env_infos/reward_run Max                 9.45682
eval/env_infos/reward_run Min                -0.540926
eval/env_infos/final/reward_ctrl Mean        -0.442981
eval/env_infos/final/reward_ctrl Std          0.0467611
eval/env_infos/final/reward_ctrl Max         -0.379598
eval/env_infos/final/reward_ctrl Min         -0.500804
eval/env_infos/initial/reward_ctrl Mean      -0.174009
eval/env_infos/initial/reward_ctrl Std        0.0346148
eval/env_infos/initial/reward_ctrl Max       -0.123559
eval/env_infos/initial/reward_ctrl Min       -0.230698
eval/env_infos/reward_ctrl Mean              -0.40949
eval/env_infos/reward_ctrl Std                0.0855187
eval/env_infos/reward_ctrl Max               -0.0854855
eval/env_infos/reward_ctrl Min               -0.579089
time/data storing (s)                         0.00450987
time/evaluation sampling (s)                  2.02091
time/exploration sampling (s)                 0.533085
time/logging (s)                              0.0136911
time/sac training (s)                         7.43468
time/saving (s)                               0.00377659
time/training (s)                             3.5136e-05
time/epoch (s)                               10.0107
time/total (s)                             4795.98
Epoch                                       455
---------------------------------------  ---------------
2021-11-24 01:49:23.037822 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 456 finished
---------------------------------------  ---------------
epoch                                       456
replay_buffer/size                       458000
trainer/num train calls                  457000
trainer/QF1 Loss                              4.77533
trainer/QF2 Loss                              4.93471
trainer/Policy Loss                        -430.169
trainer/Q1 Predictions Mean                 430.806
trainer/Q1 Predictions Std                   71.9824
trainer/Q1 Predictions Max                  490.067
trainer/Q1 Predictions Min                   21.6223
trainer/Q2 Predictions Mean                 430.935
trainer/Q2 Predictions Std                   71.8656
trainer/Q2 Predictions Max                  489.516
trainer/Q2 Predictions Min                   21.9619
trainer/Q Targets Mean                      430.704
trainer/Q Targets Std                        72.0723
trainer/Q Targets Max                       489.334
trainer/Q Targets Min                        21.607
trainer/Log Pis Mean                          6.15465
trainer/Log Pis Std                           4.22911
trainer/Log Pis Max                          15.1434
trainer/Log Pis Min                          -7.04422
trainer/policy/mean Mean                      0.0911072
trainer/policy/mean Std                       0.787517
trainer/policy/mean Max                       0.995569
trainer/policy/mean Min                      -0.99697
trainer/policy/normal/std Mean                0.443575
trainer/policy/normal/std Std                 0.139161
trainer/policy/normal/std Max                 0.908827
trainer/policy/normal/std Min                 0.0664825
trainer/policy/normal/log_std Mean           -0.884526
trainer/policy/normal/log_std Std             0.426002
trainer/policy/normal/log_std Max            -0.0956009
trainer/policy/normal/log_std Min            -2.71082
trainer/Alpha                                 0.157122
trainer/Alpha Loss                            0.28622
expl/num steps total                     458000
expl/num paths total                        458
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.94108
expl/Rewards Std                              1.29822
expl/Rewards Max                              8.61798
expl/Rewards Min                             -0.505437
expl/Returns Mean                          5941.08
expl/Returns Std                              0
expl/Returns Max                           5941.08
expl/Returns Min                           5941.08
expl/Actions Mean                             0.0963955
expl/Actions Std                              0.79807
expl/Actions Max                              0.999465
expl/Actions Min                             -0.999611
expl/Num Paths                                1
expl/Average Returns                       5941.08
expl/env_infos/final/reward_run Mean          7.41439
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.41439
expl/env_infos/final/reward_run Min           7.41439
expl/env_infos/initial/reward_run Mean       -0.250225
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.250225
expl/env_infos/initial/reward_run Min        -0.250225
expl/env_infos/reward_run Mean                6.32881
expl/env_infos/reward_run Std                 1.29752
expl/env_infos/reward_run Max                 9.07679
expl/env_infos/reward_run Min                -0.250225
expl/env_infos/final/reward_ctrl Mean        -0.380581
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.380581
expl/env_infos/final/reward_ctrl Min         -0.380581
expl/env_infos/initial/reward_ctrl Mean      -0.255212
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.255212
expl/env_infos/initial/reward_ctrl Min       -0.255212
expl/env_infos/reward_ctrl Mean              -0.387724
expl/env_infos/reward_ctrl Std                0.0860517
expl/env_infos/reward_ctrl Max               -0.0464008
expl/env_infos/reward_ctrl Min               -0.582714
eval/num steps total                          2.285e+06
eval/num paths total                       2285
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.54459
eval/Rewards Std                              1.35817
eval/Rewards Max                              9.07725
eval/Rewards Min                             -0.79648
eval/Returns Mean                          6544.59
eval/Returns Std                             64.5459
eval/Returns Max                           6627.7
eval/Returns Min                           6443.03
eval/Actions Mean                             0.0987782
eval/Actions Std                              0.821908
eval/Actions Max                              0.996573
eval/Actions Min                             -0.996617
eval/Num Paths                                5
eval/Average Returns                       6544.59
eval/env_infos/final/reward_run Mean          7.30749
eval/env_infos/final/reward_run Std           0.5354
eval/env_infos/final/reward_run Max           8.09652
eval/env_infos/final/reward_run Min           6.43908
eval/env_infos/initial/reward_run Mean       -0.337556
eval/env_infos/initial/reward_run Std         0.269588
eval/env_infos/initial/reward_run Max         0.142861
eval/env_infos/initial/reward_run Min        -0.578788
eval/env_infos/reward_run Mean                6.95576
eval/env_infos/reward_run Std                 1.35697
eval/env_infos/reward_run Max                 9.60628
eval/env_infos/reward_run Min                -0.578788
eval/env_infos/final/reward_ctrl Mean        -0.37566
eval/env_infos/final/reward_ctrl Std          0.0719562
eval/env_infos/final/reward_ctrl Max         -0.285085
eval/env_infos/final/reward_ctrl Min         -0.476502
eval/env_infos/initial/reward_ctrl Mean      -0.189342
eval/env_infos/initial/reward_ctrl Std        0.0419417
eval/env_infos/initial/reward_ctrl Max       -0.11557
eval/env_infos/initial/reward_ctrl Min       -0.235043
eval/env_infos/reward_ctrl Mean              -0.411174
eval/env_infos/reward_ctrl Std                0.0832348
eval/env_infos/reward_ctrl Max               -0.0650228
eval/env_infos/reward_ctrl Min               -0.573715
time/data storing (s)                         0.00452718
time/evaluation sampling (s)                  2.01952
time/exploration sampling (s)                 0.54233
time/logging (s)                              0.0136376
time/sac training (s)                         7.41938
time/saving (s)                               0.00375993
time/training (s)                             3.4447e-05
time/epoch (s)                               10.0032
time/total (s)                             4806.26
Epoch                                       456
---------------------------------------  ---------------
2021-11-24 01:49:33.321363 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 457 finished
---------------------------------------  ---------------
epoch                                       457
replay_buffer/size                       459000
trainer/num train calls                  458000
trainer/QF1 Loss                              5.74076
trainer/QF2 Loss                              5.97479
trainer/Policy Loss                        -419.05
trainer/Q1 Predictions Mean                 419.517
trainer/Q1 Predictions Std                   94.538
trainer/Q1 Predictions Max                  485.974
trainer/Q1 Predictions Min                   21.7015
trainer/Q2 Predictions Mean                 419.995
trainer/Q2 Predictions Std                   94.4207
trainer/Q2 Predictions Max                  488.155
trainer/Q2 Predictions Min                   23.2939
trainer/Q Targets Mean                      419.05
trainer/Q Targets Std                        94.4835
trainer/Q Targets Max                       487.739
trainer/Q Targets Min                        22.208
trainer/Log Pis Mean                          6.30035
trainer/Log Pis Std                           3.99166
trainer/Log Pis Max                          15.1403
trainer/Log Pis Min                          -4.64471
trainer/policy/mean Mean                      0.0697696
trainer/policy/mean Std                       0.780159
trainer/policy/mean Max                       0.995844
trainer/policy/mean Min                      -0.996293
trainer/policy/normal/std Mean                0.44183
trainer/policy/normal/std Std                 0.143881
trainer/policy/normal/std Max                 1.54721
trainer/policy/normal/std Min                 0.0759157
trainer/policy/normal/log_std Mean           -0.888543
trainer/policy/normal/log_std Std             0.420161
trainer/policy/normal/log_std Max             0.436453
trainer/policy/normal/log_std Min            -2.57813
trainer/Alpha                                 0.156866
trainer/Alpha Loss                            0.556363
expl/num steps total                     459000
expl/num paths total                        459
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.09354
expl/Rewards Std                              1.31665
expl/Rewards Max                              8.80969
expl/Rewards Min                             -0.497554
expl/Returns Mean                          6093.54
expl/Returns Std                              0
expl/Returns Max                           6093.54
expl/Returns Min                           6093.54
expl/Actions Mean                             0.0899531
expl/Actions Std                              0.799713
expl/Actions Max                              0.999827
expl/Actions Min                             -0.999761
expl/Num Paths                                1
expl/Average Returns                       6093.54
expl/env_infos/final/reward_run Mean          6.82162
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.82162
expl/env_infos/final/reward_run Min           6.82162
expl/env_infos/initial/reward_run Mean       -0.30951
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.30951
expl/env_infos/initial/reward_run Min        -0.30951
expl/env_infos/reward_run Mean                6.48212
expl/env_infos/reward_run Std                 1.31682
expl/env_infos/reward_run Max                 9.35283
expl/env_infos/reward_run Min                -0.30951
expl/env_infos/final/reward_ctrl Mean        -0.347738
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.347738
expl/env_infos/final/reward_ctrl Min         -0.347738
expl/env_infos/initial/reward_ctrl Mean      -0.188044
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.188044
expl/env_infos/initial/reward_ctrl Min       -0.188044
expl/env_infos/reward_ctrl Mean              -0.38858
expl/env_infos/reward_ctrl Std                0.0927445
expl/env_infos/reward_ctrl Max               -0.0792932
expl/env_infos/reward_ctrl Min               -0.577579
eval/num steps total                          2.29e+06
eval/num paths total                       2290
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.30269
eval/Rewards Std                              1.34841
eval/Rewards Max                              8.92261
eval/Rewards Min                             -0.771853
eval/Returns Mean                          6302.69
eval/Returns Std                            136.957
eval/Returns Max                           6535.3
eval/Returns Min                           6120.9
eval/Actions Mean                             0.09269
eval/Actions Std                              0.812488
eval/Actions Max                              0.997194
eval/Actions Min                             -0.998879
eval/Num Paths                                5
eval/Average Returns                       6302.69
eval/env_infos/final/reward_run Mean          7.13766
eval/env_infos/final/reward_run Std           0.972852
eval/env_infos/final/reward_run Max           8.89067
eval/env_infos/final/reward_run Min           6.30342
eval/env_infos/initial/reward_run Mean       -0.254994
eval/env_infos/initial/reward_run Std         0.21617
eval/env_infos/initial/reward_run Max         0.065911
eval/env_infos/initial/reward_run Min        -0.501412
eval/env_infos/reward_run Mean                6.70392
eval/env_infos/reward_run Std                 1.34141
eval/env_infos/reward_run Max                 9.45511
eval/env_infos/reward_run Min                -0.501412
eval/env_infos/final/reward_ctrl Mean        -0.441735
eval/env_infos/final/reward_ctrl Std          0.0492602
eval/env_infos/final/reward_ctrl Max         -0.370065
eval/env_infos/final/reward_ctrl Min         -0.513288
eval/env_infos/initial/reward_ctrl Mean      -0.208978
eval/env_infos/initial/reward_ctrl Std        0.0229928
eval/env_infos/initial/reward_ctrl Max       -0.186031
eval/env_infos/initial/reward_ctrl Min       -0.249172
eval/env_infos/reward_ctrl Mean              -0.401237
eval/env_infos/reward_ctrl Std                0.0892021
eval/env_infos/reward_ctrl Max               -0.086017
eval/env_infos/reward_ctrl Min               -0.579187
time/data storing (s)                         0.00449547
time/evaluation sampling (s)                  2.00463
time/exploration sampling (s)                 0.53636
time/logging (s)                              0.0136431
time/sac training (s)                         7.42648
time/saving (s)                               0.00376249
time/training (s)                             3.445e-05
time/epoch (s)                                9.98941
time/total (s)                             4816.53
Epoch                                       457
---------------------------------------  ---------------
2021-11-24 01:49:43.605420 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 458 finished
---------------------------------------  ----------------
epoch                                       458
replay_buffer/size                       460000
trainer/num train calls                  459000
trainer/QF1 Loss                              7.23968
trainer/QF2 Loss                              6.51484
trainer/Policy Loss                        -410.483
trainer/Q1 Predictions Mean                 411.097
trainer/Q1 Predictions Std                  103.894
trainer/Q1 Predictions Max                  489.86
trainer/Q1 Predictions Min                   24.0645
trainer/Q2 Predictions Mean                 410.982
trainer/Q2 Predictions Std                  103.819
trainer/Q2 Predictions Max                  489.74
trainer/Q2 Predictions Min                   23.5056
trainer/Q Targets Mean                      410.305
trainer/Q Targets Std                       103.782
trainer/Q Targets Max                       491.003
trainer/Q Targets Min                        23.743
trainer/Log Pis Mean                          5.508
trainer/Log Pis Std                           4.29233
trainer/Log Pis Max                          15.7408
trainer/Log Pis Min                          -6.94981
trainer/policy/mean Mean                      0.0837797
trainer/policy/mean Std                       0.768613
trainer/policy/mean Max                       0.996477
trainer/policy/mean Min                      -0.995529
trainer/policy/normal/std Mean                0.45468
trainer/policy/normal/std Std                 0.153901
trainer/policy/normal/std Max                 1.14477
trainer/policy/normal/std Min                 0.0728282
trainer/policy/normal/log_std Mean           -0.864
trainer/policy/normal/log_std Std             0.430353
trainer/policy/normal/log_std Max             0.135203
trainer/policy/normal/log_std Min            -2.61965
trainer/Alpha                                 0.155596
trainer/Alpha Loss                           -0.91537
expl/num steps total                     460000
expl/num paths total                        460
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11224
expl/Rewards Std                              1.31903
expl/Rewards Max                              8.67974
expl/Rewards Min                             -0.378727
expl/Returns Mean                          6112.24
expl/Returns Std                              0
expl/Returns Max                           6112.24
expl/Returns Min                           6112.24
expl/Actions Mean                             0.109379
expl/Actions Std                              0.803133
expl/Actions Max                              0.999482
expl/Actions Min                             -0.999541
expl/Num Paths                                1
expl/Average Returns                       6112.24
expl/env_infos/final/reward_run Mean          7.98057
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.98057
expl/env_infos/final/reward_run Min           7.98057
expl/env_infos/initial/reward_run Mean       -0.126035
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.126035
expl/env_infos/initial/reward_run Min        -0.126035
expl/env_infos/reward_run Mean                6.50643
expl/env_infos/reward_run Std                 1.31563
expl/env_infos/reward_run Max                 9.21334
expl/env_infos/reward_run Min                -0.126035
expl/env_infos/final/reward_ctrl Mean        -0.309543
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.309543
expl/env_infos/final/reward_ctrl Min         -0.309543
expl/env_infos/initial/reward_ctrl Mean      -0.252693
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.252693
expl/env_infos/initial/reward_ctrl Min       -0.252693
expl/env_infos/reward_ctrl Mean              -0.394192
expl/env_infos/reward_ctrl Std                0.0863079
expl/env_infos/reward_ctrl Max               -0.0590444
expl/env_infos/reward_ctrl Min               -0.577982
eval/num steps total                          2.295e+06
eval/num paths total                       2295
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.46713
eval/Rewards Std                              1.33937
eval/Rewards Max                              8.88727
eval/Rewards Min                             -0.924583
eval/Returns Mean                          6467.13
eval/Returns Std                             77.1276
eval/Returns Max                           6596.51
eval/Returns Min                           6362.16
eval/Actions Mean                             0.119481
eval/Actions Std                              0.814569
eval/Actions Max                              0.996732
eval/Actions Min                             -0.99584
eval/Num Paths                                5
eval/Average Returns                       6467.13
eval/env_infos/final/reward_run Mean          7.46422
eval/env_infos/final/reward_run Std           0.647032
eval/env_infos/final/reward_run Max           8.31914
eval/env_infos/final/reward_run Min           6.51826
eval/env_infos/initial/reward_run Mean       -0.308813
eval/env_infos/initial/reward_run Std         0.217364
eval/env_infos/initial/reward_run Max        -0.0892307
eval/env_infos/initial/reward_run Min        -0.726273
eval/env_infos/reward_run Mean                6.87381
eval/env_infos/reward_run Std                 1.33787
eval/env_infos/reward_run Max                 9.43327
eval/env_infos/reward_run Min                -0.726273
eval/env_infos/final/reward_ctrl Mean        -0.396338
eval/env_infos/final/reward_ctrl Std          0.0710193
eval/env_infos/final/reward_ctrl Max         -0.258215
eval/env_infos/final/reward_ctrl Min         -0.459461
eval/env_infos/initial/reward_ctrl Mean      -0.213936
eval/env_infos/initial/reward_ctrl Std        0.0378167
eval/env_infos/initial/reward_ctrl Max       -0.180498
eval/env_infos/initial/reward_ctrl Min       -0.284098
eval/env_infos/reward_ctrl Mean              -0.406679
eval/env_infos/reward_ctrl Std                0.0838819
eval/env_infos/reward_ctrl Max               -0.0916799
eval/env_infos/reward_ctrl Min               -0.576815
time/data storing (s)                         0.00446194
time/evaluation sampling (s)                  2.01317
time/exploration sampling (s)                 0.532636
time/logging (s)                              0.0136684
time/sac training (s)                         7.42174
time/saving (s)                               0.00376357
time/training (s)                             3.32361e-05
time/epoch (s)                                9.98946
time/total (s)                             4826.8
Epoch                                       458
---------------------------------------  ----------------
2021-11-24 01:49:53.932141 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 459 finished
---------------------------------------  ---------------
epoch                                       459
replay_buffer/size                       461000
trainer/num train calls                  460000
trainer/QF1 Loss                              7.48136
trainer/QF2 Loss                              7.90279
trainer/Policy Loss                        -420.272
trainer/Q1 Predictions Mean                 420.897
trainer/Q1 Predictions Std                   84.9316
trainer/Q1 Predictions Max                  491.493
trainer/Q1 Predictions Min                   23.8604
trainer/Q2 Predictions Mean                 420.923
trainer/Q2 Predictions Std                   84.9826
trainer/Q2 Predictions Max                  489.376
trainer/Q2 Predictions Min                   24.2929
trainer/Q Targets Mean                      420.843
trainer/Q Targets Std                        84.9396
trainer/Q Targets Max                       490.484
trainer/Q Targets Min                        23.6821
trainer/Log Pis Mean                          5.41788
trainer/Log Pis Std                           3.91102
trainer/Log Pis Max                          14.7126
trainer/Log Pis Min                          -4.37853
trainer/policy/mean Mean                      0.0993442
trainer/policy/mean Std                       0.767864
trainer/policy/mean Max                       0.993849
trainer/policy/mean Min                      -0.991515
trainer/policy/normal/std Mean                0.439094
trainer/policy/normal/std Std                 0.143704
trainer/policy/normal/std Max                 0.952594
trainer/policy/normal/std Min                 0.0691371
trainer/policy/normal/log_std Mean           -0.898548
trainer/policy/normal/log_std Std             0.433212
trainer/policy/normal/log_std Max            -0.0485662
trainer/policy/normal/log_std Min            -2.67166
trainer/Alpha                                 0.158595
trainer/Alpha Loss                           -1.07192
expl/num steps total                     461000
expl/num paths total                        461
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.98125
expl/Rewards Std                              1.28665
expl/Rewards Max                              8.44851
expl/Rewards Min                             -0.733493
expl/Returns Mean                          5981.25
expl/Returns Std                              0
expl/Returns Max                           5981.25
expl/Returns Min                           5981.25
expl/Actions Mean                             0.105399
expl/Actions Std                              0.799642
expl/Actions Max                              0.999487
expl/Actions Min                             -0.999414
expl/Num Paths                                1
expl/Average Returns                       5981.25
expl/env_infos/final/reward_run Mean          5.26744
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.26744
expl/env_infos/final/reward_run Min           5.26744
expl/env_infos/initial/reward_run Mean       -0.602006
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.602006
expl/env_infos/initial/reward_run Min        -0.602006
expl/env_infos/reward_run Mean                6.37157
expl/env_infos/reward_run Std                 1.27987
expl/env_infos/reward_run Max                 8.85868
expl/env_infos/reward_run Min                -0.602006
expl/env_infos/final/reward_ctrl Mean        -0.480315
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.480315
expl/env_infos/final/reward_ctrl Min         -0.480315
expl/env_infos/initial/reward_ctrl Mean      -0.131487
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.131487
expl/env_infos/initial/reward_ctrl Min       -0.131487
expl/env_infos/reward_ctrl Mean              -0.390321
expl/env_infos/reward_ctrl Std                0.0885418
expl/env_infos/reward_ctrl Max               -0.114262
expl/env_infos/reward_ctrl Min               -0.579868
eval/num steps total                          2.3e+06
eval/num paths total                       2300
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.44728
eval/Rewards Std                              1.34917
eval/Rewards Max                              9.11171
eval/Rewards Min                             -1.02797
eval/Returns Mean                          6447.28
eval/Returns Std                            116.71
eval/Returns Max                           6632.91
eval/Returns Min                           6337.75
eval/Actions Mean                             0.0911958
eval/Actions Std                              0.817278
eval/Actions Max                              0.994924
eval/Actions Min                             -0.997354
eval/Num Paths                                5
eval/Average Returns                       6447.28
eval/env_infos/final/reward_run Mean          7.64269
eval/env_infos/final/reward_run Std           0.491037
eval/env_infos/final/reward_run Max           8.38589
eval/env_infos/final/reward_run Min           7.05118
eval/env_infos/initial/reward_run Mean       -0.129616
eval/env_infos/initial/reward_run Std         0.569062
eval/env_infos/initial/reward_run Max         0.994036
eval/env_infos/initial/reward_run Min        -0.57099
eval/env_infos/reward_run Mean                6.85304
eval/env_infos/reward_run Std                 1.34474
eval/env_infos/reward_run Max                 9.66763
eval/env_infos/reward_run Min                -0.581603
eval/env_infos/final/reward_ctrl Mean        -0.346502
eval/env_infos/final/reward_ctrl Std          0.114033
eval/env_infos/final/reward_ctrl Max         -0.191144
eval/env_infos/final/reward_ctrl Min         -0.447194
eval/env_infos/initial/reward_ctrl Mean      -0.24665
eval/env_infos/initial/reward_ctrl Std        0.0478139
eval/env_infos/initial/reward_ctrl Max       -0.199795
eval/env_infos/initial/reward_ctrl Min       -0.323175
eval/env_infos/reward_ctrl Mean              -0.405756
eval/env_infos/reward_ctrl Std                0.0829026
eval/env_infos/reward_ctrl Max               -0.112904
eval/env_infos/reward_ctrl Min               -0.57548
time/data storing (s)                         0.00448371
time/evaluation sampling (s)                  2.0386
time/exploration sampling (s)                 0.552691
time/logging (s)                              0.0136657
time/sac training (s)                         7.41857
time/saving (s)                               0.00375306
time/training (s)                             3.4441e-05
time/epoch (s)                               10.0318
time/total (s)                             4837.11
Epoch                                       459
---------------------------------------  ---------------
2021-11-24 01:50:04.215859 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 460 finished
---------------------------------------  ---------------
epoch                                       460
replay_buffer/size                       462000
trainer/num train calls                  461000
trainer/QF1 Loss                              5.20592
trainer/QF2 Loss                              5.76704
trainer/Policy Loss                        -424.632
trainer/Q1 Predictions Mean                 425.446
trainer/Q1 Predictions Std                   80.6107
trainer/Q1 Predictions Max                  486.666
trainer/Q1 Predictions Min                   22.54
trainer/Q2 Predictions Mean                 425.329
trainer/Q2 Predictions Std                   80.7226
trainer/Q2 Predictions Max                  487.201
trainer/Q2 Predictions Min                   22.0158
trainer/Q Targets Mean                      425.297
trainer/Q Targets Std                        80.6379
trainer/Q Targets Max                       486.156
trainer/Q Targets Min                        23.7175
trainer/Log Pis Mean                          6.16147
trainer/Log Pis Std                           4.02813
trainer/Log Pis Max                          15.3445
trainer/Log Pis Min                          -3.45951
trainer/policy/mean Mean                      0.108528
trainer/policy/mean Std                       0.782391
trainer/policy/mean Max                       0.99896
trainer/policy/mean Min                      -0.991948
trainer/policy/normal/std Mean                0.439151
trainer/policy/normal/std Std                 0.142154
trainer/policy/normal/std Max                 1.42768
trainer/policy/normal/std Min                 0.0613231
trainer/policy/normal/log_std Mean           -0.893749
trainer/policy/normal/log_std Std             0.418612
trainer/policy/normal/log_std Max             0.356049
trainer/policy/normal/log_std Min            -2.7916
trainer/Alpha                                 0.157098
trainer/Alpha Loss                            0.298863
expl/num steps total                     462000
expl/num paths total                        462
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.06142
expl/Rewards Std                              1.28943
expl/Rewards Max                              8.31806
expl/Rewards Min                             -0.502935
expl/Returns Mean                          6061.42
expl/Returns Std                              0
expl/Returns Max                           6061.42
expl/Returns Min                           6061.42
expl/Actions Mean                             0.0946856
expl/Actions Std                              0.798532
expl/Actions Max                              0.999387
expl/Actions Min                             -0.999205
expl/Num Paths                                1
expl/Average Returns                       6061.42
expl/env_infos/final/reward_run Mean          7.3051
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.3051
expl/env_infos/final/reward_run Min           7.3051
expl/env_infos/initial/reward_run Mean       -0.218653
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.218653
expl/env_infos/initial/reward_run Min        -0.218653
expl/env_infos/reward_run Mean                6.44939
expl/env_infos/reward_run Std                 1.28886
expl/env_infos/reward_run Max                 8.80087
expl/env_infos/reward_run Min                -0.218653
expl/env_infos/final/reward_ctrl Mean        -0.309706
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.309706
expl/env_infos/final/reward_ctrl Min         -0.309706
expl/env_infos/initial/reward_ctrl Mean      -0.136266
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.136266
expl/env_infos/initial/reward_ctrl Min       -0.136266
expl/env_infos/reward_ctrl Mean              -0.387971
expl/env_infos/reward_ctrl Std                0.0908699
expl/env_infos/reward_ctrl Max               -0.0789285
expl/env_infos/reward_ctrl Min               -0.568101
eval/num steps total                          2.305e+06
eval/num paths total                       2305
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.33484
eval/Rewards Std                              1.3239
eval/Rewards Max                              8.68646
eval/Rewards Min                             -1.02476
eval/Returns Mean                          6334.84
eval/Returns Std                             60.5012
eval/Returns Max                           6432.75
eval/Returns Min                           6263
eval/Actions Mean                             0.0970878
eval/Actions Std                              0.812189
eval/Actions Max                              0.998053
eval/Actions Min                             -0.998234
eval/Num Paths                                5
eval/Average Returns                       6334.84
eval/env_infos/final/reward_run Mean          7.5723
eval/env_infos/final/reward_run Std           0.971637
eval/env_infos/final/reward_run Max           8.51465
eval/env_infos/final/reward_run Min           6.01292
eval/env_infos/initial/reward_run Mean        0.0145537
eval/env_infos/initial/reward_run Std         0.449043
eval/env_infos/initial/reward_run Max         0.87643
eval/env_infos/initial/reward_run Min        -0.397498
eval/env_infos/reward_run Mean                6.73629
eval/env_infos/reward_run Std                 1.32258
eval/env_infos/reward_run Max                 9.24125
eval/env_infos/reward_run Min                -0.483527
eval/env_infos/final/reward_ctrl Mean        -0.434699
eval/env_infos/final/reward_ctrl Std          0.0669431
eval/env_infos/final/reward_ctrl Max         -0.317699
eval/env_infos/final/reward_ctrl Min         -0.509672
eval/env_infos/initial/reward_ctrl Mean      -0.217695
eval/env_infos/initial/reward_ctrl Std        0.0332796
eval/env_infos/initial/reward_ctrl Max       -0.181861
eval/env_infos/initial/reward_ctrl Min       -0.278289
eval/env_infos/reward_ctrl Mean              -0.401446
eval/env_infos/reward_ctrl Std                0.0880957
eval/env_infos/reward_ctrl Max               -0.0592039
eval/env_infos/reward_ctrl Min               -0.578547
time/data storing (s)                         0.00448105
time/evaluation sampling (s)                  2.00738
time/exploration sampling (s)                 0.534855
time/logging (s)                              0.013659
time/sac training (s)                         7.42339
time/saving (s)                               0.00377344
time/training (s)                             3.407e-05
time/epoch (s)                                9.98757
time/total (s)                             4847.38
Epoch                                       460
---------------------------------------  ---------------
2021-11-24 01:50:14.597776 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 461 finished
---------------------------------------  ---------------
epoch                                       461
replay_buffer/size                       463000
trainer/num train calls                  462000
trainer/QF1 Loss                              4.91576
trainer/QF2 Loss                              4.34611
trainer/Policy Loss                        -413.117
trainer/Q1 Predictions Mean                 414.054
trainer/Q1 Predictions Std                  107.985
trainer/Q1 Predictions Max                  487.266
trainer/Q1 Predictions Min                   21.5108
trainer/Q2 Predictions Mean                 413.823
trainer/Q2 Predictions Std                  107.826
trainer/Q2 Predictions Max                  485.921
trainer/Q2 Predictions Min                   22.5787
trainer/Q Targets Mean                      413.756
trainer/Q Targets Std                       107.87
trainer/Q Targets Max                       488.381
trainer/Q Targets Min                        22.279
trainer/Log Pis Mean                          5.47826
trainer/Log Pis Std                           4.50762
trainer/Log Pis Max                          19.0298
trainer/Log Pis Min                          -5.03576
trainer/policy/mean Mean                      0.0949471
trainer/policy/mean Std                       0.762482
trainer/policy/mean Max                       0.994879
trainer/policy/mean Min                      -0.99817
trainer/policy/normal/std Mean                0.453079
trainer/policy/normal/std Std                 0.150741
trainer/policy/normal/std Max                 0.963243
trainer/policy/normal/std Min                 0.0737625
trainer/policy/normal/log_std Mean           -0.866082
trainer/policy/normal/log_std Std             0.426776
trainer/policy/normal/log_std Max            -0.0374493
trainer/policy/normal/log_std Min            -2.6069
trainer/Alpha                                 0.15743
trainer/Alpha Loss                           -0.964579
expl/num steps total                     463000
expl/num paths total                        463
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00292
expl/Rewards Std                              1.32741
expl/Rewards Max                              8.63292
expl/Rewards Min                             -1.07962
expl/Returns Mean                          6002.92
expl/Returns Std                              0
expl/Returns Max                           6002.92
expl/Returns Min                           6002.92
expl/Actions Mean                             0.119409
expl/Actions Std                              0.788388
expl/Actions Max                              0.999148
expl/Actions Min                             -0.999289
expl/Num Paths                                1
expl/Average Returns                       6002.92
expl/env_infos/final/reward_run Mean          7.40281
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.40281
expl/env_infos/final/reward_run Min           7.40281
expl/env_infos/initial/reward_run Mean        0.396782
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.396782
expl/env_infos/initial/reward_run Min         0.396782
expl/env_infos/reward_run Mean                6.38441
expl/env_infos/reward_run Std                 1.31576
expl/env_infos/reward_run Max                 9.10831
expl/env_infos/reward_run Min                -0.548604
expl/env_infos/final/reward_ctrl Mean        -0.337199
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.337199
expl/env_infos/final/reward_ctrl Min         -0.337199
expl/env_infos/initial/reward_ctrl Mean      -0.225009
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.225009
expl/env_infos/initial/reward_ctrl Min       -0.225009
expl/env_infos/reward_ctrl Mean              -0.381489
expl/env_infos/reward_ctrl Std                0.085319
expl/env_infos/reward_ctrl Max               -0.0777249
expl/env_infos/reward_ctrl Min               -0.566042
eval/num steps total                          2.31e+06
eval/num paths total                       2310
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.38466
eval/Rewards Std                              1.34343
eval/Rewards Max                              9.19892
eval/Rewards Min                             -0.639188
eval/Returns Mean                          6384.66
eval/Returns Std                             71.3668
eval/Returns Max                           6492.27
eval/Returns Min                           6277.07
eval/Actions Mean                             0.117263
eval/Actions Std                              0.805209
eval/Actions Max                              0.996947
eval/Actions Min                             -0.998272
eval/Num Paths                                5
eval/Average Returns                       6384.66
eval/env_infos/final/reward_run Mean          6.31547
eval/env_infos/final/reward_run Std           0.863709
eval/env_infos/final/reward_run Max           7.58986
eval/env_infos/final/reward_run Min           5.34075
eval/env_infos/initial/reward_run Mean       -0.196059
eval/env_infos/initial/reward_run Std         0.193921
eval/env_infos/initial/reward_run Max         0.112052
eval/env_infos/initial/reward_run Min        -0.462144
eval/env_infos/reward_run Mean                6.78193
eval/env_infos/reward_run Std                 1.33043
eval/env_infos/reward_run Max                 9.56277
eval/env_infos/reward_run Min                -0.462144
eval/env_infos/final/reward_ctrl Mean        -0.423143
eval/env_infos/final/reward_ctrl Std          0.0386083
eval/env_infos/final/reward_ctrl Max         -0.37006
eval/env_infos/final/reward_ctrl Min         -0.474863
eval/env_infos/initial/reward_ctrl Mean      -0.246867
eval/env_infos/initial/reward_ctrl Std        0.0451812
eval/env_infos/initial/reward_ctrl Max       -0.174719
eval/env_infos/initial/reward_ctrl Min       -0.302987
eval/env_infos/reward_ctrl Mean              -0.397267
eval/env_infos/reward_ctrl Std                0.0803369
eval/env_infos/reward_ctrl Max               -0.103187
eval/env_infos/reward_ctrl Min               -0.578
time/data storing (s)                         0.00454952
time/evaluation sampling (s)                  2.00089
time/exploration sampling (s)                 0.534969
time/logging (s)                              0.0136758
time/sac training (s)                         7.52837
time/saving (s)                               0.0037922
time/training (s)                             3.4216e-05
time/epoch (s)                               10.0863
time/total (s)                             4857.75
Epoch                                       461
---------------------------------------  ---------------
2021-11-24 01:50:24.880608 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 462 finished
---------------------------------------  ---------------
epoch                                       462
replay_buffer/size                       464000
trainer/num train calls                  463000
trainer/QF1 Loss                              9.56798
trainer/QF2 Loss                              8.53494
trainer/Policy Loss                        -423.035
trainer/Q1 Predictions Mean                 423.787
trainer/Q1 Predictions Std                   91.0387
trainer/Q1 Predictions Max                  491.663
trainer/Q1 Predictions Min                   24.205
trainer/Q2 Predictions Mean                 423.462
trainer/Q2 Predictions Std                   91.0499
trainer/Q2 Predictions Max                  491.438
trainer/Q2 Predictions Min                   23.7882
trainer/Q Targets Mean                      423.403
trainer/Q Targets Std                        91.0216
trainer/Q Targets Max                       490.451
trainer/Q Targets Min                        23.5666
trainer/Log Pis Mean                          6.17534
trainer/Log Pis Std                           4.05584
trainer/Log Pis Max                          14.7325
trainer/Log Pis Min                          -5.32657
trainer/policy/mean Mean                      0.125403
trainer/policy/mean Std                       0.783474
trainer/policy/mean Max                       0.994877
trainer/policy/mean Min                      -0.997236
trainer/policy/normal/std Mean                0.443154
trainer/policy/normal/std Std                 0.143656
trainer/policy/normal/std Max                 0.972862
trainer/policy/normal/std Min                 0.0540902
trainer/policy/normal/log_std Mean           -0.888187
trainer/policy/normal/log_std Std             0.431658
trainer/policy/normal/log_std Max            -0.0275132
trainer/policy/normal/log_std Min            -2.9171
trainer/Alpha                                 0.156671
trainer/Alpha Loss                            0.325006
expl/num steps total                     464000
expl/num paths total                        464
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00871
expl/Rewards Std                              1.26828
expl/Rewards Max                              8.2938
expl/Rewards Min                             -0.681547
expl/Returns Mean                          6008.71
expl/Returns Std                              0
expl/Returns Max                           6008.71
expl/Returns Min                           6008.71
expl/Actions Mean                             0.109195
expl/Actions Std                              0.801792
expl/Actions Max                              0.999504
expl/Actions Min                             -0.998913
expl/Num Paths                                1
expl/Average Returns                       6008.71
expl/env_infos/final/reward_run Mean          8.78571
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.78571
expl/env_infos/final/reward_run Min           8.78571
expl/env_infos/initial/reward_run Mean       -0.374848
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.374848
expl/env_infos/initial/reward_run Min        -0.374848
expl/env_infos/reward_run Mean                6.40158
expl/env_infos/reward_run Std                 1.26928
expl/env_infos/reward_run Max                 8.79334
expl/env_infos/reward_run Min                -0.374848
expl/env_infos/final/reward_ctrl Mean        -0.510274
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.510274
expl/env_infos/final/reward_ctrl Min         -0.510274
expl/env_infos/initial/reward_ctrl Mean      -0.306699
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.306699
expl/env_infos/initial/reward_ctrl Min       -0.306699
expl/env_infos/reward_ctrl Mean              -0.392876
expl/env_infos/reward_ctrl Std                0.0899937
expl/env_infos/reward_ctrl Max               -0.0972143
expl/env_infos/reward_ctrl Min               -0.577483
eval/num steps total                          2.315e+06
eval/num paths total                       2315
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.4306
eval/Rewards Std                              1.32246
eval/Rewards Max                              8.86468
eval/Rewards Min                             -0.951122
eval/Returns Mean                          6430.6
eval/Returns Std                             69.8326
eval/Returns Max                           6543.8
eval/Returns Min                           6369.88
eval/Actions Mean                             0.110516
eval/Actions Std                              0.820935
eval/Actions Max                              0.998391
eval/Actions Min                             -0.996549
eval/Num Paths                                5
eval/Average Returns                       6430.6
eval/env_infos/final/reward_run Mean          7.80724
eval/env_infos/final/reward_run Std           0.459292
eval/env_infos/final/reward_run Max           8.55184
eval/env_infos/final/reward_run Min           7.19776
eval/env_infos/initial/reward_run Mean       -0.150402
eval/env_infos/initial/reward_run Std         0.423082
eval/env_infos/initial/reward_run Max         0.554604
eval/env_infos/initial/reward_run Min        -0.703647
eval/env_infos/reward_run Mean                6.84229
eval/env_infos/reward_run Std                 1.32272
eval/env_infos/reward_run Max                 9.42509
eval/env_infos/reward_run Min                -0.703647
eval/env_infos/final/reward_ctrl Mean        -0.396446
eval/env_infos/final/reward_ctrl Std          0.0669916
eval/env_infos/final/reward_ctrl Max         -0.264431
eval/env_infos/final/reward_ctrl Min         -0.440373
eval/env_infos/initial/reward_ctrl Mean      -0.268521
eval/env_infos/initial/reward_ctrl Std        0.0648263
eval/env_infos/initial/reward_ctrl Max       -0.19194
eval/env_infos/initial/reward_ctrl Min       -0.360751
eval/env_infos/reward_ctrl Mean              -0.411689
eval/env_infos/reward_ctrl Std                0.0887806
eval/env_infos/reward_ctrl Max               -0.0304771
eval/env_infos/reward_ctrl Min               -0.576011
time/data storing (s)                         0.00453809
time/evaluation sampling (s)                  2.0191
time/exploration sampling (s)                 0.515414
time/logging (s)                              0.0136716
time/sac training (s)                         7.43038
time/saving (s)                               0.00375411
time/training (s)                             3.3817e-05
time/epoch (s)                                9.98689
time/total (s)                             4868.02
Epoch                                       462
---------------------------------------  ---------------
2021-11-24 01:50:35.158248 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 463 finished
---------------------------------------  ---------------
epoch                                       463
replay_buffer/size                       465000
trainer/num train calls                  464000
trainer/QF1 Loss                              6.41439
trainer/QF2 Loss                              5.13518
trainer/Policy Loss                        -413.457
trainer/Q1 Predictions Mean                 414.485
trainer/Q1 Predictions Std                  108.751
trainer/Q1 Predictions Max                  487.195
trainer/Q1 Predictions Min                   20.5794
trainer/Q2 Predictions Mean                 414.042
trainer/Q2 Predictions Std                  108.592
trainer/Q2 Predictions Max                  487.059
trainer/Q2 Predictions Min                   21.8429
trainer/Q Targets Mean                      414.154
trainer/Q Targets Std                       108.589
trainer/Q Targets Max                       489.489
trainer/Q Targets Min                        22.5932
trainer/Log Pis Mean                          6.01405
trainer/Log Pis Std                           4.4246
trainer/Log Pis Max                          16.7668
trainer/Log Pis Min                          -4.99601
trainer/policy/mean Mean                      0.100431
trainer/policy/mean Std                       0.773167
trainer/policy/mean Max                       0.994547
trainer/policy/mean Min                      -0.997144
trainer/policy/normal/std Mean                0.449738
trainer/policy/normal/std Std                 0.155511
trainer/policy/normal/std Max                 0.952504
trainer/policy/normal/std Min                 0.0540533
trainer/policy/normal/log_std Mean           -0.880033
trainer/policy/normal/log_std Std             0.447839
trainer/policy/normal/log_std Max            -0.0486608
trainer/policy/normal/log_std Min            -2.91778
trainer/Alpha                                 0.157033
trainer/Alpha Loss                            0.0260056
expl/num steps total                     465000
expl/num paths total                        465
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.05961
expl/Rewards Std                              1.20941
expl/Rewards Max                              8.31555
expl/Rewards Min                             -0.516675
expl/Returns Mean                          6059.61
expl/Returns Std                              0
expl/Returns Max                           6059.61
expl/Returns Min                           6059.61
expl/Actions Mean                             0.122409
expl/Actions Std                              0.788442
expl/Actions Max                              0.999521
expl/Actions Min                             -0.9991
expl/Num Paths                                1
expl/Average Returns                       6059.61
expl/env_infos/final/reward_run Mean          7.63007
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.63007
expl/env_infos/final/reward_run Min           7.63007
expl/env_infos/initial/reward_run Mean       -0.253287
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.253287
expl/env_infos/initial/reward_run Min        -0.253287
expl/env_infos/reward_run Mean                6.44159
expl/env_infos/reward_run Std                 1.205
expl/env_infos/reward_run Max                 8.86908
expl/env_infos/reward_run Min                -0.253287
expl/env_infos/final/reward_ctrl Mean        -0.374314
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.374314
expl/env_infos/final/reward_ctrl Min         -0.374314
expl/env_infos/initial/reward_ctrl Mean      -0.263388
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.263388
expl/env_infos/initial/reward_ctrl Min       -0.263388
expl/env_infos/reward_ctrl Mean              -0.381975
expl/env_infos/reward_ctrl Std                0.0881105
expl/env_infos/reward_ctrl Max               -0.0860677
expl/env_infos/reward_ctrl Min               -0.574565
eval/num steps total                          2.32e+06
eval/num paths total                       2320
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.4231
eval/Rewards Std                              1.31616
eval/Rewards Max                              8.96337
eval/Rewards Min                             -0.596418
eval/Returns Mean                          6423.1
eval/Returns Std                            113.874
eval/Returns Max                           6618.94
eval/Returns Min                           6261.59
eval/Actions Mean                             0.113749
eval/Actions Std                              0.809648
eval/Actions Max                              0.994904
eval/Actions Min                             -0.993143
eval/Num Paths                                5
eval/Average Returns                       6423.1
eval/env_infos/final/reward_run Mean          7.30878
eval/env_infos/final/reward_run Std           0.700202
eval/env_infos/final/reward_run Max           8.52478
eval/env_infos/final/reward_run Min           6.40195
eval/env_infos/initial/reward_run Mean       -0.219629
eval/env_infos/initial/reward_run Std         0.0788043
eval/env_infos/initial/reward_run Max        -0.122654
eval/env_infos/initial/reward_run Min        -0.361762
eval/env_infos/reward_run Mean                6.82418
eval/env_infos/reward_run Std                 1.31459
eval/env_infos/reward_run Max                 9.50242
eval/env_infos/reward_run Min                -0.361762
eval/env_infos/final/reward_ctrl Mean        -0.325607
eval/env_infos/final/reward_ctrl Std          0.117851
eval/env_infos/final/reward_ctrl Max         -0.171042
eval/env_infos/final/reward_ctrl Min         -0.535627
eval/env_infos/initial/reward_ctrl Mean      -0.192448
eval/env_infos/initial/reward_ctrl Std        0.050167
eval/env_infos/initial/reward_ctrl Max       -0.105601
eval/env_infos/initial/reward_ctrl Min       -0.234657
eval/env_infos/reward_ctrl Mean              -0.401081
eval/env_infos/reward_ctrl Std                0.0860139
eval/env_infos/reward_ctrl Max               -0.0996397
eval/env_infos/reward_ctrl Min               -0.575668
time/data storing (s)                         0.00449801
time/evaluation sampling (s)                  2.0101
time/exploration sampling (s)                 0.533048
time/logging (s)                              0.0136757
time/sac training (s)                         7.41596
time/saving (s)                               0.00512572
time/training (s)                             3.4161e-05
time/epoch (s)                                9.98244
time/total (s)                             4878.28
Epoch                                       463
---------------------------------------  ---------------
2021-11-24 01:50:45.448240 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 464 finished
---------------------------------------  ---------------
epoch                                       464
replay_buffer/size                       466000
trainer/num train calls                  465000
trainer/QF1 Loss                              3.95557
trainer/QF2 Loss                              4.52735
trainer/Policy Loss                        -420.177
trainer/Q1 Predictions Mean                 420.647
trainer/Q1 Predictions Std                   98.2559
trainer/Q1 Predictions Max                  489.491
trainer/Q1 Predictions Min                   22.0648
trainer/Q2 Predictions Mean                 420.799
trainer/Q2 Predictions Std                   98.3958
trainer/Q2 Predictions Max                  490.537
trainer/Q2 Predictions Min                   22.0558
trainer/Q Targets Mean                      420.542
trainer/Q Targets Std                        98.2865
trainer/Q Targets Max                       489.394
trainer/Q Targets Min                        20.3616
trainer/Log Pis Mean                          5.9358
trainer/Log Pis Std                           4.68415
trainer/Log Pis Max                          19.0225
trainer/Log Pis Min                          -5.95775
trainer/policy/mean Mean                      0.0707452
trainer/policy/mean Std                       0.785331
trainer/policy/mean Max                       0.997746
trainer/policy/mean Min                      -0.994494
trainer/policy/normal/std Mean                0.445214
trainer/policy/normal/std Std                 0.149073
trainer/policy/normal/std Max                 0.930717
trainer/policy/normal/std Min                 0.0566467
trainer/policy/normal/log_std Mean           -0.887115
trainer/policy/normal/log_std Std             0.44196
trainer/policy/normal/log_std Max            -0.0717995
trainer/policy/normal/log_std Min            -2.87092
trainer/Alpha                                 0.159784
trainer/Alpha Loss                           -0.117737
expl/num steps total                     466000
expl/num paths total                        466
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00898
expl/Rewards Std                              1.24746
expl/Rewards Max                              8.26685
expl/Rewards Min                             -0.344164
expl/Returns Mean                          6008.98
expl/Returns Std                              0
expl/Returns Max                           6008.98
expl/Returns Min                           6008.98
expl/Actions Mean                             0.104379
expl/Actions Std                              0.801448
expl/Actions Max                              0.999526
expl/Actions Min                             -0.999432
expl/Num Paths                                1
expl/Average Returns                       6008.98
expl/env_infos/final/reward_run Mean          4.92613
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           4.92613
expl/env_infos/final/reward_run Min           4.92613
expl/env_infos/initial/reward_run Mean        0.144558
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.144558
expl/env_infos/initial/reward_run Min         0.144558
expl/env_infos/reward_run Mean                6.40091
expl/env_infos/reward_run Std                 1.23983
expl/env_infos/reward_run Max                 8.72832
expl/env_infos/reward_run Min                 0.0452005
expl/env_infos/final/reward_ctrl Mean        -0.4491
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.4491
expl/env_infos/final/reward_ctrl Min         -0.4491
expl/env_infos/initial/reward_ctrl Mean      -0.161512
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.161512
expl/env_infos/initial/reward_ctrl Min       -0.161512
expl/env_infos/reward_ctrl Mean              -0.391928
expl/env_infos/reward_ctrl Std                0.0943832
expl/env_infos/reward_ctrl Max               -0.0670888
expl/env_infos/reward_ctrl Min               -0.572423
eval/num steps total                          2.325e+06
eval/num paths total                       2325
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.59836
eval/Rewards Std                              1.32307
eval/Rewards Max                              8.98577
eval/Rewards Min                             -0.674912
eval/Returns Mean                          6598.36
eval/Returns Std                             49.2708
eval/Returns Max                           6688.77
eval/Returns Min                           6539.64
eval/Actions Mean                             0.0971526
eval/Actions Std                              0.827837
eval/Actions Max                              0.996158
eval/Actions Min                             -0.998516
eval/Num Paths                                5
eval/Average Returns                       6598.36
eval/env_infos/final/reward_run Mean          7.2459
eval/env_infos/final/reward_run Std           0.775666
eval/env_infos/final/reward_run Max           8.236
eval/env_infos/final/reward_run Min           6.38142
eval/env_infos/initial/reward_run Mean       -0.308253
eval/env_infos/initial/reward_run Std         0.121061
eval/env_infos/initial/reward_run Max        -0.15503
eval/env_infos/initial/reward_run Min        -0.436699
eval/env_infos/reward_run Mean                7.01521
eval/env_infos/reward_run Std                 1.32108
eval/env_infos/reward_run Max                 9.46117
eval/env_infos/reward_run Min                -0.436699
eval/env_infos/final/reward_ctrl Mean        -0.353797
eval/env_infos/final/reward_ctrl Std          0.0831599
eval/env_infos/final/reward_ctrl Max         -0.242219
eval/env_infos/final/reward_ctrl Min         -0.494186
eval/env_infos/initial/reward_ctrl Mean      -0.247009
eval/env_infos/initial/reward_ctrl Std        0.0401191
eval/env_infos/initial/reward_ctrl Max       -0.178157
eval/env_infos/initial/reward_ctrl Min       -0.301214
eval/env_infos/reward_ctrl Mean              -0.416852
eval/env_infos/reward_ctrl Std                0.0858932
eval/env_infos/reward_ctrl Max               -0.0695411
eval/env_infos/reward_ctrl Min               -0.578381
time/data storing (s)                         0.0044984
time/evaluation sampling (s)                  2.00851
time/exploration sampling (s)                 0.5381
time/logging (s)                              0.0137046
time/sac training (s)                         7.4244
time/saving (s)                               0.00379648
time/training (s)                             3.5833e-05
time/epoch (s)                                9.99305
time/total (s)                             4888.56
Epoch                                       464
---------------------------------------  ---------------
2021-11-24 01:50:55.733052 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 465 finished
---------------------------------------  ---------------
epoch                                       465
replay_buffer/size                       467000
trainer/num train calls                  466000
trainer/QF1 Loss                              4.63018
trainer/QF2 Loss                              4.9626
trainer/Policy Loss                        -419.825
trainer/Q1 Predictions Mean                 420.724
trainer/Q1 Predictions Std                   94.6825
trainer/Q1 Predictions Max                  484.14
trainer/Q1 Predictions Min                   24.108
trainer/Q2 Predictions Mean                 420.226
trainer/Q2 Predictions Std                   94.5913
trainer/Q2 Predictions Max                  484.067
trainer/Q2 Predictions Min                   23.0389
trainer/Q Targets Mean                      420.937
trainer/Q Targets Std                        94.6203
trainer/Q Targets Max                       485.028
trainer/Q Targets Min                        22.923
trainer/Log Pis Mean                          5.59578
trainer/Log Pis Std                           4.06715
trainer/Log Pis Max                          14.5996
trainer/Log Pis Min                          -5.01064
trainer/policy/mean Mean                      0.100669
trainer/policy/mean Std                       0.771745
trainer/policy/mean Max                       0.995121
trainer/policy/mean Min                      -0.998091
trainer/policy/normal/std Mean                0.443827
trainer/policy/normal/std Std                 0.146985
trainer/policy/normal/std Max                 1.26881
trainer/policy/normal/std Min                 0.0724759
trainer/policy/normal/log_std Mean           -0.887996
trainer/policy/normal/log_std Std             0.434551
trainer/policy/normal/log_std Max             0.238079
trainer/policy/normal/log_std Min            -2.6245
trainer/Alpha                                 0.158919
trainer/Alpha Loss                           -0.743505
expl/num steps total                     467000
expl/num paths total                        467
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.02349
expl/Rewards Std                              1.3162
expl/Rewards Max                              8.70606
expl/Rewards Min                             -0.502617
expl/Returns Mean                          6023.49
expl/Returns Std                              0
expl/Returns Max                           6023.49
expl/Returns Min                           6023.49
expl/Actions Mean                             0.118951
expl/Actions Std                              0.799067
expl/Actions Max                              0.999731
expl/Actions Min                             -0.998266
expl/Num Paths                                1
expl/Average Returns                       6023.49
expl/env_infos/final/reward_run Mean          6.16768
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.16768
expl/env_infos/final/reward_run Min           6.16768
expl/env_infos/initial/reward_run Mean       -0.30997
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.30997
expl/env_infos/initial/reward_run Min        -0.30997
expl/env_infos/reward_run Mean                6.41509
expl/env_infos/reward_run Std                 1.31779
expl/env_infos/reward_run Max                 9.0964
expl/env_infos/reward_run Min                -0.30997
expl/env_infos/final/reward_ctrl Mean        -0.500724
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.500724
expl/env_infos/final/reward_ctrl Min         -0.500724
expl/env_infos/initial/reward_ctrl Mean      -0.192647
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.192647
expl/env_infos/initial/reward_ctrl Min       -0.192647
expl/env_infos/reward_ctrl Mean              -0.391595
expl/env_infos/reward_ctrl Std                0.0869515
expl/env_infos/reward_ctrl Max               -0.0671842
expl/env_infos/reward_ctrl Min               -0.567379
eval/num steps total                          2.33e+06
eval/num paths total                       2330
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.49831
eval/Rewards Std                              1.34379
eval/Rewards Max                              9.08877
eval/Rewards Min                             -0.98179
eval/Returns Mean                          6498.31
eval/Returns Std                             77.5404
eval/Returns Max                           6605.09
eval/Returns Min                           6391.31
eval/Actions Mean                             0.105712
eval/Actions Std                              0.820259
eval/Actions Max                              0.996448
eval/Actions Min                             -0.998881
eval/Num Paths                                5
eval/Average Returns                       6498.31
eval/env_infos/final/reward_run Mean          7.72898
eval/env_infos/final/reward_run Std           1.05962
eval/env_infos/final/reward_run Max           9.33318
eval/env_infos/final/reward_run Min           6.20124
eval/env_infos/initial/reward_run Mean        0.150633
eval/env_infos/initial/reward_run Std         0.539403
eval/env_infos/initial/reward_run Max         0.875058
eval/env_infos/initial/reward_run Min        -0.423283
eval/env_infos/reward_run Mean                6.90871
eval/env_infos/reward_run Std                 1.33969
eval/env_infos/reward_run Max                 9.552
eval/env_infos/reward_run Min                -0.482444
eval/env_infos/final/reward_ctrl Mean        -0.428207
eval/env_infos/final/reward_ctrl Std          0.0503453
eval/env_infos/final/reward_ctrl Max         -0.366876
eval/env_infos/final/reward_ctrl Min         -0.503154
eval/env_infos/initial/reward_ctrl Mean      -0.220019
eval/env_infos/initial/reward_ctrl Std        0.0699278
eval/env_infos/initial/reward_ctrl Max       -0.127934
eval/env_infos/initial/reward_ctrl Min       -0.32108
eval/env_infos/reward_ctrl Mean              -0.4104
eval/env_infos/reward_ctrl Std                0.081072
eval/env_infos/reward_ctrl Max               -0.082994
eval/env_infos/reward_ctrl Min               -0.575178
time/data storing (s)                         0.00447579
time/evaluation sampling (s)                  2.0025
time/exploration sampling (s)                 0.534463
time/logging (s)                              0.0136652
time/sac training (s)                         7.4296
time/saving (s)                               0.00378046
time/training (s)                             3.3888e-05
time/epoch (s)                                9.98852
time/total (s)                             4898.83
Epoch                                       465
---------------------------------------  ---------------
2021-11-24 01:51:06.003327 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 466 finished
---------------------------------------  ---------------
epoch                                       466
replay_buffer/size                       468000
trainer/num train calls                  467000
trainer/QF1 Loss                              6.06765
trainer/QF2 Loss                              5.04118
trainer/Policy Loss                        -416.453
trainer/Q1 Predictions Mean                 417.262
trainer/Q1 Predictions Std                  103.871
trainer/Q1 Predictions Max                  492.197
trainer/Q1 Predictions Min                   21.5007
trainer/Q2 Predictions Mean                 417.276
trainer/Q2 Predictions Std                  103.75
trainer/Q2 Predictions Max                  491.516
trainer/Q2 Predictions Min                   21.532
trainer/Q Targets Mean                      417.345
trainer/Q Targets Std                       103.632
trainer/Q Targets Max                       491.111
trainer/Q Targets Min                        20.4087
trainer/Log Pis Mean                          5.70157
trainer/Log Pis Std                           4.34075
trainer/Log Pis Max                          17.0174
trainer/Log Pis Min                          -7.64648
trainer/policy/mean Mean                      0.0860269
trainer/policy/mean Std                       0.767256
trainer/policy/mean Max                       0.996597
trainer/policy/mean Min                      -0.995133
trainer/policy/normal/std Mean                0.445181
trainer/policy/normal/std Std                 0.15384
trainer/policy/normal/std Max                 0.919851
trainer/policy/normal/std Min                 0.0669104
trainer/policy/normal/log_std Mean           -0.887824
trainer/policy/normal/log_std Std             0.437213
trainer/policy/normal/log_std Max            -0.0835437
trainer/policy/normal/log_std Min            -2.7044
trainer/Alpha                                 0.159775
trainer/Alpha Loss                           -0.547319
expl/num steps total                     468000
expl/num paths total                        468
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.18414
expl/Rewards Std                              1.24428
expl/Rewards Max                              8.38988
expl/Rewards Min                             -0.401204
expl/Returns Mean                          6184.14
expl/Returns Std                              0
expl/Returns Max                           6184.14
expl/Returns Min                           6184.14
expl/Actions Mean                             0.0948444
expl/Actions Std                              0.802642
expl/Actions Max                              0.999544
expl/Actions Min                             -0.999055
expl/Num Paths                                1
expl/Average Returns                       6184.14
expl/env_infos/final/reward_run Mean          8.23762
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.23762
expl/env_infos/final/reward_run Min           8.23762
expl/env_infos/initial/reward_run Mean       -0.122846
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.122846
expl/env_infos/initial/reward_run Min        -0.122846
expl/env_infos/reward_run Mean                6.57608
expl/env_infos/reward_run Std                 1.24129
expl/env_infos/reward_run Max                 8.85419
expl/env_infos/reward_run Min                -0.122846
expl/env_infos/final/reward_ctrl Mean        -0.360135
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.360135
expl/env_infos/final/reward_ctrl Min         -0.360135
expl/env_infos/initial/reward_ctrl Mean      -0.278358
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.278358
expl/env_infos/initial/reward_ctrl Min       -0.278358
expl/env_infos/reward_ctrl Mean              -0.391938
expl/env_infos/reward_ctrl Std                0.0880242
expl/env_infos/reward_ctrl Max               -0.129012
expl/env_infos/reward_ctrl Min               -0.571696
eval/num steps total                          2.335e+06
eval/num paths total                       2335
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.46017
eval/Rewards Std                              1.32431
eval/Rewards Max                              8.96294
eval/Rewards Min                             -0.750383
eval/Returns Mean                          6460.17
eval/Returns Std                             84.4927
eval/Returns Max                           6574.73
eval/Returns Min                           6321.16
eval/Actions Mean                             0.0850443
eval/Actions Std                              0.814403
eval/Actions Max                              0.994169
eval/Actions Min                             -0.998011
eval/Num Paths                                5
eval/Average Returns                       6460.17
eval/env_infos/final/reward_run Mean          6.85654
eval/env_infos/final/reward_run Std           1.27729
eval/env_infos/final/reward_run Max           8.481
eval/env_infos/final/reward_run Min           5.49941
eval/env_infos/initial/reward_run Mean       -0.18793
eval/env_infos/initial/reward_run Std         0.119986
eval/env_infos/initial/reward_run Max        -0.0677479
eval/env_infos/initial/reward_run Min        -0.391918
eval/env_infos/reward_run Mean                6.86246
eval/env_infos/reward_run Std                 1.32378
eval/env_infos/reward_run Max                 9.49272
eval/env_infos/reward_run Min                -0.391918
eval/env_infos/final/reward_ctrl Mean        -0.433308
eval/env_infos/final/reward_ctrl Std          0.0460368
eval/env_infos/final/reward_ctrl Max         -0.393914
eval/env_infos/final/reward_ctrl Min         -0.521789
eval/env_infos/initial/reward_ctrl Mean      -0.195193
eval/env_infos/initial/reward_ctrl Std        0.0647611
eval/env_infos/initial/reward_ctrl Max       -0.123323
eval/env_infos/initial/reward_ctrl Min       -0.294151
eval/env_infos/reward_ctrl Mean              -0.40229
eval/env_infos/reward_ctrl Std                0.0873331
eval/env_infos/reward_ctrl Max               -0.0504247
eval/env_infos/reward_ctrl Min               -0.577261
time/data storing (s)                         0.00460663
time/evaluation sampling (s)                  1.99292
time/exploration sampling (s)                 0.534283
time/logging (s)                              0.0135969
time/sac training (s)                         7.42497
time/saving (s)                               0.00377122
time/training (s)                             3.4088e-05
time/epoch (s)                                9.97418
time/total (s)                             4909.08
Epoch                                       466
---------------------------------------  ---------------
2021-11-24 01:51:16.308486 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 467 finished
---------------------------------------  ---------------
epoch                                       467
replay_buffer/size                       469000
trainer/num train calls                  468000
trainer/QF1 Loss                              7.2549
trainer/QF2 Loss                              6.73932
trainer/Policy Loss                        -423.806
trainer/Q1 Predictions Mean                 424.494
trainer/Q1 Predictions Std                   88.6063
trainer/Q1 Predictions Max                  491.641
trainer/Q1 Predictions Min                   21.1179
trainer/Q2 Predictions Mean                 424.512
trainer/Q2 Predictions Std                   88.4417
trainer/Q2 Predictions Max                  491.666
trainer/Q2 Predictions Min                   23.4253
trainer/Q Targets Mean                      424.023
trainer/Q Targets Std                        88.6099
trainer/Q Targets Max                       491.739
trainer/Q Targets Min                        21.72
trainer/Log Pis Mean                          6.51242
trainer/Log Pis Std                           4.47413
trainer/Log Pis Max                          17.1747
trainer/Log Pis Min                          -6.91169
trainer/policy/mean Mean                      0.0685551
trainer/policy/mean Std                       0.790467
trainer/policy/mean Max                       0.99475
trainer/policy/mean Min                      -0.996611
trainer/policy/normal/std Mean                0.444612
trainer/policy/normal/std Std                 0.142528
trainer/policy/normal/std Max                 0.884762
trainer/policy/normal/std Min                 0.0662867
trainer/policy/normal/log_std Mean           -0.886686
trainer/policy/normal/log_std Std             0.441801
trainer/policy/normal/log_std Max            -0.122437
trainer/policy/normal/log_std Min            -2.71377
trainer/Alpha                                 0.158047
trainer/Alpha Loss                            0.945345
expl/num steps total                     469000
expl/num paths total                        469
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.96545
expl/Rewards Std                              1.2737
expl/Rewards Max                              8.26559
expl/Rewards Min                             -0.481095
expl/Returns Mean                          5965.45
expl/Returns Std                              0
expl/Returns Max                           5965.45
expl/Returns Min                           5965.45
expl/Actions Mean                             0.102128
expl/Actions Std                              0.801301
expl/Actions Max                              0.999556
expl/Actions Min                             -0.999675
expl/Num Paths                                1
expl/Average Returns                       5965.45
expl/env_infos/final/reward_run Mean          6.96968
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.96968
expl/env_infos/final/reward_run Min           6.96968
expl/env_infos/initial/reward_run Mean       -0.12299
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.12299
expl/env_infos/initial/reward_run Min        -0.12299
expl/env_infos/reward_run Mean                6.35695
expl/env_infos/reward_run Std                 1.26937
expl/env_infos/reward_run Max                 8.79579
expl/env_infos/reward_run Min                -0.320611
expl/env_infos/final/reward_ctrl Mean        -0.531487
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.531487
expl/env_infos/final/reward_ctrl Min         -0.531487
expl/env_infos/initial/reward_ctrl Mean      -0.267659
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.267659
expl/env_infos/initial/reward_ctrl Min       -0.267659
expl/env_infos/reward_ctrl Mean              -0.391508
expl/env_infos/reward_ctrl Std                0.0952037
expl/env_infos/reward_ctrl Max               -0.0500487
expl/env_infos/reward_ctrl Min               -0.579937
eval/num steps total                          2.34e+06
eval/num paths total                       2340
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.41839
eval/Rewards Std                              1.31062
eval/Rewards Max                              8.97898
eval/Rewards Min                             -0.613429
eval/Returns Mean                          6418.39
eval/Returns Std                             52.0118
eval/Returns Max                           6479.27
eval/Returns Min                           6358.52
eval/Actions Mean                             0.100125
eval/Actions Std                              0.821621
eval/Actions Max                              0.996137
eval/Actions Min                             -0.998712
eval/Num Paths                                5
eval/Average Returns                       6418.39
eval/env_infos/final/reward_run Mean          7.02897
eval/env_infos/final/reward_run Std           0.533661
eval/env_infos/final/reward_run Max           7.71445
eval/env_infos/final/reward_run Min           6.27987
eval/env_infos/initial/reward_run Mean       -0.289573
eval/env_infos/initial/reward_run Std         0.118769
eval/env_infos/initial/reward_run Max        -0.144438
eval/env_infos/initial/reward_run Min        -0.415836
eval/env_infos/reward_run Mean                6.82944
eval/env_infos/reward_run Std                 1.30691
eval/env_infos/reward_run Max                 9.52727
eval/env_infos/reward_run Min                -0.415836
eval/env_infos/final/reward_ctrl Mean        -0.415636
eval/env_infos/final/reward_ctrl Std          0.0677541
eval/env_infos/final/reward_ctrl Max         -0.320635
eval/env_infos/final/reward_ctrl Min         -0.498346
eval/env_infos/initial/reward_ctrl Mean      -0.210289
eval/env_infos/initial/reward_ctrl Std        0.0269244
eval/env_infos/initial/reward_ctrl Max       -0.180015
eval/env_infos/initial/reward_ctrl Min       -0.255102
eval/env_infos/reward_ctrl Mean              -0.411052
eval/env_infos/reward_ctrl Std                0.0905276
eval/env_infos/reward_ctrl Max               -0.0913536
eval/env_infos/reward_ctrl Min               -0.580543
time/data storing (s)                         0.00452812
time/evaluation sampling (s)                  2.01623
time/exploration sampling (s)                 0.536218
time/logging (s)                              0.0136636
time/sac training (s)                         7.43237
time/saving (s)                               0.00379518
time/training (s)                             3.4716e-05
time/epoch (s)                               10.0068
time/total (s)                             4919.37
Epoch                                       467
---------------------------------------  ---------------
2021-11-24 01:51:26.591249 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 468 finished
---------------------------------------  ---------------
epoch                                       468
replay_buffer/size                       470000
trainer/num train calls                  469000
trainer/QF1 Loss                              5.03527
trainer/QF2 Loss                              5.23628
trainer/Policy Loss                        -419.517
trainer/Q1 Predictions Mean                 420.228
trainer/Q1 Predictions Std                   94.5375
trainer/Q1 Predictions Max                  488.056
trainer/Q1 Predictions Min                   16.4182
trainer/Q2 Predictions Mean                 420.391
trainer/Q2 Predictions Std                   94.511
trainer/Q2 Predictions Max                  489.401
trainer/Q2 Predictions Min                   23.7859
trainer/Q Targets Mean                      420.435
trainer/Q Targets Std                        94.5749
trainer/Q Targets Max                       491.989
trainer/Q Targets Min                        23.3478
trainer/Log Pis Mean                          5.93604
trainer/Log Pis Std                           3.99956
trainer/Log Pis Max                          15.4889
trainer/Log Pis Min                          -5.00293
trainer/policy/mean Mean                      0.0766853
trainer/policy/mean Std                       0.775852
trainer/policy/mean Max                       0.994084
trainer/policy/mean Min                      -0.997388
trainer/policy/normal/std Mean                0.444077
trainer/policy/normal/std Std                 0.14714
trainer/policy/normal/std Max                 0.89138
trainer/policy/normal/std Min                 0.0725884
trainer/policy/normal/log_std Mean           -0.888461
trainer/policy/normal/log_std Std             0.437107
trainer/policy/normal/log_std Max            -0.114985
trainer/policy/normal/log_std Min            -2.62295
trainer/Alpha                                 0.160093
trainer/Alpha Loss                           -0.117176
expl/num steps total                     470000
expl/num paths total                        470
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00343
expl/Rewards Std                              1.29005
expl/Rewards Max                              8.61741
expl/Rewards Min                             -0.550886
expl/Returns Mean                          6003.43
expl/Returns Std                              0
expl/Returns Max                           6003.43
expl/Returns Min                           6003.43
expl/Actions Mean                             0.102714
expl/Actions Std                              0.798062
expl/Actions Max                              0.999455
expl/Actions Min                             -0.999951
expl/Num Paths                                1
expl/Average Returns                       6003.43
expl/env_infos/final/reward_run Mean          6.31796
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.31796
expl/env_infos/final/reward_run Min           6.31796
expl/env_infos/initial/reward_run Mean        0.332521
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.332521
expl/env_infos/initial/reward_run Min         0.332521
expl/env_infos/reward_run Mean                6.3919
expl/env_infos/reward_run Std                 1.28898
expl/env_infos/reward_run Max                 9.06961
expl/env_infos/reward_run Min                -0.103234
expl/env_infos/final/reward_ctrl Mean        -0.434608
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.434608
expl/env_infos/final/reward_ctrl Min         -0.434608
expl/env_infos/initial/reward_ctrl Mean      -0.218129
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.218129
expl/env_infos/initial/reward_ctrl Min       -0.218129
expl/env_infos/reward_ctrl Mean              -0.388472
expl/env_infos/reward_ctrl Std                0.087915
expl/env_infos/reward_ctrl Max               -0.0971937
expl/env_infos/reward_ctrl Min               -0.566519
eval/num steps total                          2.345e+06
eval/num paths total                       2345
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.51757
eval/Rewards Std                              1.33373
eval/Rewards Max                              8.94202
eval/Rewards Min                             -0.778953
eval/Returns Mean                          6517.57
eval/Returns Std                             73.8392
eval/Returns Max                           6627.96
eval/Returns Min                           6433.96
eval/Actions Mean                             0.0975186
eval/Actions Std                              0.818669
eval/Actions Max                              0.997186
eval/Actions Min                             -0.997981
eval/Num Paths                                5
eval/Average Returns                       6517.57
eval/env_infos/final/reward_run Mean          7.45477
eval/env_infos/final/reward_run Std           0.680768
eval/env_infos/final/reward_run Max           8.28422
eval/env_infos/final/reward_run Min           6.45524
eval/env_infos/initial/reward_run Mean       -0.423447
eval/env_infos/initial/reward_run Std         0.190544
eval/env_infos/initial/reward_run Max        -0.0673528
eval/env_infos/initial/reward_run Min        -0.612732
eval/env_infos/reward_run Mean                6.92541
eval/env_infos/reward_run Std                 1.33727
eval/env_infos/reward_run Max                 9.4912
eval/env_infos/reward_run Min                -0.612732
eval/env_infos/final/reward_ctrl Mean        -0.325253
eval/env_infos/final/reward_ctrl Std          0.0687831
eval/env_infos/final/reward_ctrl Max         -0.210923
eval/env_infos/final/reward_ctrl Min         -0.410377
eval/env_infos/initial/reward_ctrl Mean      -0.17995
eval/env_infos/initial/reward_ctrl Std        0.033365
eval/env_infos/initial/reward_ctrl Max       -0.141575
eval/env_infos/initial/reward_ctrl Min       -0.229517
eval/env_infos/reward_ctrl Mean              -0.407837
eval/env_infos/reward_ctrl Std                0.0859122
eval/env_infos/reward_ctrl Max               -0.0731822
eval/env_infos/reward_ctrl Min               -0.574392
time/data storing (s)                         0.00445136
time/evaluation sampling (s)                  2.01412
time/exploration sampling (s)                 0.53145
time/logging (s)                              0.0136698
time/sac training (s)                         7.41894
time/saving (s)                               0.00376226
time/training (s)                             3.4616e-05
time/epoch (s)                                9.98643
time/total (s)                             4929.64
Epoch                                       468
---------------------------------------  ---------------
2021-11-24 01:51:36.880624 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 469 finished
---------------------------------------  ---------------
epoch                                       469
replay_buffer/size                       471000
trainer/num train calls                  470000
trainer/QF1 Loss                              5.85315
trainer/QF2 Loss                              6.24624
trainer/Policy Loss                        -408.639
trainer/Q1 Predictions Mean                 409.435
trainer/Q1 Predictions Std                  109.12
trainer/Q1 Predictions Max                  486.752
trainer/Q1 Predictions Min                   22.0777
trainer/Q2 Predictions Mean                 409.048
trainer/Q2 Predictions Std                  109.119
trainer/Q2 Predictions Max                  487.102
trainer/Q2 Predictions Min                   22.2516
trainer/Q Targets Mean                      409.594
trainer/Q Targets Std                       109.005
trainer/Q Targets Max                       488.627
trainer/Q Targets Min                        23.648
trainer/Log Pis Mean                          5.99779
trainer/Log Pis Std                           4.30725
trainer/Log Pis Max                          16.9093
trainer/Log Pis Min                          -5.89965
trainer/policy/mean Mean                      0.0757311
trainer/policy/mean Std                       0.776345
trainer/policy/mean Max                       0.993916
trainer/policy/mean Min                      -0.997489
trainer/policy/normal/std Mean                0.453629
trainer/policy/normal/std Std                 0.151748
trainer/policy/normal/std Max                 0.972782
trainer/policy/normal/std Min                 0.0664805
trainer/policy/normal/log_std Mean           -0.865346
trainer/policy/normal/log_std Std             0.429444
trainer/policy/normal/log_std Max            -0.0275953
trainer/policy/normal/log_std Min            -2.71085
trainer/Alpha                                 0.158477
trainer/Alpha Loss                           -0.00407366
expl/num steps total                     471000
expl/num paths total                        471
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.18364
expl/Rewards Std                              1.29009
expl/Rewards Max                              8.53787
expl/Rewards Min                             -0.893738
expl/Returns Mean                          6183.64
expl/Returns Std                              0
expl/Returns Max                           6183.64
expl/Returns Min                           6183.64
expl/Actions Mean                             0.104997
expl/Actions Std                              0.806496
expl/Actions Max                              0.9994
expl/Actions Min                             -0.999542
expl/Num Paths                                1
expl/Average Returns                       6183.64
expl/env_infos/final/reward_run Mean          6.5714
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.5714
expl/env_infos/final/reward_run Min           6.5714
expl/env_infos/initial/reward_run Mean        0.862177
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.862177
expl/env_infos/initial/reward_run Min         0.862177
expl/env_infos/reward_run Mean                6.58051
expl/env_infos/reward_run Std                 1.28058
expl/env_infos/reward_run Max                 8.99461
expl/env_infos/reward_run Min                -0.43388
expl/env_infos/final/reward_ctrl Mean        -0.197836
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.197836
expl/env_infos/final/reward_ctrl Min         -0.197836
expl/env_infos/initial/reward_ctrl Mean      -0.320998
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.320998
expl/env_infos/initial/reward_ctrl Min       -0.320998
expl/env_infos/reward_ctrl Mean              -0.396876
expl/env_infos/reward_ctrl Std                0.0875851
expl/env_infos/reward_ctrl Max               -0.125847
expl/env_infos/reward_ctrl Min               -0.576117
eval/num steps total                          2.35e+06
eval/num paths total                       2350
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.49949
eval/Rewards Std                              1.33308
eval/Rewards Max                              8.94224
eval/Rewards Min                             -0.724267
eval/Returns Mean                          6499.49
eval/Returns Std                             76.3984
eval/Returns Max                           6602.56
eval/Returns Min                           6419.54
eval/Actions Mean                             0.0957122
eval/Actions Std                              0.820542
eval/Actions Max                              0.995798
eval/Actions Min                             -0.998605
eval/Num Paths                                5
eval/Average Returns                       6499.49
eval/env_infos/final/reward_run Mean          7.1391
eval/env_infos/final/reward_run Std           0.826274
eval/env_infos/final/reward_run Max           7.95648
eval/env_infos/final/reward_run Min           5.56171
eval/env_infos/initial/reward_run Mean       -0.315953
eval/env_infos/initial/reward_run Std         0.220256
eval/env_infos/initial/reward_run Max         0.0457561
eval/env_infos/initial/reward_run Min        -0.516273
eval/env_infos/reward_run Mean                6.90896
eval/env_infos/reward_run Std                 1.32649
eval/env_infos/reward_run Max                 9.44809
eval/env_infos/reward_run Min                -0.516273
eval/env_infos/final/reward_ctrl Mean        -0.330988
eval/env_infos/final/reward_ctrl Std          0.135465
eval/env_infos/final/reward_ctrl Max         -0.122318
eval/env_infos/final/reward_ctrl Min         -0.478032
eval/env_infos/initial/reward_ctrl Mean      -0.185797
eval/env_infos/initial/reward_ctrl Std        0.0218435
eval/env_infos/initial/reward_ctrl Max       -0.150314
eval/env_infos/initial/reward_ctrl Min       -0.207993
eval/env_infos/reward_ctrl Mean              -0.40947
eval/env_infos/reward_ctrl Std                0.0860974
eval/env_infos/reward_ctrl Max               -0.067038
eval/env_infos/reward_ctrl Min               -0.580834
time/data storing (s)                         0.00444186
time/evaluation sampling (s)                  2.01522
time/exploration sampling (s)                 0.530114
time/logging (s)                              0.0136649
time/sac training (s)                         7.42786
time/saving (s)                               0.00373494
time/training (s)                             3.3503e-05
time/epoch (s)                                9.99507
time/total (s)                             4939.91
Epoch                                       469
---------------------------------------  ---------------
2021-11-24 01:51:47.179158 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 470 finished
---------------------------------------  ---------------
epoch                                       470
replay_buffer/size                       472000
trainer/num train calls                  471000
trainer/QF1 Loss                              6.11357
trainer/QF2 Loss                              4.57409
trainer/Policy Loss                        -411.437
trainer/Q1 Predictions Mean                 412.094
trainer/Q1 Predictions Std                  108.565
trainer/Q1 Predictions Max                  491.919
trainer/Q1 Predictions Min                   21.9666
trainer/Q2 Predictions Mean                 412.37
trainer/Q2 Predictions Std                  108.749
trainer/Q2 Predictions Max                  493.149
trainer/Q2 Predictions Min                   21.8408
trainer/Q Targets Mean                      412.629
trainer/Q Targets Std                       108.674
trainer/Q Targets Max                       490.819
trainer/Q Targets Min                        21.0659
trainer/Log Pis Mean                          5.74624
trainer/Log Pis Std                           4.4523
trainer/Log Pis Max                          16.8005
trainer/Log Pis Min                          -5.99031
trainer/policy/mean Mean                      0.092971
trainer/policy/mean Std                       0.766468
trainer/policy/mean Max                       0.995462
trainer/policy/mean Min                      -0.997641
trainer/policy/normal/std Mean                0.458121
trainer/policy/normal/std Std                 0.151872
trainer/policy/normal/std Max                 1.18443
trainer/policy/normal/std Min                 0.0662805
trainer/policy/normal/log_std Mean           -0.857291
trainer/policy/normal/log_std Std             0.438578
trainer/policy/normal/log_std Max             0.169265
trainer/policy/normal/log_std Min            -2.71386
trainer/Alpha                                 0.155618
trainer/Alpha Loss                           -0.472082
expl/num steps total                     472000
expl/num paths total                        472
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.06667
expl/Rewards Std                              1.25646
expl/Rewards Max                              8.47828
expl/Rewards Min                             -0.307692
expl/Returns Mean                          6066.67
expl/Returns Std                              0
expl/Returns Max                           6066.67
expl/Returns Min                           6066.67
expl/Actions Mean                             0.110956
expl/Actions Std                              0.797157
expl/Actions Max                              0.999276
expl/Actions Min                             -0.999265
expl/Num Paths                                1
expl/Average Returns                       6066.67
expl/env_infos/final/reward_run Mean          6.34692
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.34692
expl/env_infos/final/reward_run Min           6.34692
expl/env_infos/initial/reward_run Mean       -0.188274
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.188274
expl/env_infos/initial/reward_run Min        -0.188274
expl/env_infos/reward_run Mean                6.45533
expl/env_infos/reward_run Std                 1.24682
expl/env_infos/reward_run Max                 8.96043
expl/env_infos/reward_run Min                -0.188274
expl/env_infos/final/reward_ctrl Mean        -0.363893
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.363893
expl/env_infos/final/reward_ctrl Min         -0.363893
expl/env_infos/initial/reward_ctrl Mean      -0.119419
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.119419
expl/env_infos/initial/reward_ctrl Min       -0.119419
expl/env_infos/reward_ctrl Mean              -0.388662
expl/env_infos/reward_ctrl Std                0.0890192
expl/env_infos/reward_ctrl Max               -0.0908306
expl/env_infos/reward_ctrl Min               -0.571407
eval/num steps total                          2.355e+06
eval/num paths total                       2355
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.41499
eval/Rewards Std                              1.34612
eval/Rewards Max                              8.95613
eval/Rewards Min                             -0.678001
eval/Returns Mean                          6414.99
eval/Returns Std                             74.1022
eval/Returns Max                           6468.77
eval/Returns Min                           6278.42
eval/Actions Mean                             0.103759
eval/Actions Std                              0.813559
eval/Actions Max                              0.995396
eval/Actions Min                             -0.998091
eval/Num Paths                                5
eval/Average Returns                       6414.99
eval/env_infos/final/reward_run Mean          7.54308
eval/env_infos/final/reward_run Std           0.392326
eval/env_infos/final/reward_run Max           7.93508
eval/env_infos/final/reward_run Min           6.93341
eval/env_infos/initial/reward_run Mean       -0.301339
eval/env_infos/initial/reward_run Std         0.105505
eval/env_infos/initial/reward_run Max        -0.107158
eval/env_infos/initial/reward_run Min        -0.397718
eval/env_infos/reward_run Mean                6.81858
eval/env_infos/reward_run Std                 1.33802
eval/env_infos/reward_run Max                 9.40314
eval/env_infos/reward_run Min                -0.397718
eval/env_infos/final/reward_ctrl Mean        -0.335503
eval/env_infos/final/reward_ctrl Std          0.0274817
eval/env_infos/final/reward_ctrl Max         -0.28906
eval/env_infos/final/reward_ctrl Min         -0.373259
eval/env_infos/initial/reward_ctrl Mean      -0.166095
eval/env_infos/initial/reward_ctrl Std        0.0191646
eval/env_infos/initial/reward_ctrl Max       -0.130547
eval/env_infos/initial/reward_ctrl Min       -0.186727
eval/env_infos/reward_ctrl Mean              -0.403587
eval/env_infos/reward_ctrl Std                0.0847595
eval/env_infos/reward_ctrl Max               -0.077833
eval/env_infos/reward_ctrl Min               -0.571142
time/data storing (s)                         0.0045139
time/evaluation sampling (s)                  2.01526
time/exploration sampling (s)                 0.536323
time/logging (s)                              0.0136982
time/sac training (s)                         7.42792
time/saving (s)                               0.00377467
time/training (s)                             3.4549e-05
time/epoch (s)                               10.0015
time/total (s)                             4950.2
Epoch                                       470
---------------------------------------  ---------------
2021-11-24 01:51:57.495439 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 471 finished
---------------------------------------  ---------------
epoch                                       471
replay_buffer/size                       473000
trainer/num train calls                  472000
trainer/QF1 Loss                              4.25707
trainer/QF2 Loss                              4.27449
trainer/Policy Loss                        -427.697
trainer/Q1 Predictions Mean                 428.537
trainer/Q1 Predictions Std                   76.477
trainer/Q1 Predictions Max                  492.453
trainer/Q1 Predictions Min                   25.1454
trainer/Q2 Predictions Mean                 428.577
trainer/Q2 Predictions Std                   76.5131
trainer/Q2 Predictions Max                  492.444
trainer/Q2 Predictions Min                   25.475
trainer/Q Targets Mean                      428.712
trainer/Q Targets Std                        76.5147
trainer/Q Targets Max                       494.036
trainer/Q Targets Min                        26.1864
trainer/Log Pis Mean                          6.69069
trainer/Log Pis Std                           4.0891
trainer/Log Pis Max                          15.6879
trainer/Log Pis Min                          -4.67477
trainer/policy/mean Mean                      0.0736013
trainer/policy/mean Std                       0.798367
trainer/policy/mean Max                       0.998536
trainer/policy/mean Min                      -0.994739
trainer/policy/normal/std Mean                0.447478
trainer/policy/normal/std Std                 0.141026
trainer/policy/normal/std Max                 1.28994
trainer/policy/normal/std Min                 0.0697467
trainer/policy/normal/log_std Mean           -0.874301
trainer/policy/normal/log_std Std             0.419225
trainer/policy/normal/log_std Max             0.254599
trainer/policy/normal/log_std Min            -2.66289
trainer/Alpha                                 0.159341
trainer/Alpha Loss                            1.2686
expl/num steps total                     473000
expl/num paths total                        473
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.92927
expl/Rewards Std                              1.31176
expl/Rewards Max                              8.48324
expl/Rewards Min                             -0.606797
expl/Returns Mean                          5929.27
expl/Returns Std                              0
expl/Returns Max                           5929.27
expl/Returns Min                           5929.27
expl/Actions Mean                             0.101073
expl/Actions Std                              0.793249
expl/Actions Max                              0.998883
expl/Actions Min                             -0.999226
expl/Num Paths                                1
expl/Average Returns                       5929.27
expl/env_infos/final/reward_run Mean          5.60502
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.60502
expl/env_infos/final/reward_run Min           5.60502
expl/env_infos/initial/reward_run Mean       -0.441608
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.441608
expl/env_infos/initial/reward_run Min        -0.441608
expl/env_infos/reward_run Mean                6.31295
expl/env_infos/reward_run Std                 1.3102
expl/env_infos/reward_run Max                 8.92301
expl/env_infos/reward_run Min                -0.441608
expl/env_infos/final/reward_ctrl Mean        -0.418785
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.418785
expl/env_infos/final/reward_ctrl Min         -0.418785
expl/env_infos/initial/reward_ctrl Mean      -0.165189
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.165189
expl/env_infos/initial/reward_ctrl Min       -0.165189
expl/env_infos/reward_ctrl Mean              -0.383676
expl/env_infos/reward_ctrl Std                0.0899767
expl/env_infos/reward_ctrl Max               -0.0999099
expl/env_infos/reward_ctrl Min               -0.576052
eval/num steps total                          2.36e+06
eval/num paths total                       2360
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.31728
eval/Rewards Std                              1.31107
eval/Rewards Max                              8.8991
eval/Rewards Min                             -0.885279
eval/Returns Mean                          6317.28
eval/Returns Std                             74.1877
eval/Returns Max                           6401.29
eval/Returns Min                           6206.71
eval/Actions Mean                             0.0919335
eval/Actions Std                              0.812604
eval/Actions Max                              0.994965
eval/Actions Min                             -0.997574
eval/Num Paths                                5
eval/Average Returns                       6317.28
eval/env_infos/final/reward_run Mean          7.35385
eval/env_infos/final/reward_run Std           0.913936
eval/env_infos/final/reward_run Max           8.42489
eval/env_infos/final/reward_run Min           5.68515
eval/env_infos/initial/reward_run Mean       -0.173002
eval/env_infos/initial/reward_run Std         0.466867
eval/env_infos/initial/reward_run Max         0.749128
eval/env_infos/initial/reward_run Min        -0.497315
eval/env_infos/reward_run Mean                6.71854
eval/env_infos/reward_run Std                 1.30551
eval/env_infos/reward_run Max                 9.27408
eval/env_infos/reward_run Min                -0.497315
eval/env_infos/final/reward_ctrl Mean        -0.378892
eval/env_infos/final/reward_ctrl Std          0.0553958
eval/env_infos/final/reward_ctrl Max         -0.303073
eval/env_infos/final/reward_ctrl Min         -0.470633
eval/env_infos/initial/reward_ctrl Mean      -0.239561
eval/env_infos/initial/reward_ctrl Std        0.0305453
eval/env_infos/initial/reward_ctrl Max       -0.211879
eval/env_infos/initial/reward_ctrl Min       -0.293656
eval/env_infos/reward_ctrl Mean              -0.401266
eval/env_infos/reward_ctrl Std                0.0826548
eval/env_infos/reward_ctrl Max               -0.0498779
eval/env_infos/reward_ctrl Min               -0.576682
time/data storing (s)                         0.00451165
time/evaluation sampling (s)                  2.01343
time/exploration sampling (s)                 0.531453
time/logging (s)                              0.0136817
time/sac training (s)                         7.45427
time/saving (s)                               0.00378172
time/training (s)                             3.4202e-05
time/epoch (s)                               10.0212
time/total (s)                             4960.5
Epoch                                       471
---------------------------------------  ---------------
2021-11-24 01:52:07.798807 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 472 finished
---------------------------------------  ---------------
epoch                                       472
replay_buffer/size                       474000
trainer/num train calls                  473000
trainer/QF1 Loss                              4.24882
trainer/QF2 Loss                              4.31088
trainer/Policy Loss                        -421.464
trainer/Q1 Predictions Mean                 422.283
trainer/Q1 Predictions Std                  100.684
trainer/Q1 Predictions Max                  496.087
trainer/Q1 Predictions Min                   24.4343
trainer/Q2 Predictions Mean                 422.156
trainer/Q2 Predictions Std                  100.759
trainer/Q2 Predictions Max                  496.977
trainer/Q2 Predictions Min                   24.0243
trainer/Q Targets Mean                      422.132
trainer/Q Targets Std                       100.771
trainer/Q Targets Max                       497.035
trainer/Q Targets Min                        24.3585
trainer/Log Pis Mean                          5.94175
trainer/Log Pis Std                           3.94002
trainer/Log Pis Max                          14.7188
trainer/Log Pis Min                          -4.10679
trainer/policy/mean Mean                      0.0995419
trainer/policy/mean Std                       0.772555
trainer/policy/mean Max                       0.994794
trainer/policy/mean Min                      -0.994196
trainer/policy/normal/std Mean                0.450873
trainer/policy/normal/std Std                 0.154206
trainer/policy/normal/std Max                 1.01
trainer/policy/normal/std Min                 0.0749606
trainer/policy/normal/log_std Mean           -0.877801
trainer/policy/normal/log_std Std             0.449673
trainer/policy/normal/log_std Max             0.00994607
trainer/policy/normal/log_std Min            -2.59079
trainer/Alpha                                 0.158161
trainer/Alpha Loss                           -0.107426
expl/num steps total                     474000
expl/num paths total                        474
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.01303
expl/Rewards Std                              1.24703
expl/Rewards Max                              8.24639
expl/Rewards Min                             -0.716277
expl/Returns Mean                          6013.03
expl/Returns Std                              0
expl/Returns Max                           6013.03
expl/Returns Min                           6013.03
expl/Actions Mean                             0.0924939
expl/Actions Std                              0.791353
expl/Actions Max                              0.999161
expl/Actions Min                             -0.999293
expl/Num Paths                                1
expl/Average Returns                       6013.03
expl/env_infos/final/reward_run Mean          6.62931
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.62931
expl/env_infos/final/reward_run Min           6.62931
expl/env_infos/initial/reward_run Mean       -0.502429
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.502429
expl/env_infos/initial/reward_run Min        -0.502429
expl/env_infos/reward_run Mean                6.3939
expl/env_infos/reward_run Std                 1.24165
expl/env_infos/reward_run Max                 8.71193
expl/env_infos/reward_run Min                -0.502429
expl/env_infos/final/reward_ctrl Mean        -0.403684
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.403684
expl/env_infos/final/reward_ctrl Min         -0.403684
expl/env_infos/initial/reward_ctrl Mean      -0.213849
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.213849
expl/env_infos/initial/reward_ctrl Min       -0.213849
expl/env_infos/reward_ctrl Mean              -0.380877
expl/env_infos/reward_ctrl Std                0.0897588
expl/env_infos/reward_ctrl Max               -0.0317493
expl/env_infos/reward_ctrl Min               -0.576435
eval/num steps total                          2.365e+06
eval/num paths total                       2365
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.27958
eval/Rewards Std                              1.29436
eval/Rewards Max                              8.86911
eval/Rewards Min                             -1.04683
eval/Returns Mean                          6279.58
eval/Returns Std                             72.4673
eval/Returns Max                           6399.53
eval/Returns Min                           6172.84
eval/Actions Mean                             0.0939949
eval/Actions Std                              0.805451
eval/Actions Max                              0.999082
eval/Actions Min                             -0.996613
eval/Num Paths                                5
eval/Average Returns                       6279.58
eval/env_infos/final/reward_run Mean          7.24526
eval/env_infos/final/reward_run Std           0.752572
eval/env_infos/final/reward_run Max           7.96475
eval/env_infos/final/reward_run Min           5.8927
eval/env_infos/initial/reward_run Mean       -0.211193
eval/env_infos/initial/reward_run Std         0.249426
eval/env_infos/initial/reward_run Max         0.261467
eval/env_infos/initial/reward_run Min        -0.426319
eval/env_infos/reward_run Mean                6.67413
eval/env_infos/reward_run Std                 1.28818
eval/env_infos/reward_run Max                 9.35463
eval/env_infos/reward_run Min                -0.559954
eval/env_infos/final/reward_ctrl Mean        -0.426021
eval/env_infos/final/reward_ctrl Std          0.0840014
eval/env_infos/final/reward_ctrl Max         -0.312819
eval/env_infos/final/reward_ctrl Min         -0.533557
eval/env_infos/initial/reward_ctrl Mean      -0.206886
eval/env_infos/initial/reward_ctrl Std        0.0371718
eval/env_infos/initial/reward_ctrl Max       -0.172536
eval/env_infos/initial/reward_ctrl Min       -0.253925
eval/env_infos/reward_ctrl Mean              -0.394551
eval/env_infos/reward_ctrl Std                0.0916546
eval/env_infos/reward_ctrl Max               -0.0687285
eval/env_infos/reward_ctrl Min               -0.571656
time/data storing (s)                         0.00449975
time/evaluation sampling (s)                  2.02237
time/exploration sampling (s)                 0.530522
time/logging (s)                              0.0136895
time/sac training (s)                         7.43406
time/saving (s)                               0.00376498
time/training (s)                             3.5048e-05
time/epoch (s)                               10.0089
time/total (s)                             4970.79
Epoch                                       472
---------------------------------------  ---------------
2021-11-24 01:52:18.068252 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 473 finished
---------------------------------------  ---------------
epoch                                       473
replay_buffer/size                       475000
trainer/num train calls                  474000
trainer/QF1 Loss                              6.52335
trainer/QF2 Loss                              6.64231
trainer/Policy Loss                        -416.35
trainer/Q1 Predictions Mean                 417.067
trainer/Q1 Predictions Std                   95.8428
trainer/Q1 Predictions Max                  492.031
trainer/Q1 Predictions Min                   23.5488
trainer/Q2 Predictions Mean                 416.953
trainer/Q2 Predictions Std                   95.7791
trainer/Q2 Predictions Max                  492.638
trainer/Q2 Predictions Min                   23.725
trainer/Q Targets Mean                      416.931
trainer/Q Targets Std                        95.8129
trainer/Q Targets Max                       492.677
trainer/Q Targets Min                        22.1364
trainer/Log Pis Mean                          5.86795
trainer/Log Pis Std                           4.29175
trainer/Log Pis Max                          17.2437
trainer/Log Pis Min                          -5.1354
trainer/policy/mean Mean                      0.0692075
trainer/policy/mean Std                       0.781025
trainer/policy/mean Max                       0.993963
trainer/policy/mean Min                      -0.995458
trainer/policy/normal/std Mean                0.448253
trainer/policy/normal/std Std                 0.141127
trainer/policy/normal/std Max                 0.919947
trainer/policy/normal/std Min                 0.0643451
trainer/policy/normal/log_std Mean           -0.873762
trainer/policy/normal/log_std Std             0.426283
trainer/policy/normal/log_std Max            -0.0834393
trainer/policy/normal/log_std Min            -2.7435
trainer/Alpha                                 0.15804
trainer/Alpha Loss                           -0.243618
expl/num steps total                     475000
expl/num paths total                        475
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.14945
expl/Rewards Std                              1.25769
expl/Rewards Max                              8.56126
expl/Rewards Min                             -0.544962
expl/Returns Mean                          6149.45
expl/Returns Std                              0
expl/Returns Max                           6149.45
expl/Returns Min                           6149.45
expl/Actions Mean                             0.101866
expl/Actions Std                              0.798157
expl/Actions Max                              0.999315
expl/Actions Min                             -0.999229
expl/Num Paths                                1
expl/Average Returns                       6149.45
expl/env_infos/final/reward_run Mean          7.47828
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.47828
expl/env_infos/final/reward_run Min           7.47828
expl/env_infos/initial/reward_run Mean       -0.268888
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.268888
expl/env_infos/initial/reward_run Min        -0.268888
expl/env_infos/reward_run Mean                6.53791
expl/env_infos/reward_run Std                 1.25587
expl/env_infos/reward_run Max                 9.08577
expl/env_infos/reward_run Min                -0.268888
expl/env_infos/final/reward_ctrl Mean        -0.379097
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.379097
expl/env_infos/final/reward_ctrl Min         -0.379097
expl/env_infos/initial/reward_ctrl Mean      -0.276074
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.276074
expl/env_infos/initial/reward_ctrl Min       -0.276074
expl/env_infos/reward_ctrl Mean              -0.388458
expl/env_infos/reward_ctrl Std                0.0841645
expl/env_infos/reward_ctrl Max               -0.0909421
expl/env_infos/reward_ctrl Min               -0.564476
eval/num steps total                          2.37e+06
eval/num paths total                       2370
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.47894
eval/Rewards Std                              1.31105
eval/Rewards Max                              9.00733
eval/Rewards Min                             -0.803176
eval/Returns Mean                          6478.94
eval/Returns Std                             48.4907
eval/Returns Max                           6553.1
eval/Returns Min                           6402.05
eval/Actions Mean                             0.0940056
eval/Actions Std                              0.815755
eval/Actions Max                              0.994582
eval/Actions Min                             -0.995928
eval/Num Paths                                5
eval/Average Returns                       6478.94
eval/env_infos/final/reward_run Mean          6.79148
eval/env_infos/final/reward_run Std           0.694666
eval/env_infos/final/reward_run Max           7.95298
eval/env_infos/final/reward_run Min           5.91202
eval/env_infos/initial/reward_run Mean       -0.0439758
eval/env_infos/initial/reward_run Std         0.392018
eval/env_infos/initial/reward_run Max         0.377173
eval/env_infos/initial/reward_run Min        -0.607111
eval/env_infos/reward_run Mean                6.88352
eval/env_infos/reward_run Std                 1.31159
eval/env_infos/reward_run Max                 9.5521
eval/env_infos/reward_run Min                -0.607111
eval/env_infos/final/reward_ctrl Mean        -0.320446
eval/env_infos/final/reward_ctrl Std          0.0667434
eval/env_infos/final/reward_ctrl Max         -0.205922
eval/env_infos/final/reward_ctrl Min         -0.39135
eval/env_infos/initial/reward_ctrl Mean      -0.147092
eval/env_infos/initial/reward_ctrl Std        0.0470874
eval/env_infos/initial/reward_ctrl Max       -0.0679139
eval/env_infos/initial/reward_ctrl Min       -0.196065
eval/env_infos/reward_ctrl Mean              -0.404576
eval/env_infos/reward_ctrl Std                0.084137
eval/env_infos/reward_ctrl Max               -0.0679139
eval/env_infos/reward_ctrl Min               -0.573914
time/data storing (s)                         0.00451124
time/evaluation sampling (s)                  2.00349
time/exploration sampling (s)                 0.532843
time/logging (s)                              0.0136088
time/sac training (s)                         7.4159
time/saving (s)                               0.00378128
time/training (s)                             3.3606e-05
time/epoch (s)                                9.97417
time/total (s)                             4981.04
Epoch                                       473
---------------------------------------  ---------------
2021-11-24 01:52:28.528794 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 474 finished
---------------------------------------  ---------------
epoch                                       474
replay_buffer/size                       476000
trainer/num train calls                  475000
trainer/QF1 Loss                              6.29878
trainer/QF2 Loss                              6.94579
trainer/Policy Loss                        -426.769
trainer/Q1 Predictions Mean                 427.37
trainer/Q1 Predictions Std                   75.7246
trainer/Q1 Predictions Max                  485.817
trainer/Q1 Predictions Min                   22.9699
trainer/Q2 Predictions Mean                 427.578
trainer/Q2 Predictions Std                   75.4299
trainer/Q2 Predictions Max                  486.105
trainer/Q2 Predictions Min                   25.2588
trainer/Q Targets Mean                      427.972
trainer/Q Targets Std                        75.9321
trainer/Q Targets Max                       486.103
trainer/Q Targets Min                        23.9063
trainer/Log Pis Mean                          6.24715
trainer/Log Pis Std                           3.92876
trainer/Log Pis Max                          20.9514
trainer/Log Pis Min                          -4.57364
trainer/policy/mean Mean                      0.0692398
trainer/policy/mean Std                       0.7996
trainer/policy/mean Max                       0.998781
trainer/policy/mean Min                      -0.999689
trainer/policy/normal/std Mean                0.446886
trainer/policy/normal/std Std                 0.135671
trainer/policy/normal/std Max                 0.987471
trainer/policy/normal/std Min                 0.0629801
trainer/policy/normal/log_std Mean           -0.872936
trainer/policy/normal/log_std Std             0.415049
trainer/policy/normal/log_std Max            -0.0126079
trainer/policy/normal/log_std Min            -2.76494
trainer/Alpha                                 0.158367
trainer/Alpha Loss                            0.455459
expl/num steps total                     476000
expl/num paths total                        476
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.16329
expl/Rewards Std                              1.29885
expl/Rewards Max                              8.55343
expl/Rewards Min                             -0.715459
expl/Returns Mean                          6163.29
expl/Returns Std                              0
expl/Returns Max                           6163.29
expl/Returns Min                           6163.29
expl/Actions Mean                             0.108185
expl/Actions Std                              0.80193
expl/Actions Max                              0.999613
expl/Actions Min                             -0.999435
expl/Num Paths                                1
expl/Average Returns                       6163.29
expl/env_infos/final/reward_run Mean          6.34798
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.34798
expl/env_infos/final/reward_run Min           6.34798
expl/env_infos/initial/reward_run Mean        0.00369557
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.00369557
expl/env_infos/initial/reward_run Min         0.00369557
expl/env_infos/reward_run Mean                6.55617
expl/env_infos/reward_run Std                 1.2984
expl/env_infos/reward_run Max                 9.06701
expl/env_infos/reward_run Min                -0.262583
expl/env_infos/final/reward_ctrl Mean        -0.422018
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.422018
expl/env_infos/final/reward_ctrl Min         -0.422018
expl/env_infos/initial/reward_ctrl Mean      -0.217703
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.217703
expl/env_infos/initial/reward_ctrl Min       -0.217703
expl/env_infos/reward_ctrl Mean              -0.392878
expl/env_infos/reward_ctrl Std                0.0869267
expl/env_infos/reward_ctrl Max               -0.0917271
expl/env_infos/reward_ctrl Min               -0.568413
eval/num steps total                          2.375e+06
eval/num paths total                       2375
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.54236
eval/Rewards Std                              1.36216
eval/Rewards Max                              9.13427
eval/Rewards Min                             -0.882179
eval/Returns Mean                          6542.36
eval/Returns Std                             75.0128
eval/Returns Max                           6667.92
eval/Returns Min                           6437.47
eval/Actions Mean                             0.10936
eval/Actions Std                              0.82038
eval/Actions Max                              0.998576
eval/Actions Min                             -0.998126
eval/Num Paths                                5
eval/Average Returns                       6542.36
eval/env_infos/final/reward_run Mean          7.01587
eval/env_infos/final/reward_run Std           0.847272
eval/env_infos/final/reward_run Max           8.40657
eval/env_infos/final/reward_run Min           6.031
eval/env_infos/initial/reward_run Mean       -0.16049
eval/env_infos/initial/reward_run Std         0.16696
eval/env_infos/initial/reward_run Max         0.0118697
eval/env_infos/initial/reward_run Min        -0.449433
eval/env_infos/reward_run Mean                6.95335
eval/env_infos/reward_run Std                 1.36331
eval/env_infos/reward_run Max                 9.6796
eval/env_infos/reward_run Min                -0.449433
eval/env_infos/final/reward_ctrl Mean        -0.362018
eval/env_infos/final/reward_ctrl Std          0.121427
eval/env_infos/final/reward_ctrl Max         -0.138916
eval/env_infos/final/reward_ctrl Min         -0.473778
eval/env_infos/initial/reward_ctrl Mean      -0.219562
eval/env_infos/initial/reward_ctrl Std        0.0460556
eval/env_infos/initial/reward_ctrl Max       -0.156545
eval/env_infos/initial/reward_ctrl Min       -0.297422
eval/env_infos/reward_ctrl Mean              -0.410989
eval/env_infos/reward_ctrl Std                0.0835957
eval/env_infos/reward_ctrl Max               -0.117446
eval/env_infos/reward_ctrl Min               -0.573942
time/data storing (s)                         0.00449209
time/evaluation sampling (s)                  2.04307
time/exploration sampling (s)                 0.548093
time/logging (s)                              0.0136863
time/sac training (s)                         7.54473
time/saving (s)                               0.0037807
time/training (s)                             3.5107e-05
time/epoch (s)                               10.1579
time/total (s)                             4991.49
Epoch                                       474
---------------------------------------  ---------------
2021-11-24 01:52:38.989649 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 475 finished
---------------------------------------  ---------------
epoch                                       475
replay_buffer/size                       477000
trainer/num train calls                  476000
trainer/QF1 Loss                              4.91039
trainer/QF2 Loss                              5.80385
trainer/Policy Loss                        -418.903
trainer/Q1 Predictions Mean                 419.584
trainer/Q1 Predictions Std                   95.2472
trainer/Q1 Predictions Max                  492.063
trainer/Q1 Predictions Min                   24.7712
trainer/Q2 Predictions Mean                 419.459
trainer/Q2 Predictions Std                   95.1545
trainer/Q2 Predictions Max                  492.619
trainer/Q2 Predictions Min                   25.4943
trainer/Q Targets Mean                      419.1
trainer/Q Targets Std                        95.1238
trainer/Q Targets Max                       489.135
trainer/Q Targets Min                        24.4432
trainer/Log Pis Mean                          6.01344
trainer/Log Pis Std                           4.24068
trainer/Log Pis Max                          17.4867
trainer/Log Pis Min                          -7.01724
trainer/policy/mean Mean                      0.0958073
trainer/policy/mean Std                       0.781601
trainer/policy/mean Max                       0.997269
trainer/policy/mean Min                      -0.999105
trainer/policy/normal/std Mean                0.446263
trainer/policy/normal/std Std                 0.144944
trainer/policy/normal/std Max                 0.947013
trainer/policy/normal/std Min                 0.0741675
trainer/policy/normal/log_std Mean           -0.878252
trainer/policy/normal/log_std Std             0.41789
trainer/policy/normal/log_std Max            -0.0544422
trainer/policy/normal/log_std Min            -2.60143
trainer/Alpha                                 0.157519
trainer/Alpha Loss                            0.0248333
expl/num steps total                     477000
expl/num paths total                        477
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.23378
expl/Rewards Std                              1.29254
expl/Rewards Max                              8.58571
expl/Rewards Min                             -0.468553
expl/Returns Mean                          6233.78
expl/Returns Std                              0
expl/Returns Max                           6233.78
expl/Returns Min                           6233.78
expl/Actions Mean                             0.0987834
expl/Actions Std                              0.804034
expl/Actions Max                              0.999594
expl/Actions Min                             -0.999427
expl/Num Paths                                1
expl/Average Returns                       6233.78
expl/env_infos/final/reward_run Mean          7.42084
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.42084
expl/env_infos/final/reward_run Min           7.42084
expl/env_infos/initial/reward_run Mean       -0.169441
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.169441
expl/env_infos/initial/reward_run Min        -0.169441
expl/env_infos/reward_run Mean                6.62751
expl/env_infos/reward_run Std                 1.29115
expl/env_infos/reward_run Max                 9.1046
expl/env_infos/reward_run Min                -0.169441
expl/env_infos/final/reward_ctrl Mean        -0.316009
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.316009
expl/env_infos/final/reward_ctrl Min         -0.316009
expl/env_infos/initial/reward_ctrl Mean      -0.299112
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.299112
expl/env_infos/initial/reward_ctrl Min       -0.299112
expl/env_infos/reward_ctrl Mean              -0.393737
expl/env_infos/reward_ctrl Std                0.0796133
expl/env_infos/reward_ctrl Max               -0.14102
expl/env_infos/reward_ctrl Min               -0.567971
eval/num steps total                          2.38e+06
eval/num paths total                       2380
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.50288
eval/Rewards Std                              1.36716
eval/Rewards Max                              9.23385
eval/Rewards Min                             -0.817995
eval/Returns Mean                          6502.88
eval/Returns Std                            118.032
eval/Returns Max                           6696.47
eval/Returns Min                           6357.53
eval/Actions Mean                             0.0962332
eval/Actions Std                              0.817909
eval/Actions Max                              0.996115
eval/Actions Min                             -0.99643
eval/Num Paths                                5
eval/Average Returns                       6502.88
eval/env_infos/final/reward_run Mean          7.35506
eval/env_infos/final/reward_run Std           0.764684
eval/env_infos/final/reward_run Max           8.17601
eval/env_infos/final/reward_run Min           6.14409
eval/env_infos/initial/reward_run Mean       -0.285531
eval/env_infos/initial/reward_run Std         0.364791
eval/env_infos/initial/reward_run Max         0.397944
eval/env_infos/initial/reward_run Min        -0.603043
eval/env_infos/reward_run Mean                6.90982
eval/env_infos/reward_run Std                 1.3706
eval/env_infos/reward_run Max                 9.79025
eval/env_infos/reward_run Min                -0.603043
eval/env_infos/final/reward_ctrl Mean        -0.428155
eval/env_infos/final/reward_ctrl Std          0.0351844
eval/env_infos/final/reward_ctrl Max         -0.366746
eval/env_infos/final/reward_ctrl Min         -0.470601
eval/env_infos/initial/reward_ctrl Mean      -0.227348
eval/env_infos/initial/reward_ctrl Std        0.0660904
eval/env_infos/initial/reward_ctrl Max       -0.107156
eval/env_infos/initial/reward_ctrl Min       -0.278499
eval/env_infos/reward_ctrl Mean              -0.406941
eval/env_infos/reward_ctrl Std                0.0823477
eval/env_infos/reward_ctrl Max               -0.067125
eval/env_infos/reward_ctrl Min               -0.568014
time/data storing (s)                         0.00732332
time/evaluation sampling (s)                  2.0411
time/exploration sampling (s)                 0.533491
time/logging (s)                              0.0138241
time/sac training (s)                         7.55668
time/saving (s)                               0.00376307
time/training (s)                             3.3544e-05
time/epoch (s)                               10.1562
time/total (s)                             5001.93
Epoch                                       475
---------------------------------------  ---------------
2021-11-24 01:52:49.407052 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 476 finished
---------------------------------------  ---------------
epoch                                       476
replay_buffer/size                       478000
trainer/num train calls                  477000
trainer/QF1 Loss                              6.13203
trainer/QF2 Loss                              6.06122
trainer/Policy Loss                        -424.15
trainer/Q1 Predictions Mean                 424.723
trainer/Q1 Predictions Std                   92.3297
trainer/Q1 Predictions Max                  487.301
trainer/Q1 Predictions Min                   26.0029
trainer/Q2 Predictions Mean                 424.958
trainer/Q2 Predictions Std                   92.2392
trainer/Q2 Predictions Max                  486.68
trainer/Q2 Predictions Min                   26.5868
trainer/Q Targets Mean                      424.853
trainer/Q Targets Std                        92.519
trainer/Q Targets Max                       487.91
trainer/Q Targets Min                        23.6025
trainer/Log Pis Mean                          6.04168
trainer/Log Pis Std                           4.2175
trainer/Log Pis Max                          17.5359
trainer/Log Pis Min                          -4.73546
trainer/policy/mean Mean                      0.105968
trainer/policy/mean Std                       0.774091
trainer/policy/mean Max                       0.997371
trainer/policy/mean Min                      -0.99222
trainer/policy/normal/std Mean                0.446827
trainer/policy/normal/std Std                 0.143958
trainer/policy/normal/std Max                 1.06337
trainer/policy/normal/std Min                 0.0651872
trainer/policy/normal/log_std Mean           -0.876599
trainer/policy/normal/log_std Std             0.41928
trainer/policy/normal/log_std Max             0.0614419
trainer/policy/normal/log_std Min            -2.73049
trainer/Alpha                                 0.158175
trainer/Alpha Loss                            0.0768592
expl/num steps total                     478000
expl/num paths total                        478
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.20988
expl/Rewards Std                              1.32248
expl/Rewards Max                              8.69213
expl/Rewards Min                             -0.49216
expl/Returns Mean                          6209.88
expl/Returns Std                              0
expl/Returns Max                           6209.88
expl/Returns Min                           6209.88
expl/Actions Mean                             0.099476
expl/Actions Std                              0.804587
expl/Actions Max                              0.999601
expl/Actions Min                             -0.99928
expl/Num Paths                                1
expl/Average Returns                       6209.88
expl/env_infos/final/reward_run Mean          5.43107
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.43107
expl/env_infos/final/reward_run Min           5.43107
expl/env_infos/initial/reward_run Mean       -0.254374
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.254374
expl/env_infos/initial/reward_run Min        -0.254374
expl/env_infos/reward_run Mean                6.60423
expl/env_infos/reward_run Std                 1.31391
expl/env_infos/reward_run Max                 9.17964
expl/env_infos/reward_run Min                -0.254374
expl/env_infos/final/reward_ctrl Mean        -0.462694
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.462694
expl/env_infos/final/reward_ctrl Min         -0.462694
expl/env_infos/initial/reward_ctrl Mean      -0.237786
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.237786
expl/env_infos/initial/reward_ctrl Min       -0.237786
expl/env_infos/reward_ctrl Mean              -0.394354
expl/env_infos/reward_ctrl Std                0.0905753
expl/env_infos/reward_ctrl Max               -0.108929
expl/env_infos/reward_ctrl Min               -0.579798
eval/num steps total                          2.385e+06
eval/num paths total                       2385
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.43379
eval/Rewards Std                              1.32667
eval/Rewards Max                              8.83887
eval/Rewards Min                             -0.686155
eval/Returns Mean                          6433.79
eval/Returns Std                             21.4584
eval/Returns Max                           6467.39
eval/Returns Min                           6415.54
eval/Actions Mean                             0.0908407
eval/Actions Std                              0.818274
eval/Actions Max                              0.997357
eval/Actions Min                             -0.997748
eval/Num Paths                                5
eval/Average Returns                       6433.79
eval/env_infos/final/reward_run Mean          6.89617
eval/env_infos/final/reward_run Std           1.34611
eval/env_infos/final/reward_run Max           8.91208
eval/env_infos/final/reward_run Min           5.34869
eval/env_infos/initial/reward_run Mean       -0.306769
eval/env_infos/initial/reward_run Std         0.125268
eval/env_infos/initial/reward_run Max        -0.171696
eval/env_infos/initial/reward_run Min        -0.466358
eval/env_infos/reward_run Mean                6.84049
eval/env_infos/reward_run Std                 1.31823
eval/env_infos/reward_run Max                 9.34354
eval/env_infos/reward_run Min                -0.466358
eval/env_infos/final/reward_ctrl Mean        -0.428292
eval/env_infos/final/reward_ctrl Std          0.0484126
eval/env_infos/final/reward_ctrl Max         -0.358793
eval/env_infos/final/reward_ctrl Min         -0.484997
eval/env_infos/initial/reward_ctrl Mean      -0.204103
eval/env_infos/initial/reward_ctrl Std        0.0254004
eval/env_infos/initial/reward_ctrl Max       -0.168316
eval/env_infos/initial/reward_ctrl Min       -0.246542
eval/env_infos/reward_ctrl Mean              -0.406694
eval/env_infos/reward_ctrl Std                0.0895448
eval/env_infos/reward_ctrl Max               -0.0378139
eval/env_infos/reward_ctrl Min               -0.577636
time/data storing (s)                         0.00455077
time/evaluation sampling (s)                  2.01303
time/exploration sampling (s)                 0.532863
time/logging (s)                              0.0136776
time/sac training (s)                         7.54354
time/saving (s)                               0.00382392
time/training (s)                             3.5395e-05
time/epoch (s)                               10.1115
time/total (s)                             5012.34
Epoch                                       476
---------------------------------------  ---------------
2021-11-24 01:52:59.637600 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 477 finished
---------------------------------------  ---------------
epoch                                       477
replay_buffer/size                       479000
trainer/num train calls                  478000
trainer/QF1 Loss                              5.68633
trainer/QF2 Loss                              5.55636
trainer/Policy Loss                        -421.29
trainer/Q1 Predictions Mean                 421.808
trainer/Q1 Predictions Std                   94.6962
trainer/Q1 Predictions Max                  495.914
trainer/Q1 Predictions Min                   24.51
trainer/Q2 Predictions Mean                 421.722
trainer/Q2 Predictions Std                   94.6775
trainer/Q2 Predictions Max                  495.281
trainer/Q2 Predictions Min                   25.6884
trainer/Q Targets Mean                      422.781
trainer/Q Targets Std                        95.1465
trainer/Q Targets Max                       496.202
trainer/Q Targets Min                        23.9032
trainer/Log Pis Mean                          6.44374
trainer/Log Pis Std                           4.13925
trainer/Log Pis Max                          17.1807
trainer/Log Pis Min                          -5.71441
trainer/policy/mean Mean                      0.0981176
trainer/policy/mean Std                       0.786622
trainer/policy/mean Max                       0.998347
trainer/policy/mean Min                      -0.997934
trainer/policy/normal/std Mean                0.442568
trainer/policy/normal/std Std                 0.144414
trainer/policy/normal/std Max                 0.909977
trainer/policy/normal/std Min                 0.0577405
trainer/policy/normal/log_std Mean           -0.890513
trainer/policy/normal/log_std Std             0.435127
trainer/policy/normal/log_std Max            -0.0943361
trainer/policy/normal/log_std Min            -2.8518
trainer/Alpha                                 0.160552
trainer/Alpha Loss                            0.811656
expl/num steps total                     479000
expl/num paths total                        479
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11923
expl/Rewards Std                              1.33019
expl/Rewards Max                              8.26292
expl/Rewards Min                             -0.98684
expl/Returns Mean                          6119.23
expl/Returns Std                              0
expl/Returns Max                           6119.23
expl/Returns Min                           6119.23
expl/Actions Mean                             0.109738
expl/Actions Std                              0.798606
expl/Actions Max                              0.999469
expl/Actions Min                             -0.999366
expl/Num Paths                                1
expl/Average Returns                       6119.23
expl/env_infos/final/reward_run Mean          8.2632
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.2632
expl/env_infos/final/reward_run Min           8.2632
expl/env_infos/initial/reward_run Mean       -0.765801
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.765801
expl/env_infos/initial/reward_run Min        -0.765801
expl/env_infos/reward_run Mean                6.50912
expl/env_infos/reward_run Std                 1.33163
expl/env_infos/reward_run Max                 8.70532
expl/env_infos/reward_run Min                -0.765801
expl/env_infos/final/reward_ctrl Mean        -0.27905
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.27905
expl/env_infos/final/reward_ctrl Min         -0.27905
expl/env_infos/initial/reward_ctrl Mean      -0.221039
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.221039
expl/env_infos/initial/reward_ctrl Min       -0.221039
expl/env_infos/reward_ctrl Mean              -0.389889
expl/env_infos/reward_ctrl Std                0.0888164
expl/env_infos/reward_ctrl Max               -0.0953663
expl/env_infos/reward_ctrl Min               -0.575334
eval/num steps total                          2.39e+06
eval/num paths total                       2390
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.37155
eval/Rewards Std                              1.32247
eval/Rewards Max                              8.90863
eval/Rewards Min                             -0.94775
eval/Returns Mean                          6371.55
eval/Returns Std                             75.4638
eval/Returns Max                           6462.04
eval/Returns Min                           6266.89
eval/Actions Mean                             0.0945463
eval/Actions Std                              0.812048
eval/Actions Max                              0.995201
eval/Actions Min                             -0.998591
eval/Num Paths                                5
eval/Average Returns                       6371.55
eval/env_infos/final/reward_run Mean          7.42064
eval/env_infos/final/reward_run Std           0.252162
eval/env_infos/final/reward_run Max           7.66518
eval/env_infos/final/reward_run Min           6.95048
eval/env_infos/initial/reward_run Mean       -0.00763911
eval/env_infos/initial/reward_run Std         0.517077
eval/env_infos/initial/reward_run Max         0.990404
eval/env_infos/initial/reward_run Min        -0.449785
eval/env_infos/reward_run Mean                6.77257
eval/env_infos/reward_run Std                 1.31844
eval/env_infos/reward_run Max                 9.43031
eval/env_infos/reward_run Min                -0.471462
eval/env_infos/final/reward_ctrl Mean        -0.349822
eval/env_infos/final/reward_ctrl Std          0.0295063
eval/env_infos/final/reward_ctrl Max         -0.299533
eval/env_infos/final/reward_ctrl Min         -0.391396
eval/env_infos/initial/reward_ctrl Mean      -0.244268
eval/env_infos/initial/reward_ctrl Std        0.108015
eval/env_infos/initial/reward_ctrl Max       -0.157879
eval/env_infos/initial/reward_ctrl Min       -0.451386
eval/env_infos/reward_ctrl Mean              -0.401017
eval/env_infos/reward_ctrl Std                0.0881054
eval/env_infos/reward_ctrl Max               -0.0990002
eval/env_infos/reward_ctrl Min               -0.577419
time/data storing (s)                         0.00446078
time/evaluation sampling (s)                  2.0021
time/exploration sampling (s)                 0.531934
time/logging (s)                              0.0137012
time/sac training (s)                         7.37986
time/saving (s)                               0.00380073
time/training (s)                             3.4453e-05
time/epoch (s)                                9.93589
time/total (s)                             5022.55
Epoch                                       477
---------------------------------------  ---------------
2021-11-24 01:53:09.850482 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 478 finished
---------------------------------------  ---------------
epoch                                       478
replay_buffer/size                       480000
trainer/num train calls                  479000
trainer/QF1 Loss                              5.06841
trainer/QF2 Loss                              5.019
trainer/Policy Loss                        -422.34
trainer/Q1 Predictions Mean                 423.165
trainer/Q1 Predictions Std                   91.7835
trainer/Q1 Predictions Max                  497.201
trainer/Q1 Predictions Min                   23.3732
trainer/Q2 Predictions Mean                 423.071
trainer/Q2 Predictions Std                   91.6442
trainer/Q2 Predictions Max                  497.02
trainer/Q2 Predictions Min                   24.0016
trainer/Q Targets Mean                      422.881
trainer/Q Targets Std                        91.5484
trainer/Q Targets Max                       495.589
trainer/Q Targets Min                        23.0625
trainer/Log Pis Mean                          5.5191
trainer/Log Pis Std                           4.23006
trainer/Log Pis Max                          15.6493
trainer/Log Pis Min                          -6.67864
trainer/policy/mean Mean                      0.0808611
trainer/policy/mean Std                       0.766648
trainer/policy/mean Max                       0.992969
trainer/policy/mean Min                      -0.994236
trainer/policy/normal/std Mean                0.441179
trainer/policy/normal/std Std                 0.142362
trainer/policy/normal/std Max                 0.94797
trainer/policy/normal/std Min                 0.0698558
trainer/policy/normal/log_std Mean           -0.892414
trainer/policy/normal/log_std Std             0.432181
trainer/policy/normal/log_std Max            -0.0534328
trainer/policy/normal/log_std Min            -2.66132
trainer/Alpha                                 0.162225
trainer/Alpha Loss                           -0.87465
expl/num steps total                     480000
expl/num paths total                        480
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11195
expl/Rewards Std                              1.26284
expl/Rewards Max                              8.51676
expl/Rewards Min                             -0.807379
expl/Returns Mean                          6111.95
expl/Returns Std                              0
expl/Returns Max                           6111.95
expl/Returns Min                           6111.95
expl/Actions Mean                             0.111473
expl/Actions Std                              0.796477
expl/Actions Max                              0.999346
expl/Actions Min                             -0.998635
expl/Num Paths                                1
expl/Average Returns                       6111.95
expl/env_infos/final/reward_run Mean          5.00033
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           5.00033
expl/env_infos/final/reward_run Min           5.00033
expl/env_infos/initial/reward_run Mean       -0.602803
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.602803
expl/env_infos/initial/reward_run Min        -0.602803
expl/env_infos/reward_run Mean                6.50003
expl/env_infos/reward_run Std                 1.25463
expl/env_infos/reward_run Max                 8.9509
expl/env_infos/reward_run Min                -0.602803
expl/env_infos/final/reward_ctrl Mean        -0.460588
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.460588
expl/env_infos/final/reward_ctrl Min         -0.460588
expl/env_infos/initial/reward_ctrl Mean      -0.204576
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.204576
expl/env_infos/initial/reward_ctrl Min       -0.204576
expl/env_infos/reward_ctrl Mean              -0.388081
expl/env_infos/reward_ctrl Std                0.0876863
expl/env_infos/reward_ctrl Max               -0.0912543
expl/env_infos/reward_ctrl Min               -0.563449
eval/num steps total                          2.395e+06
eval/num paths total                       2395
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.38783
eval/Rewards Std                              1.34179
eval/Rewards Max                              8.92068
eval/Rewards Min                             -0.96847
eval/Returns Mean                          6387.83
eval/Returns Std                             79.7678
eval/Returns Max                           6487.76
eval/Returns Min                           6253.83
eval/Actions Mean                             0.105076
eval/Actions Std                              0.812802
eval/Actions Max                              0.995436
eval/Actions Min                             -0.997101
eval/Num Paths                                5
eval/Average Returns                       6387.83
eval/env_infos/final/reward_run Mean          7.25307
eval/env_infos/final/reward_run Std           0.948705
eval/env_infos/final/reward_run Max           8.20867
eval/env_infos/final/reward_run Min           5.6388
eval/env_infos/initial/reward_run Mean        0.0110223
eval/env_infos/initial/reward_run Std         0.628862
eval/env_infos/initial/reward_run Max         0.806422
eval/env_infos/initial/reward_run Min        -0.732451
eval/env_infos/reward_run Mean                6.79084
eval/env_infos/reward_run Std                 1.33492
eval/env_infos/reward_run Max                 9.35645
eval/env_infos/reward_run Min                -0.732451
eval/env_infos/final/reward_ctrl Mean        -0.380409
eval/env_infos/final/reward_ctrl Std          0.0529167
eval/env_infos/final/reward_ctrl Max         -0.310239
eval/env_infos/final/reward_ctrl Min         -0.466288
eval/env_infos/initial/reward_ctrl Mean      -0.194631
eval/env_infos/initial/reward_ctrl Std        0.0226583
eval/env_infos/initial/reward_ctrl Max       -0.164032
eval/env_infos/initial/reward_ctrl Min       -0.231358
eval/env_infos/reward_ctrl Mean              -0.403013
eval/env_infos/reward_ctrl Std                0.0852688
eval/env_infos/reward_ctrl Max               -0.105049
eval/env_infos/reward_ctrl Min               -0.573342
time/data storing (s)                         0.00447941
time/evaluation sampling (s)                  1.99843
time/exploration sampling (s)                 0.529782
time/logging (s)                              0.0136779
time/sac training (s)                         7.36891
time/saving (s)                               0.00375251
time/training (s)                             3.4303e-05
time/epoch (s)                                9.91906
time/total (s)                             5032.75
Epoch                                       478
---------------------------------------  ---------------
2021-11-24 01:53:20.064174 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 479 finished
---------------------------------------  ---------------
epoch                                       479
replay_buffer/size                       481000
trainer/num train calls                  480000
trainer/QF1 Loss                              5.12831
trainer/QF2 Loss                              5.9429
trainer/Policy Loss                        -414.133
trainer/Q1 Predictions Mean                 414.84
trainer/Q1 Predictions Std                  100.876
trainer/Q1 Predictions Max                  497.643
trainer/Q1 Predictions Min                   24.3184
trainer/Q2 Predictions Mean                 414.647
trainer/Q2 Predictions Std                  101.1
trainer/Q2 Predictions Max                  499.734
trainer/Q2 Predictions Min                   23.1013
trainer/Q Targets Mean                      414.766
trainer/Q Targets Std                       100.869
trainer/Q Targets Max                       498.12
trainer/Q Targets Min                        24.2127
trainer/Log Pis Mean                          6.03041
trainer/Log Pis Std                           4.3838
trainer/Log Pis Max                          23.776
trainer/Log Pis Min                          -5.66506
trainer/policy/mean Mean                      0.0582748
trainer/policy/mean Std                       0.783848
trainer/policy/mean Max                       0.999762
trainer/policy/mean Min                      -0.998859
trainer/policy/normal/std Mean                0.454481
trainer/policy/normal/std Std                 0.145336
trainer/policy/normal/std Max                 0.895386
trainer/policy/normal/std Min                 0.0709247
trainer/policy/normal/log_std Mean           -0.859413
trainer/policy/normal/log_std Std             0.419791
trainer/policy/normal/log_std Max            -0.1105
trainer/policy/normal/log_std Min            -2.64614
trainer/Alpha                                 0.159894
trainer/Alpha Loss                            0.0557496
expl/num steps total                     481000
expl/num paths total                        481
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11076
expl/Rewards Std                              1.33129
expl/Rewards Max                              8.69818
expl/Rewards Min                             -0.438703
expl/Returns Mean                          6110.76
expl/Returns Std                              0
expl/Returns Max                           6110.76
expl/Returns Min                           6110.76
expl/Actions Mean                             0.0761206
expl/Actions Std                              0.797897
expl/Actions Max                              0.999252
expl/Actions Min                             -0.999703
expl/Num Paths                                1
expl/Average Returns                       6110.76
expl/env_infos/final/reward_run Mean          7.60455
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.60455
expl/env_infos/final/reward_run Min           7.60455
expl/env_infos/initial/reward_run Mean       -0.245307
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.245307
expl/env_infos/initial/reward_run Min        -0.245307
expl/env_infos/reward_run Mean                6.49622
expl/env_infos/reward_run Std                 1.33726
expl/env_infos/reward_run Max                 9.24839
expl/env_infos/reward_run Min                -0.245307
expl/env_infos/final/reward_ctrl Mean        -0.41414
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.41414
expl/env_infos/final/reward_ctrl Min         -0.41414
expl/env_infos/initial/reward_ctrl Mean      -0.127518
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.127518
expl/env_infos/initial/reward_ctrl Min       -0.127518
expl/env_infos/reward_ctrl Mean              -0.38546
expl/env_infos/reward_ctrl Std                0.0831931
expl/env_infos/reward_ctrl Max               -0.106335
expl/env_infos/reward_ctrl Min               -0.568323
eval/num steps total                          2.4e+06
eval/num paths total                       2400
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.40768
eval/Rewards Std                              1.3163
eval/Rewards Max                              8.81174
eval/Rewards Min                             -0.831944
eval/Returns Mean                          6407.68
eval/Returns Std                             45.9444
eval/Returns Max                           6487.59
eval/Returns Min                           6351.07
eval/Actions Mean                             0.06694
eval/Actions Std                              0.811073
eval/Actions Max                              0.996591
eval/Actions Min                             -0.995891
eval/Num Paths                                5
eval/Average Returns                       6407.68
eval/env_infos/final/reward_run Mean          7.97625
eval/env_infos/final/reward_run Std           0.470565
eval/env_infos/final/reward_run Max           8.47231
eval/env_infos/final/reward_run Min           7.28976
eval/env_infos/initial/reward_run Mean       -0.236224
eval/env_infos/initial/reward_run Std         0.248308
eval/env_infos/initial/reward_run Max         0.215495
eval/env_infos/initial/reward_run Min        -0.546455
eval/env_infos/reward_run Mean                6.80507
eval/env_infos/reward_run Std                 1.31678
eval/env_infos/reward_run Max                 9.35262
eval/env_infos/reward_run Min                -0.546455
eval/env_infos/final/reward_ctrl Mean        -0.404056
eval/env_infos/final/reward_ctrl Std          0.098347
eval/env_infos/final/reward_ctrl Max         -0.229754
eval/env_infos/final/reward_ctrl Min         -0.507999
eval/env_infos/initial/reward_ctrl Mean      -0.193444
eval/env_infos/initial/reward_ctrl Std        0.040743
eval/env_infos/initial/reward_ctrl Max       -0.114705
eval/env_infos/initial/reward_ctrl Min       -0.230948
eval/env_infos/reward_ctrl Mean              -0.397392
eval/env_infos/reward_ctrl Std                0.0814706
eval/env_infos/reward_ctrl Max               -0.0651514
eval/env_infos/reward_ctrl Min               -0.578443
time/data storing (s)                         0.00447695
time/evaluation sampling (s)                  1.99839
time/exploration sampling (s)                 0.531006
time/logging (s)                              0.0136305
time/sac training (s)                         7.36826
time/saving (s)                               0.00379222
time/training (s)                             3.4213e-05
time/epoch (s)                                9.91959
time/total (s)                             5042.95
Epoch                                       479
---------------------------------------  ---------------
2021-11-24 01:53:30.337027 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 480 finished
---------------------------------------  ---------------
epoch                                       480
replay_buffer/size                       482000
trainer/num train calls                  481000
trainer/QF1 Loss                              5.44248
trainer/QF2 Loss                              5.29798
trainer/Policy Loss                        -430.609
trainer/Q1 Predictions Mean                 431.268
trainer/Q1 Predictions Std                   84.3919
trainer/Q1 Predictions Max                  493.456
trainer/Q1 Predictions Min                   27.5906
trainer/Q2 Predictions Mean                 431.574
trainer/Q2 Predictions Std                   84.4214
trainer/Q2 Predictions Max                  492.949
trainer/Q2 Predictions Min                   26.6234
trainer/Q Targets Mean                      431.446
trainer/Q Targets Std                        84.1101
trainer/Q Targets Max                       492.573
trainer/Q Targets Min                        27.8479
trainer/Log Pis Mean                          6.40157
trainer/Log Pis Std                           4.11188
trainer/Log Pis Max                          16.1074
trainer/Log Pis Min                          -4.23883
trainer/policy/mean Mean                      0.102391
trainer/policy/mean Std                       0.782385
trainer/policy/mean Max                       0.993357
trainer/policy/mean Min                      -0.999511
trainer/policy/normal/std Mean                0.432125
trainer/policy/normal/std Std                 0.143203
trainer/policy/normal/std Max                 0.897206
trainer/policy/normal/std Min                 0.0697467
trainer/policy/normal/log_std Mean           -0.919135
trainer/policy/normal/log_std Std             0.451532
trainer/policy/normal/log_std Max            -0.10847
trainer/policy/normal/log_std Min            -2.66289
trainer/Alpha                                 0.1604
trainer/Alpha Loss                            0.734913
expl/num steps total                     482000
expl/num paths total                        482
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.12355
expl/Rewards Std                              1.26221
expl/Rewards Max                              8.65846
expl/Rewards Min                             -0.592759
expl/Returns Mean                          6123.55
expl/Returns Std                              0
expl/Returns Max                           6123.55
expl/Returns Min                           6123.55
expl/Actions Mean                             0.0989027
expl/Actions Std                              0.805007
expl/Actions Max                              0.999403
expl/Actions Min                             -0.999865
expl/Num Paths                                1
expl/Average Returns                       6123.55
expl/env_infos/final/reward_run Mean          6.58206
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.58206
expl/env_infos/final/reward_run Min           6.58206
expl/env_infos/initial/reward_run Mean       -0.27707
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.27707
expl/env_infos/initial/reward_run Min        -0.27707
expl/env_infos/reward_run Mean                6.51824
expl/env_infos/reward_run Std                 1.25894
expl/env_infos/reward_run Max                 9.19003
expl/env_infos/reward_run Min                -0.27707
expl/env_infos/final/reward_ctrl Mean        -0.45649
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.45649
expl/env_infos/final/reward_ctrl Min         -0.45649
expl/env_infos/initial/reward_ctrl Mean      -0.315689
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.315689
expl/env_infos/initial/reward_ctrl Min       -0.315689
expl/env_infos/reward_ctrl Mean              -0.394691
expl/env_infos/reward_ctrl Std                0.0847477
expl/env_infos/reward_ctrl Max               -0.125613
expl/env_infos/reward_ctrl Min               -0.569728
eval/num steps total                          2.405e+06
eval/num paths total                       2405
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.55113
eval/Rewards Std                              1.35136
eval/Rewards Max                              9.13467
eval/Rewards Min                             -0.836663
eval/Returns Mean                          6551.13
eval/Returns Std                             93.2688
eval/Returns Max                           6699.09
eval/Returns Min                           6404.73
eval/Actions Mean                             0.103535
eval/Actions Std                              0.825122
eval/Actions Max                              0.99679
eval/Actions Min                             -0.997479
eval/Num Paths                                5
eval/Average Returns                       6551.13
eval/env_infos/final/reward_run Mean          7.99516
eval/env_infos/final/reward_run Std           0.472187
eval/env_infos/final/reward_run Max           8.54485
eval/env_infos/final/reward_run Min           7.23566
eval/env_infos/initial/reward_run Mean       -0.244305
eval/env_infos/initial/reward_run Std         0.181862
eval/env_infos/initial/reward_run Max         0.0552005
eval/env_infos/initial/reward_run Min        -0.417157
eval/env_infos/reward_run Mean                6.96606
eval/env_infos/reward_run Std                 1.35049
eval/env_infos/reward_run Max                 9.67783
eval/env_infos/reward_run Min                -0.496304
eval/env_infos/final/reward_ctrl Mean        -0.364947
eval/env_infos/final/reward_ctrl Std          0.0489102
eval/env_infos/final/reward_ctrl Max         -0.298854
eval/env_infos/final/reward_ctrl Min         -0.440615
eval/env_infos/initial/reward_ctrl Mean      -0.194075
eval/env_infos/initial/reward_ctrl Std        0.048943
eval/env_infos/initial/reward_ctrl Max       -0.125362
eval/env_infos/initial/reward_ctrl Min       -0.266436
eval/env_infos/reward_ctrl Mean              -0.414927
eval/env_infos/reward_ctrl Std                0.0833594
eval/env_infos/reward_ctrl Max               -0.0617122
eval/env_infos/reward_ctrl Min               -0.579223
time/data storing (s)                         0.0044916
time/evaluation sampling (s)                  2.04291
time/exploration sampling (s)                 0.536197
time/logging (s)                              0.0137046
time/sac training (s)                         7.37849
time/saving (s)                               0.00374252
time/training (s)                             3.3975e-05
time/epoch (s)                                9.97957
time/total (s)                             5053.21
Epoch                                       480
---------------------------------------  ---------------
2021-11-24 01:53:40.545625 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 481 finished
---------------------------------------  ---------------
epoch                                       481
replay_buffer/size                       483000
trainer/num train calls                  482000
trainer/QF1 Loss                              6.59189
trainer/QF2 Loss                              5.21751
trainer/Policy Loss                        -427.721
trainer/Q1 Predictions Mean                 428.235
trainer/Q1 Predictions Std                   84.5252
trainer/Q1 Predictions Max                  493.289
trainer/Q1 Predictions Min                   24.4994
trainer/Q2 Predictions Mean                 428.481
trainer/Q2 Predictions Std                   84.4414
trainer/Q2 Predictions Max                  493.705
trainer/Q2 Predictions Min                   24.7058
trainer/Q Targets Mean                      428.625
trainer/Q Targets Std                        84.5127
trainer/Q Targets Max                       490.632
trainer/Q Targets Min                        24.3975
trainer/Log Pis Mean                          6.3832
trainer/Log Pis Std                           4.10883
trainer/Log Pis Max                          16.1242
trainer/Log Pis Min                          -6.11325
trainer/policy/mean Mean                      0.113702
trainer/policy/mean Std                       0.7852
trainer/policy/mean Max                       0.995981
trainer/policy/mean Min                      -0.998755
trainer/policy/normal/std Mean                0.444006
trainer/policy/normal/std Std                 0.147399
trainer/policy/normal/std Max                 1.23532
trainer/policy/normal/std Min                 0.0731224
trainer/policy/normal/log_std Mean           -0.890168
trainer/policy/normal/log_std Std             0.443101
trainer/policy/normal/log_std Max             0.211331
trainer/policy/normal/log_std Min            -2.61562
trainer/Alpha                                 0.160265
trainer/Alpha Loss                            0.70161
expl/num steps total                     483000
expl/num paths total                        483
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.97295
expl/Rewards Std                              1.26339
expl/Rewards Max                              8.31189
expl/Rewards Min                             -0.766388
expl/Returns Mean                          5972.95
expl/Returns Std                              0
expl/Returns Max                           5972.95
expl/Returns Min                           5972.95
expl/Actions Mean                             0.12022
expl/Actions Std                              0.799327
expl/Actions Max                              0.999545
expl/Actions Min                             -0.999697
expl/Num Paths                                1
expl/Average Returns                       5972.95
expl/env_infos/final/reward_run Mean          7.54632
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.54632
expl/env_infos/final/reward_run Min           7.54632
expl/env_infos/initial/reward_run Mean       -0.570916
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.570916
expl/env_infos/initial/reward_run Min        -0.570916
expl/env_infos/reward_run Mean                6.36497
expl/env_infos/reward_run Std                 1.25604
expl/env_infos/reward_run Max                 8.66623
expl/env_infos/reward_run Min                -0.570916
expl/env_infos/final/reward_ctrl Mean        -0.421764
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.421764
expl/env_infos/final/reward_ctrl Min         -0.421764
expl/env_infos/initial/reward_ctrl Mean      -0.195473
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.195473
expl/env_infos/initial/reward_ctrl Min       -0.195473
expl/env_infos/reward_ctrl Mean              -0.392026
expl/env_infos/reward_ctrl Std                0.0877778
expl/env_infos/reward_ctrl Max               -0.060321
expl/env_infos/reward_ctrl Min               -0.577231
eval/num steps total                          2.41e+06
eval/num paths total                       2410
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.53296
eval/Rewards Std                              1.32626
eval/Rewards Max                              9.15727
eval/Rewards Min                             -0.885874
eval/Returns Mean                          6532.96
eval/Returns Std                             55.1932
eval/Returns Max                           6629.02
eval/Returns Min                           6477.27
eval/Actions Mean                             0.108427
eval/Actions Std                              0.821389
eval/Actions Max                              0.995742
eval/Actions Min                             -0.998296
eval/Num Paths                                5
eval/Average Returns                       6532.96
eval/env_infos/final/reward_run Mean          7.74436
eval/env_infos/final/reward_run Std           0.596397
eval/env_infos/final/reward_run Max           8.53037
eval/env_infos/final/reward_run Min           6.77622
eval/env_infos/initial/reward_run Mean       -0.360617
eval/env_infos/initial/reward_run Std         0.26837
eval/env_infos/initial/reward_run Max         0.0294203
eval/env_infos/initial/reward_run Min        -0.662971
eval/env_infos/reward_run Mean                6.94482
eval/env_infos/reward_run Std                 1.31885
eval/env_infos/reward_run Max                 9.6207
eval/env_infos/reward_run Min                -0.662971
eval/env_infos/final/reward_ctrl Mean        -0.436583
eval/env_infos/final/reward_ctrl Std          0.0500934
eval/env_infos/final/reward_ctrl Max         -0.374893
eval/env_infos/final/reward_ctrl Min         -0.526083
eval/env_infos/initial/reward_ctrl Mean      -0.215984
eval/env_infos/initial/reward_ctrl Std        0.0427327
eval/env_infos/initial/reward_ctrl Max       -0.132169
eval/env_infos/initial/reward_ctrl Min       -0.249082
eval/env_infos/reward_ctrl Mean              -0.411861
eval/env_infos/reward_ctrl Std                0.0819562
eval/env_infos/reward_ctrl Max               -0.0505169
eval/env_infos/reward_ctrl Min               -0.577045
time/data storing (s)                         0.00448932
time/evaluation sampling (s)                  1.99011
time/exploration sampling (s)                 0.517356
time/logging (s)                              0.0135732
time/sac training (s)                         7.38442
time/saving (s)                               0.00377895
time/training (s)                             3.4479e-05
time/epoch (s)                                9.91377
time/total (s)                             5063.4
Epoch                                       481
---------------------------------------  ---------------
2021-11-24 01:53:50.769428 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 482 finished
---------------------------------------  ---------------
epoch                                       482
replay_buffer/size                       484000
trainer/num train calls                  483000
trainer/QF1 Loss                              7.37755
trainer/QF2 Loss                              7.36222
trainer/Policy Loss                        -433.818
trainer/Q1 Predictions Mean                 434.681
trainer/Q1 Predictions Std                   76.8051
trainer/Q1 Predictions Max                  492.417
trainer/Q1 Predictions Min                   24.7047
trainer/Q2 Predictions Mean                 434.734
trainer/Q2 Predictions Std                   76.7865
trainer/Q2 Predictions Max                  491.515
trainer/Q2 Predictions Min                   24.8182
trainer/Q Targets Mean                      434.063
trainer/Q Targets Std                        76.545
trainer/Q Targets Max                       493.592
trainer/Q Targets Min                        24.9786
trainer/Log Pis Mean                          6.51966
trainer/Log Pis Std                           4.10211
trainer/Log Pis Max                          15.6195
trainer/Log Pis Min                          -6.99304
trainer/policy/mean Mean                      0.0888749
trainer/policy/mean Std                       0.789978
trainer/policy/mean Max                       0.997656
trainer/policy/mean Min                      -0.996727
trainer/policy/normal/std Mean                0.438697
trainer/policy/normal/std Std                 0.137974
trainer/policy/normal/std Max                 0.891891
trainer/policy/normal/std Min                 0.0756153
trainer/policy/normal/log_std Mean           -0.896266
trainer/policy/normal/log_std Std             0.427966
trainer/policy/normal/log_std Max            -0.114411
trainer/policy/normal/log_std Min            -2.5821
trainer/Alpha                                 0.160322
trainer/Alpha Loss                            0.951274
expl/num steps total                     484000
expl/num paths total                        484
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.93465
expl/Rewards Std                              1.28333
expl/Rewards Max                              8.68696
expl/Rewards Min                             -0.725028
expl/Returns Mean                          5934.65
expl/Returns Std                              0
expl/Returns Max                           5934.65
expl/Returns Min                           5934.65
expl/Actions Mean                             0.104339
expl/Actions Std                              0.80485
expl/Actions Max                              0.999316
expl/Actions Min                             -0.999939
expl/Num Paths                                1
expl/Average Returns                       5934.65
expl/env_infos/final/reward_run Mean          8.39115
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           8.39115
expl/env_infos/final/reward_run Min           8.39115
expl/env_infos/initial/reward_run Mean       -0.490509
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.490509
expl/env_infos/initial/reward_run Min        -0.490509
expl/env_infos/reward_run Mean                6.32985
expl/env_infos/reward_run Std                 1.27449
expl/env_infos/reward_run Max                 9.18792
expl/env_infos/reward_run Min                -0.490509
expl/env_infos/final/reward_ctrl Mean        -0.332484
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.332484
expl/env_infos/final/reward_ctrl Min         -0.332484
expl/env_infos/initial/reward_ctrl Mean      -0.234519
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.234519
expl/env_infos/initial/reward_ctrl Min       -0.234519
expl/env_infos/reward_ctrl Mean              -0.395202
expl/env_infos/reward_ctrl Std                0.0898917
expl/env_infos/reward_ctrl Max               -0.0896144
expl/env_infos/reward_ctrl Min               -0.573791
eval/num steps total                          2.415e+06
eval/num paths total                       2415
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.36721
eval/Rewards Std                              1.33573
eval/Rewards Max                              8.90853
eval/Rewards Min                             -0.788517
eval/Returns Mean                          6367.21
eval/Returns Std                             74.0444
eval/Returns Max                           6485.62
eval/Returns Min                           6285.18
eval/Actions Mean                             0.101688
eval/Actions Std                              0.82523
eval/Actions Max                              0.995903
eval/Actions Min                             -0.99851
eval/Num Paths                                5
eval/Average Returns                       6367.21
eval/env_infos/final/reward_run Mean          7.22564
eval/env_infos/final/reward_run Std           0.632033
eval/env_infos/final/reward_run Max           8.04859
eval/env_infos/final/reward_run Min           6.3446
eval/env_infos/initial/reward_run Mean       -0.250238
eval/env_infos/initial/reward_run Std         0.355164
eval/env_infos/initial/reward_run Max         0.395068
eval/env_infos/initial/reward_run Min        -0.586332
eval/env_infos/reward_run Mean                6.78202
eval/env_infos/reward_run Std                 1.32589
eval/env_infos/reward_run Max                 9.44772
eval/env_infos/reward_run Min                -0.586332
eval/env_infos/final/reward_ctrl Mean        -0.460766
eval/env_infos/final/reward_ctrl Std          0.0462663
eval/env_infos/final/reward_ctrl Max         -0.410323
eval/env_infos/final/reward_ctrl Min         -0.522217
eval/env_infos/initial/reward_ctrl Mean      -0.164823
eval/env_infos/initial/reward_ctrl Std        0.0654954
eval/env_infos/initial/reward_ctrl Max       -0.0423137
eval/env_infos/initial/reward_ctrl Min       -0.235054
eval/env_infos/reward_ctrl Mean              -0.414807
eval/env_infos/reward_ctrl Std                0.0856503
eval/env_infos/reward_ctrl Max               -0.0423137
eval/env_infos/reward_ctrl Min               -0.574564
time/data storing (s)                         0.00448188
time/evaluation sampling (s)                  1.98314
time/exploration sampling (s)                 0.537534
time/logging (s)                              0.0135962
time/sac training (s)                         7.38663
time/saving (s)                               0.00376604
time/training (s)                             3.4702e-05
time/epoch (s)                                9.92918
time/total (s)                             5073.61
Epoch                                       482
---------------------------------------  ---------------
2021-11-24 01:54:01.015757 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 483 finished
---------------------------------------  ---------------
epoch                                       483
replay_buffer/size                       485000
trainer/num train calls                  484000
trainer/QF1 Loss                              5.23424
trainer/QF2 Loss                              5.25861
trainer/Policy Loss                        -414.269
trainer/Q1 Predictions Mean                 414.827
trainer/Q1 Predictions Std                  112.306
trainer/Q1 Predictions Max                  493.607
trainer/Q1 Predictions Min                   25.2109
trainer/Q2 Predictions Mean                 415.262
trainer/Q2 Predictions Std                  112.401
trainer/Q2 Predictions Max                  493.355
trainer/Q2 Predictions Min                   24.2054
trainer/Q Targets Mean                      415.666
trainer/Q Targets Std                       112.58
trainer/Q Targets Max                       493.387
trainer/Q Targets Min                        24.9042
trainer/Log Pis Mean                          6.28296
trainer/Log Pis Std                           4.43159
trainer/Log Pis Max                          15.9614
trainer/Log Pis Min                          -6.68754
trainer/policy/mean Mean                      0.0880861
trainer/policy/mean Std                       0.777738
trainer/policy/mean Max                       0.994219
trainer/policy/mean Min                      -0.994037
trainer/policy/normal/std Mean                0.448154
trainer/policy/normal/std Std                 0.148259
trainer/policy/normal/std Max                 0.924479
trainer/policy/normal/std Min                 0.0564277
trainer/policy/normal/log_std Mean           -0.878842
trainer/policy/normal/log_std Std             0.436763
trainer/policy/normal/log_std Max            -0.0785255
trainer/policy/normal/log_std Min            -2.8748
trainer/Alpha                                 0.159063
trainer/Alpha Loss                            0.520209
expl/num steps total                     485000
expl/num paths total                        485
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.13567
expl/Rewards Std                              1.26067
expl/Rewards Max                              8.7358
expl/Rewards Min                             -0.70184
expl/Returns Mean                          6135.67
expl/Returns Std                              0
expl/Returns Max                           6135.67
expl/Returns Min                           6135.67
expl/Actions Mean                             0.101099
expl/Actions Std                              0.800301
expl/Actions Max                              0.99905
expl/Actions Min                             -0.999232
expl/Num Paths                                1
expl/Average Returns                       6135.67
expl/env_infos/final/reward_run Mean          7.56041
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.56041
expl/env_infos/final/reward_run Min           7.56041
expl/env_infos/initial/reward_run Mean       -0.399595
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.399595
expl/env_infos/initial/reward_run Min        -0.399595
expl/env_infos/reward_run Mean                6.52609
expl/env_infos/reward_run Std                 1.2533
expl/env_infos/reward_run Max                 9.13667
expl/env_infos/reward_run Min                -0.399595
expl/env_infos/final/reward_ctrl Mean        -0.371643
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.371643
expl/env_infos/final/reward_ctrl Min         -0.371643
expl/env_infos/initial/reward_ctrl Mean      -0.302245
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.302245
expl/env_infos/initial/reward_ctrl Min       -0.302245
expl/env_infos/reward_ctrl Mean              -0.390422
expl/env_infos/reward_ctrl Std                0.0871125
expl/env_infos/reward_ctrl Max               -0.0902119
expl/env_infos/reward_ctrl Min               -0.574008
eval/num steps total                          2.42e+06
eval/num paths total                       2420
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.5798
eval/Rewards Std                              1.36988
eval/Rewards Max                              9.20854
eval/Rewards Min                             -0.633694
eval/Returns Mean                          6579.8
eval/Returns Std                             29.9482
eval/Returns Max                           6623.66
eval/Returns Min                           6529.76
eval/Actions Mean                             0.0964096
eval/Actions Std                              0.820648
eval/Actions Max                              0.995966
eval/Actions Min                             -0.9982
eval/Num Paths                                5
eval/Average Returns                       6579.8
eval/env_infos/final/reward_run Mean          7.0904
eval/env_infos/final/reward_run Std           0.893761
eval/env_infos/final/reward_run Max           8.20132
eval/env_infos/final/reward_run Min           5.57636
eval/env_infos/initial/reward_run Mean       -0.115454
eval/env_infos/initial/reward_run Std         0.298621
eval/env_infos/initial/reward_run Max         0.429541
eval/env_infos/initial/reward_run Min        -0.365305
eval/env_infos/reward_run Mean                6.98946
eval/env_infos/reward_run Std                 1.36362
eval/env_infos/reward_run Max                 9.65445
eval/env_infos/reward_run Min                -0.365305
eval/env_infos/final/reward_ctrl Mean        -0.373662
eval/env_infos/final/reward_ctrl Std          0.0789561
eval/env_infos/final/reward_ctrl Max         -0.25388
eval/env_infos/final/reward_ctrl Min         -0.487071
eval/env_infos/initial/reward_ctrl Mean      -0.169909
eval/env_infos/initial/reward_ctrl Std        0.0498511
eval/env_infos/initial/reward_ctrl Max       -0.0787656
eval/env_infos/initial/reward_ctrl Min       -0.221756
eval/env_infos/reward_ctrl Mean              -0.409655
eval/env_infos/reward_ctrl Std                0.0844885
eval/env_infos/reward_ctrl Max               -0.0728681
eval/env_infos/reward_ctrl Min               -0.577408
time/data storing (s)                         0.00452122
time/evaluation sampling (s)                  1.99007
time/exploration sampling (s)                 0.540272
time/logging (s)                              0.0136106
time/sac training (s)                         7.39996
time/saving (s)                               0.00376252
time/training (s)                             3.5709e-05
time/epoch (s)                                9.95223
time/total (s)                             5083.84
Epoch                                       483
---------------------------------------  ---------------
2021-11-24 01:54:11.306976 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 484 finished
---------------------------------------  ---------------
epoch                                       484
replay_buffer/size                       486000
trainer/num train calls                  485000
trainer/QF1 Loss                              4.92771
trainer/QF2 Loss                              4.59077
trainer/Policy Loss                        -425.959
trainer/Q1 Predictions Mean                 426.643
trainer/Q1 Predictions Std                   90.3545
trainer/Q1 Predictions Max                  493.453
trainer/Q1 Predictions Min                   24.496
trainer/Q2 Predictions Mean                 426.529
trainer/Q2 Predictions Std                   90.4313
trainer/Q2 Predictions Max                  492.54
trainer/Q2 Predictions Min                   22.6788
trainer/Q Targets Mean                      426.17
trainer/Q Targets Std                        90.2364
trainer/Q Targets Max                       493.073
trainer/Q Targets Min                        24.9358
trainer/Log Pis Mean                          6.23094
trainer/Log Pis Std                           4.19712
trainer/Log Pis Max                          18.6302
trainer/Log Pis Min                          -4.91197
trainer/policy/mean Mean                      0.068564
trainer/policy/mean Std                       0.797776
trainer/policy/mean Max                       0.996826
trainer/policy/mean Min                      -0.998633
trainer/policy/normal/std Mean                0.449156
trainer/policy/normal/std Std                 0.145188
trainer/policy/normal/std Max                 0.942335
trainer/policy/normal/std Min                 0.0694877
trainer/policy/normal/log_std Mean           -0.872871
trainer/policy/normal/log_std Std             0.423689
trainer/policy/normal/log_std Max            -0.0593947
trainer/policy/normal/log_std Min            -2.66661
trainer/Alpha                                 0.159296
trainer/Alpha Loss                            0.424229
expl/num steps total                     486000
expl/num paths total                        486
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.98267
expl/Rewards Std                              1.25027
expl/Rewards Max                              8.43219
expl/Rewards Min                             -0.708223
expl/Returns Mean                          5982.67
expl/Returns Std                              0
expl/Returns Max                           5982.67
expl/Returns Min                           5982.67
expl/Actions Mean                             0.0789013
expl/Actions Std                              0.79389
expl/Actions Max                              0.999486
expl/Actions Min                             -0.999522
expl/Num Paths                                1
expl/Average Returns                       5982.67
expl/env_infos/final/reward_run Mean          6.68572
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.68572
expl/env_infos/final/reward_run Min           6.68572
expl/env_infos/initial/reward_run Mean       -0.431376
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.431376
expl/env_infos/initial/reward_run Min        -0.431376
expl/env_infos/reward_run Mean                6.36456
expl/env_infos/reward_run Std                 1.25052
expl/env_infos/reward_run Max                 8.82849
expl/env_infos/reward_run Min                -0.431376
expl/env_infos/final/reward_ctrl Mean        -0.265351
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.265351
expl/env_infos/final/reward_ctrl Min         -0.265351
expl/env_infos/initial/reward_ctrl Mean      -0.276846
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.276846
expl/env_infos/initial/reward_ctrl Min       -0.276846
expl/env_infos/reward_ctrl Mean              -0.381892
expl/env_infos/reward_ctrl Std                0.0911557
expl/env_infos/reward_ctrl Max               -0.0932588
expl/env_infos/reward_ctrl Min               -0.57815
eval/num steps total                          2.425e+06
eval/num paths total                       2425
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.49882
eval/Rewards Std                              1.30659
eval/Rewards Max                              8.87462
eval/Rewards Min                             -0.864226
eval/Returns Mean                          6498.82
eval/Returns Std                             73.6006
eval/Returns Max                           6602.81
eval/Returns Min                           6380.65
eval/Actions Mean                             0.0788571
eval/Actions Std                              0.820997
eval/Actions Max                              0.997191
eval/Actions Min                             -0.998485
eval/Num Paths                                5
eval/Average Returns                       6498.82
eval/env_infos/final/reward_run Mean          6.95595
eval/env_infos/final/reward_run Std           0.916434
eval/env_infos/final/reward_run Max           8.22215
eval/env_infos/final/reward_run Min           5.62103
eval/env_infos/initial/reward_run Mean       -0.396396
eval/env_infos/initial/reward_run Std         0.195919
eval/env_infos/initial/reward_run Max        -0.146283
eval/env_infos/initial/reward_run Min        -0.69309
eval/env_infos/reward_run Mean                6.90697
eval/env_infos/reward_run Std                 1.31117
eval/env_infos/reward_run Max                 9.33196
eval/env_infos/reward_run Min                -0.69309
eval/env_infos/final/reward_ctrl Mean        -0.460261
eval/env_infos/final/reward_ctrl Std          0.0670173
eval/env_infos/final/reward_ctrl Max         -0.358015
eval/env_infos/final/reward_ctrl Min         -0.563142
eval/env_infos/initial/reward_ctrl Mean      -0.208849
eval/env_infos/initial/reward_ctrl Std        0.0392262
eval/env_infos/initial/reward_ctrl Max       -0.165415
eval/env_infos/initial/reward_ctrl Min       -0.273255
eval/env_infos/reward_ctrl Mean              -0.408153
eval/env_infos/reward_ctrl Std                0.0869483
eval/env_infos/reward_ctrl Max               -0.0759053
eval/env_infos/reward_ctrl Min               -0.58069
time/data storing (s)                         0.00449213
time/evaluation sampling (s)                  2.00417
time/exploration sampling (s)                 0.528226
time/logging (s)                              0.0136359
time/sac training (s)                         7.44112
time/saving (s)                               0.00514308
time/training (s)                             3.4503e-05
time/epoch (s)                                9.99682
time/total (s)                             5094.12
Epoch                                       484
---------------------------------------  ---------------
2021-11-24 01:54:21.561192 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 485 finished
---------------------------------------  ---------------
epoch                                       485
replay_buffer/size                       487000
trainer/num train calls                  486000
trainer/QF1 Loss                              4.9342
trainer/QF2 Loss                              4.90592
trainer/Policy Loss                        -419.254
trainer/Q1 Predictions Mean                 419.971
trainer/Q1 Predictions Std                  101.113
trainer/Q1 Predictions Max                  490.945
trainer/Q1 Predictions Min                   24.0469
trainer/Q2 Predictions Mean                 420.065
trainer/Q2 Predictions Std                  100.96
trainer/Q2 Predictions Max                  490.575
trainer/Q2 Predictions Min                   24.6677
trainer/Q Targets Mean                      419.273
trainer/Q Targets Std                       101.091
trainer/Q Targets Max                       489.467
trainer/Q Targets Min                        22.7181
trainer/Log Pis Mean                          6.29434
trainer/Log Pis Std                           4.39419
trainer/Log Pis Max                          17.8164
trainer/Log Pis Min                          -5.47703
trainer/policy/mean Mean                      0.0756085
trainer/policy/mean Std                       0.789304
trainer/policy/mean Max                       0.99722
trainer/policy/mean Min                      -0.994169
trainer/policy/normal/std Mean                0.451794
trainer/policy/normal/std Std                 0.148916
trainer/policy/normal/std Max                 0.929126
trainer/policy/normal/std Min                 0.0659582
trainer/policy/normal/log_std Mean           -0.8672
trainer/policy/normal/log_std Std             0.422021
trainer/policy/normal/log_std Max            -0.0735109
trainer/policy/normal/log_std Min            -2.71873
trainer/Alpha                                 0.159799
trainer/Alpha Loss                            0.539773
expl/num steps total                     487000
expl/num paths total                        487
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.14264
expl/Rewards Std                              1.24284
expl/Rewards Max                              8.38346
expl/Rewards Min                             -0.817986
expl/Returns Mean                          6142.64
expl/Returns Std                              0
expl/Returns Max                           6142.64
expl/Returns Min                           6142.64
expl/Actions Mean                             0.0905457
expl/Actions Std                              0.810621
expl/Actions Max                              0.999747
expl/Actions Min                             -0.998892
expl/Num Paths                                1
expl/Average Returns                       6142.64
expl/env_infos/final/reward_run Mean          6.73951
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.73951
expl/env_infos/final/reward_run Min           6.73951
expl/env_infos/initial/reward_run Mean       -0.00258792
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.00258792
expl/env_infos/initial/reward_run Min        -0.00258792
expl/env_infos/reward_run Mean                6.54182
expl/env_infos/reward_run Std                 1.24189
expl/env_infos/reward_run Max                 8.90454
expl/env_infos/reward_run Min                -0.492905
expl/env_infos/final/reward_ctrl Mean        -0.338497
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.338497
expl/env_infos/final/reward_ctrl Min         -0.338497
expl/env_infos/initial/reward_ctrl Mean      -0.148103
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.148103
expl/env_infos/initial/reward_ctrl Min       -0.148103
expl/env_infos/reward_ctrl Mean              -0.399183
expl/env_infos/reward_ctrl Std                0.0912178
expl/env_infos/reward_ctrl Max               -0.0872739
expl/env_infos/reward_ctrl Min               -0.579273
eval/num steps total                          2.43e+06
eval/num paths total                       2430
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.44615
eval/Rewards Std                              1.30458
eval/Rewards Max                              8.7704
eval/Rewards Min                             -0.805595
eval/Returns Mean                          6446.15
eval/Returns Std                             44.6446
eval/Returns Max                           6506.53
eval/Returns Min                           6401.56
eval/Actions Mean                             0.0885832
eval/Actions Std                              0.82646
eval/Actions Max                              0.995145
eval/Actions Min                             -0.997348
eval/Num Paths                                5
eval/Average Returns                       6446.15
eval/env_infos/final/reward_run Mean          7.79585
eval/env_infos/final/reward_run Std           0.47775
eval/env_infos/final/reward_run Max           8.65328
eval/env_infos/final/reward_run Min           7.29239
eval/env_infos/initial/reward_run Mean       -0.23464
eval/env_infos/initial/reward_run Std         0.240498
eval/env_infos/initial/reward_run Max         0.181159
eval/env_infos/initial/reward_run Min        -0.555173
eval/env_infos/reward_run Mean                6.86068
eval/env_infos/reward_run Std                 1.3023
eval/env_infos/reward_run Max                 9.28914
eval/env_infos/reward_run Min                -0.555173
eval/env_infos/final/reward_ctrl Mean        -0.428454
eval/env_infos/final/reward_ctrl Std          0.0863643
eval/env_infos/final/reward_ctrl Max         -0.285865
eval/env_infos/final/reward_ctrl Min         -0.549229
eval/env_infos/initial/reward_ctrl Mean      -0.25286
eval/env_infos/initial/reward_ctrl Std        0.0186277
eval/env_infos/initial/reward_ctrl Max       -0.226822
eval/env_infos/initial/reward_ctrl Min       -0.282839
eval/env_infos/reward_ctrl Mean              -0.41453
eval/env_infos/reward_ctrl Std                0.0872391
eval/env_infos/reward_ctrl Max               -0.063168
eval/env_infos/reward_ctrl Min               -0.578673
time/data storing (s)                         0.00447532
time/evaluation sampling (s)                  2.01265
time/exploration sampling (s)                 0.535809
time/logging (s)                              0.0135839
time/sac training (s)                         7.38852
time/saving (s)                               0.00376768
time/training (s)                             3.3775e-05
time/epoch (s)                                9.95885
time/total (s)                             5104.36
Epoch                                       485
---------------------------------------  ---------------
2021-11-24 01:54:31.847251 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 486 finished
---------------------------------------  ---------------
epoch                                       486
replay_buffer/size                       488000
trainer/num train calls                  487000
trainer/QF1 Loss                              5.45039
trainer/QF2 Loss                              4.97785
trainer/Policy Loss                        -433.521
trainer/Q1 Predictions Mean                 434.614
trainer/Q1 Predictions Std                   76.4528
trainer/Q1 Predictions Max                  489.29
trainer/Q1 Predictions Min                   26.2949
trainer/Q2 Predictions Mean                 434.452
trainer/Q2 Predictions Std                   76.3066
trainer/Q2 Predictions Max                  488.968
trainer/Q2 Predictions Min                   26.4971
trainer/Q Targets Mean                      434.616
trainer/Q Targets Std                        76.3214
trainer/Q Targets Max                       491.665
trainer/Q Targets Min                        26.8711
trainer/Log Pis Mean                          5.69911
trainer/Log Pis Std                           4.12672
trainer/Log Pis Max                          15.8818
trainer/Log Pis Min                          -4.08905
trainer/policy/mean Mean                      0.0869942
trainer/policy/mean Std                       0.779338
trainer/policy/mean Max                       0.999319
trainer/policy/mean Min                      -0.998167
trainer/policy/normal/std Mean                0.455437
trainer/policy/normal/std Std                 0.144971
trainer/policy/normal/std Max                 1.2456
trainer/policy/normal/std Min                 0.0696499
trainer/policy/normal/log_std Mean           -0.85593
trainer/policy/normal/log_std Std             0.415584
trainer/policy/normal/log_std Max             0.219616
trainer/policy/normal/log_std Min            -2.66427
trainer/Alpha                                 0.160159
trainer/Alpha Loss                           -0.551107
expl/num steps total                     488000
expl/num paths total                        488
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             5.95033
expl/Rewards Std                              1.2598
expl/Rewards Max                              8.15037
expl/Rewards Min                             -0.362729
expl/Returns Mean                          5950.33
expl/Returns Std                              0
expl/Returns Max                           5950.33
expl/Returns Min                           5950.33
expl/Actions Mean                             0.106651
expl/Actions Std                              0.795035
expl/Actions Max                              0.999912
expl/Actions Min                             -0.999268
expl/Num Paths                                1
expl/Average Returns                       5950.33
expl/env_infos/final/reward_run Mean          6.30418
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.30418
expl/env_infos/final/reward_run Min           6.30418
expl/env_infos/initial/reward_run Mean       -0.0669158
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.0669158
expl/env_infos/initial/reward_run Min        -0.0669158
expl/env_infos/reward_run Mean                6.33641
expl/env_infos/reward_run Std                 1.25177
expl/env_infos/reward_run Max                 8.6395
expl/env_infos/reward_run Min                -0.0669158
expl/env_infos/final/reward_ctrl Mean        -0.388312
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.388312
expl/env_infos/final/reward_ctrl Min         -0.388312
expl/env_infos/initial/reward_ctrl Mean      -0.295813
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.295813
expl/env_infos/initial/reward_ctrl Min       -0.295813
expl/env_infos/reward_ctrl Mean              -0.386073
expl/env_infos/reward_ctrl Std                0.0927484
expl/env_infos/reward_ctrl Max               -0.112784
expl/env_infos/reward_ctrl Min               -0.580604
eval/num steps total                          2.435e+06
eval/num paths total                       2435
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.4315
eval/Rewards Std                              1.33023
eval/Rewards Max                              9.00856
eval/Rewards Min                             -0.65044
eval/Returns Mean                          6431.5
eval/Returns Std                             96.9132
eval/Returns Max                           6591.81
eval/Returns Min                           6326.76
eval/Actions Mean                             0.103068
eval/Actions Std                              0.815717
eval/Actions Max                              0.998937
eval/Actions Min                             -0.999108
eval/Num Paths                                5
eval/Average Returns                       6431.5
eval/env_infos/final/reward_run Mean          6.99567
eval/env_infos/final/reward_run Std           0.965997
eval/env_infos/final/reward_run Max           8.46139
eval/env_infos/final/reward_run Min           5.68486
eval/env_infos/initial/reward_run Mean       -0.285114
eval/env_infos/initial/reward_run Std         0.185301
eval/env_infos/initial/reward_run Max         0.0694035
eval/env_infos/initial/reward_run Min        -0.469091
eval/env_infos/reward_run Mean                6.83711
eval/env_infos/reward_run Std                 1.32304
eval/env_infos/reward_run Max                 9.53701
eval/env_infos/reward_run Min                -0.469091
eval/env_infos/final/reward_ctrl Mean        -0.489046
eval/env_infos/final/reward_ctrl Std          0.042859
eval/env_infos/final/reward_ctrl Max         -0.414977
eval/env_infos/final/reward_ctrl Min         -0.533252
eval/env_infos/initial/reward_ctrl Mean      -0.176857
eval/env_infos/initial/reward_ctrl Std        0.018191
eval/env_infos/initial/reward_ctrl Max       -0.158296
eval/env_infos/initial/reward_ctrl Min       -0.210111
eval/env_infos/reward_ctrl Mean              -0.405611
eval/env_infos/reward_ctrl Std                0.0906161
eval/env_infos/reward_ctrl Max               -0.0534262
eval/env_infos/reward_ctrl Min               -0.577294
time/data storing (s)                         0.00448917
time/evaluation sampling (s)                  1.99397
time/exploration sampling (s)                 0.532602
time/logging (s)                              0.0136347
time/sac training (s)                         7.44359
time/saving (s)                               0.00377283
time/training (s)                             3.3314e-05
time/epoch (s)                                9.99209
time/total (s)                             5114.63
Epoch                                       486
---------------------------------------  ---------------
2021-11-24 01:54:42.121337 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 487 finished
---------------------------------------  ---------------
epoch                                       487
replay_buffer/size                       489000
trainer/num train calls                  488000
trainer/QF1 Loss                              6.48646
trainer/QF2 Loss                              5.29816
trainer/Policy Loss                        -433.204
trainer/Q1 Predictions Mean                 434.1
trainer/Q1 Predictions Std                   76.287
trainer/Q1 Predictions Max                  494.586
trainer/Q1 Predictions Min                   26.1005
trainer/Q2 Predictions Mean                 434.176
trainer/Q2 Predictions Std                   76.448
trainer/Q2 Predictions Max                  495.344
trainer/Q2 Predictions Min                   25.2636
trainer/Q Targets Mean                      434.236
trainer/Q Targets Std                        76.3754
trainer/Q Targets Max                       494.104
trainer/Q Targets Min                        26.6096
trainer/Log Pis Mean                          5.97291
trainer/Log Pis Std                           4.09713
trainer/Log Pis Max                          15.2627
trainer/Log Pis Min                          -7.05888
trainer/policy/mean Mean                      0.0959416
trainer/policy/mean Std                       0.787528
trainer/policy/mean Max                       0.997001
trainer/policy/mean Min                      -0.996927
trainer/policy/normal/std Mean                0.448539
trainer/policy/normal/std Std                 0.145303
trainer/policy/normal/std Max                 1.00738
trainer/policy/normal/std Min                 0.0725923
trainer/policy/normal/log_std Mean           -0.876142
trainer/policy/normal/log_std Std             0.431963
trainer/policy/normal/log_std Max             0.00735066
trainer/policy/normal/log_std Min            -2.6229
trainer/Alpha                                 0.16043
trainer/Alpha Loss                           -0.049566
expl/num steps total                     489000
expl/num paths total                        489
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.11571
expl/Rewards Std                              1.24832
expl/Rewards Max                              8.51804
expl/Rewards Min                             -0.575618
expl/Returns Mean                          6115.71
expl/Returns Std                              0
expl/Returns Max                           6115.71
expl/Returns Min                           6115.71
expl/Actions Mean                             0.0943196
expl/Actions Std                              0.799339
expl/Actions Max                              0.999673
expl/Actions Min                             -0.999448
expl/Num Paths                                1
expl/Average Returns                       6115.71
expl/env_infos/final/reward_run Mean          6.9301
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.9301
expl/env_infos/final/reward_run Min           6.9301
expl/env_infos/initial/reward_run Mean        0.0559081
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max         0.0559081
expl/env_infos/initial/reward_run Min         0.0559081
expl/env_infos/reward_run Mean                6.50441
expl/env_infos/reward_run Std                 1.24636
expl/env_infos/reward_run Max                 9.06938
expl/env_infos/reward_run Min                -0.105154
expl/env_infos/final/reward_ctrl Mean        -0.227573
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.227573
expl/env_infos/final/reward_ctrl Min         -0.227573
expl/env_infos/initial/reward_ctrl Mean      -0.179209
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.179209
expl/env_infos/initial/reward_ctrl Min       -0.179209
expl/env_infos/reward_ctrl Mean              -0.388704
expl/env_infos/reward_ctrl Std                0.0864473
expl/env_infos/reward_ctrl Max               -0.126658
expl/env_infos/reward_ctrl Min               -0.561857
eval/num steps total                          2.44e+06
eval/num paths total                       2440
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.5411
eval/Rewards Std                              1.34061
eval/Rewards Max                              8.97316
eval/Rewards Min                             -0.790881
eval/Returns Mean                          6541.1
eval/Returns Std                             73.4407
eval/Returns Max                           6660.49
eval/Returns Min                           6467.38
eval/Actions Mean                             0.0971777
eval/Actions Std                              0.819141
eval/Actions Max                              0.996819
eval/Actions Min                             -0.998395
eval/Num Paths                                5
eval/Average Returns                       6541.1
eval/env_infos/final/reward_run Mean          7.90464
eval/env_infos/final/reward_run Std           1.03121
eval/env_infos/final/reward_run Max           9.01974
eval/env_infos/final/reward_run Min           6.44867
eval/env_infos/initial/reward_run Mean       -0.305482
eval/env_infos/initial/reward_run Std         0.392802
eval/env_infos/initial/reward_run Max         0.462171
eval/env_infos/initial/reward_run Min        -0.610398
eval/env_infos/reward_run Mean                6.94936
eval/env_infos/reward_run Std                 1.34141
eval/env_infos/reward_run Max                 9.44776
eval/env_infos/reward_run Min                -0.610398
eval/env_infos/final/reward_ctrl Mean        -0.418548
eval/env_infos/final/reward_ctrl Std          0.07332
eval/env_infos/final/reward_ctrl Max         -0.27406
eval/env_infos/final/reward_ctrl Min         -0.476034
eval/env_infos/initial/reward_ctrl Mean      -0.195089
eval/env_infos/initial/reward_ctrl Std        0.0418407
eval/env_infos/initial/reward_ctrl Max       -0.120036
eval/env_infos/initial/reward_ctrl Min       -0.22684
eval/env_infos/reward_ctrl Mean              -0.408261
eval/env_infos/reward_ctrl Std                0.0852858
eval/env_infos/reward_ctrl Max               -0.0864299
eval/env_infos/reward_ctrl Min               -0.574645
time/data storing (s)                         0.00446586
time/evaluation sampling (s)                  2.01192
time/exploration sampling (s)                 0.534901
time/logging (s)                              0.0136622
time/sac training (s)                         7.40924
time/saving (s)                               0.00376407
time/training (s)                             3.4334e-05
time/epoch (s)                                9.97799
time/total (s)                             5124.89
Epoch                                       487
---------------------------------------  ---------------
2021-11-24 01:54:52.375138 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 488 finished
---------------------------------------  ---------------
epoch                                       488
replay_buffer/size                       490000
trainer/num train calls                  489000
trainer/QF1 Loss                              5.84
trainer/QF2 Loss                              5.71113
trainer/Policy Loss                        -426.628
trainer/Q1 Predictions Mean                 427.249
trainer/Q1 Predictions Std                   89.3608
trainer/Q1 Predictions Max                  493.881
trainer/Q1 Predictions Min                   27.8798
trainer/Q2 Predictions Mean                 427.502
trainer/Q2 Predictions Std                   89.4869
trainer/Q2 Predictions Max                  492.621
trainer/Q2 Predictions Min                   27.5348
trainer/Q Targets Mean                      427.594
trainer/Q Targets Std                        89.774
trainer/Q Targets Max                       494.247
trainer/Q Targets Min                        25.4073
trainer/Log Pis Mean                          5.82891
trainer/Log Pis Std                           4.40489
trainer/Log Pis Max                          16.2095
trainer/Log Pis Min                          -4.98771
trainer/policy/mean Mean                      0.109066
trainer/policy/mean Std                       0.769771
trainer/policy/mean Max                       0.994737
trainer/policy/mean Min                      -0.992192
trainer/policy/normal/std Mean                0.45076
trainer/policy/normal/std Std                 0.144627
trainer/policy/normal/std Max                 1.02519
trainer/policy/normal/std Min                 0.0630532
trainer/policy/normal/log_std Mean           -0.86936
trainer/policy/normal/log_std Std             0.427305
trainer/policy/normal/log_std Max             0.0248742
trainer/policy/normal/log_std Min            -2.76378
trainer/Alpha                                 0.159703
trainer/Alpha Loss                           -0.313862
expl/num steps total                     490000
expl/num paths total                        490
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.36765
expl/Rewards Std                              1.30899
expl/Rewards Max                              8.82217
expl/Rewards Min                             -0.512721
expl/Returns Mean                          6367.65
expl/Returns Std                              0
expl/Returns Max                           6367.65
expl/Returns Min                           6367.65
expl/Actions Mean                             0.117843
expl/Actions Std                              0.808152
expl/Actions Max                              0.99947
expl/Actions Min                             -0.999644
expl/Num Paths                                1
expl/Average Returns                       6367.65
expl/env_infos/final/reward_run Mean          6.15038
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           6.15038
expl/env_infos/final/reward_run Min           6.15038
expl/env_infos/initial/reward_run Mean       -0.281007
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.281007
expl/env_infos/initial/reward_run Min        -0.281007
expl/env_infos/reward_run Mean                6.76785
expl/env_infos/reward_run Std                 1.3071
expl/env_infos/reward_run Max                 9.29587
expl/env_infos/reward_run Min                -0.281007
expl/env_infos/final/reward_ctrl Mean        -0.540102
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.540102
expl/env_infos/final/reward_ctrl Min         -0.540102
expl/env_infos/initial/reward_ctrl Mean      -0.231713
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.231713
expl/env_infos/initial/reward_ctrl Min       -0.231713
expl/env_infos/reward_ctrl Mean              -0.400198
expl/env_infos/reward_ctrl Std                0.0872048
expl/env_infos/reward_ctrl Max               -0.1298
expl/env_infos/reward_ctrl Min               -0.578364
eval/num steps total                          2.445e+06
eval/num paths total                       2445
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.59378
eval/Rewards Std                              1.34688
eval/Rewards Max                              9.1205
eval/Rewards Min                             -0.699648
eval/Returns Mean                          6593.78
eval/Returns Std                             78.2031
eval/Returns Max                           6706.2
eval/Returns Min                           6480.49
eval/Actions Mean                             0.102743
eval/Actions Std                              0.823914
eval/Actions Max                              0.997054
eval/Actions Min                             -0.998726
eval/Num Paths                                5
eval/Average Returns                       6593.78
eval/env_infos/final/reward_run Mean          7.43917
eval/env_infos/final/reward_run Std           0.832167
eval/env_infos/final/reward_run Max           8.30743
eval/env_infos/final/reward_run Min           5.89884
eval/env_infos/initial/reward_run Mean       -0.211289
eval/env_infos/initial/reward_run Std         0.214821
eval/env_infos/initial/reward_run Max         0.125563
eval/env_infos/initial/reward_run Min        -0.51161
eval/env_infos/reward_run Mean                7.00741
eval/env_infos/reward_run Std                 1.34508
eval/env_infos/reward_run Max                 9.57103
eval/env_infos/reward_run Min                -0.51161
eval/env_infos/final/reward_ctrl Mean        -0.353695
eval/env_infos/final/reward_ctrl Std          0.0580868
eval/env_infos/final/reward_ctrl Max         -0.286967
eval/env_infos/final/reward_ctrl Min         -0.431267
eval/env_infos/initial/reward_ctrl Mean      -0.198293
eval/env_infos/initial/reward_ctrl Std        0.0425503
eval/env_infos/initial/reward_ctrl Max       -0.140155
eval/env_infos/initial/reward_ctrl Min       -0.261836
eval/env_infos/reward_ctrl Mean              -0.413634
eval/env_infos/reward_ctrl Std                0.083994
eval/env_infos/reward_ctrl Max               -0.0911989
eval/env_infos/reward_ctrl Min               -0.570937
time/data storing (s)                         0.00448713
time/evaluation sampling (s)                  1.99713
time/exploration sampling (s)                 0.532917
time/logging (s)                              0.0136178
time/sac training (s)                         7.40726
time/saving (s)                               0.00375874
time/training (s)                             3.425e-05
time/epoch (s)                                9.95921
time/total (s)                             5135.13
Epoch                                       488
---------------------------------------  ---------------
2021-11-24 01:55:02.697202 EST | [name-of-experiment_2021_11_24_00_29_10_0000--s-0] Epoch 489 finished
---------------------------------------  ---------------
epoch                                       489
replay_buffer/size                       491000
trainer/num train calls                  490000
trainer/QF1 Loss                              5.19439
trainer/QF2 Loss                              4.67941
trainer/Policy Loss                        -431.47
trainer/Q1 Predictions Mean                 432.19
trainer/Q1 Predictions Std                   87.9548
trainer/Q1 Predictions Max                  502.319
trainer/Q1 Predictions Min                   26.4317
trainer/Q2 Predictions Mean                 432.367
trainer/Q2 Predictions Std                   87.9988
trainer/Q2 Predictions Max                  503.828
trainer/Q2 Predictions Min                   26.2963
trainer/Q Targets Mean                      432.176
trainer/Q Targets Std                        87.893
trainer/Q Targets Max                       503.973
trainer/Q Targets Min                        25.1767
trainer/Log Pis Mean                          5.55537
trainer/Log Pis Std                           4.28314
trainer/Log Pis Max                          17.7659
trainer/Log Pis Min                          -7.08397
trainer/policy/mean Mean                      0.0854037
trainer/policy/mean Std                       0.773986
trainer/policy/mean Max                       0.996852
trainer/policy/mean Min                      -0.99631
trainer/policy/normal/std Mean                0.439731
trainer/policy/normal/std Std                 0.143354
trainer/policy/normal/std Max                 0.952605
trainer/policy/normal/std Min                 0.0657226
trainer/policy/normal/log_std Mean           -0.897365
trainer/policy/normal/log_std Std             0.436913
trainer/policy/normal/log_std Max            -0.0485549
trainer/policy/normal/log_std Min            -2.72231
trainer/Alpha                                 0.159468
trainer/Alpha Loss                           -0.816302
expl/num steps total                     491000
expl/num paths total                        491
expl/path length Mean                      1000
expl/path length Std                          0
expl/path length Max                       1000
expl/path length Min                       1000
expl/Rewards Mean                             6.00527
expl/Rewards Std                              1.2309
expl/Rewards Max                              8.32076
expl/Rewards Min                             -0.689707
expl/Returns Mean                          6005.27
expl/Returns Std                              0
expl/Returns Max                           6005.27
expl/Returns Min                           6005.27
expl/Actions Mean                             0.0961592
expl/Actions Std                              0.794085
expl/Actions Max                              0.999593
expl/Actions Min                             -0.999074
expl/Num Paths                                1
expl/Average Returns                       6005.27
expl/env_infos/final/reward_run Mean          7.37409
expl/env_infos/final/reward_run Std           0
expl/env_infos/final/reward_run Max           7.37409
expl/env_infos/final/reward_run Min           7.37409
expl/env_infos/initial/reward_run Mean       -0.389722
expl/env_infos/initial/reward_run Std         0
expl/env_infos/initial/reward_run Max        -0.389722
expl/env_infos/initial/reward_run Min        -0.389722
expl/env_infos/reward_run Mean                6.38916
expl/env_infos/reward_run Std                 1.22807
expl/env_infos/reward_run Max                 8.75633
expl/env_infos/reward_run Min                -0.389722
expl/env_infos/final/reward_ctrl Mean        -0.237156
expl/env_infos/final/reward_ctrl Std          0
expl/env_infos/final/reward_ctrl Max         -0.237156
expl/env_infos/final/reward_ctrl Min         -0.237156
expl/env_infos/initial/reward_ctrl Mean      -0.299985
expl/env_infos/initial/reward_ctrl Std        0
expl/env_infos/initial/reward_ctrl Max       -0.299985
expl/env_infos/initial/reward_ctrl Min       -0.299985
expl/env_infos/reward_ctrl Mean              -0.383891
expl/env_infos/reward_ctrl Std                0.0864558
expl/env_infos/reward_ctrl Max               -0.111289
expl/env_infos/reward_ctrl Min               -0.579125
eval/num steps total                          2.45e+06
eval/num paths total                       2450
eval/path length Mean                      1000
eval/path length Std                          0
eval/path length Max                       1000
eval/path length Min                       1000
eval/Rewards Mean                             6.49771
eval/Rewards Std                              1.29582
eval/Rewards Max                              8.91615
eval/Rewards Min                             -0.845056
eval/Returns Mean                          6497.71
eval/Returns Std                             45.3632
eval/Returns Max                           6554.73
eval/Returns Min                           6421.45
eval/Actions Mean                             0.0917219
eval/Actions Std                              0.817987
eval/Actions Max                              0.996622
eval/Actions Min                             -0.997029
eval/Num Paths                                5
eval/Average Returns                       6497.71
eval/env_infos/final/reward_run Mean          7.17643
eval/env_infos/final/reward_run Std           0.834381
eval/env_infos/final/reward_run Max           8.38104
eval/env_infos/final/reward_run Min           6.10682
eval/env_infos/initial/reward_run Mean       -0.160733
eval/env_infos/initial/reward_run Std         0.166562
eval/env_infos/initial/reward_run Max         0.141824
eval/env_infos/initial/reward_run Min        -0.319447
eval/env_infos/reward_run Mean                6.90422
eval/env_infos/reward_run Std                 1.2971
eval/env_infos/reward_run Max                 9.34978
eval/env_infos/reward_run Min                -0.407272
eval/env_infos/final/reward_ctrl Mean        -0.357864
eval/env_infos/final/reward_ctrl Std          0.119023
eval/env_infos/final/reward_ctrl Max         -0.185435
eval/env_infos/final/reward_ctrl Min         -0.491372
eval/env_infos/initial/reward_ctrl Mean      -0.179119
eval/env_infos/initial/reward_ctrl Std        0.0457897
eval/env_infos/initial/reward_ctrl Max       -0.101303
eval/env_infos/initial/reward_ctrl Min       -0.238251
eval/env_infos/reward_ctrl Mean              -0.406509
eval/env_infos/reward_ctrl Std                0.083491
eval/env_infos/reward_ctrl Max               -0.0357413
eval/env_infos/reward_ctrl Min               -0.577587
time/data storing (s)                         0.00451714
time/evaluation sampling (s)                  1.99118
time/exploration sampling (s)                 0.51577
time/logging (s)                              0.0143815
time/sac training (s)                         7.48862
time/saving (s)                               0.00376223
time/training (s)                             3.4463e-05
time/epoch (s)                               10.0183
time/total (s)                             5145.44
Epoch                                       489
---------------------------------------  ---------------
